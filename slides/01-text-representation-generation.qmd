---
title: "LLMs: Text representation, training, and text generation"
author: "Andrew Ellis"
date: last-modified
date-format: "DD MMMM, YYYY"
bibliography: ../bibliography.bib
nocite: |
  @broschinskiGrafikenErklaertFunktioniert2023
format: 
    revealjs:
        # theme: moon
        theme: default
        title-slide-attributes:
          data-background-image: ../assets/background-purple.png
          # data-background-size: contain
          data-background-opacity: "1"
        # logo: ../assets/robot.png
        footer: <a href="../index.html">back to website ‚§¥Ô∏è</a>
        navigation-mode: vertical
        progress: true
        scrollable: true
        slide-number: true
        show-slide-number: all
        controls-layout: bottom-right
        controls-tutorial: true
        preview-links: auto
        chalkboard: true
        from: markdown+emoji
        code-fold: true
        code-summary: "Show code"
        code-tools: true
        menu: 
          sticky: true
          keyboard: true
          autoOpen: true
          width: normal
          numbers: true
          markers: true
# slide-level: 3
# number-sections: true
---

```{r}
#| warning: false
#| message: false
library(knitr)
```


# Contents {background-color="#b48ead"}

1. What is natural language processing?
2. How do LLMs represent text?
3. How are LLMs trained?
4. What is ChatGPT?
5. Wie wurde ChatGPT trainiert?
6. How do LLMs generate text?
7. Wie "denkt" ChatGPT?
8. Zuk√ºnftige Verwendungen von LLMs

<!-- ::: footer
<a href="https://virtuelleakademie.github.io/gpt-nano">üè† KI/GPT in der Hochschule</a>
::: -->



# Was ist k√ºnstliche Intelligenz? {background-color="#b48ead"}

::: {.absolute top="0" left="100%"}
::: {.sectionhead}
1 [2 3 4 5 6 7 8]{style="opacity:0.25"}
:::
:::

## What is natural language processing (NLP)?

- NLP is a subfield of [artificial intelligence (AI)]((https://www.derbund.ch/so-funktioniert-kuenstliche-intelligenz-599276436215)).
- NLP is concerned with the interactions between computers and human (natural) languages.
  
### Brief timeline

- 1950: Alan Turing proposed the Turing test to assess machine intelligence through language conversation.
- 1954: IBM introduced the first machine translation system, translating Russian to English using rules.
- 1960s-1970s: Rule-based systems like SHRDLU and ELIZA used human-crafted rules for language interaction.
- 1980s-1990s: Statistical methods employed probabilities and text data, using models like Hidden Markov Models and n-grams.
- 2000s-present: NLP shifted to neural network methods with deep learning, employing recurrent neural networks for complex language tasks.
- Transformers (first published in 2017) are the current state-of-the-art for NLP, and are the basis for large language models (LLMs), such as GPT-3.5, GPT-4, ChatGPT, Llama 2, and others.
- LLMs are models with billions of parameters, trained on massive amounts of text data. Training consists of predicting the next word in a sequence of words. 



## Long-range dependencies

:::{.callout-note}
## Complicated sentence
"The boy who was throwing stones at the birds, despite being warned by his parents not to harm any creatures, was chased by the angry flock."
:::

Who was chased?

- This type of long-range dependency is difficult for traditional NLP methods to handle.
- The verb phrase (`the boy was chased`) is separated from the subject by a long distance - you can't just look at the previous few words to answer the question.
- Transformers have a special feature that lets them easily connect words that are far apart in a sentence; `was chased` is linked directly to `The boy` without distraction by the words in between.



## Key areas in NLP

:::{.callout-note appearance="minimal"}                                  
`Sentiment Analysis`:             Identifying emotions and opinions in text.    
`Machine Translation`:            Automatically translating between languages.  
`Question Answering`:             Providing direct answers to user questions.   
`Text Summarization`:             Generating concise summaries from long text.  
`Speech Recognition`:             Converting spoken words to text.              
`Speech Synthesis`:               Creating spoken words from text.              
`Natural Language Generation`:    Generating human-like text.               
`Natural Language Understanding`: Extracting meaning from text.          
`Dialogue Systems`:               Conversing with humans using natural language.
:::

- Before LLMs, specialized models were trained for each task.
- LLMs are general-purpose models that can perform a wide variety of tasks.
  
## Example: sentiment analysis (text classification)
The task of classifying text as positive, negative, or neutral.

- `I love this movie!` ‚Üí positive üòä
- `This movie is ok.` ‚Üí neutral üòê 
- `This movie is terrible!` ‚Üí negative üò†




 


## Machine Learning primer

- Earlier, rule-based systems had to be programmed.
- Machine learning (ML) models learn implicitly, i.e. without rules being programmed in.


- Important terms:
  - __training data:__ Models are fed with data, and parameters of the model are adjusted so that the model is as "good" as possible.
  - __supervised learning:__ Categories known, e.g. classify images of animals.
  - __unsupervised learning:__ Categories are unknown, e.g. discover unknown patterns.
  - Unbekannte Muster entdecken.
  - __reinforcement learning:__ The goal is given, and the model learns through feedback (reward) how the goal can be achieved.

> We have to learn the bitter lesson that building in how we think we think does not work in the long run. We should stop trying to find simple ways to think about space, objects, multiple agents, or symmetries... instead we should build in only the meta-methods that can find and capture this arbitrary complexity. We want AI agents that can discover like we can, not which contain what we have discovered [@suttonBitterLesson2019].


## Supervised learning

```{r}
knitr::include_graphics("../assets/images/cats-dogs.png")
```

__Classifiy pictures of cats and dogs:__ The goal of a model could be to discover which features distinguish cats from dogs.





## Reinforcement learning

:::: {.columns}

::: {.column width="50%"}
```{r}
knitr::include_graphics("../assets/images/cartpole.gif")
```
:::

::: {.column width="50%"}

```{r}
knitr::include_graphics("../assets/images/RL-agent.png")
```
:::
::::






# What is ChatGPT? {background-color="#b48ead"}

::: {.absolute top="0" left="100%"}
::: {.sectionhead}
[1]{style="opacity:0.25"} 2 [3 4 5 6 7 8]{style="opacity:0.25"}
:::
:::






## ChatGPT

ChatGPT is a particular kind of LLM and consists of two models:

__Base model:__ GPT-3.5 oder GPT-4 (generative pre-trained transformer). This model is trained "simply" to predict the next word in a sequence of words. A base model produces text, but not human-like conversations.

:::{.callout-note}
## Example
Give the input `Once upon a time there was a`, the model will predict which word is likely to follow.
:::

__Assistant model:__ This model is trained using reinforcement learning from human feedback to have human-like conversations.

:::{.callout-note}
## Example
üë©‚Äçüíº: `Tell me a story!`

üí¨: `Once upon a time there was a ....`
:::


## Text generation

- LLMs produce text by predicting the next word, one word at a time: 
- This is known as "auto-regressive next toke prediction" (we'll discover what tokens are in the next section).

- The model predicts which token is likely to follow, given a sequence of tokens (words, punctuation, emojis, etc.). 
- Key idea: this simple procedure is followed over and over again, with <mark style="background: #FFF3A3A6;">each new token being added to the sequence of tokens</mark> that the model uses to predict the next token.
$$ P(w_{w+1} | w_1, w_2, ..., w_t) $$

- The sequence of words is called the <mark style="background: #FFF3A3A6;">context</mark>; the text generated by the model is dependent on the context.
- The output of the model is a probability distribution over all possible tokens. The model then chooses one token from this distribution.


## Text generation examples

```{r}
knitr::include_graphics("../assets/images/autoregressive.png")
```

- The new context is used to generate the next token, etc. 
- <mark style="background: #FFF3A3A6;">Every token is given an equal amount time (computation per token is constant)</mark>. The model has no concept of more or less important tokens. This is crucial for understanding how LLMs work.



## Tokenization
So far we have been talking about words, but LLMs operate with tokens. These are sub-words, and make working with text much easier for the model. A rule of thumb is that one token generally corresponds to ~4 characters of English text. This translates to roughly $\frac{3}{4}$ of a word (so 100 tokens is about 75 words).

```{r}
knitr::include_graphics("../assets/images/tokenization.png")
```

Feel free to try out the [OpenAI tokenizer](https://platform.openai.com/tokenizer). 

## Embeddings
- The next step is to represent tokens as vectors. 
- This is called "embedding" the tokens. The vectors are high-dimensional, and the **distance** between vectors measures the similarity between tokens.

:::: {.columns}
::: {.column width="50%"}

```{r}
knitr::include_graphics("../assets/images/embedding.png")
```
:::
::: {.column width="50%"}
- In this 2-dimensional representation, concepts that are "related" lie close together.

:::

::::

You can read more about embeddings [in this tutorial](../pages/text-representation.qmd).



# Wie wurde ChatGPT trainiert? {background-color="#b48ead"}

::: {.absolute top="0" left="100%"}
::: {.sectionhead}
[1 2]{style="opacity:0.25"} 3 [4 5 6 7 8]{style="opacity:0.25"}
:::
:::

## Zusammenfassung

ChatGPT wurde in mehreren Schritten trainiert:

1) Daten aus dem Internet werden gesammelt.
2) Pre-training: LLM wird auf diesen Daten trainiert, das n√§chste Wort vorherzusagen.
3) Reinforcement Learning from Human Feedback: Assistant wird trainiert, menschliche Konversationen zu f√ºhren.

## Daten

```{r}
knitr::include_graphics("../assets/images/karpathy-training-data.png")
```

## Methoden

```{r}
knitr::include_graphics("../assets/images/karpathy-training-pipeline-1.png")
```

::: {.notes}
We trained this model using Reinforcement Learning from Human Feedback (RLHF), using the same methods as InstructGPT, but with slight differences in the data collection setup. We trained an initial model using supervised fine-tuning: human AI trainers provided conversations in which they played both sides‚Äîthe user and an AI assistant. We gave the trainers access to model-written suggestions to help them compose their responses. We mixed this new dialogue dataset with the InstructGPT dataset, which we transformed into a dialogue format.

To create a reward model for reinforcement learning, we needed to collect comparison data, which consisted of two or more model responses ranked by quality. To collect this data, we took conversations that AI trainers had with the chatbot. We randomly selected a model-written message, sampled several alternative completions, and had AI trainers rank them. Using these reward models, we can fine-tune the model using Proximal Policy Optimization. We performed several iterations of this process.
:::

## Pre-training

```{r}
knitr::include_graphics("../assets/images/karpathy-pretraining-1.png")
```

## Pre-training

```{r}  
knitr::include_graphics("../assets/images/karpathy-training-process.png")
```



## Reinforcement Learning from Human Feedback (RLHF)

Benutzt  Feedback vom Menschen um "schlechte" Outputs zu minimieren.


```{r}
#| fig-cap: "Quelle: [openai.com/blog/chatgpt](https://openai.com/blog/chatgpt)"
knitr::include_graphics("../assets/images/RLHF.png")
```

# How do LLMs generate text? {background-color="#b48ead"}

::: {.absolute top="0" left="100%"}
::: {.sectionhead}
[1 2 3 4]{style="opacity:0.25"} 5 [6 7 8]{style="opacity:0.25"}
:::
:::

 


# Wie "denkt" ChatGPT? {background-color="#b48ead"}

::: {.absolute top="0" left="100%"}
::: {.sectionhead}
[1 2 3 4]{style="opacity:0.25"} 5 [6 7 8]{style="opacity:0.25"}
:::
:::


## Prompt

- Der urspr√ºngliche Kontext wird __Prompt__ (Eingabetext) genannt.
- Dieser ist entscheidend f√ºr die Qualit√§t der Antwort.

:::{.callout-note}
## Prompt Beispiel

"Was ist 89322/1313?"

vs. 

"Was ist 89322/1313? Arbeite Schritt f√ºr Schritt."
:::


## Prompt

```{r}
include_graphics("../assets/images/karpathy-thought-mutliple-attempts.png")
```

## Role-Playing Simulator

> We can think of an LLM as a non-deterministic simulator capable of role-playing an infinity of characters, or, to put it another way, capable of stochastically generating an infinity of simulacra. 

Quelle: @shanahanRolePlayLargeLanguage2023

- Bei jeder Interaktion mit ChatGPT wird ein Dialog neu simuliert.


## Role-Playing Simulator

![](../assets/images/simulator.png){width=800}


## Role-Playing Simulator

- Ein LLM ist keine Entit√§t mit Handlungsabsichten, sondern ein Simulator von m√∂glichen Konversationen.
- ChatGPT hat kein Konzept von Wahrheit, sondern generiert Antworten, die plausibel sind.
- Somit kann ChatGPT weder die Wahrheit sagen noch l√ºgen - diese Konzepte sind f√ºr ein LLM vorerst irrelevant.
  
## Was kann ChatGPT? 

```{r}
include_graphics("../assets/images/chain-of-thought.png")
```

```{r}
include_graphics("../assets/images/karpathy-chain-of-thought.png")
```

Weitere Beispiele: @bubeckSparksArtificialGeneral2023


::: {.notes}
Sehr viel, wenn richtig geprompted
:::


## Denkt ChatGPT?



![](../assets/images/karpathy-human-vs-LLM-2.png)

![](../assets/images/karpathy-human-vs-LLM-1.png)

## System 1 vs System 2

- [Thinking Fast and Slow](https://en.wikipedia.org/wiki/Thinking,_Fast_and_Slow)
- System 1: schnell, instinktiv, automatisch

- System 2: langsam, deliberativ, anstrengend

```{r}
include_graphics("../assets/images/system-1-vs-system-2.png")
```



## Prompt Engineering

- Qualit√§t der Antwort h√§ngt sehr von der Qualit√§t des Prompts ab.
- 2 M√∂glichkeiten, um die Qualit√§t der Antworten zu verbessern:

  - __Incrementelle Prompts:__ Schritt f√ºr Schritt durch die Konversation f√ºhren (dialogisches Prompting).
  - __Mega-Prompts:__ Alle Informationen auf einmal geben.

- Am besten selber ausprobieren.


## Mega-Prompt

1. Rolle: Wer oder was wird simuliert?
2. Aufgabe: Was ist zu tun?
3. Arbeitschritte: Was ist in welcher Reihenfolge zu tun?
4. Kontext, Einschr√§nkungen
5. Ziel: Was soll am Ende herauskommen?
6. Format: Wie soll das Ergebnis aussehen?

:::{.callout-note}
## Beispiel Hochschullehre: Feedback
"I want you to act as a harsh critic. Criticize what I will write to you and show me where my argumentation is lacking. Start by asking me what text I want to have feedback on. Then ask me questions about my context to create the best feedback possible. If you feel you have all the context necessary, think step by step when creating your feedback" (Lenk-Ostendorf & Folgmann 2023)
:::


:::{.callout-tip}
## Weitere Beispiele

- OpenAI Discord Server [discord.com/invite/openai](discord.com/invite/openai)
- [Prompting Guide](https://www.promptingguide.ai/)

:::






# Zuk√ºnftige Verwendungen von LLMs {background-color="#b48ead"}

::: {.absolute top="0" left="100%"}
::: {.sectionhead}
[1 2 3 4 5]{style="opacity:0.25"} 6 [7 8]{style="opacity:0.25"}
:::
:::

## Plug-ins

![](../assets/images/karpathy-tools-plugins.png)


## Retrieval-augmented LLMs

![](../assets/images/karpathy-retrieval-augmented.png)


## Retrieval-augmented LLMs

Beispiel: üëâüèº [Assistent der Virtuellen Akademie](https://virtuelleakademie.github.io/gpt-nano/pages/assistant.html) 

```{=html}
<iframe
src="https://www.chatbase.co/chatbot-iframe/RDbFWW85cxcCd9PEwV-uy"
width="100%"
height="700"
frameborder="0"
></iframe>
```

# References {background-color="#2e3440"}

::: {#refs}
:::

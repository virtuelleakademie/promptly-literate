{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: 'LLMs: Text representation, training, and text generation'\n",
        "author: Andrew Ellis\n",
        "date: last-modified\n",
        "date-format: 'DD MMMM, YYYY'\n",
        "bibliography: ../bibliography.bib\n",
        "nocite: |\n",
        "  @broschinskiGrafikenErklaertFunktioniert2023\n",
        "format:\n",
        "  revealjs:\n",
        "    theme: default\n",
        "    title-slide-attributes:\n",
        "      data-background-image: ../assets/background-purple.png\n",
        "      data-background-opacity: '1'\n",
        "    footer: <a href=\"../index.html\">back to website ‚§¥Ô∏è</a>\n",
        "    navigation-mode: vertical\n",
        "    progress: true\n",
        "    scrollable: true\n",
        "    slide-number: true\n",
        "    show-slide-number: all\n",
        "    controls-layout: bottom-right\n",
        "    controls-tutorial: true\n",
        "    preview-links: auto\n",
        "    chalkboard: true\n",
        "    from: markdown+emoji\n",
        "    code-fold: true\n",
        "    code-summary: Show code\n",
        "    code-tools: true\n",
        "    menu:\n",
        "      sticky: true\n",
        "      keyboard: true\n",
        "      autoOpen: true\n",
        "      width: normal\n",
        "      numbers: true\n",
        "      markers: true\n",
        "execute:\n",
        "  cache: false\n",
        "  keep-ipynb: true\n",
        "code-annotations: select\n",
        "---"
      ],
      "id": "49121bed"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```{r}\n",
        "#| warning: false\n",
        "#| message: false\n",
        "library(knitr)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "# Contents {background-color=\"#b48ead\"}\n",
        "\n",
        "1. What is natural language processing?\n",
        "2. How do LLMs represent text?\n",
        "3. How are LLMs trained?\n",
        "4. What is ChatGPT?\n",
        "5. Wie wurde ChatGPT trainiert?\n",
        "6. How do LLMs generate text?\n",
        "7. Wie \"denkt\" ChatGPT?\n",
        "8. Zuk√ºnftige Verwendungen von LLMs\n",
        "\n",
        "<!-- ::: footer\n",
        "<a href=\"https://virtuelleakademie.github.io/gpt-nano\">üè† KI/GPT in der Hochschule</a>\n",
        "::: -->\n",
        "\n",
        "\n",
        "\n",
        "# Was ist k√ºnstliche Intelligenz? {background-color=\"#b48ead\"}\n",
        "\n",
        "::: {.absolute top=\"0\" left=\"100%\"}\n",
        "::: {.sectionhead}\n",
        "1 [2 3 4 5 6 7 8]{style=\"opacity:0.25\"}\n",
        ":::\n",
        ":::\n",
        "\n",
        "## What is natural language processing (NLP)?\n",
        "\n",
        "- NLP is a subfield of [artificial intelligence (AI)]((https://www.derbund.ch/so-funktioniert-kuenstliche-intelligenz-599276436215)).\n",
        "- NLP is concerned with the interactions between computers and human (natural) languages.\n",
        "  \n",
        "### Brief timeline\n",
        "\n",
        "- 1950: Alan Turing proposed the Turing test to assess machine intelligence through language conversation.\n",
        "- 1954: IBM introduced the first machine translation system, translating Russian to English using rules.\n",
        "- 1960s-1970s: Rule-based systems like SHRDLU and ELIZA used human-crafted rules for language interaction.\n",
        "- 1980s-1990s: Statistical methods employed probabilities and text data, using models like Hidden Markov Models and n-grams.\n",
        "- 2000s-present: NLP shifted to neural network methods with deep learning, employing recurrent neural networks for complex language tasks.\n",
        "- Transformers (first published in 2017) are the current state-of-the-art for NLP, and are the basis for large language models (LLMs), such as GPT-3.5, GPT-4, ChatGPT, Llama 2, and others.\n",
        "\n",
        "\n",
        "## Long-range dependencies\n",
        "\n",
        "> \"The boy who was throwing stones at the birds, despite being warned by his parents not to harm any creatures, was chased by the angry flock.\"\n"
      ],
      "id": "de835ede"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"The boy who was throwing stones at the birds, despite being warned by his parents not to harm any creatures, was chased by the angry flock.\")\n",
        "displacy.serve(doc, style=\"dep\", auto_select_port=True\n",
        ")"
      ],
      "id": "d7d9f94d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key areas in NLP\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"50%\"}\n",
        "![](../assets/images/nlp-tasks.png){width=800}\n",
        ":::\n",
        "::: {.column width=\"50%\"}\n",
        "Up to the invention of transformer\n",
        ":::\n",
        "\n",
        "::::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "::: {.notes}\n",
        "Speaker notes go here.\n",
        ":::\n",
        "\n",
        "\n",
        "## Machine Learning\n",
        "\n",
        "- Regelbasierte Systeme m√ºssen programmiert werden.\n",
        "- ML Modelle lernen implizit, d.h. ohne Regeln einprogrammiert zu bekommen.\n",
        "\n",
        "\n",
        "- Wichtige Begriffe:\n",
        "  - __Trainingsdaten:__ Modelle werden mit Daten gef√ºttert, und Parameter des Modells werden so eingestellt, dass das Modell m√∂glichst \"gut\" ist.\n",
        "  - __Supervised learning:__ Aufgabe ist bekannt, z.B. Bilder - klassifizieren.\n",
        "  - __Unsupervised learning:__ Unbekannte Muster entdecken.\n",
        "  - __Reinforcement learning:__ Ziel ist vorgegeben, Modell lernt durch Feedback (Belohnung) wie Ziel erreicht werden kann.\n",
        "\n",
        "> We have to learn the bitter lesson that building in how we think we think does not work in the long run. We should stop trying to find simple ways to think about space, objects, multiple agents, or symmetries... instead we should build in only the meta-methods that can find and capture this arbitrary complexity. We want AI agents that can discover like we can, not which contain what we have discovered [@suttonBitterLesson2019].\n",
        "\n",
        "\n",
        "## Supervised learning\n",
        "\n",
        "\n",
        "```{r}\n",
        "knitr::include_graphics(\"../assets/images/cats-dogs.png\")\n",
        "```\n",
        "\n",
        "__Bilder von Hunden und Katzen klassifizeren:__ Was sind die Merkmale, die Hunde von Katzen unterscheiden?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Reinforcement learning\n",
        "\n",
        ":::: {.columns}\n",
        "\n",
        "::: {.column width=\"50%\"}\n",
        "\n",
        "```{r}\n",
        "knitr::include_graphics(\"../assets/images/cartpole.gif\")\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "::: {.column width=\"50%\"}\n",
        "\n",
        "\n",
        "```{r}\n",
        "knitr::include_graphics(\"../assets/images/RL-agent.png\")\n",
        "```\n",
        "\n",
        ":::\n",
        "::::\n",
        "\n",
        " \n",
        "::: aside\n",
        "Beispiel f√ºr RL Model: [AlphaGo](https://www.deepmind.com/research/highlighted-research/alphago) ist das erste Computerprogramm, das einen professionellen (menschlichen) [Go](https://de.wikipedia.org/wiki/Go_(Spiel))-Spieler besiegt hat.\n",
        ":::\n",
        "\n",
        "::: {.notes}\n",
        "- Ein \"Agent\" lernt durch Feedback (Belohnung) wie ein Ziel erreicht werden kann.\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Was ist ChatGPT? {background-color=\"#b48ead\"}\n",
        "\n",
        "::: {.absolute top=\"0\" left=\"100%\"}\n",
        "::: {.sectionhead}\n",
        "[1]{style=\"opacity:0.25\"} 2 [3 4 5 6 7 8]{style=\"opacity:0.25\"}\n",
        ":::\n",
        ":::\n",
        "\n",
        "\n",
        "## Natural Language Processing \n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"50%\"}\n",
        "\n",
        "- Speech recognition\n",
        "- Text-to-speech synthesis\n",
        "- Machine translation\n",
        "- Information extraction\n",
        "- Information retrieval\n",
        "- Question answering\n",
        "\n",
        ":::\n",
        "\n",
        "::: {.column width=\"50%\"}\n",
        "- Sentiment analysis\n",
        "  - üòä I love this movie!\n",
        "  - üòê This movie is ok.\n",
        "  - üò† This movie is terrible!\n",
        "  \n",
        ":::\n",
        "\n",
        "::::\n",
        "\n",
        "\n",
        "\n",
        "## Tokenization\n",
        "\n",
        "\n",
        "```{r}\n",
        "#| fig-cap: \"Quelle: [State of ChatGPT](https://build.microsoft.com/en-US/sessions/db3f4859-cd30-4445-a0cd-553c3304f8e2?source=sessions)\"\n",
        "knitr::include_graphics(\"../assets/images/karpathy-tokenization.png\")\n",
        "```\n",
        "\n",
        "\n",
        "## Embeddings\n",
        "- Numerische Tokens werden in einem hochdimensionalen Vektorraum abgebildet.\n",
        "- Distanz zwischen Vektoren misst √Ñhnlichkeit zwischen Tokens.\n",
        "\n",
        "\n",
        "```{r}\n",
        "#| fig-cap: \"Quelle: @wolframWhatChatGPTDoing2023\"\n",
        "knitr::include_graphics(\"../assets/images/wolfram-embeddings.png\")\n",
        "```\n",
        "\n",
        "```{r}\n",
        "#| fig-cap: \"Quelle: [So funktioniert ChatGPT](https://www.golem.de/news/kuenstliche-intelligenz-so-funktioniert-chatgpt-2302-171644.html)\"\n",
        "knitr::include_graphics(\"../assets/images/3_Wortgruppen_im_sem_Raum.png\")\n",
        "```\n",
        "\n",
        "\n",
        "## ChatGPT\n",
        "\n",
        "Besteht aus 2 Modellen:\n",
        "\n",
        "\n",
        "- __Large language model (LLM):__ GPT-3.5 oder GPT-4 (generative pre-trained transformer): das eigentliche Sprachmodell\n",
        "\n",
        "- __Assistant:__ Ein f√ºr Dialoge spezialisiertes Modell\n",
        "\n",
        "\n",
        "## LLM\n",
        "\n",
        "Aufgabe eines LLMs: \"auto-regressive next word prediction\" (eigentlich \"token prediction\"):\n",
        "\n",
        "$$ P(w_{w+1} | w_1, w_2, ..., w_t) $$\n",
        "\n",
        "- Das n√§chste Wort wird vorhergesagt, basierend auf den vorherigen Worten. \n",
        "- Diese vorherigen W√∂rter werden als \"context\" bezeichnet.\n",
        "\n",
        "\n",
        "```{r}\n",
        "knitr::include_graphics(\"../assets/images/word-probs.png\")\n",
        "knitr::include_graphics(\"../assets/images/gpt-2-autoregression-2.gif\")\n",
        "```\n",
        "\n",
        "\n",
        "## Assistant\n",
        "\n",
        "- LLM produziert Text, aber nicht menschliche Konversationen.\n",
        "- Weiteres Training ist erforderlich, damit das Modell lernt, wie ein Mensch \"Konversationen\" zu f√ºhren.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Wie wurde ChatGPT trainiert? {background-color=\"#b48ead\"}\n",
        "\n",
        "::: {.absolute top=\"0\" left=\"100%\"}\n",
        "::: {.sectionhead}\n",
        "[1 2]{style=\"opacity:0.25\"} 3 [4 5 6 7 8]{style=\"opacity:0.25\"}\n",
        ":::\n",
        ":::\n",
        "\n",
        "## Zusammenfassung\n",
        "\n",
        "ChatGPT wurde in mehreren Schritten trainiert:\n",
        "\n",
        "1) Daten aus dem Internet werden gesammelt.\n",
        "2) Pre-training: LLM wird auf diesen Daten trainiert, das n√§chste Wort vorherzusagen.\n",
        "3) Reinforcement Learning from Human Feedback: Assistant wird trainiert, menschliche Konversationen zu f√ºhren.\n",
        "\n",
        "## Daten\n",
        "\n",
        "\n",
        "```{r}\n",
        "knitr::include_graphics(\"../assets/images/karpathy-training-data.png\")\n",
        "```\n",
        "\n",
        "\n",
        "## Methoden\n",
        "\n",
        "\n",
        "```{r}\n",
        "knitr::include_graphics(\"../assets/images/karpathy-training-pipeline-1.png\")\n",
        "```\n",
        "\n",
        "\n",
        "::: {.notes}\n",
        "We trained this model using Reinforcement Learning from Human Feedback (RLHF), using the same methods as InstructGPT, but with slight differences in the data collection setup. We trained an initial model using supervised fine-tuning: human AI trainers provided conversations in which they played both sides‚Äîthe user and an AI assistant. We gave the trainers access to model-written suggestions to help them compose their responses. We mixed this new dialogue dataset with the InstructGPT dataset, which we transformed into a dialogue format.\n",
        "\n",
        "To create a reward model for reinforcement learning, we needed to collect comparison data, which consisted of two or more model responses ranked by quality. To collect this data, we took conversations that AI trainers had with the chatbot. We randomly selected a model-written message, sampled several alternative completions, and had AI trainers rank them. Using these reward models, we can fine-tune the model using Proximal Policy Optimization. We performed several iterations of this process.\n",
        ":::\n",
        "\n",
        "## Pre-training\n",
        "\n",
        "\n",
        "```{r}\n",
        "knitr::include_graphics(\"../assets/images/karpathy-pretraining-1.png\")\n",
        "```\n",
        "\n",
        "\n",
        "## Pre-training\n",
        "\n",
        "\n",
        "```{r}  \n",
        "knitr::include_graphics(\"../assets/images/karpathy-training-process.png\")\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Reinforcement Learning from Human Feedback (RLHF)\n",
        "\n",
        "Benutzt  Feedback vom Menschen um \"schlechte\" Outputs zu minimieren.\n",
        "\n",
        "\n",
        "\n",
        "```{r}\n",
        "#| fig-cap: \"Quelle: [openai.com/blog/chatgpt](https://openai.com/blog/chatgpt)\"\n",
        "knitr::include_graphics(\"../assets/images/RLHF.png\")\n",
        "```\n",
        "\n",
        "\n",
        "# How do LLMs generate text? {background-color=\"#b48ead\"}\n",
        "\n",
        "::: {.absolute top=\"0\" left=\"100%\"}\n",
        "::: {.sectionhead}\n",
        "[1 2 3 4]{style=\"opacity:0.25\"} 5 [6 7 8]{style=\"opacity:0.25\"}\n",
        ":::\n",
        ":::\n",
        "\n",
        " \n",
        "## Wie generiert ChatGPT Text?\n",
        "<!-- TODO: https://docs.cohere.com/docs/temperature -->\n",
        "- LLM: Gegeben einer Input-Sequenz (Kontext) von Tokens (W√∂rter, Teile von W√∂rtern, Satzzeichen, Emojis, etc.), was sind die wahrscheinlichsten n√§chsten Tokens?\n",
        "- Auto-regressiv: Ein Token wird generiert, wird dem Kontext hinzugef√ºgt.\n",
        "  \n",
        "![](../assets/images/autoregressive.png){width=600}\n",
        "<!-- ```{r}\n",
        "include_graphics(\"../assets/images/autoregressive.png\")\n",
        "``` -->\n",
        "\n",
        "- Der neue Kontext wird verwendet, um das n√§chste Token zu generieren, etc.\n",
        "- __Wichtig:__ Jedes Token erh√§lt gleich viel Zeit. Es gibt keine Tokens, die mehr oder weniger wichtig sind (Computation per Token ist konstant).\n",
        "- Weil jedes Token gleich gewichtet wird, kann es an jeder Stelle im Output zu \"ung√ºnstigen\" Pfaden f√ºhren.\n",
        "\n",
        "\n",
        "# Wie \"denkt\" ChatGPT? {background-color=\"#b48ead\"}\n",
        "\n",
        "::: {.absolute top=\"0\" left=\"100%\"}\n",
        "::: {.sectionhead}\n",
        "[1 2 3 4]{style=\"opacity:0.25\"} 5 [6 7 8]{style=\"opacity:0.25\"}\n",
        ":::\n",
        ":::\n",
        "\n",
        "\n",
        "## Prompt\n",
        "\n",
        "- Der urspr√ºngliche Kontext wird __Prompt__ (Eingabetext) genannt.\n",
        "- Dieser ist entscheidend f√ºr die Qualit√§t der Antwort.\n",
        "\n",
        ":::{.callout-note}\n",
        "## Prompt Beispiel\n",
        "\n",
        "\"Was ist 89322/1313?\"\n",
        "\n",
        "vs. \n",
        "\n",
        "\"Was ist 89322/1313? Arbeite Schritt f√ºr Schritt.\"\n",
        ":::\n",
        "\n",
        "\n",
        "## Prompt\n",
        "\n",
        "```{r}\n",
        "include_graphics(\"../assets/images/karpathy-thought-mutliple-attempts.png\")\n",
        "```\n",
        "\n",
        "## Role-Playing Simulator\n",
        "\n",
        "> We can think of an LLM as a non-deterministic simulator capable of role-playing an infinity of characters, or, to put it another way, capable of stochastically generating an infinity of simulacra. \n",
        "\n",
        "Quelle: @shanahanRolePlayLargeLanguage2023\n",
        "\n",
        "- Bei jeder Interaktion mit ChatGPT wird ein Dialog neu simuliert.\n",
        "\n",
        "\n",
        "## Role-Playing Simulator\n",
        "\n",
        "![](../assets/images/simulator.png){width=800}\n",
        "\n",
        "\n",
        "## Role-Playing Simulator\n",
        "\n",
        "- Ein LLM ist keine Entit√§t mit Handlungsabsichten, sondern ein Simulator von m√∂glichen Konversationen.\n",
        "- ChatGPT hat kein Konzept von Wahrheit, sondern generiert Antworten, die plausibel sind.\n",
        "- Somit kann ChatGPT weder die Wahrheit sagen noch l√ºgen - diese Konzepte sind f√ºr ein LLM vorerst irrelevant.\n",
        "  \n",
        "## Was kann ChatGPT? \n",
        "\n",
        "\n",
        "```{r}\n",
        "include_graphics(\"../assets/images/chain-of-thought.png\")\n",
        "```\n",
        "\n",
        "```{r}\n",
        "include_graphics(\"../assets/images/karpathy-chain-of-thought.png\")\n",
        "```\n",
        "\n",
        "\n",
        "Weitere Beispiele: @bubeckSparksArtificialGeneral2023\n",
        "\n",
        "\n",
        "::: {.notes}\n",
        "Sehr viel, wenn richtig geprompted\n",
        ":::\n",
        "\n",
        "\n",
        "## Denkt ChatGPT?\n",
        "\n",
        "\n",
        "\n",
        "![](../assets/images/karpathy-human-vs-LLM-2.png)\n",
        "\n",
        "![](../assets/images/karpathy-human-vs-LLM-1.png)\n",
        "\n",
        "## System 1 vs System 2\n",
        "\n",
        "- [Thinking Fast and Slow](https://en.wikipedia.org/wiki/Thinking,_Fast_and_Slow)\n",
        "- System 1: schnell, instinktiv, automatisch\n",
        "\n",
        "- System 2: langsam, deliberativ, anstrengend\n",
        "\n",
        "\n",
        "```{r}\n",
        "include_graphics(\"../assets/images/system-1-vs-system-2.png\")\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Prompt Engineering\n",
        "\n",
        "- Qualit√§t der Antwort h√§ngt sehr von der Qualit√§t des Prompts ab.\n",
        "- 2 M√∂glichkeiten, um die Qualit√§t der Antworten zu verbessern:\n",
        "\n",
        "  - __Incrementelle Prompts:__ Schritt f√ºr Schritt durch die Konversation f√ºhren (dialogisches Prompting).\n",
        "  - __Mega-Prompts:__ Alle Informationen auf einmal geben.\n",
        "\n",
        "- Am besten selber ausprobieren.\n",
        "\n",
        "\n",
        "## Mega-Prompt\n",
        "\n",
        "1. Rolle: Wer oder was wird simuliert?\n",
        "2. Aufgabe: Was ist zu tun?\n",
        "3. Arbeitschritte: Was ist in welcher Reihenfolge zu tun?\n",
        "4. Kontext, Einschr√§nkungen\n",
        "5. Ziel: Was soll am Ende herauskommen?\n",
        "6. Format: Wie soll das Ergebnis aussehen?\n",
        "\n",
        ":::{.callout-note}\n",
        "## Beispiel Hochschullehre: Feedback\n",
        "\"I want you to act as a harsh critic. Criticize what I will write to you and show me where my argumentation is lacking. Start by asking me what text I want to have feedback on. Then ask me questions about my context to create the best feedback possible. If you feel you have all the context necessary, think step by step when creating your feedback\" (Lenk-Ostendorf & Folgmann 2023)\n",
        ":::\n",
        "\n",
        "\n",
        ":::{.callout-tip}\n",
        "## Weitere Beispiele\n",
        "\n",
        "- OpenAI Discord Server [discord.com/invite/openai](discord.com/invite/openai)\n",
        "- [Prompting Guide](https://www.promptingguide.ai/)\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Zuk√ºnftige Verwendungen von LLMs {background-color=\"#b48ead\"}\n",
        "\n",
        "::: {.absolute top=\"0\" left=\"100%\"}\n",
        "::: {.sectionhead}\n",
        "[1 2 3 4 5]{style=\"opacity:0.25\"} 6 [7 8]{style=\"opacity:0.25\"}\n",
        ":::\n",
        ":::\n",
        "\n",
        "## Plug-ins\n",
        "\n",
        "![](../assets/images/karpathy-tools-plugins.png)\n",
        "\n",
        "\n",
        "## Retrieval-augmented LLMs\n",
        "\n",
        "![](../assets/images/karpathy-retrieval-augmented.png)\n",
        "\n",
        "\n",
        "## Retrieval-augmented LLMs\n",
        "\n",
        "Beispiel: üëâüèº [Assistent der Virtuellen Akademie](https://virtuelleakademie.github.io/gpt-nano/pages/assistant.html) \n",
        "\n",
        "\n",
        "```{=html}\n",
        "<iframe\n",
        "src=\"https://www.chatbase.co/chatbot-iframe/RDbFWW85cxcCd9PEwV-uy\"\n",
        "width=\"100%\"\n",
        "height=\"700\"\n",
        "frameborder=\"0\"\n",
        "></iframe>\n",
        "```\n",
        "\n",
        "\n",
        "# References {background-color=\"#2e3440\"}\n",
        "\n",
        "::: {#refs}\n",
        ":::"
      ],
      "id": "44086459"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
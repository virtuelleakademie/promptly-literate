---
title: "Prompt Labor: Basics"
author: "Andrew Ellis"
date: last-modified
date-format: "DD MMMM, YYYY"
bibliography: ../bibliography.bib
nocite: |
  @shanahanTalkingLargeLanguage2023, @shanahanRolePlayLargeLanguage2023, @weiEmergentAbilitiesLarge2022b
format: 
    revealjs:
        theme: [simple, ../styles/custom-reveal.scss]
      #   theme: default
        title-slide-attributes:
          # data-background-image: ../assets/background-purple.png
          # data-background-size: contain
          data-background-opacity: "1"
        # logo: ../assets/robot.png
        footer: <a href="../index.html">back to website {{< bi box-arrow-up-left >}} </a>
        # navigation-mode: vertical
        progress: true
        scrollable: false
        slide-number: true
        slide-level: 2
        show-slide-number: all
        controls-layout: bottom-right
        controls-tutorial: true
        preview-links: auto
        chalkboard: true
        from: markdown+emoji
        code-fold: true
        code-summary: "Show code"
        code-tools: true
        menu: 
          sticky: true
          keyboard: true
          autoOpen: true
          width: normal
          numbers: true
          markers: true
        callout-appearance: simple
        callout-icon: false
revealjs-plugins:
  - attribution
---

## Assistant menagerie {.smaller}

| Assistant                                  | Provider         | Privacy | LLM                                                                                                                                                                                                                                                                                                     | Capabilities                              | Pricing model    |
| ------------------------------------------ | ---------------- | ------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------- | ---------- |
| [ChatGPT](https://chat.openai.com/)        | OpenAI           | üëéüèº  | GPT-3.5, GPT-4                                                                                                                                                                                                                                                                                          | Web search, DALLE, GPTs, multimodal input | üí∂        |
| [Copilot](https://copilot.microsoft.com/)  | Microsoft        | üëçüèº  | GPT-3.5, GPT-4                                                                                                                                                                                                                                                                                          | Web search, DALLE, multimodal input       | üÜì for BFH employees and students|
| [Gemini](https://gemini.google.com/app)    | Google           | üëéüèº  | Gemini Ultra, Gemini Pro, and Gemini Nano                                                                                                                                                                                                                                                               | Web search, multimodal input              | üí∂        |
| [HuggingChat](https://huggingface.co/chat) | ü§ó Hugging Face | üëçüèº  | Various open models, e.g. [CodeLlama](https://about.fb.com/news/2023/08/code-llama-ai-for-coding/), [Llama 2](https://huggingface.co/meta-llama/Llama-2-70b-chat-hf),  [Mistral](https://mistral.ai/news/announcing-mistral-7b/), [Gemma](https://blog.google/technology/developers/gemma-open-models/) |                                           | üÜì         |



## {{< bi bookmark-star >}} Orientierungshilfe f√ºr Lehrpersonen der BFH


:::{.callout-note}

- **Haltung der BFH**: Technologien, die den Lernprozess unterst√ºtzen und praxisrelevant sind, sollen in die Lehre einbezogen werden.

- **Einsatz von KI in der Lehre**: Die Mehrheit der Studierenden wird KI-Tools nutzen. Studierende sollen lernen, Technologien kompetent einzusetzen und kritisch zu hinterfragen.

:::

<br> <br>

[{{< bi link >}} Knowledge Base der Virtuellen Akademie](https://virtuelleakademie.ch/knowledge-base/ki-basierte-schreibtools-in-der-lehre-chatgpt-im-fokus/)

[{{< bi link >}} PDF](https://bernerfachhochschule.sharepoint.com/sites/mybfh-BFH-News-de/SitePages/Nachrichten-K%C3%BCnstliche-Intelligenz-(KI)-in-der-Lehre.aspx)

## What is Artifical Intelligence?

:::: {.columns}
::: {.column width="50%"}
![](../assets/images/what-is-AI.svg){width=100%}
:::

::: {.column width="50%"}
A branch of computer science that aims to create machines that can perform tasks that typically require human intelligence.
:::
::::


<!-- ## What is Generative AI?

Generative AI uses machine learning to create complex statistical models of how data are generated.

- Generative AI models learn from existing data.
- Produce new data that resembles the original data: images, music, text, etc. -->


## What is a Large Language Model?

:::: {.columns}
::: {.column width="50%"}
![](../assets/images/LLM.svg){width=100%}
:::

::: {.column width="50%"}
An LLM is a type of generative AI model that is trained to predict the next word following the input (prompt).
:::
::::







## Training
:::: {.columns}

::: {.column width="30%"}
![](../assets/images/LLM-Bookshelf.png){width=100%}
:::

::: {.column width="70%"}
![](../assets/images/training-steps.svg){width=100%}
:::
::::



## How to train a language model

<br> <br>

<!-- ![](../assets/images/llm-training.excalidraw.svg){width=80%} -->

![](../assets/images/pretraining.png){width=100%}

<!-- ## Generalization
- The ability to apply knowledge to new, unseen data/situations
- E.g. a language model should learn to generate rhymes
- Extracts knowledge from text: linguistic, factual, commonsense, etc. -->

## How to train a language model

- An LLM learns to predict the next word in a sequence, given the previous words:
 $$ P(word | context) $$
- Think of as "fancy autocomplete" (but very very powerful and sopisticated)


![](../assets/images/ppl_full.gif){width=100%}






## Text Generation
:::: {.columns}

::: {.column width="50%"}
:::

::: {.column width="50%"}
![](../assets/images/textgeneration.png){width=100%}
:::
::::


## How does an LLM generate text?

![](../assets/images/text-generation-output.excalidraw.svg){width=100%}


## Sampling

![](../assets/images/sampling.excalidraw.svg){width=100%}


## Auto-regressive generation

Text is generated __one word at a time__ (actually tokens, not words).

:::: {.columns}
::: {.column width="50%"}

1. Model predicts which word is likely to follow, given a sequence of tokens (words, punctuation, emojis, etc.). 
2. A word is sampled from the predicted distribution.
3. The new word is added to the sequence of words (context) that is used to predict the next word.

$$ P(w_{w+1} | w_1, w_2, ..., w_t) $$

:::
::: {.column width="50%"}


{{< bi arrow-right-circle-fill >}} Generated text is dependent on the context.

{{< bi arrow-right-circle-fill >}} Every token is given an equal amount time (computation per token is constant). 
:::
::::

## Auto-regressive generation

![](../assets/images/autoregressive.png){width=100%}



<!-- ## Tokenization
LLMs operate with tokens, not words. These are sub-words, and make working with text much easier for the model. A rule of thumb is that one token generally corresponds to ~4 characters of English text. This translates to roughly $\frac{3}{4}$ of a word (so 100 tokens is about 75 words).

```{r}
knitr::include_graphics("../assets/images/tokenization.png")
```

Feel free to try out the [OpenAI tokenizer](https://platform.openai.com/tokenizer). 

## Embeddings
- The next step is to represent tokens as vectors. 
- This is called "embedding" the tokens. The vectors are high-dimensional, and the **distance** between vectors measures the similarity between tokens.

:::: {.columns}
::: {.column width="50%"}

```{r}
knitr::include_graphics("../assets/images/embedding.png")
```
:::
::: {.column width="50%"}
In this 2-dimensional representation, concepts that are "related" lie close together. Read about embeddings [in this tutorial](../pages/text-representation.qmd).

:::

:::: -->




## Foundation models

A foundation model, or large language model (LLM):

- is a type of machine learning model that is trained to predict the next word following the input (prompt).
- is trained "simply" to predict the next word following a sequence of words. 
- does not necessarily produce human-like conversations.

:::{.callout-note}
{{< bi person >}}: 
What is the capital of France?

{{< bi robot >}}: 
What is the capital of Germany? 
What is the capital of Italy? .
..
:::


## Training data

![](../assets/images/karpathy-training-data.png){width=100%}

::: attribution
Figure courtesy of [Andrej Karpathy](https://karpathy.ai/)
:::

## Training process

![](../assets/images/karpathy-training-process.png){width=100%}

::: attribution
Figure courtesy of [Andrej Karpathy](https://karpathy.ai/)
:::

<!-- ## Emergent abilities

LLMs are thought to show emergent abilities - abilities not explicitly taught. Instead, they emerge _as a result of text prediction_.

Abilities include:

- performing arithmetic, answering questions, summarizing text, translating, etc.
- zero-shot learning: LLMs can perform tasks without being trained on them.
- few-shot learning: LLMs can perform tasks with few examples.

## Emergent abilities

What kind of knowledge does an LLM have to have to be able to write a continuation of the following text?^[Continue this conversation with [ChatGPT](https://chat.openai.com/share/2661773e-3bf6-4be3-b251-41f639bfc2a1).]

::::{.columns}
::: {.column width="50%"}

:::{.callout-note}
{{< bi person >}}: 
How many holes does a straw have?

{{< bi robot >}}: 
A straw has one hole. It's a cylindrical tunnel that runs through the entire length, creating a single continuous space from one end to the other.

{{< bi person >}}: 
What about a tunnel?

{{< bi robot >}}:
Similar to a straw, a tunnel can also be considered to have one hole. It's an elongated pathway carved through an obstruction, allowing passage from one side to the other, thus creating a single continuous space or hole through the material.
:::
:::

::: {.column width="50%"}
![](../assets/images/straw-tunnel.png){width=100%}
:::
:::: -->



## Assistant models

Trained (fine-tuned) to have conversations: turn-taking, question answering, not being [rude/sexist/racist].

:::: {.columns}

::: {.column width="34%"}
![](../assets/images/Chat.png){width=100%}


<!-- ![](../assets/images/RLHF.svg){width=100%} -->
:::

::: {.column width="66%"}

- Foundation model has learned to predict all kinds of text, including both desirable and undesirable text.
- Fine-tuning is a process narrow down the space of all possible output to only desirable, human-like dialogue.

:::
::::


<!-- ## Instruction fine-tuning

![](../assets/images/finetuning.png){width=100%} -->

## Reinforcement learning from human feedback (RLHF)

![](../assets/images/RLHF.svg){width=100%}


Model is **aligned** with the values of the fine-tuner.




## How do Chatbots work?

![](../assets/images/chatbotexcalidraw.svg){width=100%}

- Designed to present the illusion of a conversation between two entities.

## How do chatbots actually work?

:::: {.columns}

::: {.column width="50%"}
![](../assets/images/chatbot.svg){width=100%}
:::

::: {.column width="50%"}
![](../assets/images/chatbot-2.svg){width=100%}


:::
::::



## An assistant model is a role-play simulator

:::: {.columns}

::: {.column width="34%"}
![](../assets/images/live-action-role-play.png){width=100%}

:::

::: {.column width="64%"}

- An assistant is trained to respond to user prompts in a human-like way.
- Simulates **possible** human conversations.
- Has no intentions. It is not an entity with its own goals.
- Does not have a "personality" or "character" in the traditional sense. It can be thought of as a role-playing simulator.
- Has no concept of "truth" or "lying". The model is not trying to deceive the user, it is simply trying to respond in a human-like way.
  
:::
::::



<!-- ## Stochastic generation

![](../assets/images/simulator.png){width=100%} -->



## Hallucination

:::: {.columns}

::: {.column width="34%"}
![](../assets/images/confabulating.png){width=100%}

:::

::: {.column width="64%"}
- LLMs can generate text that is not true, or not based on any real-world knowledge.
- This is known as "hallucination". A better term would be "confabulation".

:::
::::

## Can an LLM tell the truth?

- How would you know if an LLM is able to give you factual information?
- How would you test this?

:::{.callout-note}
{{< bi person >}}: 
What is the capital of Uzbekistan?

{{< bi robot >}}: 
Tashkent
:::

 

It looks like the LLM knows the capital of Uzbekistan^[What it is actually doing is responding with the most likely sequence following the question.].


## Knowledge base

:::: {.columns}

::: {.column width="66%"}

- A knowledge base is a collection of facts about the world.
  - You can `ask` (retrieve) and `tell` (store) facts.
- An LLM is not a knowledge base.
  - LLMs generate text based on on how probable the next word is given the context, not based on stored facts.
:::

::: {.column width="34%"}

![](../assets/images/KnowledgeBase.png){width=100%}

:::
::::


## What are LLMs good at?

- Fixing grammar, bad writing, etc.
- Rephrasing
- Analyze texts
- Write computer code
- Answer questions about a knowledge base
- Translate languages
- Creating structured output
- Factual output only with external documents or web search




## Prompting

![](../assets/images/magic.svg){width=66%}


## What is a prompt?

- Remember: the goal of an LLM is complete text.
- A prompt is a piece of text (instruction) that is given to a language model to complete. 

:::{.callout-note}
PROMPT {{< bi person >}}: Write a haiku about a workshop on large language models.

ASSISTANT {{< bi robot >}}: 
    Whispers of circuits,  
    Knowledge blooms in bytes and bits,  
    Model learns and fits.
:::



- The response is generated as continuation of the prompt. 

::: {.notes}

More technical definition: The output is generated by auto-regressively sampling from the probability distribution over the vocabulary, conditioned on the prompt.
:::


## Unlocking knowledge
:::: {.columns}
::: {.column width="50%"}
![](../assets/images/unlock.svg)

<!-- ::: {.incremental} -->
- LLMs learn to do things they were not explicitly trained to do. 
<!-- - They can solve logic puzzles and perform complex multistep reasoning.  -->
- Often, these capabilities need to be "unlocked" by the right prompt.
<!-- ::: -->

:::

::: {.column width="50%"}
- But what is the right prompt?
- The answer is very similar to what you would tell a human dialogue partner/assistant.
- You can increase the probability of getting the desired output by asking good questions or giving enough information.
:::
::::


## Basics of prompting

OpenAI give a set of strategies for using their models effectively: 

{{< bi link >}} [Prompt engineering](https://platform.openai.com/docs/guides/prompt-engineering) 


These include:

- writing clear instructions
- providing reference texts
- splitting tasks into subtasks
- giving the LLM 'time to think'
- using external tools


## Writing clear instructions


:::: {.columns}
::: {.column width="50%"}
- Think of an LLM as a role-playing conversation simulator.
- Instructions should be clear and unambiguous.
- Indicate which role the model (persona) should adopt.

:::

::: {.column width="50%"}
:::{.callout-note}
- [Include details in your query to get more relevant answers](https://platform.openai.com/docs/guides/prompt-engineering/tactic-include-details-in-your-query-to-get-more-relevant-answers)
- [Ask the model to adopt a persona](https://platform.openai.com/docs/guides/prompt-engineering/tactic-ask-the-model-to-adopt-a-persona)
- [Use delimiters to clearly indicate distinct parts of the input](https://platform.openai.com/docs/guides/prompt-engineering/tactic-use-delimiters-to-clearly-indicate-distinct-parts-of-the-input)
- [Specify the steps required to complete a task](https://platform.openai.com/docs/guides/prompt-engineering/tactic-specify-the-steps-required-to-complete-a-task)
- [Provide examples](https://platform.openai.com/docs/guides/prompt-engineering/tactic-provide-examples)
- [Specify the desired length of the output](https://platform.openai.com/docs/guides/prompt-engineering/tactic-specify-the-desired-length-of-the-output)

:::
:::
::::


## Adopt a persona (role)

:::{.callout-note}
{{< bi person >}}: You are an expert on learning techniques. Explain the concept of 'flipped classroom' in one paragraph.
:::

:::{.callout-note}
{{< bi person >}}: You are an expert financial derivatives. Explain the concept of 'flipped classroom' in one paragraph.
:::



## Provide reference texts


- Provide a model with trusted and relevant information. 
- Then instruct the model to use the provided information to compose its answer.


[{{< bi link >}} Instruct the model to answer using a reference text](https://platform.openai.com/docs/guides/prompt-engineering/tactic-instruct-the-model-to-answer-using-a-reference-text)

:::aside
This leads to **retrieval-augmented generation (RAG)**. First create a database of documents, then retrieve the most relevant documents, based on a user's query. These are then included in the prompt to the model. The model is instructed to use the information in the documents to compose its answer.
:::

<!-- ## Provide reference texts {.scrollable}

:::{.callout-note}
{{< fa person >}}: You will be provided with a document delimited by triple quotes and a question. Your task is to provide a simplified answer to the question using only the provided document and to cite the passage(s) of the document used to answer the question. If the document does not contain the information needed to answer this question then simply write: "Insufficient information." If an answer to the question is provided, it must be annotated with a citation. Use the following format for to cite relevant passages ({"citation": ‚Ä¶}). Cite only the relevant passage(s) of the document, not the entire document.

"""
The flipped classroom intentionally shifts instruction to a learner-centered model, in which students are often initially introduced to new topics outside of school, freeing up classroom time for the exploration of topics in greater depth, creating meaningful learning opportunities. With a flipped classroom, 'content delivery' may take a variety of forms, often featuring video lessons prepared by the teacher or third parties, although online collaborative discussions, digital research, and text readings may alternatively be used. The ideal length for a video lesson is widely cited as eight to twelve minutes.
"""

**Question**: What is flipped classroom?

::: -->



## Giving GPT 'time to think'

- LLMs generate text one word at a time--the model spends the same amount of computation on each word.
- Giving the model more context gives it more steps to "think". 
- This increases the chances that the model will give a good answer.
- This technique is known as **chain-of-thought** prompting, and can often be induced by simply instructing the model to `think step-by-step` or `Take a deep breath and work on this problem step-by-step` [@yangLargeLanguageModels2023].

<!-- ![Chain-of-thought example](../assets/images/chain-of-thought.png) -->



## Chain-of-thought prompting

- Chain-of-thought prompting encourages the LLM to "explain" its intermediate reasoning steps.
- Enables complex reasoning and problem solving.

Instead of this:

:::{.callout-note}
{{< bi person >}}: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1. Yes or no?
:::

Do this:

:::{.callout-note}
{{< bi person >}}: Is this statement correct? The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1. 

Reason through the problem step-by-step. Start by identifying the odd numbers. Next, add them up. Finally, determine if the sum is even or odd. Write down your reasoning steps in a numbered list.

:::

:::{.notes}
Why does this work?
:::

## Zero-shot chain-of-thought prompting

:::{.callout-note}

{{< fa person >}}: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1. <mark style="background: #BBFABBA6;">Take a deep breath and think step-by-step.</mark>


:::


:::aside
When using GPT-4, ChatGPT and Copilot do this automatically.
:::


## Use Markdown formatting

- Use [Markdown](https://www.markdownguide.org/) to format your prompts.
- Instruct the LLM to format its output using Markdown.

:::{.callout-note}
{{< bi person >}}: Improve this haiku:

Words weave through the air,  
Minds meld with machine's deep thought,  
Knowledge blooms anew.  

It is about about a workshop on large language models. I'm not happy with it.

Show me all the text. Format your edits as `**TEXT**` and show the deleted text as `~~TEXT~~`. Keep you review short (max 100 words).
:::

Try this example in [ChatGPT](https://chat.openai.com/share/c2230c3c-04cc-4aa5-b802-9646496aadbd).

## Advanced prompting techniques

For more advanced prompting techniques, see these websites:

- {{< bi link >}} [Learn prompting](https://learnprompting.org/docs/intro)
- {{< bi link >}} [Prompting guide](https://www.promptingguide.ai/)
- {{< bi link >}} [OpenAI cookbook](https://cookbook.openai.com/)

and explore this [activity](../pages/activity-cas-hochschuldidaktik.qmd).


# Advanced LLM techniques

![](../assets/images/finetuning-vs-prompting.png){width=50%}

## Retrieval-augmented generation (RAG)

![](../assets/images/rag-volvo.png){width=100%}

:::{.attribution}

Figure courtesy of [Pinecone](https://www.pinecone.io/learn/retrieval-augmented-generation/)
:::

## Web search

- Similar to retrieval-augmented generation, but with web search.
- LLMs can be instructed to use web search to find information.
- Copilot does this automatically - ChatGPT (paid version only) can be instructed to do this.
  


## External tools

- LLMs can be instructed to use external tools to complete tasks.
- For example, an LLM can be instructed to use a calculator to perform arithmetic.
- OpenAI calls this approach [function calling](https://platform.openai.com/docs/guides/function-calling/function-calling).

## Multi-agent conversations

:::: {.columns}
::: {.column width="50%"}

![](../assets/images/multi-agent.excalidraw.svg){width=100%}
:::

::: {.column width="50%"}

<!-- - {{< bi arrow-right-circle >}} DEMO: haiku writing team -->
:::
::::

## Local models

- Download and run models, such as e.g. Llama 2 or Code Llama, locally.
- [Ollama](https://ollama.com/)
- [LM Studio](https://lmstudio.ai/)

Hardware requirements:

- Apple Silicon Mac (M1/M2/M3) / Windows / Linux
- 16GB+ of RAM is recommended
- NVIDIA/AMD GPUs supported




# References {background-color="#D8DEE9"}

::: {#refs}
:::

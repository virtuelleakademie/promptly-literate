---
title: "Informationsanlass zu KI/ChatGPT"
author: "Andrew Ellis"
date: last-modified
date-format: "DD MMMM, YYYY"
bibliography: ../bibliography.bib
nocite: |
  @broschinskiGrafikenErklaertFunktioniert2023
format: 
    revealjs:
        # theme: moon
        theme: default
        title-slide-attributes:
          data-background-image: ../assets/background-yellow.png
          # data-background-size: contain
          data-background-opacity: "1"
        # logo: ../assets/robot.png
        footer: <a href="https://virtuelleakademie.github.io/gpt-nano">‚§¥Ô∏è KI/GPT in der Hochschule </a>
        navigation-mode: vertical
        progress: true
        scrollable: true
        slide-number: true
        show-slide-number: all
        controls-layout: bottom-right
        controls-tutorial: true
        preview-links: auto
        chalkboard: true
        from: markdown+emoji
        code-fold: true
        code-summary: "Show code"
        code-tools: true
        menu: 
          sticky: true
          keyboard: true
          autoOpen: true
          width: normal
          numbers: true
          markers: true

# slide-level: 3
# number-sections: true
---

```{r}
#| warning: false
#| message: false
library(knitr)
```


#  {background-color="#2e3440"}

:::: {.columns}
::: {.column width="50%"}

Here‚Äôs What Happens When Your Lawyer Uses ChatGPT

```{=html}
<iframe width="780" height="500" src="https://simonwillison.net/2023/May/27/lawyer-chatgpt/" title="ChatGPT: US lawyer admits using AI for case research"></iframe>
```
:::

::: {.column width="50%"}

The Best Prompts For ChatGPT: The ultimate list

```{=html}
<iframe width="780" height="500" src="https://www.writingbeginner.com/best-prompts-for-chatgpt/" title="Best prompts for ChatGPT"></iframe>
```
:::
::::

# Inhalt {background-color="#2e3440"}

1. Was ist k√ºnstliche Intelligenz?
2. Was ist ChatGPT?
3. Wie wurde ChatGPT trainiert?
4. Energieverbrauch, Bias, Ethik
5. Wie "denkt" ChatGPT?
6. Zuk√ºnftige Verwendungen von LLMs
7. Wissenschaftliches Arbeiten

<!-- ::: footer
<a href="https://virtuelleakademie.github.io/gpt-nano">üè† KI/GPT in der Hochschule</a>
::: -->



# Was ist k√ºnstliche Intelligenz? {background-color="#ebcb8b"}

::: {.absolute top="0" left="100%"}
::: {.sectionhead}
1 [2 3 4 5 6 7]{style="opacity:0.25"}
:::
:::

## Was ist K√ºnstliche Intelligenz?


```{r}
#| fig-cap: "Quelle: [derbund.ch/so-funktioniert-kuenstliche-intelligenz-599276436215](https://www.derbund.ch/so-funktioniert-kuenstliche-intelligenz-599276436215)"
include_graphics("../assets/images/was-ist-KI.png")
```


::: {.notes}
Speaker notes go here.
:::


## Machine Learning

- Regelbasierte Systeme m√ºssen programmiert werden.
- ML Modelle lernen implizit, d.h. ohne Regeln einprogrammiert zu bekommen.


- Wichtige Begriffe:
  - __Trainingsdaten:__ Modelle werden mit Daten gef√ºttert, und Parameter des Modells werden so eingestellt, dass das Modell m√∂glichst "gut" ist.
  - __Supervised learning:__ Aufgabe ist bekannt, z.B. Bilder - klassifizieren.
  - __Unsupervised learning:__ Unbekannte Muster entdecken.
  - __Reinforcement learning:__ Ziel ist vorgegeben, Modell lernt durch Feedback (Belohnung) wie Ziel erreicht werden kann.

> We have to learn the bitter lesson that building in how we think we think does not work in the long run. We should stop trying to find simple ways to think about space, objects, multiple agents, or symmetries... instead we should build in only the meta-methods that can find and capture this arbitrary complexity. We want AI agents that can discover like we can, not which contain what we have discovered [@suttonBitterLesson2019].


## Supervised learning

```{r}
knitr::include_graphics("../assets/images/cats-dogs.png")
```
__Bilder von Hunden und Katzen klassifizeren:__ Was sind die Merkmale, die Hunde von Katzen unterscheiden?




## Reinforcement learning

:::: {.columns}

::: {.column width="50%"}
```{r}
knitr::include_graphics("../assets/images/cartpole.gif")
```
:::

::: {.column width="50%"}

```{r}
knitr::include_graphics("../assets/images/RL-agent.png")
```
:::
::::

 
::: aside
Beispiel f√ºr RL Model: [AlphaGo](https://www.deepmind.com/research/highlighted-research/alphago) ist das erste Computerprogramm, das einen professionellen (menschlichen) [Go](https://de.wikipedia.org/wiki/Go_(Spiel))-Spieler besiegt hat.
:::

::: {.notes}
- Ein "Agent" lernt durch Feedback (Belohnung) wie ein Ziel erreicht werden kann.
:::






# Was ist ChatGPT? {background-color="#ebcb8b"}

::: {.absolute top="0" left="100%"}
::: {.sectionhead}
[1]{style="opacity:0.25"} 2 [3 4 5 6 7]{style="opacity:0.25"}
:::
:::

## Natural Language Processing 

:::: {.columns}
::: {.column width="50%"}

- Speech recognition
- Text-to-speech synthesis
- Machine translation
- Information extraction
- Information retrieval
- Question answering

:::

::: {.column width="50%"}
- Sentiment analysis
  - üòä I love this movie!
  - üòê This movie is ok.
  - üò† This movie is terrible!
  
:::

::::



## Tokenization

```{r}
#| fig-cap: "Quelle: [State of ChatGPT](https://build.microsoft.com/en-US/sessions/db3f4859-cd30-4445-a0cd-553c3304f8e2?source=sessions)"
knitr::include_graphics("../assets/images/karpathy-tokenization.png")
```

## Embeddings
- Numerische Tokens werden in einem hochdimensionalen Vektorraum abgebildet.
- Distanz zwischen Vektoren misst √Ñhnlichkeit zwischen Tokens.

```{r}
#| fig-cap: "Quelle: @wolframWhatChatGPTDoing2023"
knitr::include_graphics("../assets/images/wolfram-embeddings.png")
```

```{r}
#| fig-cap: "Quelle: [So funktioniert ChatGPT](https://www.golem.de/news/kuenstliche-intelligenz-so-funktioniert-chatgpt-2302-171644.html)"
knitr::include_graphics("../assets/images/3_Wortgruppen_im_sem_Raum.png")
```

## ChatGPT

Besteht aus 2 Modellen:


- __Large language model (LLM):__ GPT-3.5 oder GPT-4 (generative pre-trained transformer): das eigentliche Sprachmodell

- __Assistant:__ Ein f√ºr Dialoge spezialisiertes Modell


## LLM

Aufgabe eines LLMs: "auto-regressive next word prediction" (eigentlich "token prediction"):

$$ P(w_{w+1} | w_1, w_2, ..., w_t) $$

- Das n√§chste Wort wird vorhergesagt, basierend auf den vorherigen Worten. 
- Diese vorherigen W√∂rter werden als "context" bezeichnet.

```{r}
knitr::include_graphics("../assets/images/word-probs.png")
knitr::include_graphics("../assets/images/gpt-2-autoregression-2.gif")
```

## Assistant

- LLM produziert Text, aber nicht menschliche Konversationen.
- Weiteres Training ist erforderlich, damit das Modell lernt, wie ein Mensch "Konversationen" zu f√ºhren.





# Wie wurde ChatGPT trainiert? {background-color="#ebcb8b"}

::: {.absolute top="0" left="100%"}
::: {.sectionhead}
[1 2]{style="opacity:0.25"} 3 [4 5 6 7]{style="opacity:0.25"}
:::
:::


## Daten

```{r}
knitr::include_graphics("../assets/images/karpathy-training-data.png")
```

## Methoden

```{r}
knitr::include_graphics("../assets/images/karpathy-training-pipeline-1.png")
```

::: {.notes}
We trained this model using Reinforcement Learning from Human Feedback (RLHF), using the same methods as InstructGPT, but with slight differences in the data collection setup. We trained an initial model using supervised fine-tuning: human AI trainers provided conversations in which they played both sides‚Äîthe user and an AI assistant. We gave the trainers access to model-written suggestions to help them compose their responses. We mixed this new dialogue dataset with the InstructGPT dataset, which we transformed into a dialogue format.

To create a reward model for reinforcement learning, we needed to collect comparison data, which consisted of two or more model responses ranked by quality. To collect this data, we took conversations that AI trainers had with the chatbot. We randomly selected a model-written message, sampled several alternative completions, and had AI trainers rank them. Using these reward models, we can fine-tune the model using Proximal Policy Optimization. We performed several iterations of this process.
:::

## Pre-training

```{r}
knitr::include_graphics("../assets/images/karpathy-pretraining-1.png")
```

## Pre-training

```{r}  
knitr::include_graphics("../assets/images/karpathy-training-process.png")
```



## Reinforcement Learning from Human Feedback (RLHF)

Benutzt  Feedback vom Menschen um "schlechte" Outputs zu minimieren.


```{r}
#| fig-cap: "Quelle: [openai.com/blog/chatgpt](https://openai.com/blog/chatgpt)"
knitr::include_graphics("../assets/images/RLHF.png")
```


 

# Energieverbrauch, Bias, Ethik {background-color="#ebcb8b"}

::: {.absolute top="0" left="100%"}
::: {.sectionhead}
[1 2 3]{style="opacity:0.25"} 4 [5 6 7]{style="opacity:0.25"}
:::
:::

## Energieverbrauch

- __Training:__ "What we do know is that training ChatGPT used $1.287$ GWh, roughly equivalent to the consumption of 120 US homes for a year." Quelle: [Heating up: how much energy does AI use?](https://techhq.com/2023/03/data-center-energy-usage-chatgpt/)

- @pattersonCarbonEmissionsLarge2022 sch√§tzen die Trainingskosten auf 502 Tonnen $\text{CO}_2$ (RLHF w√ºrde etwas mehr kosten, ca. 1% der urspr√ºnglichen Kosten).

- __Benutzung:__ 7 Tonnen $\text{CO}_2$ pro Tag (Ende Februar). Quelle: [How much energy does ChatGPT use?](https://xcorr.net/2023/04/08/how-much-energy-does-chatgpt-use/)
  
- Der Energieverbrauch von ChatGPT ist equivalent zu 400-800 US Haushalten. Das ist betr√§chtlich, im Vergleich zu z.B. Kryptow√§hrungen eher gering.



## Bias

:::: {.columns}

::: {.column width="50%"}
```{=html}
<iframe width="780" height="500" src="https://www.societybyte.swiss/2022/12/22/hi-chatgpt-hast-du-vorurteile/" title="Vorurteile"></iframe>
```
:::

::: {.column width="50%"}

- Da LLMs von Texten lernen, die von Menschen geschrieben wurden, k√∂nnen sie auch Vorurteile lernen.

Quelle: [Hast du Vorurteile?](https://www.societybyte.swiss/2022/12/22/hi-chatgpt-hast-du-vorurteile/)
:::

::::

## Ethik

:::: {.columns}

::: {.column width="50%"}
```{=html}
<iframe width="780" height="500" src="https://www.societybyte.swiss/2023/06/07/traumatische-klickarbeit-die-menschen-hinter-chatgpt/" title="Traumatische Klickarbeit"></iframe>
```
:::

::: {.column width="50%"}
- Auf Grund der grossen Menge von Trainingsdaten, die f√ºr Sprachmodelle ben√∂tigt werden, ist Qualit√§tskontrolle schwierig.
- Diskriminierende oder beleidigende Aussagen werden von einem Chatbot generiert.
- Solche Antworten k√∂nnen als unerw√ºnscht markiert werden.
- Toxische Inhalte wie k√∂rperliche und sexuelle Gewalt, Suizide und Tierqu√§lerei, m√ºssen beim Trainieren aus den Antworten gefiltert werden. Dabei mussten angestellte Arbeitskr√§fte f√ºr weniger als 2 Dollar die Stunde teils schockierende Inhalte lesen. 

Quelle: [Traumatische Klickarbeit](https://www.societybyte.swiss/2023/06/07/traumatische-klickarbeit-die-menschen-hinter-chatgpt/)

:::

::::

## Use Cases

```{r}
include_graphics("../assets/images/karpathy-bias.png")
```



# Wie "denkt" ChatGPT? {background-color="#ebcb8b"}

::: {.absolute top="0" left="100%"}
::: {.sectionhead}
[1 2 3 4]{style="opacity:0.25"} 5 [6 7]{style="opacity:0.25"}
:::
:::

## Wie generiert ChatGPT Text?



- LLM: Gegeben eine Input-Sequenz von Tokens (W√∂rter, Teile von W√∂rtern, Satzzeichen, Emojis, etc.), was sind die wahrscheinlichsten n√§chsten Tokens?
- Auto-regressiv: Ein Token wird generiert, wird dem Kontext hinzugef√ºgt.
  
![](../assets/images/autoregressive.png){width=600}
<!-- ```{r}
include_graphics("../assets/images/autoregressive.png")
``` -->

- Der neue Kontext wird verwendet, um das n√§chste Token zu generieren, etc.
- __Wichtig:__ Jedes Token erh√§lt gleich viel Zeit. Es gibt keine Tokens, die mehr oder weniger wichtig sind (Computation per Token ist konstant).


## Prompt

- Der urspr√ºngliche Kontext wird __Prompt__ (Eingabetext) genannt.
- Dieser ist entscheidend f√ºr die Qualit√§t der Antwort.
- Weil jedes Token gleich gewichtet wird, kann es an jeder Stelle im Ouptut zu "ung√ºnstigen" Pfaden f√ºhren.


## Prompt

```{r}
include_graphics("../assets/images/karpathy-thought-mutliple-attempts.png")
```

## Role-Playing Simulator

> We can think of an LLM as a non-deterministic simulator capable of role-playing an infinity of characters, or, to put it another way, capable of stochastically generating an infinity of simulacra. 

Quelle: @shanahanRolePlayLargeLanguage2023

- Bei jeder Interaktion mit ChatGPT wird neu simuliert.


## Role-Playing Simulator

![](../assets/images/simulator.png){width=800}


## Role-Playing Simulator

- Ein LLM ist keine Entit√§t mit Handlungsabsichten, sondern ein Simulator von m√∂glichen Konversationen.
- ChatGPT hat kein Konzept von Wahrheit, sondern generiert Antworten, die plausibel sind.
- Somit kann ChatGPT weder die Wahrheit sagen noch l√ºgen - diese Konzepte sind f√ºr ein LLM vorerst irrelevant.
  
## Was kann ChatGPT? 

```{r}
include_graphics("../assets/images/chain-of-thought.png")
```

```{r}
include_graphics("../assets/images/karpathy-chain-of-thought.png")
```

Weitere Beispiele: @bubeckSparksArtificialGeneral2023


::: {.notes}
Sehr viel, wenn richtig geprompted
:::


## Denkt ChatGPT?



![](../assets/images/karpathy-human-vs-LLM-2.png)

![](../assets/images/karpathy-human-vs-LLM-1.png)

## System 1 vs System 2

- [Thinking Fast and Slow](https://en.wikipedia.org/wiki/Thinking,_Fast_and_Slow)
- System 1: schnell, instinktiv, automatisch

- System 2: langsam, deliberativ, anstrengend

```{r}
include_graphics("../assets/images/system-1-vs-system-2.png")
```



## Prompt Engineering

- Qualit√§t der Antwort h√§ngt sehr von der Qualit√§t des Prompts ab.
- 2 M√∂glichkeiten, um die Qualit√§t der Antworten zu verbessern:

  - Incrementelle Prompts: Schritt f√ºr Schritt durch die Konversation f√ºhren (dialogisches Prompting).
  - Mega-Prompts: Alle Informationen auf einmal geben.

- Am besten selber ausprobieren.


## Mega-Prompt

1. Rolle: Wer oder was wird simuliert?
2. Aufgabe: Was ist zu tun?
3. Arbeitschritte: Was ist in welcher Reihenfolge zu tun?
4. Kontext, Einschr√§nkungen
5. Ziel: Was soll am Ende herauskommen?
6. Format: Wie soll das Ergebnis aussehen?

:::{.callout-note}
## Beispiel Hochschullehre: Feedback
"I want you to act as a harsh critic. Criticize what I will write to you and show me where my argumentation is lacking. Start by ask- ing me what text I want to have feedback on. Then ask me questions about my context to create the best feedback possible. If you feel you have all the context necessary, think step by step when creating your feedback" (Lenk-Ostendorf & Folgmann 2023)
:::


:::{.callout-tip}
## Weitere Beispiele

- OpenAI Discord Server [discord.com/invite/openai](discord.com/invite/openai)
- [Prompting Guide](https://www.promptingguide.ai/)

:::






# Zuk√ºnftige Verwendungen von LLMs {background-color="#ebcb8b"}

::: {.absolute top="0" left="100%"}
::: {.sectionhead}
[1 2 3 4 5]{style="opacity:0.25"} 6 [7]{style="opacity:0.25"}
:::
:::

## Plug-ins

![](../assets/images/karpathy-tools-plugins.png)


## Retrieval-augmented LLMs

![](../assets/images/karpathy-retrieval-augmented.png)


## Retrieval-augmented LLMs

Beispiel: Assistant f√ºr KI in der Hochschullehre

```{=html}
<iframe
src="https://www.chatbase.co/chatbot-iframe/RDbFWW85cxcCd9PEwV-uy"
width="100%"
height="700"
frameborder="0"
></iframe>
```

# Wissenschaftliches Arbeiten {background-color="#ebcb8b"}

::: {.absolute top="0" left="100%"}
::: {.sectionhead}
[1 2 3 4 5 6]{style="opacity:0.25"} 7
:::
:::

## Zitieren

- Es existieren noch keine Richtlinien f√ºr das Zitieren von ChatGPT oder anderen KI-basierte Schreibtools.
- ChatGPT ist rein rechtlich keine zitierf√§hige Quelle und damit auch nicht zitierpflichtig [@fleckPruefungsrechtlicheFragenChatGPT2023].
  
:::{.callout-note}
## M√∂glicher Pauschalverweis
  
"Beim Verfassen der Arbeit habe ich das KI-gest√ºtzte Schreibwerkzeug ChatGPT zur Textoptimierung verwendet. W√∂rtlich aus dem Tool √ºbernommene Passagen wurden im Text als pers√∂nliche Kommunikation zitiert."
:::

## Plagiate und Detektion

- Texte von ChatGPT werden jedes Mal individuell erstellt. Es handelt sich nicht um Plagiate. 
- Die klassischen Tools zur Aufdeckung von Plagiaten wie z.B. _TurnItIn_ funktionieren hier nicht.


## Kompetenznachweise

- Siehe [KI-basierte Schreibtools in der Lehre ‚Äì ChatGPT im Fokus](https://virtuelleakademie.notion.site/KI-in-der-Lehre-af068030108844c4834ef00824fd8da6?p=f671067195a94f2d8239931c09ae92ec&pm=s)

## Rechtliche Aspekte

- ChatGPT kann keine Urheberschaft und keine Autorenschaft beanspruchen, da dies nur nat√ºrliche Personen k√∂nnen.
- Menschen k√∂nnen die Urheberschaft eines Textes beanspruchen, auch wenn sie auf Unterst√ºtzung durch ChatGPT zur√ºckgegriffen haben ‚Äì sofern sie eine wesentliche gestalterische Eigenleistung am Text erbracht haben.

Quelle: @saldenDidaktischeUndRechtliche2023 


## Datenschutz

- Anonyme Nutzung von ChatGPT ist mit pers√∂nlichen Konto nicht m√∂glich (√ºber Handynummer identifizierbar).
- Alle Eingaben und alle Antworten werden bei ChatGPT unverschl√ºsselt abgespeichert.
- Daten liegen auf amerikanischen Servern und sind damit f√ºr amerikanische Ermittlungsbeh√∂rden grunds√§tzlich zug√§nglich.


# References {background-color="#2e3440"}

::: {#refs}
:::

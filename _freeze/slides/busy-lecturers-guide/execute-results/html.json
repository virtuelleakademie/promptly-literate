{
  "hash": "15323131f88a4af1d98642b8e7e63ac5",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"The busy lecturer's guide to LLMs\"\nauthor: \"Andrew Ellis\"\ndate: last-modified\ndate-format: \"DD MMMM, YYYY\"\nbibliography: ../bibliography.bib\nnocite: |\n  @shanahanTalkingLargeLanguage2023, @shanahanRolePlayLargeLanguage2023, @weiEmergentAbilitiesLarge2022b\nformat: \n    revealjs:\n        theme: [simple, ../styles/custom-reveal.scss]\n      #   theme: default\n        title-slide-attributes:\n          # data-background-image: ../assets/background-purple.png\n          # data-background-size: contain\n          data-background-opacity: \"1\"\n        # logo: ../assets/robot.png\n        footer: <a href=\"../index.html\">back to website {{< bi box-arrow-up-left >}} </a>\n        navigation-mode: vertical\n        progress: true\n        scrollable: false\n        slide-number: true\n        show-slide-number: all\n        controls-layout: bottom-right\n        controls-tutorial: true\n        preview-links: auto\n        chalkboard: true\n        from: markdown+emoji\n        code-fold: true\n        code-summary: \"Show code\"\n        code-tools: true\n        menu: \n          sticky: true\n          keyboard: true\n          autoOpen: true\n          width: normal\n          numbers: true\n          markers: true\n        callout-appearance: simple\n        callout-icon: false\nrevealjs-plugins:\n  - attribution\n---\n\n\n\n# {{< bi house-door >}} Take-home messages\n\n- Explore LLMs firsthand to understand their strengths and weaknesses.\n- Combine domain knowledge with an understanding of how LLMs work, and effective prompting strategies.\n- Integrate LLMs into teaching to foster AI literacy among students.\n- Critically evaluate an LLM‚Äôs output. They are language models, not knowledge bases. \n- Keep a human in the loop.\n  \n\n\n# Assistant menagerie {.smaller}\n\n| Assistant                                  | Provider         | Privacy | LLM                                                                                                                                                                                                                                                                                                     | Capabilities                              | Pricing model    |\n| ------------------------------------------ | ---------------- | ------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------- | ---------- |\n| [ChatGPT](https://chat.openai.com/)        | OpenAI           | üëéüèº  | GPT-3.5, GPT-4                                                                                                                                                                                                                                                                                          | Web search, DALLE, GPTs, multimodal input | üí∂        |\n| [Copilot](https://copilot.microsoft.com/)  | Microsoft        | üëçüèº  | GPT-3.5, GPT-4                                                                                                                                                                                                                                                                                          | Web search, DALLE, multimodal input       | üÜì for BFH employees and students|\n| [Gemini](https://gemini.google.com/app)    | Google           | üëéüèº  | Gemini Ultra, Gemini Pro, and Gemini Nano                                                                                                                                                                                                                                                               | Web search, multimodal input              | üí∂        |\n| [HuggingChat](https://huggingface.co/chat) | ü§ó Hugging Face | üëçüèº  | Various open models, e.g. [CodeLlama](https://about.fb.com/news/2023/08/code-llama-ai-for-coding/), [Llama 2](https://huggingface.co/meta-llama/Llama-2-70b-chat-hf),  [Mistral](https://mistral.ai/news/announcing-mistral-7b/), [Gemma](https://blog.google/technology/developers/gemma-open-models/) |                                           | üÜì         |\n\n\n# Training\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n:::\n\n::: {.column width=\"50%\"}\n![](../assets/images/LLM-Bookshelf.png){width=100%}\n:::\n::::\n\n## How to train a language model\n\n<br> <br>\n\n![](../assets/images/llm-training.excalidraw.svg){width=80%}\n\n## Example\n![](../assets/images/pretraining.png){width=100%}\n\n## Generalization\n- The ability to apply knowledge to new, unseen data/situations\n- E.g. a language model should learn to generate rhymes\n- Extracts knowledge from text: linguistic, factual, commonsense, etc.\n\n## What is learned?\n::: {.incremental}\n- An LLM learns to predict the next word in a sequence, given the previous words:\n $$ P(word | context) $$\n- Think of as \"fancy autocomplete\" (but very very powerful and sopisticated)\n:::\n\n. . .\n\n![](../assets/images/ppl_full.gif){width=100%}\n\n\n\n\n\n\n# Text Generation\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n:::\n\n::: {.column width=\"50%\"}\n![](../assets/images/textgeneration.png){width=100%}\n:::\n::::\n\n\n## How does an LLM generate text?\n\n![](../assets/images/text-generation-output.excalidraw.svg){width=100%}\n\n\n## Sampling\n\n![](../assets/images/sampling.excalidraw.svg){width=100%}\n\n## Auto-regressive generation\n\n![](../assets/images/autoregressive.png){width=100%}\n\n## Auto-regressive generation\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n- Text is generated __one word at a time__ (actually tokens, not words).\n- Model predicts which token is likely to follow, given a sequence of tokens (words, punctuation, emojis, etc.). \n- Key idea: this simple procedure is followed over and over again, with <mark style=\"background: #EBCB8B;\">each new token being added to the sequence of tokens</mark> that the model uses to predict the next token.\n\n:::\n::: {.column width=\"50%\"}\n$$ P(w_{w+1} | w_1, w_2, ..., w_t) $$\n\n- Sequence of words is called the <mark style=\"background: #EBCB8B;\">context</mark>.\n\n{{< bi arrow-right-circle-fill >}} Generated text is dependent on the context.\n\n{{< bi arrow-right-circle-fill >}} Every token is given an equal amount time (computation per token is constant). \n:::\n::::\n\n\n\n## Tokenization\nLLMs operate with tokens, not words. These are sub-words, and make working with text much easier for the model. A rule of thumb is that one token generally corresponds to ~4 characters of English text. This translates to roughly $\\frac{3}{4}$ of a word (so 100 tokens is about 75 words).\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](../assets/images/tokenization.png){width=675}\n:::\n:::\n\n\nFeel free to try out the [OpenAI tokenizer](https://platform.openai.com/tokenizer). \n\n## Embeddings\n- The next step is to represent tokens as vectors. \n- This is called \"embedding\" the tokens. The vectors are high-dimensional, and the **distance** between vectors measures the similarity between tokens.\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](../assets/images/embedding.png){width=751}\n:::\n:::\n\n:::\n::: {.column width=\"50%\"}\nIn this 2-dimensional representation, concepts that are \"related\" lie close together. Read about embeddings [in this tutorial](../pages/text-representation.qmd).\n\n:::\n\n::::\n\n\n\n\n# Foundation models\n\nA foundation model, or large language model (LLM):\n\n- is a type of machine learning model that is trained to predict the next word following the input (prompt).\n- is trained \"simply\" to predict the next word following a sequence of words. \n- does not necessarily produce human-like conversations.\n\n:::{.callout-note}\n{{< bi person >}}: \nWhat is the capital of France?\n\n{{< bi robot >}}: \nWhat is the capital of Germany? \nWhat is the capital of Italy? .\n..\n:::\n\n\n## Training data\n\n![](../assets/images/karpathy-training-data.png){width=100%}\n\n::: attribution\nFigure courtesy of [Andrej Karpathy](https://karpathy.ai/)\n:::\n\n## Training process\n\n![](../assets/images/karpathy-training-process.png){width=100%}\n\n::: attribution\nFigure courtesy of [Andrej Karpathy](https://karpathy.ai/)\n:::\n\n## Emergent abilities\n\nLLMs are thought to show emergent abilities - abilities not explicitly taught. Instead, they emerge _as a result of text prediction_.\n\nAbilities include:\n\n- performing arithmetic, answering questions, summarizing text, translating, etc.\n- zero-shot learning: LLMs can perform tasks without being trained on them.\n- few-shot learning: LLMs can perform tasks with few examples.\n\n## Emergent abilities\n\nWhat kind of knowledge does an LLM have to have to be able to write a continuation of the following text?^[Continue this conversation with [ChatGPT](https://chat.openai.com/share/2661773e-3bf6-4be3-b251-41f639bfc2a1).]\n\n::::{.columns}\n::: {.column width=\"50%\"}\n\n:::{.callout-note}\n{{< bi person >}}: \nHow many holes does a straw have?\n\n{{< bi robot >}}: \nA straw has one hole. It's a cylindrical tunnel that runs through the entire length, creating a single continuous space from one end to the other.\n\n{{< bi person >}}: \nWhat about a tunnel?\n\n{{< bi robot >}}:\nSimilar to a straw, a tunnel can also be considered to have one hole. It's an elongated pathway carved through an obstruction, allowing passage from one side to the other, thus creating a single continuous space or hole through the material.\n:::\n:::\n\n::: {.column width=\"50%\"}\n![](../assets/images/straw-tunnel.png){width=100%}\n:::\n::::\n\n\n\n# Assistant models\n\n  \n:::: {.columns}\n\n::: {.column width=\"34%\"}\n![](../assets/images/Chat.png){width=100%}\n\n\n<!-- ![](../assets/images/RLHF.svg){width=100%} -->\n:::\n\n::: {.column width=\"66%\"}\n\n- Trained (fine-tuned) in two stages to have conversations: turn-taking, question answering, not being [rude/sexist/racist], etc.\n\n- Foundation model has learned to predict all kinds of text, including both desirable and undesirable text.\n- Fine-tuning is a process narrow down the space of all possible output to only desirable, human-like dialogue.\n- Model is **aligned** with the values of the fine-tuner.\n\n:::\n::::\n\n\n## Instruction fine-tuning\n\n![](../assets/images/finetuning.png){width=100%}\n\n## Reinforcement learning from human feedback (RLHF)\n\n![](../assets/images/RLHF.svg){width=100%}\n\n\n\n\n\n\n# How do Chatbots work?\n\n![](../assets/images/chatbotexcalidraw.svg){width=100%}\n\n- Designed to present the illusion of a conversation between two entities.\n\n## How do chatbots actually work?\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n![](../assets/images/chatbot.svg){width=100%}\n:::\n\n::: {.column width=\"50%\"}\n![](../assets/images/chatbot-2.svg){width=100%}\n\n\n:::\n::::\n\n\n\n## An LLM is a role-play simulator\n\n:::: {.columns}\n\n::: {.column width=\"34%\"}\n![](../assets/images/live-action-role-play.png){width=100%}\n\n:::\n\n::: {.column width=\"64%\"}\n\n:::{.callout-note}\nWe can think of an LLM as a non-deterministic simulator capable of role-playing an infinity of characters, or, to put it another way, capable of stochastically generating an infinity of simulacra [@shanahanRolePlayLargeLanguage2023]\n:::\n:::\n::::\n\n## An LLM is a role-play simulator\n\n- An assistant is trained to respond to user prompts in a human-like way.\n- A simulator of **possible** human conversation.\n- Has no intentions. It is not an entity with its own goals.\n- Does not have a \"personality\" or \"character\" in the traditional sense. It can be thought of as a role-playing simulator.\n- Has no concept of \"truth\" or \"lying\". The model is not trying to deceive the user, it is simply trying to respond in a human-like way.\n\n\n## Stochastic generation\n\n![](../assets/images/simulator.png){width=100%}\n\n\n\n# Hallucination\n\n:::: {.columns}\n\n::: {.column width=\"34%\"}\n![](../assets/images/confabulating.png){width=100%}\n\n:::\n\n::: {.column width=\"64%\"}\n- LLMs can generate text that is not true, or not based on any real-world knowledge.\n- This is known as \"hallucination\". A better term would be \"confabulation\".\n\n:::\n::::\n\n\n## Knowledge base\n\n:::: {.columns}\n\n::: {.column width=\"66%\"}\n\n- A knowledge base is a collection of facts about the world.\n- I can `ask` (retrieve) and `tell` (store) facts.\n:::\n\n::: {.column width=\"34%\"}\n\n![](../assets/images/KnowledgeBase.png){width=100%}\n\n:::\n::::\n\n## Can an LLM tell the truth?\n\n- How would you know if an LLM is able to give you factual information?\n- How would you test this?\n\n:::{.callout-note}\n{{< bi person >}}: \nWhat is the capital of Uzbekistan?\n\n{{< bi robot >}}: \nTashkent\n:::\n\n \n\nIt looks like the LLM knows the capital of Uzbekistan^[What it is actually doing is responding with the most likely sequence following the question.].\n\n## Confirmation bias\n\n- People tend to search for evidence consistent with their current beliefs.\n\n\n## Are LLMs knowledge bases?\n\n:::: {.columns}\n\n::: {.column width=\"34%\"}\n![](../assets/images/Pothole.png){width=100%}\n\n:::\n\n::: {.column width=\"64%\"}\n\n- I can ask but the response is not verifiable.\n- I can't tell, i.e. can't store new information (expensive/difficult to update with new knowledge).\n- LLM can't tell me where it got its information from.\n- LLMs are models of knowledge bases, but not knowledge bases themselves.\n- Produce ethically questionable results.\n\n:::\n::::\n\n\n\n# But can an LLM think?\n\n::: {.incremental}\n- LLMs generate text token-by-token.\n- They output a probability distribution over all tokens.\n- The \"magic\" happens here: the learned probability distribution.\n- LLMs do not plan ahead.\n- LLMs cannot go back and edit their output.\n- The output depends on the context.\n:::\n\n## How do humans think?\n\nE.g. physical reasoning\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n![@battagliaSimulationEnginePhysical2013](../assets/images/physics-intuition.png){width=100%}\n\n:::\n::: {.column width=\"50%\"}\n![@gerstenbergWhatWouldHave2022](../assets/images/causal-simulation.png){width=100%}\n:::\n::::\n\n\n\n\n\n# Prompting\n\n## Basic\n\n## Advanced\n\n\n# Advanced LLM techniques\n\n## Retrieval-augmented generation (RAG)\n\n## Web search\n\n## Multi-agent conversations\n\n## Local models\n\n\n# Are LLMs the future of AI?\n\nNo.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# What are LLMs good at?\n\n\n- Fixing grammar, bad writing, etc.\n- Rephrasing\n- Analyze texts\n- Write computer code\n- Answer questions about a knowledge base\n- Translate languages\n- Creating structured output\n\n\n# References {background-color=\"#D8DEE9\"}\n\n::: {#refs}\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
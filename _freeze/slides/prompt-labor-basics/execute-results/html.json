{
  "hash": "c4cc5ae639731b807930330d5c7d38b3",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Prompt Labor: Basics\"\nauthor: \"Andrew Ellis\"\ndate: last-modified\ndate-format: \"DD MMMM, YYYY\"\nbibliography: ../bibliography.bib\nnocite: |\n  @shanahanTalkingLargeLanguage2023, @shanahanRolePlayLargeLanguage2023, @weiEmergentAbilitiesLarge2022b\nformat: \n    revealjs:\n        theme: [simple, ../styles/custom-reveal.scss]\n      #   theme: default\n        title-slide-attributes:\n          # data-background-image: ../assets/background-purple.png\n          # data-background-size: contain\n          data-background-opacity: \"1\"\n        # logo: ../assets/robot.png\n        footer: <a href=\"../index.html\">back to website {{< bi box-arrow-up-left >}} </a>\n        # navigation-mode: vertical\n        progress: true\n        scrollable: false\n        slide-number: true\n        slide-level: 2\n        show-slide-number: all\n        controls-layout: bottom-right\n        controls-tutorial: true\n        preview-links: auto\n        chalkboard: true\n        from: markdown+emoji\n        code-fold: true\n        code-summary: \"Show code\"\n        code-tools: true\n        menu: \n          sticky: true\n          keyboard: true\n          autoOpen: true\n          width: normal\n          numbers: true\n          markers: true\n        callout-appearance: simple\n        callout-icon: false\nrevealjs-plugins:\n  - attribution\n---\n\n\n## Assistant menagerie {.smaller}\n\n| Assistant                                  | Provider         | Privacy | LLM                                                                                                                                                                                                                                                                                                     | Capabilities                              | Pricing model    |\n| ------------------------------------------ | ---------------- | ------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------- | ---------- |\n| [ChatGPT](https://chat.openai.com/)        | OpenAI           | üëéüèº  | GPT-3.5, GPT-4                                                                                                                                                                                                                                                                                          | Web search, DALLE, GPTs, multimodal input | üí∂        |\n| [Copilot](https://copilot.microsoft.com/)  | Microsoft        | üëçüèº  | GPT-3.5, GPT-4                                                                                                                                                                                                                                                                                          | Web search, DALLE, multimodal input       | üÜì for BFH employees and students|\n| [Gemini](https://gemini.google.com/app)    | Google           | üëéüèº  | Gemini Ultra, Gemini Pro, and Gemini Nano                                                                                                                                                                                                                                                               | Web search, multimodal input              | üí∂        |\n| [HuggingChat](https://huggingface.co/chat) | ü§ó Hugging Face | üëçüèº  | Various open models, e.g. [CodeLlama](https://about.fb.com/news/2023/08/code-llama-ai-for-coding/), [Llama 2](https://huggingface.co/meta-llama/Llama-2-70b-chat-hf),  [Mistral](https://mistral.ai/news/announcing-mistral-7b/), [Gemma](https://blog.google/technology/developers/gemma-open-models/) |                                           | üÜì         |\n\n\n\n## {{< bi bookmark-star >}} Orientierungshilfe f√ºr Lehrpersonen der BFH\n\n\n:::{.callout-note}\n\n- **Haltung der BFH**: Technologien, die den Lernprozess unterst√ºtzen und praxisrelevant sind, sollen in die Lehre einbezogen werden.\n\n- **Einsatz von KI in der Lehre**: Die Mehrheit der Studierenden wird KI-Tools nutzen. Studierende sollen lernen, Technologien kompetent einzusetzen und kritisch zu hinterfragen.\n\n:::\n\n<br> <br>\n\n[{{< bi link >}} Knowledge Base der Virtuellen Akademie](https://virtuelleakademie.ch/knowledge-base/ki-basierte-schreibtools-in-der-lehre-chatgpt-im-fokus/)\n\n[{{< bi link >}} PDF](https://bernerfachhochschule.sharepoint.com/sites/mybfh-BFH-News-de/SitePages/Nachrichten-K%C3%BCnstliche-Intelligenz-(KI)-in-der-Lehre.aspx)\n\n## What is Artifical Intelligence?\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n![](../assets/images/what-is-AI.svg){width=100%}\n:::\n\n::: {.column width=\"50%\"}\nA branch of computer science that aims to create machines that can perform tasks that typically require human intelligence.\n:::\n::::\n\n\n<!-- ## What is Generative AI?\n\nGenerative AI uses machine learning to create complex statistical models of how data are generated.\n\n- Generative AI models learn from existing data.\n- Produce new data that resembles the original data: images, music, text, etc. -->\n\n\n## What is a Large Language Model?\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n![](../assets/images/LLM.svg){width=100%}\n:::\n\n::: {.column width=\"50%\"}\nAn LLM is a type of generative AI model that is trained to predict the next word following the input (prompt).\n:::\n::::\n\n\n\n\n\n\n\n## Training\n:::: {.columns}\n\n::: {.column width=\"30%\"}\n![](../assets/images/LLM-Bookshelf.png){width=100%}\n:::\n\n::: {.column width=\"70%\"}\n![](../assets/images/training-steps.svg){width=100%}\n:::\n::::\n\n\n\n## How to train a language model\n\n<br> <br>\n\n<!-- ![](../assets/images/llm-training.excalidraw.svg){width=80%} -->\n\n![](../assets/images/pretraining.png){width=100%}\n\n<!-- ## Generalization\n- The ability to apply knowledge to new, unseen data/situations\n- E.g. a language model should learn to generate rhymes\n- Extracts knowledge from text: linguistic, factual, commonsense, etc. -->\n\n## How to train a language model\n\n- An LLM learns to predict the next word in a sequence, given the previous words:\n $$ P(word | context) $$\n- Think of as \"fancy autocomplete\" (but very very powerful and sopisticated)\n\n\n![](../assets/images/ppl_full.gif){width=100%}\n\n\n\n\n\n\n## Text Generation\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n:::\n\n::: {.column width=\"50%\"}\n![](../assets/images/textgeneration.png){width=100%}\n:::\n::::\n\n\n## How does an LLM generate text?\n\n![](../assets/images/text-generation-output.excalidraw.svg){width=100%}\n\n\n## Sampling\n\n![](../assets/images/sampling.excalidraw.svg){width=100%}\n\n\n## Auto-regressive generation\n\nText is generated __one word at a time__ (actually tokens, not words).\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n1. Model predicts which word is likely to follow, given a sequence of tokens (words, punctuation, emojis, etc.). \n2. A word is sampled from the predicted distribution.\n3. The new word is added to the sequence of words (context) that is used to predict the next word.\n\n$$ P(w_{w+1} | w_1, w_2, ..., w_t) $$\n\n:::\n::: {.column width=\"50%\"}\n\n\n{{< bi arrow-right-circle-fill >}} Generated text is dependent on the context.\n\n{{< bi arrow-right-circle-fill >}} Every token is given an equal amount time (computation per token is constant). \n:::\n::::\n\n## Auto-regressive generation\n\n![](../assets/images/autoregressive.png){width=100%}\n\n\n\n<!-- ## Tokenization\nLLMs operate with tokens, not words. These are sub-words, and make working with text much easier for the model. A rule of thumb is that one token generally corresponds to ~4 characters of English text. This translates to roughly $\\frac{3}{4}$ of a word (so 100 tokens is about 75 words).\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](../assets/images/tokenization.png){width=675}\n:::\n:::\n\n\nFeel free to try out the [OpenAI tokenizer](https://platform.openai.com/tokenizer). \n\n## Embeddings\n- The next step is to represent tokens as vectors. \n- This is called \"embedding\" the tokens. The vectors are high-dimensional, and the **distance** between vectors measures the similarity between tokens.\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](../assets/images/embedding.png){width=751}\n:::\n:::\n\n:::\n::: {.column width=\"50%\"}\nIn this 2-dimensional representation, concepts that are \"related\" lie close together. Read about embeddings [in this tutorial](../pages/text-representation.qmd).\n\n:::\n\n:::: -->\n\n\n\n\n## Foundation models\n\nA foundation model, or large language model (LLM):\n\n- is a type of machine learning model that is trained to predict the next word following the input (prompt).\n- is trained \"simply\" to predict the next word following a sequence of words. \n- does not necessarily produce human-like conversations.\n\n:::{.callout-note}\n{{< bi person >}}: \nWhat is the capital of France?\n\n{{< bi robot >}}: \nWhat is the capital of Germany? \nWhat is the capital of Italy? .\n..\n:::\n\n\n## Training data\n\n![](../assets/images/karpathy-training-data.png){width=100%}\n\n::: attribution\nFigure courtesy of [Andrej Karpathy](https://karpathy.ai/)\n:::\n\n## Training process\n\n![](../assets/images/karpathy-training-process.png){width=100%}\n\n::: attribution\nFigure courtesy of [Andrej Karpathy](https://karpathy.ai/)\n:::\n\n<!-- ## Emergent abilities\n\nLLMs are thought to show emergent abilities - abilities not explicitly taught. Instead, they emerge _as a result of text prediction_.\n\nAbilities include:\n\n- performing arithmetic, answering questions, summarizing text, translating, etc.\n- zero-shot learning: LLMs can perform tasks without being trained on them.\n- few-shot learning: LLMs can perform tasks with few examples.\n\n## Emergent abilities\n\nWhat kind of knowledge does an LLM have to have to be able to write a continuation of the following text?^[Continue this conversation with [ChatGPT](https://chat.openai.com/share/2661773e-3bf6-4be3-b251-41f639bfc2a1).]\n\n::::{.columns}\n::: {.column width=\"50%\"}\n\n:::{.callout-note}\n{{< bi person >}}: \nHow many holes does a straw have?\n\n{{< bi robot >}}: \nA straw has one hole. It's a cylindrical tunnel that runs through the entire length, creating a single continuous space from one end to the other.\n\n{{< bi person >}}: \nWhat about a tunnel?\n\n{{< bi robot >}}:\nSimilar to a straw, a tunnel can also be considered to have one hole. It's an elongated pathway carved through an obstruction, allowing passage from one side to the other, thus creating a single continuous space or hole through the material.\n:::\n:::\n\n::: {.column width=\"50%\"}\n![](../assets/images/straw-tunnel.png){width=100%}\n:::\n:::: -->\n\n\n\n## Assistant models\n\nTrained (fine-tuned) to have conversations: turn-taking, question answering, not being [rude/sexist/racist].\n\n:::: {.columns}\n\n::: {.column width=\"34%\"}\n![](../assets/images/Chat.png){width=100%}\n\n\n<!-- ![](../assets/images/RLHF.svg){width=100%} -->\n:::\n\n::: {.column width=\"66%\"}\n\n- Foundation model has learned to predict all kinds of text, including both desirable and undesirable text.\n- Fine-tuning is a process narrow down the space of all possible output to only desirable, human-like dialogue.\n\n:::\n::::\n\n\n<!-- ## Instruction fine-tuning\n\n![](../assets/images/finetuning.png){width=100%} -->\n\n## Reinforcement learning from human feedback (RLHF)\n\n![](../assets/images/RLHF.svg){width=100%}\n\n\nModel is **aligned** with the values of the fine-tuner.\n\n\n\n\n## How do Chatbots work?\n\n![](../assets/images/chatbotexcalidraw.svg){width=100%}\n\n- Designed to present the illusion of a conversation between two entities.\n\n## How do chatbots actually work?\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n![](../assets/images/chatbot.svg){width=100%}\n:::\n\n::: {.column width=\"50%\"}\n![](../assets/images/chatbot-2.svg){width=100%}\n\n\n:::\n::::\n\n\n\n## An assistant model is a role-play simulator\n\n:::: {.columns}\n\n::: {.column width=\"34%\"}\n![](../assets/images/live-action-role-play.png){width=100%}\n\n:::\n\n::: {.column width=\"64%\"}\n\n- An assistant is trained to respond to user prompts in a human-like way.\n- Simulates **possible** human conversations.\n- Has no intentions. It is not an entity with its own goals.\n- Does not have a \"personality\" or \"character\" in the traditional sense. It can be thought of as a role-playing simulator.\n- Has no concept of \"truth\" or \"lying\". The model is not trying to deceive the user, it is simply trying to respond in a human-like way.\n  \n:::\n::::\n\n\n\n<!-- ## Stochastic generation\n\n![](../assets/images/simulator.png){width=100%} -->\n\n\n\n## Hallucination\n\n:::: {.columns}\n\n::: {.column width=\"34%\"}\n![](../assets/images/confabulating.png){width=100%}\n\n:::\n\n::: {.column width=\"64%\"}\n- LLMs can generate text that is not true, or not based on any real-world knowledge.\n- This is known as \"hallucination\". A better term would be \"confabulation\".\n\n:::\n::::\n\n## Can an LLM tell the truth?\n\n- How would you know if an LLM is able to give you factual information?\n- How would you test this?\n\n:::{.callout-note}\n{{< bi person >}}: \nWhat is the capital of Uzbekistan?\n\n{{< bi robot >}}: \nTashkent\n:::\n\n \n\nIt looks like the LLM knows the capital of Uzbekistan^[What it is actually doing is responding with the most likely sequence following the question.].\n\n\n## Knowledge base\n\n:::: {.columns}\n\n::: {.column width=\"66%\"}\n\n- A knowledge base is a collection of facts about the world.\n  - You can `ask` (retrieve) and `tell` (store) facts.\n- An LLM is not a knowledge base.\n  - LLMs generate text based on on how probable the next word is given the context, not based on stored facts.\n:::\n\n::: {.column width=\"34%\"}\n\n![](../assets/images/KnowledgeBase.png){width=100%}\n\n:::\n::::\n\n\n## What are LLMs good at?\n\n- Fixing grammar, bad writing, etc.\n- Rephrasing\n- Analyze texts\n- Write computer code\n- Answer questions about a knowledge base\n- Translate languages\n- Creating structured output\n- Factual output only with external documents or web search\n\n\n\n\n## Prompting\n\n![](../assets/images/magic.svg){width=66%}\n\n\n## What is a prompt?\n\n- Remember: the goal of an LLM is complete text.\n- A prompt is a piece of text (instruction) that is given to a language model to complete. \n\n:::{.callout-note}\nPROMPT {{< bi person >}}: Write a haiku about a workshop on large language models.\n\nASSISTANT {{< bi robot >}}: \n    Whispers of circuits,  \n    Knowledge blooms in bytes and bits,  \n    Model learns and fits.\n:::\n\n\n\n- The response is generated as continuation of the prompt. \n\n::: {.notes}\n\nMore technical definition: The output is generated by auto-regressively sampling from the probability distribution over the vocabulary, conditioned on the prompt.\n:::\n\n\n## Unlocking knowledge\n:::: {.columns}\n::: {.column width=\"50%\"}\n![](../assets/images/unlock.svg)\n\n<!-- ::: {.incremental} -->\n- LLMs learn to do things they were not explicitly trained to do. \n<!-- - They can solve logic puzzles and perform complex multistep reasoning.  -->\n- Often, these capabilities need to be \"unlocked\" by the right prompt.\n<!-- ::: -->\n\n:::\n\n::: {.column width=\"50%\"}\n- But what is the right prompt?\n- The answer is very similar to what you would tell a human dialogue partner/assistant.\n- You can increase the probability of getting the desired output by asking good questions or giving enough information.\n:::\n::::\n\n\n## Basics of prompting\n\nOpenAI give a set of strategies for using their models effectively: \n\n{{< bi link >}} [Prompt engineering](https://platform.openai.com/docs/guides/prompt-engineering) \n\n\nThese include:\n\n- writing clear instructions\n- providing reference texts\n- splitting tasks into subtasks\n- giving the LLM 'time to think'\n- using external tools\n\n\n## Writing clear instructions\n\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n- Think of an LLM as a role-playing conversation simulator.\n- Instructions should be clear and unambiguous.\n- Indicate which role the model (persona) should adopt.\n\n:::\n\n::: {.column width=\"50%\"}\n:::{.callout-note}\n- [Include details in your query to get more relevant answers](https://platform.openai.com/docs/guides/prompt-engineering/tactic-include-details-in-your-query-to-get-more-relevant-answers)\n- [Ask the model to adopt a persona](https://platform.openai.com/docs/guides/prompt-engineering/tactic-ask-the-model-to-adopt-a-persona)\n- [Use delimiters to clearly indicate distinct parts of the input](https://platform.openai.com/docs/guides/prompt-engineering/tactic-use-delimiters-to-clearly-indicate-distinct-parts-of-the-input)\n- [Specify the steps required to complete a task](https://platform.openai.com/docs/guides/prompt-engineering/tactic-specify-the-steps-required-to-complete-a-task)\n- [Provide examples](https://platform.openai.com/docs/guides/prompt-engineering/tactic-provide-examples)\n- [Specify the desired length of the output](https://platform.openai.com/docs/guides/prompt-engineering/tactic-specify-the-desired-length-of-the-output)\n\n:::\n:::\n::::\n\n\n## Adopt a persona (role)\n\n:::{.callout-note}\n{{< bi person >}}: You are an expert on learning techniques. Explain the concept of 'flipped classroom' in one paragraph.\n:::\n\n:::{.callout-note}\n{{< bi person >}}: You are an expert financial derivatives. Explain the concept of 'flipped classroom' in one paragraph.\n:::\n\n\n\n## Provide reference texts\n\n\n- Provide a model with trusted and relevant information. \n- Then instruct the model to use the provided information to compose its answer.\n\n\n[{{< bi link >}} Instruct the model to answer using a reference text](https://platform.openai.com/docs/guides/prompt-engineering/tactic-instruct-the-model-to-answer-using-a-reference-text)\n\n:::aside\nThis leads to **retrieval-augmented generation (RAG)**. First create a database of documents, then retrieve the most relevant documents, based on a user's query. These are then included in the prompt to the model. The model is instructed to use the information in the documents to compose its answer.\n:::\n\n<!-- ## Provide reference texts {.scrollable}\n\n:::{.callout-note}\n{{< fa person >}}: You will be provided with a document delimited by triple quotes and a question. Your task is to provide a simplified answer to the question using only the provided document and to cite the passage(s) of the document used to answer the question. If the document does not contain the information needed to answer this question then simply write: \"Insufficient information.\" If an answer to the question is provided, it must be annotated with a citation. Use the following format for to cite relevant passages ({\"citation\": ‚Ä¶}). Cite only the relevant passage(s) of the document, not the entire document.\n\n\"\"\"\nThe flipped classroom intentionally shifts instruction to a learner-centered model, in which students are often initially introduced to new topics outside of school, freeing up classroom time for the exploration of topics in greater depth, creating meaningful learning opportunities. With a flipped classroom, 'content delivery' may take a variety of forms, often featuring video lessons prepared by the teacher or third parties, although online collaborative discussions, digital research, and text readings may alternatively be used. The ideal length for a video lesson is widely cited as eight to twelve minutes.\n\"\"\"\n\n**Question**: What is flipped classroom?\n\n::: -->\n\n\n\n## Giving GPT 'time to think'\n\n- LLMs generate text one word at a time--the model spends the same amount of computation on each word.\n- Giving the model more context gives it more steps to \"think\". \n- This increases the chances that the model will give a good answer.\n- This technique is known as **chain-of-thought** prompting, and can often be induced by simply instructing the model to `think step-by-step` or `Take a deep breath and work on this problem step-by-step` [@yangLargeLanguageModels2023].\n\n<!-- ![Chain-of-thought example](../assets/images/chain-of-thought.png) -->\n\n\n\n## Chain-of-thought prompting\n\n- Chain-of-thought prompting encourages the LLM to \"explain\" its intermediate reasoning steps.\n- Enables complex reasoning and problem solving.\n\nInstead of this:\n\n:::{.callout-note}\n{{< bi person >}}: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1. Yes or no?\n:::\n\nDo this:\n\n:::{.callout-note}\n{{< bi person >}}: Is this statement correct? The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1. \n\nReason through the problem step-by-step. Start by identifying the odd numbers. Next, add them up. Finally, determine if the sum is even or odd. Write down your reasoning steps in a numbered list.\n\n:::\n\n:::{.notes}\nWhy does this work?\n:::\n\n## Zero-shot chain-of-thought prompting\n\n:::{.callout-note}\n\n{{< fa person >}}: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1. <mark style=\"background: #BBFABBA6;\">Take a deep breath and think step-by-step.</mark>\n\n\n:::\n\n\n:::aside\nWhen using GPT-4, ChatGPT and Copilot do this automatically.\n:::\n\n\n## Use Markdown formatting\n\n- Use [Markdown](https://www.markdownguide.org/) to format your prompts.\n- Instruct the LLM to format its output using Markdown.\n\n:::{.callout-note}\n{{< bi person >}}: Improve this haiku:\n\nWords weave through the air,  \nMinds meld with machine's deep thought,  \nKnowledge blooms anew.  \n\nIt is about about a workshop on large language models. I'm not happy with it.\n\nShow me all the text. Format your edits as `**TEXT**` and show the deleted text as `~~TEXT~~`. Keep you review short (max 100 words).\n:::\n\nTry this example in [ChatGPT](https://chat.openai.com/share/c2230c3c-04cc-4aa5-b802-9646496aadbd).\n\n## Advanced prompting techniques\n\nFor more advanced prompting techniques, see these websites:\n\n- {{< bi link >}} [Learn prompting](https://learnprompting.org/docs/intro)\n- {{< bi link >}} [Prompting guide](https://www.promptingguide.ai/)\n- {{< bi link >}} [OpenAI cookbook](https://cookbook.openai.com/)\n\nand explore this [activity](../pages/activity-cas-hochschuldidaktik.qmd).\n\n\n# Advanced LLM techniques\n\n![](../assets/images/finetuning-vs-prompting.png){width=50%}\n\n## Retrieval-augmented generation (RAG)\n\n![](../assets/images/rag-volvo.png){width=100%}\n\n:::{.attribution}\n\nFigure courtesy of [Pinecone](https://www.pinecone.io/learn/retrieval-augmented-generation/)\n:::\n\n## Web search\n\n- Similar to retrieval-augmented generation, but with web search.\n- LLMs can be instructed to use web search to find information.\n- Copilot does this automatically - ChatGPT (paid version only) can be instructed to do this.\n  \n\n\n## External tools\n\n- LLMs can be instructed to use external tools to complete tasks.\n- For example, an LLM can be instructed to use a calculator to perform arithmetic.\n- OpenAI calls this approach [function calling](https://platform.openai.com/docs/guides/function-calling/function-calling).\n\n## Multi-agent conversations\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n![](../assets/images/multi-agent.excalidraw.svg){width=100%}\n:::\n\n::: {.column width=\"50%\"}\n\n<!-- - {{< bi arrow-right-circle >}} DEMO: haiku writing team -->\n:::\n::::\n\n## Local models\n\n- Download and run models, such as e.g. Llama 2 or Code Llama, locally.\n- [Ollama](https://ollama.com/)\n- [LM Studio](https://lmstudio.ai/)\n\nHardware requirements:\n\n- Apple Silicon Mac (M1/M2/M3) / Windows / Linux\n- 16GB+ of RAM is recommended\n- NVIDIA/AMD GPUs supported\n\n\n\n\n# References {background-color=\"#D8DEE9\"}\n\n::: {#refs}\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
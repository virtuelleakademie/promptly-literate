{
  "hash": "7d0c1f0ac0c410abcfb589f43cf12c2c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"What is ChatGPT?\"\nauthor: \"Andrew Ellis\"\ndate: last-modified\ndate-format: \"DD MMMM, YYYY\"\nbibliography: ../bibliography.bib\nnocite: |\n  @shanahanTalkingLargeLanguage2023, @shanahanRolePlayLargeLanguage2023, @weiEmergentAbilitiesLarge2022b\nformat: \n    revealjs:\n        # theme: moon\n        theme: default\n        title-slide-attributes:\n          # data-background-image: ../assets/background-purple.png\n          # data-background-size: contain\n          data-background-opacity: \"1\"\n        # logo: ../assets/robot.png\n        footer: <a href=\"../index.html\">back to website ‚§¥Ô∏è</a>\n        navigation-mode: vertical\n        progress: true\n        scrollable: false\n        slide-number: true\n        show-slide-number: all\n        controls-layout: bottom-right\n        controls-tutorial: true\n        preview-links: auto\n        chalkboard: true\n        from: markdown+emoji\n        code-fold: true\n        code-summary: \"Show code\"\n        code-tools: true\n        menu: \n          sticky: true\n          keyboard: true\n          autoOpen: true\n          width: normal\n          numbers: true\n          markers: true\n        callout-appearance: simple\n        callout-icon: false\n\n# slide-level: 3\n# number-sections: true\n---\n\n::: {.cell hash='00-introduction_cache/revealjs/unnamed-chunk-1_bbbb4a43ec8e9f5ef6ed764019386a3d'}\n\n:::\n\n\n\n## Contents\n\n- Example: 20 questions\n- What is ChatGPT?\n  - Base model\n  - Assistant model\n- What is it not?\n- ChatGPT as a role-play simulator\n\n\n\n\n<!-- ## Key messages\n\n1) üë©‚Äç‚öñÔ∏è Keep a human in the loop: LLMs should be used to augment human writing, not to replace it.\n\n2) This workshop is mainly about prompting. We can think about prompting as a way of \"programming\" LLMs, i.e. getting LLMs to do what we want them to do. -->\n\n## 20 questions\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n```{=html}\n<iframe width=\"600\" height=\"600\" src=\"https://chat.openai.com/share/a4daa92d-4631-4d7e-bfe6-ef9b3b5eb0a0\" title=\"Once upon a time\"></iframe>\n\n```\n\n\n:::\n\n::: {.column width=\"50%\"}\n- ü§∑‚Äç‚ôÇÔ∏è What is ChatGPT doing here? \n- How does this work?\n:::\n\n::::\n\n## What is ChatGPT?\n\n:::: {.columns}\n\n::: {.column width=\"34%\"}\n![](../assets/images/Language%20Model.png){width=100%}\n:::\n\n::: {.column width=\"66%\"}\n- Consists of a **base** model and an **assistant** model.\n- **Base or foundation** model: probabilistic model of how language is generated.\n- **Assistant**: able to create human-like dialogue.\n:::\n::::\n\n## Base model\n\n:::: {.columns}\n\n::: {.column width=\"34%\"}\n![](../assets/images/LLM-Bookshelf.png){width=100%}\n\n![](../assets/images/pretraining.png){width=100%}\n:::\n\n::: {.column width=\"66%\"}\n- Is trained to predict text. \n\n:::{.callout-note}\n{{< fa person >}}: What is the capital of France?\n\n{{< fa robot >}}: What is the capital of Germany? What is the capital of Italy? ...\n:::\n\n- Extracts various types of knowledge from text: linguistic, factual, commonsense, etc.\n- Does not know how to have a conversation.\n\n:::\n::::\n\n## Base model\n\nProduces text that most likely follows the input (prompt).\n\n:::{.callout-note}\n{{< fa person >}}: The first person to walk on the Moon was\n\n{{< fa robot >}}: Neil Armstrong\n:::\n\n:::{.callout-caution collapse=\"true\"}\n## Does an LLM know facts?\n\nWhat we are really asking: \nGiven what it learned during training, what words are most likely to follow _\"The first person to walk on the Moon was \"_? A good reply to this question is _\"Neil Armstrong\"_.\n  \n:::\n\n## Base model: emergent properties\n\n- LLMs are thought to show emergent properties - abilities not explicitly programmed into the model, but emerge as a result of text prediction.\n  - performing arithmetic, answering questions, summarizing text, translating, etc.\n  - zero-shot learning: LLMs can perform tasks without being trained on them.\n  - few-shot learning: LLMs can perform tasks with few examples.\n\n\n\n## Assistant model\n:::: {.columns}\n\n::: {.column width=\"34%\"}\n![](../assets/images/Chat.png){width=100%}\n\n![](../assets/images/RLHF.svg){width=100%}\n:::\n\n::: {.column width=\"66%\"}\n- Is trained to create human-like dialogue. \n\n:::{.callout-note}\n{{< fa person >}}: What is the capital of France?\n{{< fa robot >}}: Paris. Is there anything else you would like to know about France?\n:::\n\n- Trained to have conversations: turn-taking, question answering, not being [rude/sexist/racist], etc.\n\n:::\n::::\n\n## Knowledge base\n\n:::: {.columns}\n\n::: {.column width=\"34%\"}\n![](../assets/images/KnowledgeBase.png){width=100%}\n\n:::\n\n::: {.column width=\"66%\"}\n- A knowledge base is a collection of facts about the world.\n- `Ask` and `Tell`\n- I can ask but I can't tell.\n- It cannot give me verifiable facts.\n\n\n\n\n:::\n::::\n\n## Knowledge base\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n![Am Strande von Rainer Maria Rilke <br> üëâ [Open in ChatGPT](https://chat.openai.com/share/37698510-9047-4d4f-8a6b-00f054d06457)](../assets/images/Rilke.png){width=75%}\n\n:::\n\n::: {.column width=\"50%\"}\n\n![Kennst du dieses Gedicht? <br> üëâ [Open in ChatGPT](https://chat.openai.com/share/37698510-9047-4d4f-8a6b-00f054d06457)](../assets/images/Hesse.png){width=75%}\n\n\n:::\n::::\n\n. . . \n\nWhat can we learn from this?\n\n## Knowledge base\n\n:::: {.columns}\n\n::: {.column width=\"34%\"}\n![](../assets/images/Pothole.png){width=100%}\n\n:::\n\n::: {.column width=\"64%\"}\n\n- Can't tell me where it got its information from.\n- LLMs are models of knowledge bases, but not knowledge bases themselves.\n- Expensive/difficult to update with new knowledge.\n- Produce ethically questionable results.\n\n:::\n::::\n\n\n\n\n\n## An LLM is a role-play simulator\n\n:::: {.columns}\n\n::: {.column width=\"34%\"}\n![](../assets/images/live-action-role-play.png){width=100%}\n\n:::\n\n::: {.column width=\"64%\"}\n\n:::{.callout-note}\nWe can think of an LLM as a non-deterministic simulator capable of role-playing an infinity of characters, or, to put it another way, capable of stochastically generating an infinity of simulacra [@shanahanRolePlayLargeLanguage2023]\n:::\n:::\n::::\n\n## An LLM is a role-play simulator\n\n- An assistant is trained to respond to user prompts in a human-like way.\n- A simulator of **possible** human conversation.\n- Has no intentions. It is not an entity with its own goals.\n- Does not have a \"personality\" or \"character\" in the traditional sense. It can be thought of as a role-playing simulator.\n- Has no concept of \"truth\" or \"lying\". The model is not trying to deceive the user, it is simply trying to respond in a human-like way.\n\n\n## An LLM is a role-play simulator\n\n\n![](../assets/images/simulator.png){width=100%}\n\n:::{.callout-note}\n- The dialogue agent will do its best to role-play a character in a dialogue.\n- At every step, the model is trying to generate text that is most likely to follow the input. \n- It can take many different paths. Your interaction is just one of those possible paths.\n:::\n\n\n## An LLM is a role-play simulator\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n\n```{=html}\n<iframe width=\"600\" height=\"600\" src=\"https://chat.openai.com/share/01f39c79-7c23-4a33-8f3e-9d052113cdd5\" title=\"Once upon a time\"></iframe>\n\n```\n\n:::\n\n::: {.column width=\"34%\"}\n- You can open this conversation in ChatGPT.\n- Try re-generating the conversation after the initial prompt.\n:::\n\n::::\n\n# References {background-color=\"#2e3440\"}\n\n::: {#refs}\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
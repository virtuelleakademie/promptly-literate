{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Prompting Programmatically\n",
        "description: |\n",
        "  Programming a GPT model.\n",
        "date: last-modified\n",
        "date-format: 'DD MMM, YYYY'\n",
        "author:\n",
        "  - name: Andrew Ellis\n",
        "    url: 'https://github.com/awellis'\n",
        "    affiliation: 'Virtuelle Akademie, Berner Fachhochschule'\n",
        "    affiliation-url: 'https://virtuelleakademie.ch'\n",
        "    orcid: 0000-0002-2788-936X\n",
        "license: CC BY\n",
        "citation: true\n",
        "bibliography: ../bibliography.bib\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    code-fold: false\n",
        "    code-link: true\n",
        "execute:\n",
        "  cache: false\n",
        "  keep-ipynb: true\n",
        "code-annotations: select\n",
        "---"
      ],
      "id": "f121347e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import openai\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "import os\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "openai.api_key  = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "from IPython.display import display, Markdown, Latex, HTML, JSON"
      ],
      "id": "9ca81852",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def get_completion(prompt, model=\"gpt-4-turbo-preview\", temperature=0.0):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "id": "05950e7b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prompting Principles\n",
        "- **Principle 1: Write clear and specific instructions**\n",
        "- **Principle 2: Give the model time to “think”**\n",
        "\n",
        "### Tactics\n",
        "\n",
        "#### Tactic 1: Use delimiters to clearly indicate distinct parts of the input\n",
        "- Delimiters can be anything, such as: ```, \"\"\", < >, `<tag> </tag>`, `:`\n"
      ],
      "id": "8584ef43"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "text = f\"\"\"\n",
        "You should express what you want a model to do by \\ \n",
        "providing instructions that are as clear and \\ \n",
        "specific as you can possibly make them. \\ \n",
        "This will guide the model towards the desired output, \\ \n",
        "and reduce the chances of receiving irrelevant \\ \n",
        "or incorrect responses. Don't confuse writing a \\ \n",
        "clear prompt with writing a short prompt. \\ \n",
        "In many cases, longer prompts provide more clarity \\ \n",
        "and context for the model, which can lead to \\ \n",
        "more detailed and relevant outputs.\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "Summarize the text delimited by triple backticks \\ \n",
        "into a single sentence.\n",
        "```{text}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "id": "17fe65ac",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Tactic 4: \"Few-shot\" prompting\n"
      ],
      "id": "93ac0a8a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to answer in a consistent style.\n",
        "\n",
        "<child>: Teach me about patience.\n",
        "\n",
        "<grandparent>: The river that carves the deepest \\ \n",
        "valley flows from a modest spring; the \\ \n",
        "grandest symphony originates from a single note; \\ \n",
        "the most intricate tapestry begins with a solitary thread.\n",
        "\n",
        "<child>: Teach me about resilience.\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "id": "ff3e1620",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sentment Analysis\n"
      ],
      "id": "fab1e933"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lamp_review = \"\"\"\n",
        "Needed a nice lamp for my bedroom, and this one had \\\n",
        "additional storage and not too high of a price point. \\\n",
        "Got it fast.  The string to our lamp broke during the \\\n",
        "transit and the company happily sent over a new one. \\\n",
        "Came within a few days as well. It was easy to put \\\n",
        "together.  I had a missing part, so I contacted their \\\n",
        "support and they very quickly got me the missing piece! \\\n",
        "Lumina seems to me to be a great company that cares \\\n",
        "about their customers and products!!\n",
        "\"\"\""
      ],
      "id": "0f814e6c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "prompt = f\"\"\"\n",
        "What is the sentiment of the following product review, \n",
        "which is delimited with triple backticks?\n",
        "\n",
        "Review text: '''{lamp_review}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "id": "42cb578a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tone transformation\n"
      ],
      "id": "e06299d6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following from slang to a business letter: \n",
        "'Dude, This is Joe, check out this spec on this standing lamp.'\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "id": "ffd32103",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Proofreading and editing\n"
      ],
      "id": "5ed25041"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "text = f\"\"\"\n",
        "Got this for my daughter for her birthday cuz she keeps taking \\\n",
        "mine from my room.  Yes, adults also like pandas too.  She takes \\\n",
        "it everywhere with her, and it's super soft and cute.  One of the \\\n",
        "ears is a bit lower than the other, and I don't think that was \\\n",
        "designed to be asymmetrical. It's a bit small for what I paid for it \\\n",
        "though. I think there might be other options that are bigger for \\\n",
        "the same price.  It arrived a day earlier than expected, so I got \\\n",
        "to play with it myself before I gave it to my daughter.\n",
        "\"\"\"\n",
        "prompt = f\"proofread and correct this review: ```{text}```\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "id": "31504a74",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from redlines import Redlines\n",
        "\n",
        "diff = Redlines(text,response)\n",
        "display(Markdown(diff.output_markdown))"
      ],
      "id": "f30519e8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "prompt = f\"\"\"\n",
        "proofread and correct this review. Make it more compelling. \n",
        "Ensure it follows APA style guide and targets an advanced reader. \n",
        "Output in markdown format.\n",
        "Text: ```{text}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "display(Markdown(response))"
      ],
      "id": "19585e02",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
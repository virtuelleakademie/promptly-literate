---
title: "Take-home messages"
description: |
  Programming a GPT model.
date: last-modified
date-format: "DD MMM, YYYY"
author: 
  - name: Andrew Ellis
    url: https://github.com/awellis
    affiliation: Virtuelle Akademie, Berner Fachhochschule
    affiliation-url: https://virtuelleakademie.ch
    orcid: 0000-0002-2788-936X
license: CC BY
citation: true
bibliography: ../bibliography.bib
format:
    html:
        toc: true
        code-fold: false
        code-link: true
jupyter: python3
execute: 
  cache: false
  keep-ipynb: true
code-annotations: select

# filters:
#    - lightbox
lightbox: auto
---

1) An LLM is not a knowledge base, instead it's a statistical model of a knowledge base. An LLM is trained to be a language model.
An LLM is a probabilistic model of its training corpus. It can be used to predict text auto-regressively.


 {{< fa chess-pawn >}}
 {{< fa thumbs-up >}} 

![](../assets/robot.png)

{{< youtube YDiSFS-yHwk >}}


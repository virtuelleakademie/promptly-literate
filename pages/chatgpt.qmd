---
title: "Prompt Design"
description: |
  Programming a GPT model.
date: last-modified
date-format: "DD MMM, YYYY"
author: 
  - name: Andrew Ellis
    url: https://github.com/awellis
    affiliation: Virtuelle Akademie, Berner Fachhochschule
    affiliation-url: https://virtuelleakademie.ch
    orcid: 0000-0002-2788-936X
license: CC BY
citation: true
bibliography: ../bibliography.bib
format:
    html:
        toc: true
        code-link: true
execute: 
  cache: false
code-annotations: select
---


## images

![GPT-3](../assets/10-gpt3-fine-tuning.gif)


## OpenAI Documentation
[Doc](https://platform.openai.com/docs/guides/gpt)
OpenAI's GPT (generative pre-trained transformer) models have been trained to understand natural language and code. GPTs provide text outputs in response to their inputs. The inputs to GPTs are also referred to as "prompts". Designing a prompt is essentially how you “program” a GPT model, usually by providing instructions or some examples of how to successfully complete a task.

Using GPTs, you can build applications to:

    Draft documents
    Write computer code
    Answer questions about a knowledge base
    Analyze texts
    Create conversational agents
    Give software a natural language interface
    Tutor in a range of subjects
    Translate languages
    Simulate characters for games
    and much more

To use a GPT model via the OpenAI API, you’ll send a request containing the inputs and your API key, and receive a response containing the model’s output. Our latest models, gpt-4 and gpt-3.5-turbo, are accessed through the chat completions API endpoint. Currently, only the older legacy models are available via the completions API endpoint.


## GPT best practices

This guide shares strategies and tactics for getting better results from GPTs. The methods described here can sometimes be deployed in combination for greater effect. We encourage experimentation to find the methods that work best for you.

Some of the examples demonstrated here currently work only with our most capable model, gpt-4. If you don't yet have access to gpt-4 consider joining the waitlist. In general, if you find that a GPT model fails at a task and a more capable model is available, it's often worth trying again with the more capable model.
Six strategies for getting better results
Write clear instructions

GPTs can’t read your mind. If outputs are too long, ask for brief replies. If outputs are too simple, ask for expert-level writing. If you dislike the format, demonstrate the format you’d like to see. The less GPTs have to guess at what you want, the more likely you’ll get it.

### Tactics:

    Include details in your query to get more relevant answers
    Ask the model to adopt a persona
    Use delimiters to clearly indicate distinct parts of the input
    Specify the steps required to complete a task
    Provide examples
    Specify the desired length of the output


## Provide reference text

GPTs can confidently invent fake answers, especially when asked about esoteric topics or for citations and URLs. In the same way that a sheet of notes can help a student do better on a test, providing reference text to GPTs can help in answering with fewer fabrications.

### Tactics:

    Instruct the model to answer using a reference text
    Instruct the model to answer with citations from a reference text


## Strategy: Give GPTs time to "think"
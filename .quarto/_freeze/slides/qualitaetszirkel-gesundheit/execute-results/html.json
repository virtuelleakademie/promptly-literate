{
  "hash": "c9adc345b9d232c5220fa4c4c0cf10ed",
  "result": {
    "markdown": "---\ntitle: \"Qualit√§tszirkel Departement Gesundheit \"\nauthor: \"Andrew Ellis\"\ndate: last-modified\ndate-format: \"DD MMMM, YYYY\"\nbibliography: ../bibliography.bib\nnocite: |\n  @broschinskiGrafikenErklaertFunktioniert2023\nformat: \n    revealjs:\n        # theme: moon\n        theme: default\n        title-slide-attributes:\n          data-background-image: ../assets/background-purple.png\n          # data-background-size: contain\n          data-background-opacity: \"1\"\n        # logo: ../assets/robot.png\n        footer: <a href=\"https://virtuelleakademie.github.io/gpt-nano\">‚§¥Ô∏è KI/GPT in der Hochschule </a>\n        navigation-mode: vertical\n        progress: true\n        scrollable: true\n        slide-number: true\n        show-slide-number: all\n        controls-layout: bottom-right\n        controls-tutorial: true\n        preview-links: auto\n        chalkboard: true\n        from: markdown+emoji\n        code-fold: true\n        code-summary: \"Show code\"\n        code-tools: true\n        menu: \n          sticky: true\n          keyboard: true\n          autoOpen: true\n          width: normal\n          numbers: true\n          markers: true\n\n# slide-level: 3\n# number-sections: true\n---\n\n::: {.cell hash='qualitaetszirkel-gesundheit_cache/revealjs/unnamed-chunk-1_581604e7b22e2d80dc8c7d2452142fa5'}\n\n:::\n\n\n\n##  Here‚Äôs What Happens When Your Lawyer Uses ChatGPT {background-color=\"#2e3440\"}\n\n\n\n\n```{=html}\n<iframe width=\"780\" height=\"500\" src=\"https://simonwillison.net/2023/May/27/lawyer-chatgpt/\" title=\"ChatGPT: US lawyer admits using AI for case research\"></iframe>\n```\n\n\n\n\n## The Best Prompts For ChatGPT: The ultimate list {background-color=\"#2e3440\"}\n\n\n```{=html}\n<iframe width=\"780\" height=\"500\" src=\"https://www.writingbeginner.com/best-prompts-for-chatgpt/\" title=\"Best prompts for ChatGPT\"></iframe>\n```\n\n\n\n\n# Inhalt {background-color=\"#b48ead\"}\n\n1. Was ist k√ºnstliche Intelligenz?\n2. Was ist ChatGPT?\n3. Wie wurde ChatGPT trainiert?\n4. Energieverbrauch, Bias, Ethik\n5. Wie \"denkt\" ChatGPT?\n6. Zuk√ºnftige Verwendungen von LLMs\n7. Wissenschaftliches Arbeiten\n8. Case Study: Seminararbeit mit KI-Unterst√ºtzung\n\n<!-- ::: footer\n<a href=\"https://virtuelleakademie.github.io/gpt-nano\">üè† KI/GPT in der Hochschule</a>\n::: -->\n\n\n\n# Was ist k√ºnstliche Intelligenz? {background-color=\"#b48ead\"}\n\n::: {.absolute top=\"0\" left=\"100%\"}\n::: {.sectionhead}\n1 [2 3 4 5 6 7 8]{style=\"opacity:0.25\"}\n:::\n:::\n\n## Was ist K√ºnstliche Intelligenz?\n\n\n\n::: {.cell hash='qualitaetszirkel-gesundheit_cache/revealjs/unnamed-chunk-2_514c48c949d7f8752e42eaeefdda66bc'}\n::: {.cell-output-display}\n![Quelle: [derbund.ch/so-funktioniert-kuenstliche-intelligenz-599276436215](https://www.derbund.ch/so-funktioniert-kuenstliche-intelligenz-599276436215)](../assets/images/was-ist-KI.png){width=964}\n:::\n:::\n\n\n\n::: {.notes}\nSpeaker notes go here.\n:::\n\n\n## Machine Learning\n\n- Regelbasierte Systeme m√ºssen programmiert werden.\n- ML Modelle lernen implizit, d.h. ohne Regeln einprogrammiert zu bekommen.\n\n\n- Wichtige Begriffe:\n  - __Trainingsdaten:__ Modelle werden mit Daten gef√ºttert, und Parameter des Modells werden so eingestellt, dass das Modell m√∂glichst \"gut\" ist.\n  - __Supervised learning:__ Aufgabe ist bekannt, z.B. Bilder - klassifizieren.\n  - __Unsupervised learning:__ Unbekannte Muster entdecken.\n  - __Reinforcement learning:__ Ziel ist vorgegeben, Modell lernt durch Feedback (Belohnung) wie Ziel erreicht werden kann.\n\n> We have to learn the bitter lesson that building in how we think we think does not work in the long run. We should stop trying to find simple ways to think about space, objects, multiple agents, or symmetries... instead we should build in only the meta-methods that can find and capture this arbitrary complexity. We want AI agents that can discover like we can, not which contain what we have discovered [@suttonBitterLesson2019].\n\n\n## Supervised learning\n\n\n::: {.cell hash='qualitaetszirkel-gesundheit_cache/revealjs/unnamed-chunk-3_59f396e2d2b4fc1e920b42858ae0d17d'}\n::: {.cell-output-display}\n![](../assets/images/cats-dogs.png){width=496}\n:::\n:::\n\n__Bilder von Hunden und Katzen klassifizeren:__ Was sind die Merkmale, die Hunde von Katzen unterscheiden?\n\n\n\n\n## Reinforcement learning\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n::: {.cell hash='qualitaetszirkel-gesundheit_cache/revealjs/unnamed-chunk-4_889729183f30d08020015c5247435fac'}\n::: {.cell-output-display}\n![](../assets/images/cartpole.gif)\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n\n::: {.cell hash='qualitaetszirkel-gesundheit_cache/revealjs/unnamed-chunk-5_28b440f009b25fc4d0d616d37f87d55e'}\n::: {.cell-output-display}\n![](../assets/images/RL-agent.png){width=803}\n:::\n:::\n\n:::\n::::\n\n \n::: aside\nBeispiel f√ºr RL Model: [AlphaGo](https://www.deepmind.com/research/highlighted-research/alphago) ist das erste Computerprogramm, das einen professionellen (menschlichen) [Go](https://de.wikipedia.org/wiki/Go_(Spiel))-Spieler besiegt hat.\n:::\n\n::: {.notes}\n- Ein \"Agent\" lernt durch Feedback (Belohnung) wie ein Ziel erreicht werden kann.\n:::\n\n\n\n\n\n\n# Was ist ChatGPT? {background-color=\"#b48ead\"}\n\n::: {.absolute top=\"0\" left=\"100%\"}\n::: {.sectionhead}\n[1]{style=\"opacity:0.25\"} 2 [3 4 5 6 7 8]{style=\"opacity:0.25\"}\n:::\n:::\n\n\n## Natural Language Processing \n\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n- Speech recognition\n- Text-to-speech synthesis\n- Machine translation\n- Information extraction\n- Information retrieval\n- Question answering\n\n:::\n\n::: {.column width=\"50%\"}\n- Sentiment analysis\n  - üòä I love this movie!\n  - üòê This movie is ok.\n  - üò† This movie is terrible!\n  \n:::\n\n::::\n\n\n\n## Tokenization\n\n\n::: {.cell hash='qualitaetszirkel-gesundheit_cache/revealjs/unnamed-chunk-6_9085254ed4e8880b1c37a39304ed00f8'}\n::: {.cell-output-display}\n![Quelle: [State of ChatGPT](https://build.microsoft.com/en-US/sessions/db3f4859-cd30-4445-a0cd-553c3304f8e2?source=sessions)](../assets/images/karpathy-tokenization.png){width=723}\n:::\n:::\n\n\n## Embeddings\n- Numerische Tokens werden in einem hochdimensionalen Vektorraum abgebildet.\n- Distanz zwischen Vektoren misst √Ñhnlichkeit zwischen Tokens.\n\n\n::: {.cell hash='qualitaetszirkel-gesundheit_cache/revealjs/unnamed-chunk-7_fbd82d4f0472d069f1ec092f4557b37b'}\n::: {.cell-output-display}\n![Quelle: @wolframWhatChatGPTDoing2023](../assets/images/wolfram-embeddings.png){width=352}\n:::\n:::\n\n::: {.cell hash='qualitaetszirkel-gesundheit_cache/revealjs/unnamed-chunk-8_99b7da7765009ced2a53d7b9b6d6af29'}\n::: {.cell-output-display}\n![Quelle: [So funktioniert ChatGPT](https://www.golem.de/news/kuenstliche-intelligenz-so-funktioniert-chatgpt-2302-171644.html)](../assets/images/3_Wortgruppen_im_sem_Raum.png){width=333}\n:::\n:::\n\n\n## ChatGPT\n\nBesteht aus 2 Modellen:\n\n\n- __Large language model (LLM):__ GPT-3.5 oder GPT-4 (generative pre-trained transformer): das eigentliche Sprachmodell\n\n- __Assistant:__ Ein f√ºr Dialoge spezialisiertes Modell\n\n\n## LLM\n\nAufgabe eines LLMs: \"auto-regressive next word prediction\" (eigentlich \"token prediction\"):\n\n$$ P(w_{w+1} | w_1, w_2, ..., w_t) $$\n\n- Das n√§chste Wort wird vorhergesagt, basierend auf den vorherigen Worten. \n- Diese vorherigen W√∂rter werden als \"context\" bezeichnet.\n\n\n::: {.cell hash='qualitaetszirkel-gesundheit_cache/revealjs/unnamed-chunk-9_c1d03f726f65302d00d07428abe27fe8'}\n::: {.cell-output-display}\n![](../assets/images/word-probs.png){width=712}\n:::\n\n::: {.cell-output-display}\n![](../assets/images/gpt-2-autoregression-2.gif)\n:::\n:::\n\n\n## Assistant\n\n- LLM produziert Text, aber nicht menschliche Konversationen.\n- Weiteres Training ist erforderlich, damit das Modell lernt, wie ein Mensch \"Konversationen\" zu f√ºhren.\n\n\n\n\n\n# Wie wurde ChatGPT trainiert? {background-color=\"#b48ead\"}\n\n::: {.absolute top=\"0\" left=\"100%\"}\n::: {.sectionhead}\n[1 2]{style=\"opacity:0.25\"} 3 [4 5 6 7 8]{style=\"opacity:0.25\"}\n:::\n:::\n\n## Zusammenfassung\n\nChatGPT wurde in mehreren Schritten trainiert:\n\n1) Daten aus dem Internet werden gesammelt.\n2) Pre-training: LLM wird auf diesen Daten trainiert, das n√§chste Wort vorherzusagen.\n3) Reinforcement Learning from Human Feedback: Assistant wird trainiert, menschliche Konversationen zu f√ºhren.\n\n## Daten\n\n\n::: {.cell hash='qualitaetszirkel-gesundheit_cache/revealjs/unnamed-chunk-10_2ff798cbc42955b4c4daf003a77cbdb0'}\n::: {.cell-output-display}\n![](../assets/images/karpathy-training-data.png){width=723}\n:::\n:::\n\n\n## Methoden\n\n\n::: {.cell hash='qualitaetszirkel-gesundheit_cache/revealjs/unnamed-chunk-11_a5ab97bfbddd0dfb4f3a06355fc0b802'}\n::: {.cell-output-display}\n![](../assets/images/karpathy-training-pipeline-1.png){width=723}\n:::\n:::\n\n\n::: {.notes}\nWe trained this model using Reinforcement Learning from Human Feedback (RLHF), using the same methods as InstructGPT, but with slight differences in the data collection setup. We trained an initial model using supervised fine-tuning: human AI trainers provided conversations in which they played both sides‚Äîthe user and an AI assistant. We gave the trainers access to model-written suggestions to help them compose their responses. We mixed this new dialogue dataset with the InstructGPT dataset, which we transformed into a dialogue format.\n\nTo create a reward model for reinforcement learning, we needed to collect comparison data, which consisted of two or more model responses ranked by quality. To collect this data, we took conversations that AI trainers had with the chatbot. We randomly selected a model-written message, sampled several alternative completions, and had AI trainers rank them. Using these reward models, we can fine-tune the model using Proximal Policy Optimization. We performed several iterations of this process.\n:::\n\n## Pre-training\n\n\n::: {.cell hash='qualitaetszirkel-gesundheit_cache/revealjs/unnamed-chunk-12_fecec6eec43565b6f74b49a5188685ca'}\n::: {.cell-output-display}\n![](../assets/images/karpathy-pretraining-1.png){width=723}\n:::\n:::\n\n\n## Pre-training\n\n\n::: {.cell hash='qualitaetszirkel-gesundheit_cache/revealjs/unnamed-chunk-13_fa25de2d2b38ad15e3b0189eb1369d07'}\n::: {.cell-output-display}\n![](../assets/images/karpathy-training-process.png){width=723}\n:::\n:::\n\n\n\n\n## Reinforcement Learning from Human Feedback (RLHF)\n\nBenutzt  Feedback vom Menschen um \"schlechte\" Outputs zu minimieren.\n\n\n\n::: {.cell hash='qualitaetszirkel-gesundheit_cache/revealjs/unnamed-chunk-14_6b3feabe74ba18175444b17d03e3685e'}\n::: {.cell-output-display}\n![Quelle: [openai.com/blog/chatgpt](https://openai.com/blog/chatgpt)](../assets/images/RLHF.png){width=2053}\n:::\n:::\n\n\n\n \n\n# Energieverbrauch, Bias, Ethik {background-color=\"#b48ead\"}\n\n::: {.absolute top=\"0\" left=\"100%\"}\n::: {.sectionhead}\n[1 2 3]{style=\"opacity:0.25\"} 4 [5 6 7 8]{style=\"opacity:0.25\"}\n:::\n:::\n\n## Zusammenfassung\n\n- ChatGPT hat einen hohen Energieverbrauch.\n- LLM lernt Vorurteile aus den Trainingsdaten.\n- Toxische Inhalte werden durch Billigarbeiter:innen moderiert.\n\n\n## Energieverbrauch\n\n- __Training:__ \"What we do know is that training ChatGPT used $1.287$ GWh, roughly equivalent to the consumption of 120 US homes for a year.\" Quelle: [Heating up: how much energy does AI use?](https://techhq.com/2023/03/data-center-energy-usage-chatgpt/)\n\n- @pattersonCarbonEmissionsLarge2022 sch√§tzen die Trainingskosten auf 502 Tonnen $\\text{CO}_2$ (RLHF w√ºrde etwas mehr kosten, ca. 1% der urspr√ºnglichen Kosten).\n\n- __Benutzung:__ 7 Tonnen $\\text{CO}_2$ pro Tag (Ende Februar). Quelle: [How much energy does ChatGPT use?](https://xcorr.net/2023/04/08/how-much-energy-does-chatgpt-use/)\n  \n- Der Energieverbrauch von ChatGPT ist equivalent zu 400-800 US Haushalten. Das ist betr√§chtlich, im Vergleich zu z.B. Kryptow√§hrungen eher gering.\n\n\n\n## Bias\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n```{=html}\n<iframe width=\"780\" height=\"500\" src=\"https://www.societybyte.swiss/2022/12/22/hi-chatgpt-hast-du-vorurteile/\" title=\"Vorurteile\"></iframe>\n```\n\n:::\n\n::: {.column width=\"50%\"}\n\n- Da LLMs von Texten lernen, die von Menschen geschrieben wurden, k√∂nnen sie auch Vorurteile lernen.\n\nQuelle: [Hast du Vorurteile?](https://www.societybyte.swiss/2022/12/22/hi-chatgpt-hast-du-vorurteile/)\n:::\n\n::::\n\n## Ethik\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n```{=html}\n<iframe width=\"780\" height=\"500\" src=\"https://www.societybyte.swiss/2023/06/07/traumatische-klickarbeit-die-menschen-hinter-chatgpt/\" title=\"Traumatische Klickarbeit\"></iframe>\n```\n\n:::\n\n::: {.column width=\"50%\"}\n- Auf Grund der grossen Menge von Trainingsdaten, die f√ºr Sprachmodelle ben√∂tigt werden, ist Qualit√§tskontrolle schwierig.\n- Diskriminierende oder beleidigende Aussagen werden von einem Chatbot generiert.\n- Solche Antworten k√∂nnen als unerw√ºnscht markiert werden.\n- Toxische Inhalte wie k√∂rperliche und sexuelle Gewalt, Suizide und Tierqu√§lerei, m√ºssen beim Trainieren aus den Antworten gefiltert werden. Dabei mussten angestellte Arbeitskr√§fte f√ºr weniger als 2 Dollar die Stunde teils schockierende Inhalte lesen. \n\nQuelle: [Traumatische Klickarbeit](https://www.societybyte.swiss/2023/06/07/traumatische-klickarbeit-die-menschen-hinter-chatgpt/)\n\n:::\n\n::::\n\n\n\n# Wie \"denkt\" ChatGPT? {background-color=\"#b48ead\"}\n\n::: {.absolute top=\"0\" left=\"100%\"}\n::: {.sectionhead}\n[1 2 3 4]{style=\"opacity:0.25\"} 5 [6 7 8]{style=\"opacity:0.25\"}\n:::\n:::\n\n## Wie generiert ChatGPT Text?\n\n- LLM: Gegeben einer Input-Sequenz (Kontext) von Tokens (W√∂rter, Teile von W√∂rtern, Satzzeichen, Emojis, etc.), was sind die wahrscheinlichsten n√§chsten Tokens?\n- Auto-regressiv: Ein Token wird generiert, wird dem Kontext hinzugef√ºgt.\n  \n![](../assets/images/autoregressive.png){width=600}\n<!-- ```{r}\ninclude_graphics(\"../assets/images/autoregressive.png\")\n``` -->\n\n- Der neue Kontext wird verwendet, um das n√§chste Token zu generieren, etc.\n- __Wichtig:__ Jedes Token erh√§lt gleich viel Zeit. Es gibt keine Tokens, die mehr oder weniger wichtig sind (Computation per Token ist konstant).\n- Weil jedes Token gleich gewichtet wird, kann es an jeder Stelle im Output zu \"ung√ºnstigen\" Pfaden f√ºhren.\n\n## Prompt\n\n- Der urspr√ºngliche Kontext wird __Prompt__ (Eingabetext) genannt.\n- Dieser ist entscheidend f√ºr die Qualit√§t der Antwort.\n\n:::{.callout-note}\n## Prompt Beispiel\n\n\"Was ist 89322/1313?\"\n\nvs. \n\n\"Was ist 89322/1313? Arbeite Schritt f√ºr Schritt.\"\n:::\n\n\n## Prompt\n\n::: {.cell hash='qualitaetszirkel-gesundheit_cache/revealjs/unnamed-chunk-15_bc66bd3ca17c91c01f844e022b5036dd'}\n::: {.cell-output-display}\n![](../assets/images/karpathy-thought-mutliple-attempts.png){width=1446}\n:::\n:::\n\n## Role-Playing Simulator\n\n> We can think of an LLM as a non-deterministic simulator capable of role-playing an infinity of characters, or, to put it another way, capable of stochastically generating an infinity of simulacra. \n\nQuelle: @shanahanRolePlayLargeLanguage2023\n\n- Bei jeder Interaktion mit ChatGPT wird ein Dialog neu simuliert.\n\n\n## Role-Playing Simulator\n\n![](../assets/images/simulator.png){width=800}\n\n\n## Role-Playing Simulator\n\n- Ein LLM ist keine Entit√§t mit Handlungsabsichten, sondern ein Simulator von m√∂glichen Konversationen.\n- ChatGPT hat kein Konzept von Wahrheit, sondern generiert Antworten, die plausibel sind.\n- Somit kann ChatGPT weder die Wahrheit sagen noch l√ºgen - diese Konzepte sind f√ºr ein LLM vorerst irrelevant.\n  \n## Was kann ChatGPT? \n\n\n::: {.cell hash='qualitaetszirkel-gesundheit_cache/revealjs/unnamed-chunk-16_d45cd79f4c210131eeca2d417f72a0c6'}\n::: {.cell-output-display}\n![](../assets/images/chain-of-thought.png){width=858}\n:::\n:::\n\n::: {.cell hash='qualitaetszirkel-gesundheit_cache/revealjs/unnamed-chunk-17_6b73cb6520c486bc4926c51cc48cfe12'}\n::: {.cell-output-display}\n![](../assets/images/karpathy-chain-of-thought.png){width=1446}\n:::\n:::\n\n\nWeitere Beispiele: @bubeckSparksArtificialGeneral2023\n\n\n::: {.notes}\nSehr viel, wenn richtig geprompted\n:::\n\n\n## Denkt ChatGPT?\n\n\n\n![](../assets/images/karpathy-human-vs-LLM-2.png)\n\n![](../assets/images/karpathy-human-vs-LLM-1.png)\n\n## System 1 vs System 2\n\n- [Thinking Fast and Slow](https://en.wikipedia.org/wiki/Thinking,_Fast_and_Slow)\n- System 1: schnell, instinktiv, automatisch\n\n- System 2: langsam, deliberativ, anstrengend\n\n\n::: {.cell hash='qualitaetszirkel-gesundheit_cache/revealjs/unnamed-chunk-18_a1fe6de112719820203586f9c4e06b0a'}\n::: {.cell-output-display}\n![](../assets/images/system-1-vs-system-2.png){width=731}\n:::\n:::\n\n\n\n\n## Prompt Engineering\n\n- Qualit√§t der Antwort h√§ngt sehr von der Qualit√§t des Prompts ab.\n- 2 M√∂glichkeiten, um die Qualit√§t der Antworten zu verbessern:\n\n  - __Incrementelle Prompts:__ Schritt f√ºr Schritt durch die Konversation f√ºhren (dialogisches Prompting).\n  - __Mega-Prompts:__ Alle Informationen auf einmal geben.\n\n- Am besten selber ausprobieren.\n\n\n## Mega-Prompt\n\n1. Rolle: Wer oder was wird simuliert?\n2. Aufgabe: Was ist zu tun?\n3. Arbeitschritte: Was ist in welcher Reihenfolge zu tun?\n4. Kontext, Einschr√§nkungen\n5. Ziel: Was soll am Ende herauskommen?\n6. Format: Wie soll das Ergebnis aussehen?\n\n:::{.callout-note}\n## Beispiel Hochschullehre: Feedback\n\"I want you to act as a harsh critic. Criticize what I will write to you and show me where my argumentation is lacking. Start by asking me what text I want to have feedback on. Then ask me questions about my context to create the best feedback possible. If you feel you have all the context necessary, think step by step when creating your feedback\" (Lenk-Ostendorf & Folgmann 2023)\n:::\n\n\n:::{.callout-tip}\n## Weitere Beispiele\n\n- OpenAI Discord Server [discord.com/invite/openai](discord.com/invite/openai)\n- [Prompting Guide](https://www.promptingguide.ai/)\n\n:::\n\n\n\n\n\n\n# Zuk√ºnftige Verwendungen von LLMs {background-color=\"#b48ead\"}\n\n::: {.absolute top=\"0\" left=\"100%\"}\n::: {.sectionhead}\n[1 2 3 4 5]{style=\"opacity:0.25\"} 6 [7 8]{style=\"opacity:0.25\"}\n:::\n:::\n\n## Plug-ins\n\n![](../assets/images/karpathy-tools-plugins.png)\n\n\n## Retrieval-augmented LLMs\n\n![](../assets/images/karpathy-retrieval-augmented.png)\n\n\n## Retrieval-augmented LLMs\n\nBeispiel: üëâüèº [Assistent der Virtuellen Akademie](https://virtuelleakademie.github.io/gpt-nano/pages/assistant.html) \n\n\n```{=html}\n<iframe\nsrc=\"https://www.chatbase.co/chatbot-iframe/RDbFWW85cxcCd9PEwV-uy\"\nwidth=\"100%\"\nheight=\"700\"\nframeborder=\"0\"\n></iframe>\n```\n\n\n\n# Wissenschaftliches Arbeiten {background-color=\"#b48ead\"}\n\n::: {.absolute top=\"0\" left=\"100%\"}\n::: {.sectionhead}\n[1 2 3 4 5 6]{style=\"opacity:0.25\"} 7 [8]{style=\"opacity:0.25\"}\n:::\n:::\n\n## Haltung der BFH\n\n- Technologien sollen dort, wo sie den Lernprozess unterst√ºtzen und praxisrelevant sind, in die Lehre einbezogen werden. \n- Studierende sollen lernen, Technologien kompetent einzusetzen und kritisch zu hinterfragen. Dies gilt uneingeschr√§nkt auch f√ºr ChatGPT und andere gleichgerichtete Tools.\n\n## Zitieren\n\n- Es existieren noch keine Richtlinien f√ºr das Zitieren von ChatGPT oder anderen KI-basierte Schreibtools.\n- ChatGPT ist rein rechtlich keine zitierf√§hige Quelle und damit auch nicht zitierpflichtig [@fleckPruefungsrechtlicheFragenChatGPT2023].\n- Aus der Orientierungshilfe: \"KI-basierte Schreibtools sind externe Quellen und m√ºssen daher im Sinne der wissenschaftlichen Integrit√§t immer, wie andere Quellen auch, zitiert werden, sofern ganze Textpassagen von ChatGPT benutzt werden. Falls mit dem Tool der eigene Text √ºberarbeitet wurde, muss ChatGPT als verwendetes Hilfsmittel angef√ºhrt werden.\"\n  \n:::{.callout-note}\n## M√∂glicher Pauschalverweis\n  \n\"Beim Verfassen der Arbeit habe ich das KI-gest√ºtzte Schreibwerkzeug ChatGPT zur Textoptimierung verwendet. W√∂rtlich aus dem Tool √ºbernommene Passagen wurden im Text als pers√∂nliche Kommunikation zitiert.\"\n:::\n\n## Plagiate und Detektion\n\n- Texte von ChatGPT werden jedes Mal individuell erstellt. Es handelt sich nicht um Plagiate. \n- Die klassischen Tools zur Aufdeckung von Plagiaten wie z.B. _TurnItIn_ funktionieren hier nicht.\n- Die BFH empfiehlt weiterhin, schriftliche Arbeiten mit der Plagiatserkennungssoftware Turnitin zu pr√ºfen. \n\n## Kompetenznachweise\n\n- Siehe [KI-basierte Schreibtools in der Lehre ‚Äì ChatGPT im Fokus](https://virtuelleakademie.notion.site/KI-in-der-Lehre-af068030108844c4834ef00824fd8da6?p=f671067195a94f2d8239931c09ae92ec&pm=s)\n- Beim Benutzen von KI-generierten Texten in Kompetenznachweisen ohne Deklaration oder Zitierung kann von einem Plagiat _im weiteren Sinne_ ausgegangen werden, welches das bisher etablierte Plagiatsverst√§ndnis im engeren Sinne erweitert.\n- __Open Book-Pr√ºfungen:__ KI-Tools m√ºssten explizit ausgeschlossen werden.\n- __Closed Book-Pr√ºfungen:__ KI-Tools k√∂nnen durch Einsatz von Safe Exam-Browser und [Lernstick](https://www.bfh.ch/de/forschung/forschungsbereiche/lernstick/) ausgeschlossen werden.\n- __Schriftliche Arbeiten:__ KI-Tools durch pauschalen Hilfsmittelverweis am Ende der Arbeit deklarieren.\n- __Alternative oder erg√§nzende Pr√ºfungsformen:__ praktische Pr√ºfungen, m√ºndliche Pr√ºfungen, Pr√§sentationen.\n\n## Rechtliche Aspekte\n\n- ChatGPT kann keine Urheberschaft und keine Autorenschaft beanspruchen, da dies nur nat√ºrliche Personen k√∂nnen.\n- Menschen k√∂nnen die Urheberschaft eines Textes beanspruchen, auch wenn sie auf Unterst√ºtzung durch ChatGPT zur√ºckgegriffen haben ‚Äì sofern sie eine wesentliche gestalterische Eigenleistung am Text erbracht haben.\n\nQuelle: @saldenDidaktischeUndRechtliche2023 \n\n\n## Datenschutz\n\n- Anonyme Nutzung von ChatGPT ist mit pers√∂nlichen Konto nicht m√∂glich (√ºber Handynummer identifizierbar).\n- Alle Eingaben und alle Antworten werden bei ChatGPT unverschl√ºsselt abgespeichert.\n- Daten liegen auf amerikanischen Servern und sind damit f√ºr amerikanische Ermittlungsbeh√∂rden grunds√§tzlich zug√§nglich.\n\n\n\n# Case Study: Seminararbeit mit KI-Unterst√ºtzung {background-color=\"#b48ead\"}\n\n::: {.absolute top=\"0\" left=\"100%\"}\n::: {.sectionhead}\n[1 2 3 4 5 6 7]{style=\"opacity:0.25\"} 8\n:::\n:::\n\n## Seminararbeit mit KI-Unterst√ºtzung\n\nLehrperson: Kerstin Denecke, Technik und Informatik, Institut f√ºr Medizininformatik \n\n1) __Elicit__ [Brainstorm research questions]: Idee f√ºr Forschungsfrage \n2) __ChatGPT:__ Feedback zu Fragestellungen, Verbesserungsvorschl√§ge\n3) __Elicit__ [Abstract summary]: Rechercheunterst√ºtzung\n4) __Consensus:__ Unterst√ºtzung f√ºr Belege in der Diskussion\n\n\n:::{.callout-note}\n## ChatGPT Prompt\n\nVerhalte dich wie eine wissenschaftliche Betreuungsperson in ihrer Sprechstunde. Du musst den aktuellen Stand meiner Hausarbeit √ºberpr√ºfen und kritisch beurteilen. Dazu evaluierst du meine Forschungsfrage und √§usserst konstruktive Kritik in Bezug auf deren St√§rken und Schw√§chen. Die Fragestellung lautet:\n\n\"Wie binden Therapeuten Chatbots in die Behandlung ein?\"\n\n:::\n\n# References {background-color=\"#2e3440\"}\n\n::: {#refs}\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
{"title":"Informationsanlass zu KI/ChatGPT","markdown":{"yaml":{"title":"Informationsanlass zu KI/ChatGPT","author":"Andrew Ellis","date":"last-modified","date-format":"DD MMMM, YYYY","bibliography":"../bibliography.bib","nocite":"@broschinskiGrafikenErklaertFunktioniert2023\n","format":{"revealjs":{"theme":"default","title-slide-attributes":{"data-background-image":"../assets/background-yellow.png","data-background-opacity":"1"},"footer":"<a href=\"https://virtuelleakademie.github.io/gpt-nano\">‚§¥Ô∏è KI/GPT in der Hochschule </a>","navigation-mode":"vertical","progress":true,"scrollable":true,"slide-number":true,"show-slide-number":"all","controls-layout":"bottom-right","controls-tutorial":true,"preview-links":"auto","chalkboard":true,"from":"markdown+emoji","code-fold":true,"code-summary":"Show code","code-tools":true,"menu":{"sticky":true,"keyboard":true,"autoOpen":true,"width":"normal","numbers":true,"markers":true}}}},"headingText":"Inhalt","headingAttr":{"id":"","classes":[],"keyvalue":[["background-color","#2e3440"]]},"containsRefs":true,"markdown":"\n\n```{r}\n#| warning: false\n#| message: false\nlibrary(knitr)\n```\n\n\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n\nHere‚Äôs What Happens When Your Lawyer Uses ChatGPT\n\n```{=html}\n<iframe width=\"780\" height=\"500\" src=\"https://simonwillison.net/2023/May/27/lawyer-chatgpt/\" title=\"ChatGPT: US lawyer admits using AI for case research\"></iframe>\n```\n:::\n\n::: {.column width=\"50%\"}\n\nThe Best Prompts For ChatGPT: The ultimate list\n\n```{=html}\n<iframe width=\"780\" height=\"500\" src=\"https://www.writingbeginner.com/best-prompts-for-chatgpt/\" title=\"Best prompts for ChatGPT\"></iframe>\n```\n:::\n::::\n\n\n1. Was ist k√ºnstliche Intelligenz?\n2. Was ist ChatGPT?\n3. Wie wurde ChatGPT trainiert?\n4. Energieverbrauch, Bias, Ethik\n5. Wie \"denkt\" ChatGPT?\n6. Zuk√ºnftige Verwendungen von LLMs\n7. Wissenschaftliches Arbeiten\n\n<!-- ::: footer\n<a href=\"https://virtuelleakademie.github.io/gpt-nano\">üè† KI/GPT in der Hochschule</a>\n::: -->\n\n\n\n# Was ist k√ºnstliche Intelligenz? {background-color=\"#ebcb8b\"}\n\n::: {.absolute top=\"0\" left=\"100%\"}\n::: {.sectionhead}\n1 [2 3 4 5 6 7]{style=\"opacity:0.25\"}\n:::\n:::\n\n## Was ist K√ºnstliche Intelligenz?\n\n\n```{r}\n#| fig-cap: \"Quelle: [derbund.ch/so-funktioniert-kuenstliche-intelligenz-599276436215](https://www.derbund.ch/so-funktioniert-kuenstliche-intelligenz-599276436215)\"\ninclude_graphics(\"../assets/images/was-ist-KI.png\")\n```\n\n\n::: {.notes}\nSpeaker notes go here.\n:::\n\n\n## Machine Learning\n\n- Regelbasierte Systeme m√ºssen programmiert werden.\n- ML Modelle lernen implizit, d.h. ohne Regeln einprogrammiert zu bekommen.\n\n\n- Wichtige Begriffe:\n  - __Trainingsdaten:__ Modelle werden mit Daten gef√ºttert, und Parameter des Modells werden so eingestellt, dass das Modell m√∂glichst \"gut\" ist.\n  - __Supervised learning:__ Aufgabe ist bekannt, z.B. Bilder - klassifizieren.\n  - __Unsupervised learning:__ Unbekannte Muster entdecken.\n  - __Reinforcement learning:__ Ziel ist vorgegeben, Modell lernt durch Feedback (Belohnung) wie Ziel erreicht werden kann.\n\n> We have to learn the bitter lesson that building in how we think we think does not work in the long run. We should stop trying to find simple ways to think about space, objects, multiple agents, or symmetries... instead we should build in only the meta-methods that can find and capture this arbitrary complexity. We want AI agents that can discover like we can, not which contain what we have discovered [@suttonBitterLesson2019].\n\n\n## Supervised learning\n\n```{r}\nknitr::include_graphics(\"../assets/images/cats-dogs.png\")\n```\n__Bilder von Hunden und Katzen klassifizeren:__ Was sind die Merkmale, die Hunde von Katzen unterscheiden?\n\n\n\n\n## Reinforcement learning\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n```{r}\nknitr::include_graphics(\"../assets/images/cartpole.gif\")\n```\n:::\n\n::: {.column width=\"50%\"}\n\n```{r}\nknitr::include_graphics(\"../assets/images/RL-agent.png\")\n```\n:::\n::::\n\n \n::: aside\nBeispiel f√ºr RL Model: [AlphaGo](https://www.deepmind.com/research/highlighted-research/alphago) ist das erste Computerprogramm, das einen professionellen (menschlichen) [Go](https://de.wikipedia.org/wiki/Go_(Spiel))-Spieler besiegt hat.\n:::\n\n::: {.notes}\n- Ein \"Agent\" lernt durch Feedback (Belohnung) wie ein Ziel erreicht werden kann.\n:::\n\n\n\n\n\n\n# Was ist ChatGPT? {background-color=\"#ebcb8b\"}\n\n::: {.absolute top=\"0\" left=\"100%\"}\n::: {.sectionhead}\n[1]{style=\"opacity:0.25\"} 2 [3 4 5 6 7]{style=\"opacity:0.25\"}\n:::\n:::\n\n## Natural Language Processing \n\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n- Speech recognition\n- Text-to-speech synthesis\n- Machine translation\n- Information extraction\n- Information retrieval\n- Question answering\n\n:::\n\n::: {.column width=\"50%\"}\n- Sentiment analysis\n  - üòä I love this movie!\n  - üòê This movie is ok.\n  - üò† This movie is terrible!\n  \n:::\n\n::::\n\n\n\n## Tokenization\n\n```{r}\n#| fig-cap: \"Quelle: [State of ChatGPT](https://build.microsoft.com/en-US/sessions/db3f4859-cd30-4445-a0cd-553c3304f8e2?source=sessions)\"\nknitr::include_graphics(\"../assets/images/karpathy-tokenization.png\")\n```\n\n## Embeddings\n- Numerische Tokens werden in einem hochdimensionalen Vektorraum abgebildet.\n- Distanz zwischen Vektoren misst √Ñhnlichkeit zwischen Tokens.\n\n```{r}\n#| fig-cap: \"Quelle: @wolframWhatChatGPTDoing2023\"\nknitr::include_graphics(\"../assets/images/wolfram-embeddings.png\")\n```\n\n```{r}\n#| fig-cap: \"Quelle: [So funktioniert ChatGPT](https://www.golem.de/news/kuenstliche-intelligenz-so-funktioniert-chatgpt-2302-171644.html)\"\nknitr::include_graphics(\"../assets/images/3_Wortgruppen_im_sem_Raum.png\")\n```\n\n## ChatGPT\n\nBesteht aus 2 Modellen:\n\n\n- __Large language model (LLM):__ GPT-3.5 oder GPT-4 (generative pre-trained transformer): das eigentliche Sprachmodell\n\n- __Assistant:__ Ein f√ºr Dialoge spezialisiertes Modell\n\n\n## LLM\n\nAufgabe eines LLMs: \"auto-regressive next word prediction\" (eigentlich \"token prediction\"):\n\n$$ P(w_{w+1} | w_1, w_2, ..., w_t) $$\n\n- Das n√§chste Wort wird vorhergesagt, basierend auf den vorherigen Worten. \n- Diese vorherigen W√∂rter werden als \"context\" bezeichnet.\n\n```{r}\nknitr::include_graphics(\"../assets/images/word-probs.png\")\nknitr::include_graphics(\"../assets/images/gpt-2-autoregression-2.gif\")\n```\n\n## Assistant\n\n- LLM produziert Text, aber nicht menschliche Konversationen.\n- Weiteres Training ist erforderlich, damit das Modell lernt, wie ein Mensch \"Konversationen\" zu f√ºhren.\n\n\n\n\n\n# Wie wurde ChatGPT trainiert? {background-color=\"#ebcb8b\"}\n\n::: {.absolute top=\"0\" left=\"100%\"}\n::: {.sectionhead}\n[1 2]{style=\"opacity:0.25\"} 3 [4 5 6 7]{style=\"opacity:0.25\"}\n:::\n:::\n\n\n## Daten\n\n```{r}\nknitr::include_graphics(\"../assets/images/karpathy-training-data.png\")\n```\n\n## Methoden\n\n```{r}\nknitr::include_graphics(\"../assets/images/karpathy-training-pipeline-1.png\")\n```\n\n::: {.notes}\nWe trained this model using Reinforcement Learning from Human Feedback (RLHF), using the same methods as InstructGPT, but with slight differences in the data collection setup. We trained an initial model using supervised fine-tuning: human AI trainers provided conversations in which they played both sides‚Äîthe user and an AI assistant. We gave the trainers access to model-written suggestions to help them compose their responses. We mixed this new dialogue dataset with the InstructGPT dataset, which we transformed into a dialogue format.\n\nTo create a reward model for reinforcement learning, we needed to collect comparison data, which consisted of two or more model responses ranked by quality. To collect this data, we took conversations that AI trainers had with the chatbot. We randomly selected a model-written message, sampled several alternative completions, and had AI trainers rank them. Using these reward models, we can fine-tune the model using Proximal Policy Optimization. We performed several iterations of this process.\n:::\n\n## Pre-training\n\n```{r}\nknitr::include_graphics(\"../assets/images/karpathy-pretraining-1.png\")\n```\n\n## Pre-training\n\n```{r}  \nknitr::include_graphics(\"../assets/images/karpathy-training-process.png\")\n```\n\n\n\n## Reinforcement Learning from Human Feedback (RLHF)\n\nBenutzt  Feedback vom Menschen um \"schlechte\" Outputs zu minimieren.\n\n\n```{r}\n#| fig-cap: \"Quelle: [openai.com/blog/chatgpt](https://openai.com/blog/chatgpt)\"\nknitr::include_graphics(\"../assets/images/RLHF.png\")\n```\n\n\n \n\n# Energieverbrauch, Bias, Ethik {background-color=\"#ebcb8b\"}\n\n::: {.absolute top=\"0\" left=\"100%\"}\n::: {.sectionhead}\n[1 2 3]{style=\"opacity:0.25\"} 4 [5 6 7]{style=\"opacity:0.25\"}\n:::\n:::\n\n## Energieverbrauch\n\n- __Training:__ \"What we do know is that training ChatGPT used $1.287$ GWh, roughly equivalent to the consumption of 120 US homes for a year.\" Quelle: [Heating up: how much energy does AI use?](https://techhq.com/2023/03/data-center-energy-usage-chatgpt/)\n\n- @pattersonCarbonEmissionsLarge2022 sch√§tzen die Trainingskosten auf 502 Tonnen $\\text{CO}_2$ (RLHF w√ºrde etwas mehr kosten, ca. 1% der urspr√ºnglichen Kosten).\n\n- __Benutzung:__ 7 Tonnen $\\text{CO}_2$ pro Tag (Ende Februar). Quelle: [How much energy does ChatGPT use?](https://xcorr.net/2023/04/08/how-much-energy-does-chatgpt-use/)\n  \n- Der Energieverbrauch von ChatGPT ist equivalent zu 400-800 US Haushalten. Das ist betr√§chtlich, im Vergleich zu z.B. Kryptow√§hrungen eher gering.\n\n\n\n## Bias\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n```{=html}\n<iframe width=\"780\" height=\"500\" src=\"https://www.societybyte.swiss/2022/12/22/hi-chatgpt-hast-du-vorurteile/\" title=\"Vorurteile\"></iframe>\n```\n:::\n\n::: {.column width=\"50%\"}\n\n- Da LLMs von Texten lernen, die von Menschen geschrieben wurden, k√∂nnen sie auch Vorurteile lernen.\n\nQuelle: [Hast du Vorurteile?](https://www.societybyte.swiss/2022/12/22/hi-chatgpt-hast-du-vorurteile/)\n:::\n\n::::\n\n## Ethik\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n```{=html}\n<iframe width=\"780\" height=\"500\" src=\"https://www.societybyte.swiss/2023/06/07/traumatische-klickarbeit-die-menschen-hinter-chatgpt/\" title=\"Traumatische Klickarbeit\"></iframe>\n```\n:::\n\n::: {.column width=\"50%\"}\n- Auf Grund der grossen Menge von Trainingsdaten, die f√ºr Sprachmodelle ben√∂tigt werden, ist Qualit√§tskontrolle schwierig.\n- Diskriminierende oder beleidigende Aussagen werden von einem Chatbot generiert.\n- Solche Antworten k√∂nnen als unerw√ºnscht markiert werden.\n- Toxische Inhalte wie k√∂rperliche und sexuelle Gewalt, Suizide und Tierqu√§lerei, m√ºssen beim Trainieren aus den Antworten gefiltert werden. Dabei mussten angestellte Arbeitskr√§fte f√ºr weniger als 2 Dollar die Stunde teils schockierende Inhalte lesen. \n\nQuelle: [Traumatische Klickarbeit](https://www.societybyte.swiss/2023/06/07/traumatische-klickarbeit-die-menschen-hinter-chatgpt/)\n\n:::\n\n::::\n\n## Use Cases\n\n```{r}\ninclude_graphics(\"../assets/images/karpathy-bias.png\")\n```\n\n\n\n# Wie \"denkt\" ChatGPT? {background-color=\"#ebcb8b\"}\n\n::: {.absolute top=\"0\" left=\"100%\"}\n::: {.sectionhead}\n[1 2 3 4]{style=\"opacity:0.25\"} 5 [6 7]{style=\"opacity:0.25\"}\n:::\n:::\n\n## Wie generiert ChatGPT Text?\n\n\n\n- LLM: Gegeben eine Input-Sequenz von Tokens (W√∂rter, Teile von W√∂rtern, Satzzeichen, Emojis, etc.), was sind die wahrscheinlichsten n√§chsten Tokens?\n- Auto-regressiv: Ein Token wird generiert, wird dem Kontext hinzugef√ºgt.\n  \n![](../assets/images/autoregressive.png){width=600}\n<!-- ```{r}\ninclude_graphics(\"../assets/images/autoregressive.png\")\n``` -->\n\n- Der neue Kontext wird verwendet, um das n√§chste Token zu generieren, etc.\n- __Wichtig:__ Jedes Token erh√§lt gleich viel Zeit. Es gibt keine Tokens, die mehr oder weniger wichtig sind (Computation per Token ist konstant).\n\n\n## Prompt\n\n- Der urspr√ºngliche Kontext wird __Prompt__ (Eingabetext) genannt.\n- Dieser ist entscheidend f√ºr die Qualit√§t der Antwort.\n- Weil jedes Token gleich gewichtet wird, kann es an jeder Stelle im Ouptut zu \"ung√ºnstigen\" Pfaden f√ºhren.\n\n\n## Prompt\n\n```{r}\ninclude_graphics(\"../assets/images/karpathy-thought-mutliple-attempts.png\")\n```\n\n## Role-Playing Simulator\n\n> We can think of an LLM as a non-deterministic simulator capable of role-playing an infinity of characters, or, to put it another way, capable of stochastically generating an infinity of simulacra. \n\nQuelle: @shanahanRolePlayLargeLanguage2023\n\n- Bei jeder Interaktion mit ChatGPT wird neu simuliert.\n\n\n## Role-Playing Simulator\n\n![](../assets/images/simulator.png){width=800}\n\n\n## Role-Playing Simulator\n\n- Ein LLM ist keine Entit√§t mit Handlungsabsichten, sondern ein Simulator von m√∂glichen Konversationen.\n- ChatGPT hat kein Konzept von Wahrheit, sondern generiert Antworten, die plausibel sind.\n- Somit kann ChatGPT weder die Wahrheit sagen noch l√ºgen - diese Konzepte sind f√ºr ein LLM vorerst irrelevant.\n  \n## Was kann ChatGPT? \n\n```{r}\ninclude_graphics(\"../assets/images/chain-of-thought.png\")\n```\n\n```{r}\ninclude_graphics(\"../assets/images/karpathy-chain-of-thought.png\")\n```\n\nWeitere Beispiele: @bubeckSparksArtificialGeneral2023\n\n\n::: {.notes}\nSehr viel, wenn richtig geprompted\n:::\n\n\n## Denkt ChatGPT?\n\n\n\n![](../assets/images/karpathy-human-vs-LLM-2.png)\n\n![](../assets/images/karpathy-human-vs-LLM-1.png)\n\n## System 1 vs System 2\n\n- [Thinking Fast and Slow](https://en.wikipedia.org/wiki/Thinking,_Fast_and_Slow)\n- System 1: schnell, instinktiv, automatisch\n\n- System 2: langsam, deliberativ, anstrengend\n\n```{r}\ninclude_graphics(\"../assets/images/system-1-vs-system-2.png\")\n```\n\n\n\n## Prompt Engineering\n\n- Qualit√§t der Antwort h√§ngt sehr von der Qualit√§t des Prompts ab.\n- 2 M√∂glichkeiten, um die Qualit√§t der Antworten zu verbessern:\n\n  - Incrementelle Prompts: Schritt f√ºr Schritt durch die Konversation f√ºhren (dialogisches Prompting).\n  - Mega-Prompts: Alle Informationen auf einmal geben.\n\n- Am besten selber ausprobieren.\n\n\n## Mega-Prompt\n\n1. Rolle: Wer oder was wird simuliert?\n2. Aufgabe: Was ist zu tun?\n3. Arbeitschritte: Was ist in welcher Reihenfolge zu tun?\n4. Kontext, Einschr√§nkungen\n5. Ziel: Was soll am Ende herauskommen?\n6. Format: Wie soll das Ergebnis aussehen?\n\n:::{.callout-note}\n## Beispiel Hochschullehre: Feedback\n\"I want you to act as a harsh critic. Criticize what I will write to you and show me where my argumentation is lacking. Start by ask- ing me what text I want to have feedback on. Then ask me questions about my context to create the best feedback possible. If you feel you have all the context necessary, think step by step when creating your feedback\" (Lenk-Ostendorf & Folgmann 2023)\n:::\n\n\n:::{.callout-tip}\n## Weitere Beispiele\n\n- OpenAI Discord Server [discord.com/invite/openai](discord.com/invite/openai)\n- [Prompting Guide](https://www.promptingguide.ai/)\n\n:::\n\n\n\n\n\n\n# Zuk√ºnftige Verwendungen von LLMs {background-color=\"#ebcb8b\"}\n\n::: {.absolute top=\"0\" left=\"100%\"}\n::: {.sectionhead}\n[1 2 3 4 5]{style=\"opacity:0.25\"} 6 [7]{style=\"opacity:0.25\"}\n:::\n:::\n\n## Plug-ins\n\n![](../assets/images/karpathy-tools-plugins.png)\n\n\n## Retrieval-augmented LLMs\n\n![](../assets/images/karpathy-retrieval-augmented.png)\n\n\n## Retrieval-augmented LLMs\n\nBeispiel: Assistant f√ºr KI in der Hochschullehre\n\n```{=html}\n<iframe\nsrc=\"https://www.chatbase.co/chatbot-iframe/RDbFWW85cxcCd9PEwV-uy\"\nwidth=\"100%\"\nheight=\"700\"\nframeborder=\"0\"\n></iframe>\n```\n\n# Wissenschaftliches Arbeiten {background-color=\"#ebcb8b\"}\n\n::: {.absolute top=\"0\" left=\"100%\"}\n::: {.sectionhead}\n[1 2 3 4 5 6]{style=\"opacity:0.25\"} 7\n:::\n:::\n\n## Zitieren\n\n- Es existieren noch keine Richtlinien f√ºr das Zitieren von ChatGPT oder anderen KI-basierte Schreibtools.\n- ChatGPT ist rein rechtlich keine zitierf√§hige Quelle und damit auch nicht zitierpflichtig [@fleckPruefungsrechtlicheFragenChatGPT2023].\n  \n:::{.callout-note}\n## M√∂glicher Pauschalverweis\n  \n\"Beim Verfassen der Arbeit habe ich das KI-gest√ºtzte Schreibwerkzeug ChatGPT zur Textoptimierung verwendet. W√∂rtlich aus dem Tool √ºbernommene Passagen wurden im Text als pers√∂nliche Kommunikation zitiert.\"\n:::\n\n## Plagiate und Detektion\n\n- Texte von ChatGPT werden jedes Mal individuell erstellt. Es handelt sich nicht um Plagiate. \n- Die klassischen Tools zur Aufdeckung von Plagiaten wie z.B. _TurnItIn_ funktionieren hier nicht.\n\n\n## Kompetenznachweise\n\n- Siehe [KI-basierte Schreibtools in der Lehre ‚Äì ChatGPT im Fokus](https://virtuelleakademie.notion.site/KI-in-der-Lehre-af068030108844c4834ef00824fd8da6?p=f671067195a94f2d8239931c09ae92ec&pm=s)\n\n## Rechtliche Aspekte\n\n- ChatGPT kann keine Urheberschaft und keine Autorenschaft beanspruchen, da dies nur nat√ºrliche Personen k√∂nnen.\n- Menschen k√∂nnen die Urheberschaft eines Textes beanspruchen, auch wenn sie auf Unterst√ºtzung durch ChatGPT zur√ºckgegriffen haben ‚Äì sofern sie eine wesentliche gestalterische Eigenleistung am Text erbracht haben.\n\nQuelle: @saldenDidaktischeUndRechtliche2023 \n\n\n## Datenschutz\n\n- Anonyme Nutzung von ChatGPT ist mit pers√∂nlichen Konto nicht m√∂glich (√ºber Handynummer identifizierbar).\n- Alle Eingaben und alle Antworten werden bei ChatGPT unverschl√ºsselt abgespeichert.\n- Daten liegen auf amerikanischen Servern und sind damit f√ºr amerikanische Ermittlungsbeh√∂rden grunds√§tzlich zug√§nglich.\n\n\n# References {background-color=\"#2e3440\"}\n\n::: {#refs}\n:::\n","srcMarkdownNoYaml":"\n\n```{r}\n#| warning: false\n#| message: false\nlibrary(knitr)\n```\n\n\n#  {background-color=\"#2e3440\"}\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n\nHere‚Äôs What Happens When Your Lawyer Uses ChatGPT\n\n```{=html}\n<iframe width=\"780\" height=\"500\" src=\"https://simonwillison.net/2023/May/27/lawyer-chatgpt/\" title=\"ChatGPT: US lawyer admits using AI for case research\"></iframe>\n```\n:::\n\n::: {.column width=\"50%\"}\n\nThe Best Prompts For ChatGPT: The ultimate list\n\n```{=html}\n<iframe width=\"780\" height=\"500\" src=\"https://www.writingbeginner.com/best-prompts-for-chatgpt/\" title=\"Best prompts for ChatGPT\"></iframe>\n```\n:::\n::::\n\n# Inhalt {background-color=\"#2e3440\"}\n\n1. Was ist k√ºnstliche Intelligenz?\n2. Was ist ChatGPT?\n3. Wie wurde ChatGPT trainiert?\n4. Energieverbrauch, Bias, Ethik\n5. Wie \"denkt\" ChatGPT?\n6. Zuk√ºnftige Verwendungen von LLMs\n7. Wissenschaftliches Arbeiten\n\n<!-- ::: footer\n<a href=\"https://virtuelleakademie.github.io/gpt-nano\">üè† KI/GPT in der Hochschule</a>\n::: -->\n\n\n\n# Was ist k√ºnstliche Intelligenz? {background-color=\"#ebcb8b\"}\n\n::: {.absolute top=\"0\" left=\"100%\"}\n::: {.sectionhead}\n1 [2 3 4 5 6 7]{style=\"opacity:0.25\"}\n:::\n:::\n\n## Was ist K√ºnstliche Intelligenz?\n\n\n```{r}\n#| fig-cap: \"Quelle: [derbund.ch/so-funktioniert-kuenstliche-intelligenz-599276436215](https://www.derbund.ch/so-funktioniert-kuenstliche-intelligenz-599276436215)\"\ninclude_graphics(\"../assets/images/was-ist-KI.png\")\n```\n\n\n::: {.notes}\nSpeaker notes go here.\n:::\n\n\n## Machine Learning\n\n- Regelbasierte Systeme m√ºssen programmiert werden.\n- ML Modelle lernen implizit, d.h. ohne Regeln einprogrammiert zu bekommen.\n\n\n- Wichtige Begriffe:\n  - __Trainingsdaten:__ Modelle werden mit Daten gef√ºttert, und Parameter des Modells werden so eingestellt, dass das Modell m√∂glichst \"gut\" ist.\n  - __Supervised learning:__ Aufgabe ist bekannt, z.B. Bilder - klassifizieren.\n  - __Unsupervised learning:__ Unbekannte Muster entdecken.\n  - __Reinforcement learning:__ Ziel ist vorgegeben, Modell lernt durch Feedback (Belohnung) wie Ziel erreicht werden kann.\n\n> We have to learn the bitter lesson that building in how we think we think does not work in the long run. We should stop trying to find simple ways to think about space, objects, multiple agents, or symmetries... instead we should build in only the meta-methods that can find and capture this arbitrary complexity. We want AI agents that can discover like we can, not which contain what we have discovered [@suttonBitterLesson2019].\n\n\n## Supervised learning\n\n```{r}\nknitr::include_graphics(\"../assets/images/cats-dogs.png\")\n```\n__Bilder von Hunden und Katzen klassifizeren:__ Was sind die Merkmale, die Hunde von Katzen unterscheiden?\n\n\n\n\n## Reinforcement learning\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n```{r}\nknitr::include_graphics(\"../assets/images/cartpole.gif\")\n```\n:::\n\n::: {.column width=\"50%\"}\n\n```{r}\nknitr::include_graphics(\"../assets/images/RL-agent.png\")\n```\n:::\n::::\n\n \n::: aside\nBeispiel f√ºr RL Model: [AlphaGo](https://www.deepmind.com/research/highlighted-research/alphago) ist das erste Computerprogramm, das einen professionellen (menschlichen) [Go](https://de.wikipedia.org/wiki/Go_(Spiel))-Spieler besiegt hat.\n:::\n\n::: {.notes}\n- Ein \"Agent\" lernt durch Feedback (Belohnung) wie ein Ziel erreicht werden kann.\n:::\n\n\n\n\n\n\n# Was ist ChatGPT? {background-color=\"#ebcb8b\"}\n\n::: {.absolute top=\"0\" left=\"100%\"}\n::: {.sectionhead}\n[1]{style=\"opacity:0.25\"} 2 [3 4 5 6 7]{style=\"opacity:0.25\"}\n:::\n:::\n\n## Natural Language Processing \n\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n- Speech recognition\n- Text-to-speech synthesis\n- Machine translation\n- Information extraction\n- Information retrieval\n- Question answering\n\n:::\n\n::: {.column width=\"50%\"}\n- Sentiment analysis\n  - üòä I love this movie!\n  - üòê This movie is ok.\n  - üò† This movie is terrible!\n  \n:::\n\n::::\n\n\n\n## Tokenization\n\n```{r}\n#| fig-cap: \"Quelle: [State of ChatGPT](https://build.microsoft.com/en-US/sessions/db3f4859-cd30-4445-a0cd-553c3304f8e2?source=sessions)\"\nknitr::include_graphics(\"../assets/images/karpathy-tokenization.png\")\n```\n\n## Embeddings\n- Numerische Tokens werden in einem hochdimensionalen Vektorraum abgebildet.\n- Distanz zwischen Vektoren misst √Ñhnlichkeit zwischen Tokens.\n\n```{r}\n#| fig-cap: \"Quelle: @wolframWhatChatGPTDoing2023\"\nknitr::include_graphics(\"../assets/images/wolfram-embeddings.png\")\n```\n\n```{r}\n#| fig-cap: \"Quelle: [So funktioniert ChatGPT](https://www.golem.de/news/kuenstliche-intelligenz-so-funktioniert-chatgpt-2302-171644.html)\"\nknitr::include_graphics(\"../assets/images/3_Wortgruppen_im_sem_Raum.png\")\n```\n\n## ChatGPT\n\nBesteht aus 2 Modellen:\n\n\n- __Large language model (LLM):__ GPT-3.5 oder GPT-4 (generative pre-trained transformer): das eigentliche Sprachmodell\n\n- __Assistant:__ Ein f√ºr Dialoge spezialisiertes Modell\n\n\n## LLM\n\nAufgabe eines LLMs: \"auto-regressive next word prediction\" (eigentlich \"token prediction\"):\n\n$$ P(w_{w+1} | w_1, w_2, ..., w_t) $$\n\n- Das n√§chste Wort wird vorhergesagt, basierend auf den vorherigen Worten. \n- Diese vorherigen W√∂rter werden als \"context\" bezeichnet.\n\n```{r}\nknitr::include_graphics(\"../assets/images/word-probs.png\")\nknitr::include_graphics(\"../assets/images/gpt-2-autoregression-2.gif\")\n```\n\n## Assistant\n\n- LLM produziert Text, aber nicht menschliche Konversationen.\n- Weiteres Training ist erforderlich, damit das Modell lernt, wie ein Mensch \"Konversationen\" zu f√ºhren.\n\n\n\n\n\n# Wie wurde ChatGPT trainiert? {background-color=\"#ebcb8b\"}\n\n::: {.absolute top=\"0\" left=\"100%\"}\n::: {.sectionhead}\n[1 2]{style=\"opacity:0.25\"} 3 [4 5 6 7]{style=\"opacity:0.25\"}\n:::\n:::\n\n\n## Daten\n\n```{r}\nknitr::include_graphics(\"../assets/images/karpathy-training-data.png\")\n```\n\n## Methoden\n\n```{r}\nknitr::include_graphics(\"../assets/images/karpathy-training-pipeline-1.png\")\n```\n\n::: {.notes}\nWe trained this model using Reinforcement Learning from Human Feedback (RLHF), using the same methods as InstructGPT, but with slight differences in the data collection setup. We trained an initial model using supervised fine-tuning: human AI trainers provided conversations in which they played both sides‚Äîthe user and an AI assistant. We gave the trainers access to model-written suggestions to help them compose their responses. We mixed this new dialogue dataset with the InstructGPT dataset, which we transformed into a dialogue format.\n\nTo create a reward model for reinforcement learning, we needed to collect comparison data, which consisted of two or more model responses ranked by quality. To collect this data, we took conversations that AI trainers had with the chatbot. We randomly selected a model-written message, sampled several alternative completions, and had AI trainers rank them. Using these reward models, we can fine-tune the model using Proximal Policy Optimization. We performed several iterations of this process.\n:::\n\n## Pre-training\n\n```{r}\nknitr::include_graphics(\"../assets/images/karpathy-pretraining-1.png\")\n```\n\n## Pre-training\n\n```{r}  \nknitr::include_graphics(\"../assets/images/karpathy-training-process.png\")\n```\n\n\n\n## Reinforcement Learning from Human Feedback (RLHF)\n\nBenutzt  Feedback vom Menschen um \"schlechte\" Outputs zu minimieren.\n\n\n```{r}\n#| fig-cap: \"Quelle: [openai.com/blog/chatgpt](https://openai.com/blog/chatgpt)\"\nknitr::include_graphics(\"../assets/images/RLHF.png\")\n```\n\n\n \n\n# Energieverbrauch, Bias, Ethik {background-color=\"#ebcb8b\"}\n\n::: {.absolute top=\"0\" left=\"100%\"}\n::: {.sectionhead}\n[1 2 3]{style=\"opacity:0.25\"} 4 [5 6 7]{style=\"opacity:0.25\"}\n:::\n:::\n\n## Energieverbrauch\n\n- __Training:__ \"What we do know is that training ChatGPT used $1.287$ GWh, roughly equivalent to the consumption of 120 US homes for a year.\" Quelle: [Heating up: how much energy does AI use?](https://techhq.com/2023/03/data-center-energy-usage-chatgpt/)\n\n- @pattersonCarbonEmissionsLarge2022 sch√§tzen die Trainingskosten auf 502 Tonnen $\\text{CO}_2$ (RLHF w√ºrde etwas mehr kosten, ca. 1% der urspr√ºnglichen Kosten).\n\n- __Benutzung:__ 7 Tonnen $\\text{CO}_2$ pro Tag (Ende Februar). Quelle: [How much energy does ChatGPT use?](https://xcorr.net/2023/04/08/how-much-energy-does-chatgpt-use/)\n  \n- Der Energieverbrauch von ChatGPT ist equivalent zu 400-800 US Haushalten. Das ist betr√§chtlich, im Vergleich zu z.B. Kryptow√§hrungen eher gering.\n\n\n\n## Bias\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n```{=html}\n<iframe width=\"780\" height=\"500\" src=\"https://www.societybyte.swiss/2022/12/22/hi-chatgpt-hast-du-vorurteile/\" title=\"Vorurteile\"></iframe>\n```\n:::\n\n::: {.column width=\"50%\"}\n\n- Da LLMs von Texten lernen, die von Menschen geschrieben wurden, k√∂nnen sie auch Vorurteile lernen.\n\nQuelle: [Hast du Vorurteile?](https://www.societybyte.swiss/2022/12/22/hi-chatgpt-hast-du-vorurteile/)\n:::\n\n::::\n\n## Ethik\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n```{=html}\n<iframe width=\"780\" height=\"500\" src=\"https://www.societybyte.swiss/2023/06/07/traumatische-klickarbeit-die-menschen-hinter-chatgpt/\" title=\"Traumatische Klickarbeit\"></iframe>\n```\n:::\n\n::: {.column width=\"50%\"}\n- Auf Grund der grossen Menge von Trainingsdaten, die f√ºr Sprachmodelle ben√∂tigt werden, ist Qualit√§tskontrolle schwierig.\n- Diskriminierende oder beleidigende Aussagen werden von einem Chatbot generiert.\n- Solche Antworten k√∂nnen als unerw√ºnscht markiert werden.\n- Toxische Inhalte wie k√∂rperliche und sexuelle Gewalt, Suizide und Tierqu√§lerei, m√ºssen beim Trainieren aus den Antworten gefiltert werden. Dabei mussten angestellte Arbeitskr√§fte f√ºr weniger als 2 Dollar die Stunde teils schockierende Inhalte lesen. \n\nQuelle: [Traumatische Klickarbeit](https://www.societybyte.swiss/2023/06/07/traumatische-klickarbeit-die-menschen-hinter-chatgpt/)\n\n:::\n\n::::\n\n## Use Cases\n\n```{r}\ninclude_graphics(\"../assets/images/karpathy-bias.png\")\n```\n\n\n\n# Wie \"denkt\" ChatGPT? {background-color=\"#ebcb8b\"}\n\n::: {.absolute top=\"0\" left=\"100%\"}\n::: {.sectionhead}\n[1 2 3 4]{style=\"opacity:0.25\"} 5 [6 7]{style=\"opacity:0.25\"}\n:::\n:::\n\n## Wie generiert ChatGPT Text?\n\n\n\n- LLM: Gegeben eine Input-Sequenz von Tokens (W√∂rter, Teile von W√∂rtern, Satzzeichen, Emojis, etc.), was sind die wahrscheinlichsten n√§chsten Tokens?\n- Auto-regressiv: Ein Token wird generiert, wird dem Kontext hinzugef√ºgt.\n  \n![](../assets/images/autoregressive.png){width=600}\n<!-- ```{r}\ninclude_graphics(\"../assets/images/autoregressive.png\")\n``` -->\n\n- Der neue Kontext wird verwendet, um das n√§chste Token zu generieren, etc.\n- __Wichtig:__ Jedes Token erh√§lt gleich viel Zeit. Es gibt keine Tokens, die mehr oder weniger wichtig sind (Computation per Token ist konstant).\n\n\n## Prompt\n\n- Der urspr√ºngliche Kontext wird __Prompt__ (Eingabetext) genannt.\n- Dieser ist entscheidend f√ºr die Qualit√§t der Antwort.\n- Weil jedes Token gleich gewichtet wird, kann es an jeder Stelle im Ouptut zu \"ung√ºnstigen\" Pfaden f√ºhren.\n\n\n## Prompt\n\n```{r}\ninclude_graphics(\"../assets/images/karpathy-thought-mutliple-attempts.png\")\n```\n\n## Role-Playing Simulator\n\n> We can think of an LLM as a non-deterministic simulator capable of role-playing an infinity of characters, or, to put it another way, capable of stochastically generating an infinity of simulacra. \n\nQuelle: @shanahanRolePlayLargeLanguage2023\n\n- Bei jeder Interaktion mit ChatGPT wird neu simuliert.\n\n\n## Role-Playing Simulator\n\n![](../assets/images/simulator.png){width=800}\n\n\n## Role-Playing Simulator\n\n- Ein LLM ist keine Entit√§t mit Handlungsabsichten, sondern ein Simulator von m√∂glichen Konversationen.\n- ChatGPT hat kein Konzept von Wahrheit, sondern generiert Antworten, die plausibel sind.\n- Somit kann ChatGPT weder die Wahrheit sagen noch l√ºgen - diese Konzepte sind f√ºr ein LLM vorerst irrelevant.\n  \n## Was kann ChatGPT? \n\n```{r}\ninclude_graphics(\"../assets/images/chain-of-thought.png\")\n```\n\n```{r}\ninclude_graphics(\"../assets/images/karpathy-chain-of-thought.png\")\n```\n\nWeitere Beispiele: @bubeckSparksArtificialGeneral2023\n\n\n::: {.notes}\nSehr viel, wenn richtig geprompted\n:::\n\n\n## Denkt ChatGPT?\n\n\n\n![](../assets/images/karpathy-human-vs-LLM-2.png)\n\n![](../assets/images/karpathy-human-vs-LLM-1.png)\n\n## System 1 vs System 2\n\n- [Thinking Fast and Slow](https://en.wikipedia.org/wiki/Thinking,_Fast_and_Slow)\n- System 1: schnell, instinktiv, automatisch\n\n- System 2: langsam, deliberativ, anstrengend\n\n```{r}\ninclude_graphics(\"../assets/images/system-1-vs-system-2.png\")\n```\n\n\n\n## Prompt Engineering\n\n- Qualit√§t der Antwort h√§ngt sehr von der Qualit√§t des Prompts ab.\n- 2 M√∂glichkeiten, um die Qualit√§t der Antworten zu verbessern:\n\n  - Incrementelle Prompts: Schritt f√ºr Schritt durch die Konversation f√ºhren (dialogisches Prompting).\n  - Mega-Prompts: Alle Informationen auf einmal geben.\n\n- Am besten selber ausprobieren.\n\n\n## Mega-Prompt\n\n1. Rolle: Wer oder was wird simuliert?\n2. Aufgabe: Was ist zu tun?\n3. Arbeitschritte: Was ist in welcher Reihenfolge zu tun?\n4. Kontext, Einschr√§nkungen\n5. Ziel: Was soll am Ende herauskommen?\n6. Format: Wie soll das Ergebnis aussehen?\n\n:::{.callout-note}\n## Beispiel Hochschullehre: Feedback\n\"I want you to act as a harsh critic. Criticize what I will write to you and show me where my argumentation is lacking. Start by ask- ing me what text I want to have feedback on. Then ask me questions about my context to create the best feedback possible. If you feel you have all the context necessary, think step by step when creating your feedback\" (Lenk-Ostendorf & Folgmann 2023)\n:::\n\n\n:::{.callout-tip}\n## Weitere Beispiele\n\n- OpenAI Discord Server [discord.com/invite/openai](discord.com/invite/openai)\n- [Prompting Guide](https://www.promptingguide.ai/)\n\n:::\n\n\n\n\n\n\n# Zuk√ºnftige Verwendungen von LLMs {background-color=\"#ebcb8b\"}\n\n::: {.absolute top=\"0\" left=\"100%\"}\n::: {.sectionhead}\n[1 2 3 4 5]{style=\"opacity:0.25\"} 6 [7]{style=\"opacity:0.25\"}\n:::\n:::\n\n## Plug-ins\n\n![](../assets/images/karpathy-tools-plugins.png)\n\n\n## Retrieval-augmented LLMs\n\n![](../assets/images/karpathy-retrieval-augmented.png)\n\n\n## Retrieval-augmented LLMs\n\nBeispiel: Assistant f√ºr KI in der Hochschullehre\n\n```{=html}\n<iframe\nsrc=\"https://www.chatbase.co/chatbot-iframe/RDbFWW85cxcCd9PEwV-uy\"\nwidth=\"100%\"\nheight=\"700\"\nframeborder=\"0\"\n></iframe>\n```\n\n# Wissenschaftliches Arbeiten {background-color=\"#ebcb8b\"}\n\n::: {.absolute top=\"0\" left=\"100%\"}\n::: {.sectionhead}\n[1 2 3 4 5 6]{style=\"opacity:0.25\"} 7\n:::\n:::\n\n## Zitieren\n\n- Es existieren noch keine Richtlinien f√ºr das Zitieren von ChatGPT oder anderen KI-basierte Schreibtools.\n- ChatGPT ist rein rechtlich keine zitierf√§hige Quelle und damit auch nicht zitierpflichtig [@fleckPruefungsrechtlicheFragenChatGPT2023].\n  \n:::{.callout-note}\n## M√∂glicher Pauschalverweis\n  \n\"Beim Verfassen der Arbeit habe ich das KI-gest√ºtzte Schreibwerkzeug ChatGPT zur Textoptimierung verwendet. W√∂rtlich aus dem Tool √ºbernommene Passagen wurden im Text als pers√∂nliche Kommunikation zitiert.\"\n:::\n\n## Plagiate und Detektion\n\n- Texte von ChatGPT werden jedes Mal individuell erstellt. Es handelt sich nicht um Plagiate. \n- Die klassischen Tools zur Aufdeckung von Plagiaten wie z.B. _TurnItIn_ funktionieren hier nicht.\n\n\n## Kompetenznachweise\n\n- Siehe [KI-basierte Schreibtools in der Lehre ‚Äì ChatGPT im Fokus](https://virtuelleakademie.notion.site/KI-in-der-Lehre-af068030108844c4834ef00824fd8da6?p=f671067195a94f2d8239931c09ae92ec&pm=s)\n\n## Rechtliche Aspekte\n\n- ChatGPT kann keine Urheberschaft und keine Autorenschaft beanspruchen, da dies nur nat√ºrliche Personen k√∂nnen.\n- Menschen k√∂nnen die Urheberschaft eines Textes beanspruchen, auch wenn sie auf Unterst√ºtzung durch ChatGPT zur√ºckgegriffen haben ‚Äì sofern sie eine wesentliche gestalterische Eigenleistung am Text erbracht haben.\n\nQuelle: @saldenDidaktischeUndRechtliche2023 \n\n\n## Datenschutz\n\n- Anonyme Nutzung von ChatGPT ist mit pers√∂nlichen Konto nicht m√∂glich (√ºber Handynummer identifizierbar).\n- Alle Eingaben und alle Antworten werden bei ChatGPT unverschl√ºsselt abgespeichert.\n- Daten liegen auf amerikanischen Servern und sind damit f√ºr amerikanische Ermittlungsbeh√∂rden grunds√§tzlich zug√§nglich.\n\n\n# References {background-color=\"#2e3440\"}\n\n::: {#refs}\n:::\n"},"formats":{"revealjs":{"identifier":{"display-name":"RevealJS","target-format":"revealjs","base-format":"revealjs"},"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":true,"freeze":false,"echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"execute-dir":"project","engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","from":"markdown+emoji","output-file":"informationsanlass-bibliotheksmitarbeitende-chatgpt.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.4.358","auto-stretch":true,"page-footer":{"right":[{"icon":"github","href":"https://github.com/virtuelleakademie/gpt-nano/"}]},"editor":{"render-on-save":true},"title":"Informationsanlass zu KI/ChatGPT","author":"Andrew Ellis","date":"last-modified","date-format":"DD MMMM, YYYY","bibliography":["../bibliography.bib"],"nocite":"@broschinskiGrafikenErklaertFunktioniert2023\n","theme":"default","title-slide-attributes":{"data-background-image":"../assets/background-yellow.png","data-background-opacity":"1"},"footer":"<a href=\"https://virtuelleakademie.github.io/gpt-nano\">‚§¥Ô∏è KI/GPT in der Hochschule </a>","navigationMode":"default","progress":true,"scrollable":true,"slideNumber":true,"showSlideNumber":"all","controlsLayout":"bottom-right","controlsTutorial":true,"previewLinks":"auto","chalkboard":true,"code-summary":"Show code","menu":{"sticky":true,"keyboard":true,"autoOpen":true,"width":"normal","numbers":true,"markers":true}}}},"projectFormats":["html"]}
{"title":"Prompt Design","markdown":{"yaml":{"title":"Prompt Design","description":"Programming an GPT model.\n","date":"last-modified","date-format":"DD MMM, YYYY","author":[{"name":"Andrew Ellis","url":"https://github.com/awellis","affiliation":"Virtuelle Akademie, Berner Fachhochschule","affiliation-url":"https://virtuelleakademie.ch","orcid":"0000-0002-2788-936X"}],"license":"CC BY","citation":true,"bibliography":"../bibliography.bib","format":{"html":{"toc":true,"code-link":true}},"execute":{"cache":false},"code-annotations":"select"},"headingText":"Principles of prompting","containsRefs":false,"markdown":"\n\n\n1) Write clear and specific instructions\n   1) Use delimiters\n   2) ASk for structured output\n   3) Check whether conditions are satisfied (assumptions)\n   4) Few-shot prompting\n2) Give the model time to think\n\n\n\n\n## OpenAI Documentation\n[Doc](https://platform.openai.com/docs/guides/gpt)\nOpenAI's GPT (generative pre-trained transformer) models have been trained to understand natural language and code. GPTs provide text outputs in response to their inputs. The inputs to GPTs are also referred to as \"prompts\". Designing a prompt is essentially how you “program” a GPT model, usually by providing instructions or some examples of how to successfully complete a task.\n\nUsing GPTs, you can build applications to:\n\n    Draft documents\n    Write computer code\n    Answer questions about a knowledge base\n    Analyze texts\n    Create conversational agents\n    Give software a natural language interface\n    Tutor in a range of subjects\n    Translate languages\n    Simulate characters for games\n    and much more\n\nTo use a GPT model via the OpenAI API, you’ll send a request containing the inputs and your API key, and receive a response containing the model’s output. Our latest models, gpt-4 and gpt-3.5-turbo, are accessed through the chat completions API endpoint. Currently, only the older legacy models are available via the completions API endpoint.\n\n\n## GPT best practices\n\nThis guide shares strategies and tactics for getting better results from GPTs. The methods described here can sometimes be deployed in combination for greater effect. We encourage experimentation to find the methods that work best for you.\n\nSome of the examples demonstrated here currently work only with our most capable model, gpt-4. If you don't yet have access to gpt-4 consider joining the waitlist. In general, if you find that a GPT model fails at a task and a more capable model is available, it's often worth trying again with the more capable model.\nSix strategies for getting better results\nWrite clear instructions\n\nGPTs can’t read your mind. If outputs are too long, ask for brief replies. If outputs are too simple, ask for expert-level writing. If you dislike the format, demonstrate the format you’d like to see. The less GPTs have to guess at what you want, the more likely you’ll get it.\n\n### Tactics:\n\n    Include details in your query to get more relevant answers\n    Ask the model to adopt a persona\n    Use delimiters to clearly indicate distinct parts of the input\n    Specify the steps required to complete a task\n    Provide examples\n    Specify the desired length of the output\n\n\n## Provide reference text\n\nGPTs can confidently invent fake answers, especially when asked about esoteric topics or for citations and URLs. In the same way that a sheet of notes can help a student do better on a test, providing reference text to GPTs can help in answering with fewer fabrications.\n\n### Tactics:\n\n    Instruct the model to answer using a reference text\n    Instruct the model to answer with citations from a reference text\n\n\n## Strategy: Give GPTs time to \"think\"","srcMarkdownNoYaml":"\n\n## Principles of prompting\n\n1) Write clear and specific instructions\n   1) Use delimiters\n   2) ASk for structured output\n   3) Check whether conditions are satisfied (assumptions)\n   4) Few-shot prompting\n2) Give the model time to think\n\n\n\n\n## OpenAI Documentation\n[Doc](https://platform.openai.com/docs/guides/gpt)\nOpenAI's GPT (generative pre-trained transformer) models have been trained to understand natural language and code. GPTs provide text outputs in response to their inputs. The inputs to GPTs are also referred to as \"prompts\". Designing a prompt is essentially how you “program” a GPT model, usually by providing instructions or some examples of how to successfully complete a task.\n\nUsing GPTs, you can build applications to:\n\n    Draft documents\n    Write computer code\n    Answer questions about a knowledge base\n    Analyze texts\n    Create conversational agents\n    Give software a natural language interface\n    Tutor in a range of subjects\n    Translate languages\n    Simulate characters for games\n    and much more\n\nTo use a GPT model via the OpenAI API, you’ll send a request containing the inputs and your API key, and receive a response containing the model’s output. Our latest models, gpt-4 and gpt-3.5-turbo, are accessed through the chat completions API endpoint. Currently, only the older legacy models are available via the completions API endpoint.\n\n\n## GPT best practices\n\nThis guide shares strategies and tactics for getting better results from GPTs. The methods described here can sometimes be deployed in combination for greater effect. We encourage experimentation to find the methods that work best for you.\n\nSome of the examples demonstrated here currently work only with our most capable model, gpt-4. If you don't yet have access to gpt-4 consider joining the waitlist. In general, if you find that a GPT model fails at a task and a more capable model is available, it's often worth trying again with the more capable model.\nSix strategies for getting better results\nWrite clear instructions\n\nGPTs can’t read your mind. If outputs are too long, ask for brief replies. If outputs are too simple, ask for expert-level writing. If you dislike the format, demonstrate the format you’d like to see. The less GPTs have to guess at what you want, the more likely you’ll get it.\n\n### Tactics:\n\n    Include details in your query to get more relevant answers\n    Ask the model to adopt a persona\n    Use delimiters to clearly indicate distinct parts of the input\n    Specify the steps required to complete a task\n    Provide examples\n    Specify the desired length of the output\n\n\n## Provide reference text\n\nGPTs can confidently invent fake answers, especially when asked about esoteric topics or for citations and URLs. In the same way that a sheet of notes can help a student do better on a test, providing reference text to GPTs can help in answering with fewer fabrications.\n\n### Tactics:\n\n    Instruct the model to answer using a reference text\n    Instruct the model to answer with citations from a reference text\n\n\n## Strategy: Give GPTs time to \"think\""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":false,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"execute-dir":"project","engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":true,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":true,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"output-file":"prompting.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.358","page-footer":{"right":[{"icon":"github","href":"https://github.com/virtuelleakademie/gpt-nano/"}]},"editor":{"render-on-save":true},"theme":{"light":["cosmo","../styles/theme-light.scss"],"dark":["cosmo","../styles/theme-dark.scss"]},"title":"Prompt Design","description":"Programming an GPT model.\n","date":"last-modified","date-format":"DD MMM, YYYY","author":[{"name":"Andrew Ellis","url":"https://github.com/awellis","affiliation":"Virtuelle Akademie, Berner Fachhochschule","affiliation-url":"https://virtuelleakademie.ch","orcid":"0000-0002-2788-936X"}],"license":"CC BY","citation":true,"bibliography":["../bibliography.bib"],"code-annotations":"select"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}
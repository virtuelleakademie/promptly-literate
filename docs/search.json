[
  {
    "objectID": "pages/activity-global-management.html",
    "href": "pages/activity-global-management.html",
    "title": "Activities: Learn Prompting",
    "section": "",
    "text": "Designing effective prompts to instruct LLMS to generate a desired output is referred to as prompt engineering. This activity will guide you through the process of creating prompts for LLMs."
  },
  {
    "objectID": "pages/activity-global-management.html#practice-basic-techniques",
    "href": "pages/activity-global-management.html#practice-basic-techniques",
    "title": "Activities: Learn Prompting",
    "section": "Practice basic techniques",
    "text": "Practice basic techniques"
  },
  {
    "objectID": "pages/activity-global-management.html#summarize-research-paper",
    "href": "pages/activity-global-management.html#summarize-research-paper",
    "title": "Activities: Learn Prompting",
    "section": "Summarize research paper",
    "text": "Summarize research paper\nSearch for literature and summarize on {topic}"
  },
  {
    "objectID": "pages/activity-global-management.html#write-essay",
    "href": "pages/activity-global-management.html#write-essay",
    "title": "Activities: Learn Prompting",
    "section": "Write essay",
    "text": "Write essay\nEssay on the pros and cons of the introduction of a universal basic income (UBI)"
  },
  {
    "objectID": "pages/activity-global-management.html#prompting-guidelines",
    "href": "pages/activity-global-management.html#prompting-guidelines",
    "title": "Activities: Learn Prompting",
    "section": "Prompting Guidelines",
    "text": "Prompting Guidelines\nIn this activity, you can explore various prompting guides for LLMs. They more or less all converge on the same set of techniques. You can then use these techniques to write your own prompts\nOpenAI give a set of  strategies for using their models.\nThese include:\n\nwriting clear instructions\nproviding reference texts\nsplitting tasks into subtasks\ngiving GPT ‚Äòtime to think‚Äô\nusing external tools\n\nSome general techniques are:\n\nNumbered Steps:: For sequential tasks, use numbered steps. This helps the model understand the sequence of actions.\nUse delimiters: To separate various parts of the prompt (e.g.¬†\", `,, ', |, #, ‚Ä¶).\nFew-shot prompting: Provide a few examples for guidance.\nGive the LLM a role: Make the model assume a role. For example, instruct the model to act like a tutor or you are an expert programmer.\nIterate and refine prompts: Often, you won‚Äôt get your desired result straight away. Improve your prompting strategy iteratively, and then once you are happy, choose your final prompt and use it in a new chat session.\n\nCombining these techniques, a template prompt might look like this:\n\n\n\n\n\n\nTemplate\n\n\n\n\nRole: who is being simulated?\nTask: what is to be done?\nSteps: what are the steps to complete the task?\nContext: what is the context of the task?\nGoal: what is the goal of the task?\nFormat: what is the format of the output? How long should it be?\n\n\n\nRemember to structure your prompt in a way that is clear and easy to understand. You can use markdown to format your prompt, and you instruct the mode to format its response using markdown."
  },
  {
    "objectID": "pages/activity-global-management.html#examples",
    "href": "pages/activity-global-management.html#examples",
    "title": "Activities: Learn Prompting",
    "section": "Examples",
    "text": "Examples\n\nAdopt a persona\n\n\n\n\n\n\n Prompt:\n\n\n\nYou are an expert on the topic of university education and didactics. Explain the concept of ‚Äúflipped classroom‚Äù to a group of teachers. Use markdown to format your response. Keep you explanation concise and to the point.\n\n\nNow let‚Äôs try a different persona:\n\n\n\n\n\n\n Prompt:\n\n\n\nYou are 13 year old high school student. Explain the concept of ‚Äúflipped classroom‚Äù to your friends. Use markdown to format your response. Keep you explanation concise and to the point.\n\n\n\n\nReference texts\n\n\n\n\n\n\n Prompt:\n\n\n\nYou will be provided with\n\ncontext: documents delimited by triple quotes\na question\n\nYour task is to provide a simplified answer to the question using only the provided document and to cite the passage(s) of the document used to answer the question. If the document does not contain the information needed to answer this question then simply write: ‚ÄúInsufficient information.‚Äù If an answer to the question is provided, it must be annotated with a citation. Use the following format for to cite relevant passages ({‚Äúcitation‚Äù: ‚Ä¶}). Cite only the relevant sentence(s) of the document, not the entire document.\nDocument 1: ‚Äô‚Äò‚ÄôThe flipped classroom intentionally shifts instruction to a learner-centered model, in which students are often initially introduced to new topics outside of school, freeing up classroom time for the exploration of topics in greater depth, creating meaningful learning opportunities.‚Äô‚Äô‚Äô\nDocument 2:‚Äô‚Äò‚ÄôWith a flipped classroom, ‚Äôcontent delivery‚Äô may take a variety of forms, often featuring video lessons prepared by the teacher or third parties, although online collaborative discussions, digital research, and text readings may alternatively be used. The ideal length for a video lesson is widely cited as eight to twelve minutes.‚Äô‚Äô‚Äô\nQuestion: What is a good length for a video?\n\n\nTry asking a question that cannot be answered with the provided documents:\n\n\n\n\n\n\n Prompt:\n\n\n\nYou will be provided with\n\ncontext: documents delimited by triple quotes\na question\n\nYour task is to provide a simplified answer to the question using only the provided document and to cite the passage(s) of the document used to answer the question. If the document does not contain the information needed to answer this question then simply write: ‚ÄúInsufficient information.‚Äù If an answer to the question is provided, it must be annotated with a citation. Use the following format for to cite relevant passages (‚ÄúSOURCE‚Äù: ‚Ä¶). Cite only the relevant sentence(s) of the document, not the entire document.\nDocument 1:‚Äô‚Äò‚ÄôThe flipped classroom intentionally shifts instruction to a learner-centered model, in which students are often initially introduced to new topics outside of school, freeing up classroom time for the exploration of topics in greater depth, creating meaningful learning opportunities.‚Äô‚Äô‚Äô\nDocument 2:‚Äô‚Äò‚ÄôWith a flipped classroom, ‚Äôcontent delivery‚Äô may take a variety of forms, often featuring video lessons prepared by the teacher or third parties, although online collaborative discussions, digital research, and text readings may alternatively be used. The ideal length for a video lesson is widely cited as eight to twelve minutes.‚Äô‚Äô‚Äô\nQuestion: Can you recommend a good book on the topic of flipped classrooms?\n\n\n\n\nStructured output\nYou can also use prompts to instruct the model to produce structured output. For example, you can ask the model to give you a table.\n\n\n\n\n\n\n Prompt:\n\n\n\nYou are a high school teacher. Give me a table containing Greek letters in one column, their pronunciation in the second column, and examples of usage in the third column. Give me a maximum of 6 rows."
  },
  {
    "objectID": "pages/activity-global-management.html#exercises",
    "href": "pages/activity-global-management.html#exercises",
    "title": "Activities: Learn Prompting",
    "section": "Exercises",
    "text": "Exercises"
  },
  {
    "objectID": "pages/activity-global-management.html#further-resources",
    "href": "pages/activity-global-management.html#further-resources",
    "title": "Activities: Learn Prompting",
    "section": "Further Resources",
    "text": "Further Resources\n\nExplore these prompt guides. Use both/either ChatGPT and Copilot to try out new ideas.\n\n\n\n\n\n\n\nLearn prompting: An comprehensive (and free) guide aimed at non-technical users.\n\n\n\n\n\n Learn prompting\n\n\n\n\n\n\n\n\n\n\nPrompting guide: A more technical guide to prompting\n\n\n\n\n\n Prompting guide: DAIR.AI (Democratizing Artificial Intelligence Research, Education, and Technologies). The guide is licensed under an MIT license."
  },
  {
    "objectID": "slides/zz-00-introduction.html#the-best-prompts-for-chatgpt-the-ultimate-list",
    "href": "slides/zz-00-introduction.html#the-best-prompts-for-chatgpt-the-ultimate-list",
    "title": "Introduction",
    "section": "The Best Prompts For ChatGPT: The ultimate list",
    "text": "The Best Prompts For ChatGPT: The ultimate list"
  },
  {
    "objectID": "slides/zz-00-introduction.html#key-messages",
    "href": "slides/zz-00-introduction.html#key-messages",
    "title": "Introduction",
    "section": "Key messages",
    "text": "Key messages\n\nKeep human in the loop: LLMs should be used to augment human writing, not to replace it.\nPrompting, prompting, prompting: this workshop is mainly about prompting. We can think about prompting as a way of ‚Äúprogramming‚Äù LLMs, i.e.¬†getting LLMs to do what we want them to do."
  },
  {
    "objectID": "slides/zz-00-introduction.html#summary",
    "href": "slides/zz-00-introduction.html#summary",
    "title": "Introduction",
    "section": "Summary",
    "text": "Summary\n\nChatGPT has comparatively high energy requirements.\nLarge language models (LMMs) learn all kinds of human biases from their training data.\nToxic content produced by LLMs is flagged by cheap labor."
  },
  {
    "objectID": "slides/zz-00-introduction.html#energy-consumption",
    "href": "slides/zz-00-introduction.html#energy-consumption",
    "title": "Introduction",
    "section": "Energy consumption",
    "text": "Energy consumption\n\nTraining:\n\n‚ÄúWhat we do know is that training ChatGPT used \\(1.3\\) GWh, roughly equivalent to the consumption of 120 US homes for a year.‚Äù Quelle: Heating up: how much energy does AI use?\nPatterson et al. (2022) estimate training costs at 502 tons of \\(\\text{CO}_2\\).\n\nUsage:\n\n7 tons of \\(\\text{CO}_2\\) per day (end of February). Source: How much energy does ChatGPT use?\nChatGPT‚Äôs energy consumption is equivalent to 400-800 US households. This is considerable, but compared to e.g.¬†cryptocurrencies it is rather low."
  },
  {
    "objectID": "slides/zz-00-introduction.html#bias",
    "href": "slides/zz-00-introduction.html#bias",
    "title": "Introduction",
    "section": "Bias",
    "text": "Bias\n\n\n\n\n\nDa LLMs von Texten lernen, die von Menschen geschrieben wurden, k√∂nnen sie auch Vorurteile lernen.\n\nQuelle: Hast du Vorurteile?"
  },
  {
    "objectID": "slides/zz-00-introduction.html#ethical-aspects",
    "href": "slides/zz-00-introduction.html#ethical-aspects",
    "title": "Introduction",
    "section": "Ethical aspects",
    "text": "Ethical aspects\n\n\n\n\n\nAuf Grund der grossen Menge von Trainingsdaten, die f√ºr Sprachmodelle ben√∂tigt werden, ist Qualit√§tskontrolle schwierig.\nDiskriminierende oder beleidigende Aussagen werden von einem Chatbot generiert.\nSolche Antworten k√∂nnen als unerw√ºnscht markiert werden.\nToxische Inhalte wie k√∂rperliche und sexuelle Gewalt, Suizide und Tierqu√§lerei, m√ºssen beim Trainieren aus den Antworten gefiltert werden. Dabei mussten angestellte Arbeitskr√§fte f√ºr weniger als 2 Dollar die Stunde teils schockierende Inhalte lesen.\n\nQuelle: Traumatische Klickarbeit"
  },
  {
    "objectID": "slides/zz-00-introduction.html#haltung-der-bfh",
    "href": "slides/zz-00-introduction.html#haltung-der-bfh",
    "title": "Introduction",
    "section": "Haltung der BFH",
    "text": "Haltung der BFH\n\nTechnologien sollen dort, wo sie den Lernprozess unterst√ºtzen und praxisrelevant sind, in die Lehre einbezogen werden.\nStudierende sollen lernen, Technologien kompetent einzusetzen und kritisch zu hinterfragen. Dies gilt uneingeschr√§nkt auch f√ºr ChatGPT und andere gleichgerichtete Tools."
  },
  {
    "objectID": "slides/zz-00-introduction.html#zitieren",
    "href": "slides/zz-00-introduction.html#zitieren",
    "title": "Introduction",
    "section": "Zitieren",
    "text": "Zitieren\n\nEs existieren noch keine Richtlinien f√ºr das Zitieren von ChatGPT oder anderen KI-basierte Schreibtools.\nChatGPT ist rein rechtlich keine zitierf√§hige Quelle und damit auch nicht zitierpflichtig (Fleck 2023).\nAus der Orientierungshilfe: ‚ÄúKI-basierte Schreibtools sind externe Quellen und m√ºssen daher im Sinne der wissenschaftlichen Integrit√§t immer, wie andere Quellen auch, zitiert werden, sofern ganze Textpassagen von ChatGPT benutzt werden. Falls mit dem Tool der eigene Text √ºberarbeitet wurde, muss ChatGPT als verwendetes Hilfsmittel angef√ºhrt werden.‚Äù\n\n\n\n\n\n\n\nM√∂glicher Pauschalverweis\n\n\n\n‚ÄúBeim Verfassen der Arbeit habe ich das KI-gest√ºtzte Schreibwerkzeug ChatGPT zur Textoptimierung verwendet. W√∂rtlich aus dem Tool √ºbernommene Passagen wurden im Text als pers√∂nliche Kommunikation zitiert.‚Äù"
  },
  {
    "objectID": "slides/zz-00-introduction.html#plagiate-und-detektion",
    "href": "slides/zz-00-introduction.html#plagiate-und-detektion",
    "title": "Introduction",
    "section": "Plagiate und Detektion",
    "text": "Plagiate und Detektion\n\nTexte von ChatGPT werden jedes Mal individuell erstellt. Es handelt sich nicht um Plagiate.\nDie klassischen Tools zur Aufdeckung von Plagiaten wie z.B. TurnItIn funktionieren hier nicht.\nDie BFH empfiehlt weiterhin, schriftliche Arbeiten mit der Plagiatserkennungssoftware Turnitin zu pr√ºfen."
  },
  {
    "objectID": "slides/zz-00-introduction.html#kompetenznachweise",
    "href": "slides/zz-00-introduction.html#kompetenznachweise",
    "title": "Introduction",
    "section": "Kompetenznachweise",
    "text": "Kompetenznachweise\n\nSiehe KI-basierte Schreibtools in der Lehre ‚Äì ChatGPT im Fokus\nBeim Benutzen von KI-generierten Texten in Kompetenznachweisen ohne Deklaration oder Zitierung kann von einem Plagiat im weiteren Sinne ausgegangen werden, welches das bisher etablierte Plagiatsverst√§ndnis im engeren Sinne erweitert.\nOpen Book-Pr√ºfungen: KI-Tools m√ºssten explizit ausgeschlossen werden.\nClosed Book-Pr√ºfungen: KI-Tools k√∂nnen durch Einsatz von Safe Exam-Browser und Lernstick ausgeschlossen werden.\nSchriftliche Arbeiten: KI-Tools durch pauschalen Hilfsmittelverweis am Ende der Arbeit deklarieren.\nAlternative oder erg√§nzende Pr√ºfungsformen: praktische Pr√ºfungen, m√ºndliche Pr√ºfungen, Pr√§sentationen."
  },
  {
    "objectID": "slides/zz-00-introduction.html#rechtliche-aspekte",
    "href": "slides/zz-00-introduction.html#rechtliche-aspekte",
    "title": "Introduction",
    "section": "Rechtliche Aspekte",
    "text": "Rechtliche Aspekte\n\nChatGPT kann keine Urheberschaft und keine Autorenschaft beanspruchen, da dies nur nat√ºrliche Personen k√∂nnen.\nMenschen k√∂nnen die Urheberschaft eines Textes beanspruchen, auch wenn sie auf Unterst√ºtzung durch ChatGPT zur√ºckgegriffen haben ‚Äì sofern sie eine wesentliche gestalterische Eigenleistung am Text erbracht haben.\n\nQuelle: Salden (2023)"
  },
  {
    "objectID": "slides/zz-00-introduction.html#datenschutz",
    "href": "slides/zz-00-introduction.html#datenschutz",
    "title": "Introduction",
    "section": "Datenschutz",
    "text": "Datenschutz\n\nAnonyme Nutzung von ChatGPT ist mit pers√∂nlichen Konto nicht m√∂glich (√ºber Handynummer identifizierbar).\nAlle Eingaben und alle Antworten werden bei ChatGPT unverschl√ºsselt abgespeichert.\nDaten liegen auf amerikanischen Servern und sind damit f√ºr amerikanische Ermittlungsbeh√∂rden grunds√§tzlich zug√§nglich."
  },
  {
    "objectID": "slides/questions-topics.html",
    "href": "slides/questions-topics.html",
    "title": "Fragen und Themen",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport networkx as nx\nimport seaborn as sns\n\n# Create a new graph\nG = nx.Graph()\n\n# Define the categories/nodes\ncategories = [\"Unterricht & Bildung\", \"Sprache & Schreiben\", \"Technologie & Innovation\", \"Freizeit & Lifestyle\", \"Feedback & Repr√§sentation\"]\n\n# Add nodes to the graph\nG.add_nodes_from(categories)\n\n# Define the relationships/edges based on the interpretation\nrelationships = [\n    (\"Unterricht & Bildung\", \"Sprache & Schreiben\"),\n    (\"Unterricht & Bildung\", \"Technologie & Innovation\"),\n    (\"Sprache & Schreiben\", \"Technologie & Innovation\"),\n    (\"Technologie & Innovation\", \"Freizeit & Lifestyle\"),\n    (\"Unterricht & Bildung\", \"Feedback & Repr√§sentation\")\n]\n\n# Add edges to the graph\nG.add_edges_from(relationships)\n\n# Define the topics under each category\ntopics = {\n    \"Unterricht & Bildung\": [\n        \"MC Fragen Entwicklung\", \"Case Study entwickeln\", \"Unterrichtsvorbereitung\", \n        \"KI-Management in den Unterricht integrieren\", \"Grundlagen kennen lernen\", \n        \"Sinnvoller Einsatz f√ºr Lehre reflektieren\", \"Generieren von MC-Fragen\", \n        \"Brainstorming/Ideengenerierung (z.T. mit Studierenden)\", \"Akademisches und berufliches Schreiben unterrichten\", \n        \"Funktionsweise von KI-Schreibtools\", \"Einsatzszenarien f√ºr KI-Schreibtools\", \n        \"Reflektierter Umgang mit KI-Schreibtools\", \"Unterst√ºtzung f√ºr Sch√ºler*innen mit sprachlichen Schwierigkeiten\", \n        \"Verst√§ndnis von Schreibtools\", \"Sinnvoller Einsatz von Schreibtools durch Studierende und Mitarbeitende\"\n    ],\n    \"Sprache & Schreiben\": [\n        \"Formulierungshilfe bei wissenschaftlichen Schreibarbeiten\", \"√úbersetzungen oder √úberpr√ºfungen von Texten in Deutsch\", \n        \"Kreative Schreib√ºbung\", \"√úbersetzungen\", \"Ideensammlung\", \n        \"Textkorrekturen/-anpassungen\", \"Perspektivenwechsel\", \"Szenarien erfinden lassen\", \n        \"Mails verfassen\", \"Konzepte √ºberpr√ºfen\"\n    ],\n    \"Technologie & Innovation\": [\n        \"Diverses\", \"Zeitersparnis bei Vorbereitungen mithilfe neuer Technologien\", \n        \"Pr√ºfungen mit KI\", \"Open Book Pr√ºfungen\", \"Grenzen der KI ausloten\", \n        \"Interesse an Entwicklungen der Sprachmodelle\"\n    ],\n    \"Freizeit & Lifestyle\": [\n        \"Fragen f√ºr Freizeitaktivit√§ten, z.B. bei Regenwetter mit Kleinkindern\", \n        \"Ideensammlung f√ºr Ausfl√ºge in der Freizeit\", \"Programmplanung der Ferien\", \"Vorschlag f√ºr einen Mailtest\"\n    ],\n    \"Feedback & Repr√§sentation\": [\"R√ºckmeldung an das Institut an der BFH\"]\n}\n\n# Add topics as nodes to the graph\nfor category, topic_list in topics.items():\n    G.add_nodes_from(topic_list)\n    for topic in topic_list:\n        G.add_edge(category, topic)\n\n# Get a color palette with as many colors as there are topics\ncolors = sns.color_palette(\"husl\", len(topics))\n\n# Map each category to a color\ncolor_map = {}\nfor idx, category in enumerate(topics):\n    for topic in topics[category]:\n        color_map[topic] = colors[idx]\n\n# Add colors for the categories themselves\ncategory_colors = [\"red\", \"green\", \"blue\", \"purple\", \"orange\"]\nfor idx, category in enumerate(categories):\n    color_map[category] = category_colors[idx]\n\n# Get the colors for each node in the order they are in the graph\nnode_colors = [color_map[node] for node in G.nodes()]\n\n\n# Plotting the graph with different colors for each topic\nplt.figure(figsize=(20, 20)) #figsize=(20, 15)\npos = nx.spring_layout(G, seed=42, k=0.5, iterations=100)\nnx.draw(G, pos, with_labels=True, node_size=2000, node_color=node_colors, font_size=12, font_color='black', width=2, edge_color='gray', alpha=0.6)\nplt.title(\"Beziehungen zwischen den Bereichen und zugeh√∂rigen Themen\", fontsize=18)\nplt.show()\n\n\n\n\n\n\n\n\n\n# Adjust the figure size to be wider\nplt.figure(figsize=(25, 10))\n\n# Adjust the layout to be more spread out horizontally\npos = nx.spring_layout(G, seed=42, k=0.7, iterations=150, scale=2)\n\n# Plotting the graph with the adjusted layout\nnx.draw(G, pos, with_labels=True, node_size=2000, node_color=node_colors, font_size=12, font_color='black', width=2, edge_color='gray', alpha=0.6)\nplt.title(\"Beziehungen zwischen den Bereichen und zugeh√∂rigen Themen\", fontsize=20)\nplt.show()"
  },
  {
    "objectID": "slides/questions-topics.html#themen",
    "href": "slides/questions-topics.html#themen",
    "title": "Fragen und Themen",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport networkx as nx\nimport seaborn as sns\n\n# Create a new graph\nG = nx.Graph()\n\n# Define the categories/nodes\ncategories = [\"Unterricht & Bildung\", \"Sprache & Schreiben\", \"Technologie & Innovation\", \"Freizeit & Lifestyle\", \"Feedback & Repr√§sentation\"]\n\n# Add nodes to the graph\nG.add_nodes_from(categories)\n\n# Define the relationships/edges based on the interpretation\nrelationships = [\n    (\"Unterricht & Bildung\", \"Sprache & Schreiben\"),\n    (\"Unterricht & Bildung\", \"Technologie & Innovation\"),\n    (\"Sprache & Schreiben\", \"Technologie & Innovation\"),\n    (\"Technologie & Innovation\", \"Freizeit & Lifestyle\"),\n    (\"Unterricht & Bildung\", \"Feedback & Repr√§sentation\")\n]\n\n# Add edges to the graph\nG.add_edges_from(relationships)\n\n# Define the topics under each category\ntopics = {\n    \"Unterricht & Bildung\": [\n        \"MC Fragen Entwicklung\", \"Case Study entwickeln\", \"Unterrichtsvorbereitung\", \n        \"KI-Management in den Unterricht integrieren\", \"Grundlagen kennen lernen\", \n        \"Sinnvoller Einsatz f√ºr Lehre reflektieren\", \"Generieren von MC-Fragen\", \n        \"Brainstorming/Ideengenerierung (z.T. mit Studierenden)\", \"Akademisches und berufliches Schreiben unterrichten\", \n        \"Funktionsweise von KI-Schreibtools\", \"Einsatzszenarien f√ºr KI-Schreibtools\", \n        \"Reflektierter Umgang mit KI-Schreibtools\", \"Unterst√ºtzung f√ºr Sch√ºler*innen mit sprachlichen Schwierigkeiten\", \n        \"Verst√§ndnis von Schreibtools\", \"Sinnvoller Einsatz von Schreibtools durch Studierende und Mitarbeitende\"\n    ],\n    \"Sprache & Schreiben\": [\n        \"Formulierungshilfe bei wissenschaftlichen Schreibarbeiten\", \"√úbersetzungen oder √úberpr√ºfungen von Texten in Deutsch\", \n        \"Kreative Schreib√ºbung\", \"√úbersetzungen\", \"Ideensammlung\", \n        \"Textkorrekturen/-anpassungen\", \"Perspektivenwechsel\", \"Szenarien erfinden lassen\", \n        \"Mails verfassen\", \"Konzepte √ºberpr√ºfen\"\n    ],\n    \"Technologie & Innovation\": [\n        \"Diverses\", \"Zeitersparnis bei Vorbereitungen mithilfe neuer Technologien\", \n        \"Pr√ºfungen mit KI\", \"Open Book Pr√ºfungen\", \"Grenzen der KI ausloten\", \n        \"Interesse an Entwicklungen der Sprachmodelle\"\n    ],\n    \"Freizeit & Lifestyle\": [\n        \"Fragen f√ºr Freizeitaktivit√§ten, z.B. bei Regenwetter mit Kleinkindern\", \n        \"Ideensammlung f√ºr Ausfl√ºge in der Freizeit\", \"Programmplanung der Ferien\", \"Vorschlag f√ºr einen Mailtest\"\n    ],\n    \"Feedback & Repr√§sentation\": [\"R√ºckmeldung an das Institut an der BFH\"]\n}\n\n# Add topics as nodes to the graph\nfor category, topic_list in topics.items():\n    G.add_nodes_from(topic_list)\n    for topic in topic_list:\n        G.add_edge(category, topic)\n\n# Get a color palette with as many colors as there are topics\ncolors = sns.color_palette(\"husl\", len(topics))\n\n# Map each category to a color\ncolor_map = {}\nfor idx, category in enumerate(topics):\n    for topic in topics[category]:\n        color_map[topic] = colors[idx]\n\n# Add colors for the categories themselves\ncategory_colors = [\"red\", \"green\", \"blue\", \"purple\", \"orange\"]\nfor idx, category in enumerate(categories):\n    color_map[category] = category_colors[idx]\n\n# Get the colors for each node in the order they are in the graph\nnode_colors = [color_map[node] for node in G.nodes()]\n\n\n# Plotting the graph with different colors for each topic\nplt.figure(figsize=(20, 20)) #figsize=(20, 15)\npos = nx.spring_layout(G, seed=42, k=0.5, iterations=100)\nnx.draw(G, pos, with_labels=True, node_size=2000, node_color=node_colors, font_size=12, font_color='black', width=2, edge_color='gray', alpha=0.6)\nplt.title(\"Beziehungen zwischen den Bereichen und zugeh√∂rigen Themen\", fontsize=18)\nplt.show()\n\n\n\n\n\n\n\n\n\n# Adjust the figure size to be wider\nplt.figure(figsize=(25, 10))\n\n# Adjust the layout to be more spread out horizontally\npos = nx.spring_layout(G, seed=42, k=0.7, iterations=150, scale=2)\n\n# Plotting the graph with the adjusted layout\nnx.draw(G, pos, with_labels=True, node_size=2000, node_color=node_colors, font_size=12, font_color='black', width=2, edge_color='gray', alpha=0.6)\nplt.title(\"Beziehungen zwischen den Bereichen und zugeh√∂rigen Themen\", fontsize=20)\nplt.show()"
  },
  {
    "objectID": "slides/prompt-labor-basics.html",
    "href": "slides/prompt-labor-basics.html",
    "title": "Prompt Labor: Basics",
    "section": "",
    "text": "Assistant\nProvider\nPrivacy\nLLM\nCapabilities\nPricing model\n\n\n\n\nChatGPT\nOpenAI\nüëéüèº\nGPT-3.5, GPT-4\nWeb search, DALLE, GPTs, multimodal input\nüí∂\n\n\nCopilot\nMicrosoft\nüëçüèº\nGPT-3.5, GPT-4\nWeb search, DALLE, multimodal input\nüÜì for BFH employees and students\n\n\nGemini\nGoogle\nüëéüèº\nGemini Ultra, Gemini Pro, and Gemini Nano\nWeb search, multimodal input\nüí∂\n\n\nHuggingChat\nü§ó Hugging Face\nüëçüèº\nVarious open models, e.g.¬†CodeLlama, Llama 2, Mistral, Gemma\n\nüÜì"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#assistant-menagerie",
    "href": "slides/prompt-labor-basics.html#assistant-menagerie",
    "title": "Prompt Labor: Basics",
    "section": "",
    "text": "Assistant\nProvider\nPrivacy\nLLM\nCapabilities\nPricing model\n\n\n\n\nChatGPT\nOpenAI\nüëéüèº\nGPT-3.5, GPT-4\nWeb search, DALLE, GPTs, multimodal input\nüí∂\n\n\nCopilot\nMicrosoft\nüëçüèº\nGPT-3.5, GPT-4\nWeb search, DALLE, multimodal input\nüÜì for BFH employees and students\n\n\nGemini\nGoogle\nüëéüèº\nGemini Ultra, Gemini Pro, and Gemini Nano\nWeb search, multimodal input\nüí∂\n\n\nHuggingChat\nü§ó Hugging Face\nüëçüèº\nVarious open models, e.g.¬†CodeLlama, Llama 2, Mistral, Gemma\n\nüÜì"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#orientierungshilfe-f√ºr-lehrpersonen-der-bfh",
    "href": "slides/prompt-labor-basics.html#orientierungshilfe-f√ºr-lehrpersonen-der-bfh",
    "title": "Prompt Labor: Basics",
    "section": " Orientierungshilfe f√ºr Lehrpersonen der BFH",
    "text": "Orientierungshilfe f√ºr Lehrpersonen der BFH\n\n\n\n\n\n\nNote\n\n\n\n\nHaltung der BFH: Technologien, die den Lernprozess unterst√ºtzen und praxisrelevant sind, sollen in die Lehre einbezogen werden.\nEinsatz von KI in der Lehre: Die Mehrheit der Studierenden wird KI-Tools nutzen. Studierende sollen lernen, Technologien kompetent einzusetzen und kritisch zu hinterfragen.\n\n\n\n \n Knowledge Base der Virtuellen Akademie\n PDF"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#what-is-artifical-intelligence",
    "href": "slides/prompt-labor-basics.html#what-is-artifical-intelligence",
    "title": "Prompt Labor: Basics",
    "section": "What is Artifical Intelligence?",
    "text": "What is Artifical Intelligence?\n\n\n\n\nA branch of computer science that aims to create machines that can perform tasks that typically require human intelligence."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#what-is-a-large-language-model",
    "href": "slides/prompt-labor-basics.html#what-is-a-large-language-model",
    "title": "Prompt Labor: Basics",
    "section": "What is a Large Language Model?",
    "text": "What is a Large Language Model?\n\n\n\n\nAn LLM is a type of generative AI model that is trained to predict the next word following the input (prompt)."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#training",
    "href": "slides/prompt-labor-basics.html#training",
    "title": "Prompt Labor: Basics",
    "section": "Training",
    "text": "Training"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#how-to-train-a-language-model",
    "href": "slides/prompt-labor-basics.html#how-to-train-a-language-model",
    "title": "Prompt Labor: Basics",
    "section": "How to train a language model",
    "text": "How to train a language model"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#how-to-train-a-language-model-1",
    "href": "slides/prompt-labor-basics.html#how-to-train-a-language-model-1",
    "title": "Prompt Labor: Basics",
    "section": "How to train a language model",
    "text": "How to train a language model\n\nAn LLM learns to predict the next word in a sequence, given the previous words: \\[ P(word | context) \\]\nThink of as ‚Äúfancy autocomplete‚Äù (but very very powerful and sopisticated)"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#text-generation",
    "href": "slides/prompt-labor-basics.html#text-generation",
    "title": "Prompt Labor: Basics",
    "section": "Text Generation",
    "text": "Text Generation"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#how-does-an-llm-generate-text",
    "href": "slides/prompt-labor-basics.html#how-does-an-llm-generate-text",
    "title": "Prompt Labor: Basics",
    "section": "How does an LLM generate text?",
    "text": "How does an LLM generate text?"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#sampling",
    "href": "slides/prompt-labor-basics.html#sampling",
    "title": "Prompt Labor: Basics",
    "section": "Sampling",
    "text": "Sampling"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#auto-regressive-generation",
    "href": "slides/prompt-labor-basics.html#auto-regressive-generation",
    "title": "Prompt Labor: Basics",
    "section": "Auto-regressive generation",
    "text": "Auto-regressive generation\nText is generated one word at a time (actually tokens, not words).\n\n\n\nModel predicts which word is likely to follow, given a sequence of tokens (words, punctuation, emojis, etc.).\nA word is sampled from the predicted distribution.\nThe new word is added to the sequence of words (context) that is used to predict the next word.\n\n\\[ P(w_{w+1} | w_1, w_2, ..., w_t) \\]\n\n Generated text is dependent on the context.\n Every token is given an equal amount time (computation per token is constant)."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#auto-regressive-generation-1",
    "href": "slides/prompt-labor-basics.html#auto-regressive-generation-1",
    "title": "Prompt Labor: Basics",
    "section": "Auto-regressive generation",
    "text": "Auto-regressive generation"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#foundation-models",
    "href": "slides/prompt-labor-basics.html#foundation-models",
    "title": "Prompt Labor: Basics",
    "section": "Foundation models",
    "text": "Foundation models\nA foundation model, or large language model (LLM):\n\nis a type of machine learning model that is trained to predict the next word following the input (prompt).\nis trained ‚Äúsimply‚Äù to predict the next word following a sequence of words.\ndoes not necessarily produce human-like conversations.\n\n\n\n\n\n\n\nNote\n\n\n\n: What is the capital of France?\n: What is the capital of Germany? What is the capital of Italy? . .."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#training-data",
    "href": "slides/prompt-labor-basics.html#training-data",
    "title": "Prompt Labor: Basics",
    "section": "Training data",
    "text": "Training data\n\n\nFigure courtesy of Andrej Karpathy"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#training-process",
    "href": "slides/prompt-labor-basics.html#training-process",
    "title": "Prompt Labor: Basics",
    "section": "Training process",
    "text": "Training process\n\n\nFigure courtesy of Andrej Karpathy"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#assistant-models",
    "href": "slides/prompt-labor-basics.html#assistant-models",
    "title": "Prompt Labor: Basics",
    "section": "Assistant models",
    "text": "Assistant models\nTrained (fine-tuned) to have conversations: turn-taking, question answering, not being [rude/sexist/racist].\n\n\n\n\n\n\nFoundation model has learned to predict all kinds of text, including both desirable and undesirable text.\nFine-tuning is a process narrow down the space of all possible output to only desirable, human-like dialogue."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#reinforcement-learning-from-human-feedback-rlhf",
    "href": "slides/prompt-labor-basics.html#reinforcement-learning-from-human-feedback-rlhf",
    "title": "Prompt Labor: Basics",
    "section": "Reinforcement learning from human feedback (RLHF)",
    "text": "Reinforcement learning from human feedback (RLHF)\n\nModel is aligned with the values of the fine-tuner."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#how-do-chatbots-work",
    "href": "slides/prompt-labor-basics.html#how-do-chatbots-work",
    "title": "Prompt Labor: Basics",
    "section": "How do Chatbots work?",
    "text": "How do Chatbots work?\n\n\nDesigned to present the illusion of a conversation between two entities."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#how-do-chatbots-actually-work",
    "href": "slides/prompt-labor-basics.html#how-do-chatbots-actually-work",
    "title": "Prompt Labor: Basics",
    "section": "How do chatbots actually work?",
    "text": "How do chatbots actually work?"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#an-assistant-model-is-a-role-play-simulator",
    "href": "slides/prompt-labor-basics.html#an-assistant-model-is-a-role-play-simulator",
    "title": "Prompt Labor: Basics",
    "section": "An assistant model is a role-play simulator",
    "text": "An assistant model is a role-play simulator\n\n\n\n\n\nAn assistant is trained to respond to user prompts in a human-like way.\nSimulates possible human conversations.\nHas no intentions. It is not an entity with its own goals.\nDoes not have a ‚Äúpersonality‚Äù or ‚Äúcharacter‚Äù in the traditional sense. It can be thought of as a role-playing simulator.\nHas no concept of ‚Äútruth‚Äù or ‚Äúlying‚Äù. The model is not trying to deceive the user, it is simply trying to respond in a human-like way."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#hallucination",
    "href": "slides/prompt-labor-basics.html#hallucination",
    "title": "Prompt Labor: Basics",
    "section": "Hallucination",
    "text": "Hallucination\n\n\n\n\n\nLLMs can generate text that is not true, or not based on any real-world knowledge.\nThis is known as ‚Äúhallucination‚Äù. A better term would be ‚Äúconfabulation‚Äù."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#can-an-llm-tell-the-truth",
    "href": "slides/prompt-labor-basics.html#can-an-llm-tell-the-truth",
    "title": "Prompt Labor: Basics",
    "section": "Can an LLM tell the truth?",
    "text": "Can an LLM tell the truth?\n\nHow would you know if an LLM is able to give you factual information?\nHow would you test this?\n\n\n\n\n\n\n\nNote\n\n\n\n: What is the capital of Uzbekistan?\n: Tashkent\n\n\nIt looks like the LLM knows the capital of Uzbekistan1."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#knowledge-base",
    "href": "slides/prompt-labor-basics.html#knowledge-base",
    "title": "Prompt Labor: Basics",
    "section": "Knowledge base",
    "text": "Knowledge base\n\n\n\nA knowledge base is a collection of facts about the world.\n\nYou can ask (retrieve) and tell (store) facts.\n\nAn LLM is not a knowledge base.\n\nLLMs generate text based on on how probable the next word is given the context, not based on stored facts."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#what-are-llms-good-at",
    "href": "slides/prompt-labor-basics.html#what-are-llms-good-at",
    "title": "Prompt Labor: Basics",
    "section": "What are LLMs good at?",
    "text": "What are LLMs good at?\n\nFixing grammar, bad writing, etc.\nRephrasing\nAnalyze texts\nWrite computer code\nAnswer questions about a knowledge base\nTranslate languages\nCreating structured output\nFactual output only with external documents or web search"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#prompting",
    "href": "slides/prompt-labor-basics.html#prompting",
    "title": "Prompt Labor: Basics",
    "section": "Prompting",
    "text": "Prompting"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#what-is-a-prompt",
    "href": "slides/prompt-labor-basics.html#what-is-a-prompt",
    "title": "Prompt Labor: Basics",
    "section": "What is a prompt?",
    "text": "What is a prompt?\n\nRemember: the goal of an LLM is complete text.\nA prompt is a piece of text (instruction) that is given to a language model to complete.\n\n\n\n\n\n\n\nNote\n\n\n\nPROMPT : Write a haiku about a workshop on large language models.\nASSISTANT : Whispers of circuits,\nKnowledge blooms in bytes and bits,\nModel learns and fits.\n\n\n\nThe response is generated as continuation of the prompt.\n\n\nMore technical definition: The output is generated by auto-regressively sampling from the probability distribution over the vocabulary, conditioned on the prompt."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#unlocking-knowledge",
    "href": "slides/prompt-labor-basics.html#unlocking-knowledge",
    "title": "Prompt Labor: Basics",
    "section": "Unlocking knowledge",
    "text": "Unlocking knowledge\n\n\n\n\n\nLLMs learn to do things they were not explicitly trained to do. \nOften, these capabilities need to be ‚Äúunlocked‚Äù by the right prompt. \n\n\n\nBut what is the right prompt?\nThe answer is very similar to what you would tell a human dialogue partner/assistant.\nYou can increase the probability of getting the desired output by asking good questions or giving enough information."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#basics-of-prompting",
    "href": "slides/prompt-labor-basics.html#basics-of-prompting",
    "title": "Prompt Labor: Basics",
    "section": "Basics of prompting",
    "text": "Basics of prompting\nOpenAI give a set of strategies for using their models effectively:\n Prompt engineering\nThese include:\n\nwriting clear instructions\nproviding reference texts\nsplitting tasks into subtasks\ngiving the LLM ‚Äòtime to think‚Äô\nusing external tools"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#writing-clear-instructions",
    "href": "slides/prompt-labor-basics.html#writing-clear-instructions",
    "title": "Prompt Labor: Basics",
    "section": "Writing clear instructions",
    "text": "Writing clear instructions\n\n\n\nThink of an LLM as a role-playing conversation simulator.\nInstructions should be clear and unambiguous.\nIndicate which role the model (persona) should adopt.\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nInclude details in your query to get more relevant answers\nAsk the model to adopt a persona\nUse delimiters to clearly indicate distinct parts of the input\nSpecify the steps required to complete a task\nProvide examples\nSpecify the desired length of the output"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#adopt-a-persona-role",
    "href": "slides/prompt-labor-basics.html#adopt-a-persona-role",
    "title": "Prompt Labor: Basics",
    "section": "Adopt a persona (role)",
    "text": "Adopt a persona (role)\n\n\n\n\n\n\nNote\n\n\n\n: You are an expert on learning techniques. Explain the concept of ‚Äòflipped classroom‚Äô in one paragraph.\n\n\n\n\n\n\n\n\nNote\n\n\n\n: You are an expert financial derivatives. Explain the concept of ‚Äòflipped classroom‚Äô in one paragraph."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#provide-reference-texts",
    "href": "slides/prompt-labor-basics.html#provide-reference-texts",
    "title": "Prompt Labor: Basics",
    "section": "Provide reference texts",
    "text": "Provide reference texts\n\nProvide a model with trusted and relevant information.\nThen instruct the model to use the provided information to compose its answer.\n\n Instruct the model to answer using a reference text\n\n\n\nThis leads to retrieval-augmented generation (RAG). First create a database of documents, then retrieve the most relevant documents, based on a user‚Äôs query. These are then included in the prompt to the model. The model is instructed to use the information in the documents to compose its answer."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#giving-gpt-time-to-think",
    "href": "slides/prompt-labor-basics.html#giving-gpt-time-to-think",
    "title": "Prompt Labor: Basics",
    "section": "Giving GPT ‚Äòtime to think‚Äô",
    "text": "Giving GPT ‚Äòtime to think‚Äô\n\nLLMs generate text one word at a time‚Äìthe model spends the same amount of computation on each word.\nGiving the model more context gives it more steps to ‚Äúthink‚Äù.\nThis increases the chances that the model will give a good answer.\nThis technique is known as chain-of-thought prompting, and can often be induced by simply instructing the model to think step-by-step or Take a deep breath and work on this problem step-by-step (Yang et al. 2023)."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#chain-of-thought-prompting",
    "href": "slides/prompt-labor-basics.html#chain-of-thought-prompting",
    "title": "Prompt Labor: Basics",
    "section": "Chain-of-thought prompting",
    "text": "Chain-of-thought prompting\n\nChain-of-thought prompting encourages the LLM to ‚Äúexplain‚Äù its intermediate reasoning steps.\nEnables complex reasoning and problem solving.\n\nInstead of this:\n\n\n\n\n\n\nNote\n\n\n\n: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1. Yes or no?\n\n\nDo this:\n\n\n\n\n\n\nNote\n\n\n\n: Is this statement correct? The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\nReason through the problem step-by-step. Start by identifying the odd numbers. Next, add them up. Finally, determine if the sum is even or odd. Write down your reasoning steps in a numbered list.\n\n\n\nWhy does this work?"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#zero-shot-chain-of-thought-prompting",
    "href": "slides/prompt-labor-basics.html#zero-shot-chain-of-thought-prompting",
    "title": "Prompt Labor: Basics",
    "section": "Zero-shot chain-of-thought prompting",
    "text": "Zero-shot chain-of-thought prompting\n\n\n\n\n\n\nNote\n\n\n\n: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1. Take a deep breath and think step-by-step.\n\n\n\n\nWhen using GPT-4, ChatGPT and Copilot do this automatically."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#use-markdown-formatting",
    "href": "slides/prompt-labor-basics.html#use-markdown-formatting",
    "title": "Prompt Labor: Basics",
    "section": "Use Markdown formatting",
    "text": "Use Markdown formatting\n\nUse Markdown to format your prompts.\nInstruct the LLM to format its output using Markdown.\n\n\n\n\n\n\n\nNote\n\n\n\n: Improve this haiku:\nWords weave through the air,\nMinds meld with machine‚Äôs deep thought,\nKnowledge blooms anew.\nIt is about about a workshop on large language models. I‚Äôm not happy with it.\nShow me all the text. Format your edits as **TEXT** and show the deleted text as ~~TEXT~~. Keep you review short (max 100 words).\n\n\nTry this example in ChatGPT."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#advanced-prompting-techniques",
    "href": "slides/prompt-labor-basics.html#advanced-prompting-techniques",
    "title": "Prompt Labor: Basics",
    "section": "Advanced prompting techniques",
    "text": "Advanced prompting techniques\nFor more advanced prompting techniques, see these websites:\n\n Learn prompting\n Prompting guide\n OpenAI cookbook\n\nand explore this activity."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#retrieval-augmented-generation-rag",
    "href": "slides/prompt-labor-basics.html#retrieval-augmented-generation-rag",
    "title": "Prompt Labor: Basics",
    "section": "Retrieval-augmented generation (RAG)",
    "text": "Retrieval-augmented generation (RAG)\n\n\nFigure courtesy of Pinecone"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#web-search",
    "href": "slides/prompt-labor-basics.html#web-search",
    "title": "Prompt Labor: Basics",
    "section": "Web search",
    "text": "Web search\n\nSimilar to retrieval-augmented generation, but with web search.\nLLMs can be instructed to use web search to find information.\nCopilot does this automatically - ChatGPT (paid version only) can be instructed to do this."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#external-tools",
    "href": "slides/prompt-labor-basics.html#external-tools",
    "title": "Prompt Labor: Basics",
    "section": "External tools",
    "text": "External tools\n\nLLMs can be instructed to use external tools to complete tasks.\nFor example, an LLM can be instructed to use a calculator to perform arithmetic.\nOpenAI calls this approach function calling."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#multi-agent-conversations",
    "href": "slides/prompt-labor-basics.html#multi-agent-conversations",
    "title": "Prompt Labor: Basics",
    "section": "Multi-agent conversations",
    "text": "Multi-agent conversations"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#local-models",
    "href": "slides/prompt-labor-basics.html#local-models",
    "title": "Prompt Labor: Basics",
    "section": "Local models",
    "text": "Local models\n\nDownload and run models, such as e.g.¬†Llama 2 or Code Llama, locally.\nOllama\nLM Studio\n\nHardware requirements:\n\nApple Silicon Mac (M1/M2/M3) / Windows / Linux\n16GB+ of RAM is recommended\nNVIDIA/AMD GPUs supported"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#footnotes",
    "href": "slides/prompt-labor-basics.html#footnotes",
    "title": "Prompt Labor: Basics",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWhat it is actually doing is responding with the most likely sequence following the question.‚Ü©Ô∏é"
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html",
    "href": "slides/cas-hochschuldidaktik.html",
    "title": "CAS Hochschuldidaktik",
    "section": "",
    "text": "Note\n\n\n\n\nHaltung der BFH: Technologien, die den Lernprozess unterst√ºtzen und praxisrelevant sind, sollen in die Lehre einbezogen werden.\nEinsatz von KI in der Lehre: Die Mehrheit der Studierenden wird KI-Tools nutzen. Studierende sollen lernen, Technologien kompetent einzusetzen und kritisch zu hinterfragen.\n\n\n\n \n Knowledge Base der Virtuellen Akademie\n PDF"
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#orientierungshilfe-f√ºr-lehrpersonen-der-bfh",
    "href": "slides/cas-hochschuldidaktik.html#orientierungshilfe-f√ºr-lehrpersonen-der-bfh",
    "title": "CAS Hochschuldidaktik",
    "section": "",
    "text": "Note\n\n\n\n\nHaltung der BFH: Technologien, die den Lernprozess unterst√ºtzen und praxisrelevant sind, sollen in die Lehre einbezogen werden.\nEinsatz von KI in der Lehre: Die Mehrheit der Studierenden wird KI-Tools nutzen. Studierende sollen lernen, Technologien kompetent einzusetzen und kritisch zu hinterfragen.\n\n\n\n \n Knowledge Base der Virtuellen Akademie\n PDF"
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#assistant-menagerie",
    "href": "slides/cas-hochschuldidaktik.html#assistant-menagerie",
    "title": "CAS Hochschuldidaktik",
    "section": " Assistant Menagerie",
    "text": "Assistant Menagerie\n\n\n\nAssistant\nProvider\nPrivacy\nLLM\nCapabilities\nPricing model\n\n\n\n\nChatGPT\nOpenAI\nüëéüèº\nGPT-3.5, GPT-4\nWeb search, DALLE, GPTs, multimodal input\nüí∂\n\n\nCopilot\nMicrosoft\nüëçüèº\nGPT-3.5, GPT-4\nWeb search, DALLE, multimodal input\nüÜì F√ºr BFH Mitarbeitende/Studierende\n\n\nGemini\nGoogle\nüëéüèº\nGemini Ultra/Pro/Nano\nWeb search, multimodal input\nüí∂\n\n\nHuggingChat\nü§ó Hugging Face\nüëçüèº\nOpen models (CodeLlama, Llama 2, Mistral, Gemma)\n\nüÜì"
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#prompting",
    "href": "slides/cas-hochschuldidaktik.html#prompting",
    "title": "CAS Hochschuldidaktik",
    "section": " Prompting",
    "text": "Prompting"
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#was-ist-ein-prompt",
    "href": "slides/cas-hochschuldidaktik.html#was-ist-ein-prompt",
    "title": "CAS Hochschuldidaktik",
    "section": "Was ist ein Prompt?",
    "text": "Was ist ein Prompt?\n\nDas Ziel eines LLM ist es, Text zu vervollst√§ndigen.\nEin Prompt ist der Input (Anweisung) eines Sprachmodelles.\n\n\n\n\n\n\n\n Prompt:\n\n\n\nWrite a haiku about a workshop on large language models.\n\n\n\n\n\n\n\n\n Output:\n\n\n\nWhispers of circuits, Knowledge blooms in bytes and bits, Model learns and fits.\n\n\n\nDie Antwort wird als Fortsetzung des Prompts generiert."
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#f√§higkeiten-freischalten",
    "href": "slides/cas-hochschuldidaktik.html#f√§higkeiten-freischalten",
    "title": "CAS Hochschuldidaktik",
    "section": "F√§higkeiten freischalten",
    "text": "F√§higkeiten freischalten\n\n\n\nLLMs lernen Aufgaben zu l√∂sen, f√ºr die sie nicht trainiert wurden.\nF√§higkeiten m√ºssen durch den richtigen Prompt ‚Äúfreigeschaltet‚Äù werden.\n \n\n\n\nWas ist der richtige Prompt?\n\nSehr √§hnlich zu dem, was man einem menschlichen Dialogpartner/Assistenten sagen w√ºrde.\nChancen, die gew√ºnschte Ausgabe zu erhalten, werden durch gute Fragen oder gen√ºgend Informationen erh√∂ht."
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#grundlagen-des-prompting",
    "href": "slides/cas-hochschuldidaktik.html#grundlagen-des-prompting",
    "title": "CAS Hochschuldidaktik",
    "section": "Grundlagen des Prompting",
    "text": "Grundlagen des Prompting\n\nOpenAI gibt eine  Reihe von Strategien f√ºr die effektive Nutzung ihrer Modelle.\n\nDiese beinhalten:\n\nklare Anweisungen schreiben\nReferenztexte bereitstellen\nAufgaben in Teilaufgaben unterteilen\ndem LLM ‚ÄòZeit zum Nachdenken‚Äô geben\nexterne Tools verwenden"
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#klare-anweisungen-schreiben",
    "href": "slides/cas-hochschuldidaktik.html#klare-anweisungen-schreiben",
    "title": "CAS Hochschuldidaktik",
    "section": "Klare Anweisungen schreiben",
    "text": "Klare Anweisungen schreiben\n\n\n\nTeile einem LLM mit, welche Art von Gespr√§ch du f√ºhren m√∂chtest.\n\nAnweisungen sollten klar und eindeutig sein.\nGib an, welche Rolle (Persona) das Modell √ºbernehmen soll.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nGib Details in deiner Anfrage an, um relevantere Antworten zu bekommen\nBitte das Modell, eine Persona zu √ºbernehmen\nVerwende Trennzeichen, um klar auf die unterschiedlichen Teile der Eingabe hinzuweisen\nGib die Schritte an, die zur Durchf√ºhrung einer Aufgabe erforderlich sind\nGib Beispiele\nGib die gew√ºnschte L√§nge der Ausgabe an"
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#eine-rolle-zuweisen",
    "href": "slides/cas-hochschuldidaktik.html#eine-rolle-zuweisen",
    "title": "CAS Hochschuldidaktik",
    "section": "Eine Rolle zuweisen",
    "text": "Eine Rolle zuweisen\n\n\n\n\n\n\n Prompt:\n\n\n\nYou are an expert on learning techniques. Explain the concept of ‚Äòflipped classroom‚Äô in one paragraph.\n\n\n\n\n\n\n\n\n Prompt:\n\n\n\nYou are an expert on financial derivatives. Explain the concept of ‚Äòflipped classroom‚Äô in one paragraph."
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#referenztexte-bereitstellen",
    "href": "slides/cas-hochschuldidaktik.html#referenztexte-bereitstellen",
    "title": "CAS Hochschuldidaktik",
    "section": "Referenztexte bereitstellen",
    "text": "Referenztexte bereitstellen\n\nStelle einem Modell vertrauensw√ºrdige und relevante Informationen zur Verf√ºgung.\nWeise das Modell an, die bereitgestellten Informationen zur Erstellung der Antwort zu verwenden.\n\n Weise das Modell an, eine Antwort unter Verwendung eines Referenztextes zu geben"
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#einem-llm-zeit-zum-denken-geben",
    "href": "slides/cas-hochschuldidaktik.html#einem-llm-zeit-zum-denken-geben",
    "title": "CAS Hochschuldidaktik",
    "section": "Einem LLM ‚ÄòZeit zum Denken‚Äô geben",
    "text": "Einem LLM ‚ÄòZeit zum Denken‚Äô geben\n\nLLMs generieren Text ein Wort nach dem anderen - das Modell verwendet die gleiche Menge an Berechnung f√ºr jedes Wort.\nWenn das Modell gezwungen wird, mehr Text zu produzieren, hat es mehr Schritte um ‚ÄúNachzudenken‚Äù.\n\n Das Modell wird eine bessere Antwort geben.\n\nDiese Technik ist bekannt als chain-of-thought-Prompting und kann oft einfach durch die Anweisung an das Modell induziert werden, ‚ÄúSchritt f√ºr Schritt zu denken‚Äù (think step-by-step) oder ‚ÄúNimm dir einen Moment Zeit und arbeite dieses Problem Schritt f√ºr Schritt durch‚Äù (Take a deep breath and work on this problem step-by-step)(Yang et al. 2023).\nCopilot und ChatGPT machen dies seit Neuem automatisch."
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#markdown-formatierung-verwenden",
    "href": "slides/cas-hochschuldidaktik.html#markdown-formatierung-verwenden",
    "title": "CAS Hochschuldidaktik",
    "section": "Markdown-Formatierung verwenden",
    "text": "Markdown-Formatierung verwenden\n\nVerwende Markdown zur Formatierung deiner Prompts.\nWeise das LLM an, den Output mit Markdown zu formatieren.\n\n\n\n\n\n\n\n Prompt:\n\n\n\nImprove this haiku:\n\n## Whispers of circuits\n\nWords weave through the air,  \nMinds meld with machine's deep thought,  \nKnowledge blooms anew.  \n\nIt is about about a workshop on large language models. I'm not happy with the phrase \" machine's deep thought\".\n\nShow me all the text. Format the text you added as _TEXT_ and show me the deleted text formatted as ~~TEXT~~ in the new haiku. Keep you review short (max 100 words)."
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#fortgeschrittene-prompting-techniken",
    "href": "slides/cas-hochschuldidaktik.html#fortgeschrittene-prompting-techniken",
    "title": "CAS Hochschuldidaktik",
    "section": "Fortgeschrittene Prompting-Techniken",
    "text": "Fortgeschrittene Prompting-Techniken\nWeiterf√ºhrende Information zu Prompting-Techniken:\n\n Learn prompting\n Prompting guide\n OpenAI cookbook"
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#wof√ºr-sind-llms-gut",
    "href": "slides/cas-hochschuldidaktik.html#wof√ºr-sind-llms-gut",
    "title": "CAS Hochschuldidaktik",
    "section": "Wof√ºr sind LLMs gut?",
    "text": "Wof√ºr sind LLMs gut?\n\nKorrigieren von Grammatik, schlechtem Stil, usw.\nUmschreiben/Paraphrasieren von Texten\nAnalysieren von Texten (Argumentation, Stil, usw.)\n√úbersetzen von Sprachen\nErstellen von strukturiertem Output\nSchreiben von Computercode\nBeantworten von Fragen zu einer Wissensbasis\nFaktische Ausgabe nur mit RAG oder Websuche"
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#√ºbungen",
    "href": "slides/cas-hochschuldidaktik.html#√ºbungen",
    "title": "CAS Hochschuldidaktik",
    "section": " √úbungen",
    "text": "√úbungen\n Prompt Techniken selber ausprobieren"
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#fortgeschrittene-llm-techniken",
    "href": "slides/cas-hochschuldidaktik.html#fortgeschrittene-llm-techniken",
    "title": "CAS Hochschuldidaktik",
    "section": "Fortgeschrittene LLM-Techniken",
    "text": "Fortgeschrittene LLM-Techniken"
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#retrieval-augmented-generation-rag",
    "href": "slides/cas-hochschuldidaktik.html#retrieval-augmented-generation-rag",
    "title": "CAS Hochschuldidaktik",
    "section": "Retrieval-augmented Generation (RAG)",
    "text": "Retrieval-augmented Generation (RAG)\n\n\nAbbildung von Pinecone"
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#websuche",
    "href": "slides/cas-hochschuldidaktik.html#websuche",
    "title": "CAS Hochschuldidaktik",
    "section": "Websuche",
    "text": "Websuche\n\n√Ñhnlich wie die Retrieval-augmented Generation, aber mit Websuche.\nLLMs k√∂nnen angewiesen werden, die Websuche zur Informationsbeschaffung zu nutzen.\nLLM fasst die Informationen zusammen und benutzt sie als Referenztext zur Beantwortung der Frage.\nCopilot macht dies automatisch - ChatGPT (nur kostenpflichtige Version) kann angewiesen werden, dies zu tun."
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#externe-werkzeuge",
    "href": "slides/cas-hochschuldidaktik.html#externe-werkzeuge",
    "title": "CAS Hochschuldidaktik",
    "section": "Externe Werkzeuge",
    "text": "Externe Werkzeuge\n\nLLMs k√∂nnen angewiesen werden, externe Werkzeuge zur Aufgabenerf√ºllung zu nutzen.\nZum Beispiel kann ein LLM angewiesen werden, einen Taschenrechner zur Durchf√ºhrung von Rechenoperationen zu verwenden.\nOpenAI nennt diesen Ansatz Funktionsaufruf."
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#lokale-modelle",
    "href": "slides/cas-hochschuldidaktik.html#lokale-modelle",
    "title": "CAS Hochschuldidaktik",
    "section": "Lokale Modelle",
    "text": "Lokale Modelle\n\nLaden Sie Modelle herunter und f√ºhren Sie sie lokal aus, wie z.B. Llama 2 oder Code Llama.\nOllama\nLM Studio\n\nHardwareanforderungen:\n\nApple Silicon Mac (M1/M2/M3) / Windows / Linux\nEs wird empfohlen, 16GB+ RAM zu haben\nNVIDIA/AMD GPUs werden unterst√ºtzt"
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#references",
    "href": "slides/cas-hochschuldidaktik.html#references",
    "title": "CAS Hochschuldidaktik",
    "section": "References",
    "text": "References\n\n\nYang, Chengrun, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V. Le, Denny Zhou, and Xinyun Chen. 2023. ‚ÄúLarge Language Models as Optimizers.‚Äù September 6, 2023. http://arxiv.org/abs/2309.03409."
  },
  {
    "objectID": "slides/04-reflection.html",
    "href": "slides/04-reflection.html",
    "title": "Idea Generation and Reflection",
    "section": "",
    "text": "Ideas for tools: Do you have any ideas that weren‚Äôt discussed in this workshop? What would you like to see in the future?\nOpportunities and challenges: What are the opportunities and challenges involved with using LLMs in educational settings?"
  },
  {
    "objectID": "slides/04-reflection.html#idea-generation",
    "href": "slides/04-reflection.html#idea-generation",
    "title": "Idea Generation and Reflection",
    "section": "",
    "text": "Ideas for tools: Do you have any ideas that weren‚Äôt discussed in this workshop? What would you like to see in the future?\nOpportunities and challenges: What are the opportunities and challenges involved with using LLMs in educational settings?"
  },
  {
    "objectID": "slides/04-reflection.html#reflection",
    "href": "slides/04-reflection.html#reflection",
    "title": "Idea Generation and Reflection",
    "section": "Reflection",
    "text": "Reflection\n\nDo you feel confident in using LLMs in your educational practice? What would help you feel more confident?\nDo you feel that you understand how to apply LLMs?\nDo you feel confident in evaluating LLM-based tools?"
  },
  {
    "objectID": "slides/04-reflection.html#thank-you-for-attending-this-workshop",
    "href": "slides/04-reflection.html#thank-you-for-attending-this-workshop",
    "title": "Idea Generation and Reflection",
    "section": "Thank you for attending this workshop!",
    "text": "Thank you for attending this workshop!\n  \nüåü Your feedback matters! Please take 5 minutes to complete our üëâ evaluation form."
  },
  {
    "objectID": "slides/04-reflection.html#evaluation-form",
    "href": "slides/04-reflection.html#evaluation-form",
    "title": "Idea Generation and Reflection",
    "section": "Evaluation Form",
    "text": "Evaluation Form"
  },
  {
    "objectID": "slides/02-prompting-techniques.html",
    "href": "slides/02-prompting-techniques.html",
    "title": "Basic Prompting Techniques",
    "section": "",
    "text": "Remember: the goal of an LLM is complete text.\nA prompt is a piece of text (instruction) that is given to a language model to complete.\n\n\n\n\n\n\n\nNote\n\n\n\nPROMPT : Write a haiku about a workshop on large language models.\nASSISTANT : Whispers of circuits,\nKnowledge blooms in bytes and bits,\nModel learns and fits.\n\n\n\nThe response is generated as continuation of the prompt.\n\n\nMore technical definition: The output is generated by auto-regressively sampling from the probability distribution over the vocabulary, conditioned on the prompt."
  },
  {
    "objectID": "slides/02-prompting-techniques.html#what-is-a-prompt",
    "href": "slides/02-prompting-techniques.html#what-is-a-prompt",
    "title": "Basic Prompting Techniques",
    "section": "",
    "text": "Remember: the goal of an LLM is complete text.\nA prompt is a piece of text (instruction) that is given to a language model to complete.\n\n\n\n\n\n\n\nNote\n\n\n\nPROMPT : Write a haiku about a workshop on large language models.\nASSISTANT : Whispers of circuits,\nKnowledge blooms in bytes and bits,\nModel learns and fits.\n\n\n\nThe response is generated as continuation of the prompt.\n\n\nMore technical definition: The output is generated by auto-regressively sampling from the probability distribution over the vocabulary, conditioned on the prompt."
  },
  {
    "objectID": "slides/02-prompting-techniques.html#unlocking-knowledge",
    "href": "slides/02-prompting-techniques.html#unlocking-knowledge",
    "title": "Basic Prompting Techniques",
    "section": "Unlocking knowledge",
    "text": "Unlocking knowledge\n\n\n\n\n\nLLMs learn to do things they were not explicitly trained to do. \nOften, these capabilities need to be ‚Äúunlocked‚Äù by the right prompt. \n\n\n\nWhat is the right prompt?\nThe answer is very similar to what you would tell a human dialogue partner.\nYou can increase the probability of getting the desired output by asking good questions."
  },
  {
    "objectID": "slides/02-prompting-techniques.html#basics-of-prompting",
    "href": "slides/02-prompting-techniques.html#basics-of-prompting",
    "title": "Basic Prompting Techniques",
    "section": "Basics of prompting",
    "text": "Basics of prompting"
  },
  {
    "objectID": "slides/02-prompting-techniques.html#basics-of-prompting-1",
    "href": "slides/02-prompting-techniques.html#basics-of-prompting-1",
    "title": "Basic Prompting Techniques",
    "section": "Basics of prompting",
    "text": "Basics of prompting\nOpenAI give a set of strategies for using their models\n\n\nüëâ Prompt engineering\nThese include:\n\nwriting clear instructions\nproviding reference texts\nsplitting tasks into subtasks\ngiving GPT ‚Äòtime to think‚Äô\nusing external tools"
  },
  {
    "objectID": "slides/02-prompting-techniques.html#writing-clear-instructions",
    "href": "slides/02-prompting-techniques.html#writing-clear-instructions",
    "title": "Basic Prompting Techniques",
    "section": "Writing clear instructions",
    "text": "Writing clear instructions\n\n\n\nThink of an LLM as a role-playing conversation simulator.\nInstructions should be clear and unambiguous.\nIndicate which role the model (persona) should adopt.\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nInclude details in your query to get more relevant answers\nAsk the model to adopt a persona\nUse delimiters to clearly indicate distinct parts of the input\nSpecify the steps required to complete a task\nProvide examples\nSpecify the desired length of the output"
  },
  {
    "objectID": "slides/02-prompting-techniques.html#adopt-a-persona-role",
    "href": "slides/02-prompting-techniques.html#adopt-a-persona-role",
    "title": "Basic Prompting Techniques",
    "section": "Adopt a persona (role)",
    "text": "Adopt a persona (role)\n\n\n\n\n\n\nNote\n\n\n\n: You are an expert on learning techniques. Explain the concept of ‚Äòflipped classroom‚Äô in one paragraph.\n: You are an expert financial derivatives. Explain the concept of ‚Äòflipped classroom‚Äô in one paragraph."
  },
  {
    "objectID": "slides/02-prompting-techniques.html#provide-reference-texts",
    "href": "slides/02-prompting-techniques.html#provide-reference-texts",
    "title": "Basic Prompting Techniques",
    "section": "Provide reference texts",
    "text": "Provide reference texts\n\nProvide a model with trusted and relevant information.\nThen instruct the model to use the provided information to compose its answer.\n\n\n\nThis leads to retrieval-augmented generation (RAG). First create a database of documents, then retrieve the most relevant documents, based on a user‚Äôs query. These are then included in the prompt to the model. The model is instructed to use the information in the documents to compose its answer."
  },
  {
    "objectID": "slides/02-prompting-techniques.html#provide-reference-texts-1",
    "href": "slides/02-prompting-techniques.html#provide-reference-texts-1",
    "title": "Basic Prompting Techniques",
    "section": "Provide reference texts",
    "text": "Provide reference texts\n\n\n\n\n\n\nNote\n\n\n\n: You will be provided with a document delimited by triple quotes and a question. Your task is to provide a simplified answer to the question using only the provided document and to cite the passage(s) of the document used to answer the question. If the document does not contain the information needed to answer this question then simply write: ‚ÄúInsufficient information.‚Äù If an answer to the question is provided, it must be annotated with a citation. Use the following format for to cite relevant passages ({‚Äúcitation‚Äù: ‚Ä¶}).\n## Document\n‚Äô‚Äò‚ÄôThe flipped classroom intentionally shifts instruction to a learner-centered model, in which students are often initially introduced to new topics outside of school, freeing up classroom time for the exploration of topics in greater depth, creating meaningful learning opportunities. With a flipped classroom, ‚Äôcontent delivery‚Äô may take a variety of forms, often featuring video lessons prepared by the teacher or third parties, although online collaborative discussions, digital research, and text readings may alternatively be used. The ideal length for a video lesson is widely cited as eight to twelve minutes.‚Äô‚Äô‚Äô\n## Question\nWhat is flipped classroom?"
  },
  {
    "objectID": "slides/02-prompting-techniques.html#giving-gpt-time-to-think",
    "href": "slides/02-prompting-techniques.html#giving-gpt-time-to-think",
    "title": "Basic Prompting Techniques",
    "section": "Giving GPT ‚Äòtime to think‚Äô",
    "text": "Giving GPT ‚Äòtime to think‚Äô\n\nLLMs generate text one word at a time‚Äìthe model spends the same amount of computation on each word.\nGiving the model more context gives it more steps to ‚Äúthink‚Äù.\nThis increases the chances that the model will give a good answer.\nThis technique is known as chain-of-thought prompting, and can often be induced by simply instructing the model to think step-by-step or Take a deep breath and work on this problem step-by-step (Yang et al. 2023)."
  },
  {
    "objectID": "slides/02-prompting-techniques.html#chain-of-thought-prompting",
    "href": "slides/02-prompting-techniques.html#chain-of-thought-prompting",
    "title": "Basic Prompting Techniques",
    "section": "Chain-of-thought prompting",
    "text": "Chain-of-thought prompting\n\nChain-of-thought prompting encourages the LLM to ‚Äúexplain‚Äù its intermediate reasoning steps.\nEnables complex reasoning and problem solving.\n\n\n\n\n\n\n\nNote\n\n\n\nInstead of this:\n: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\nDo this:\n: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.  The odd numbers are 9, 15, 1.  The sum of the odd numbers is 9 + 15 + 1 = 25.  25 is an odd number.  Therefore, the statement is false.\n\n\n\nWhy does this work?"
  },
  {
    "objectID": "slides/02-prompting-techniques.html#zero-shot-chain-of-thought-prompting",
    "href": "slides/02-prompting-techniques.html#zero-shot-chain-of-thought-prompting",
    "title": "Basic Prompting Techniques",
    "section": "Zero-shot chain-of-thought prompting",
    "text": "Zero-shot chain-of-thought prompting\n\n\n\n\n\n\nNote\n\n\n\n: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1. Take a deep breath and think step-by-step.\n\n\n\n\nWhen using GPT-4, ChatGPT and Bing seem to be doing this automatically."
  },
  {
    "objectID": "slides/02-prompting-techniques.html#explore-prompting-techniques",
    "href": "slides/02-prompting-techniques.html#explore-prompting-techniques",
    "title": "Basic Prompting Techniques",
    "section": "Explore prompting techniques",
    "text": "Explore prompting techniques\nNow open the first activity to learn more about ChatGPT and OpenAI Playground:\nüëâ Activity 1."
  },
  {
    "objectID": "slides/00-introduction.html",
    "href": "slides/00-introduction.html",
    "title": "What is ChatGPT?",
    "section": "",
    "text": "Use LLMs yourself! It‚Äôs important to gain an intuition for their capabilities and limitations.\nCombine domain knowledge of the ‚Äúthing‚Äù you are working on, an understanding of how LLMs work, and an understanding of how to prompt them.\nUse LLMs with students in a classroom setting. This will help students to develop their own understanding of LLMs and become AI-literate.\nAlways (critically üë©‚Äçüî¨) check an LLM‚Äôs output. They are language models, not knowledge bases. Keep a human in the loop."
  },
  {
    "objectID": "slides/00-introduction.html#take-home-messages",
    "href": "slides/00-introduction.html#take-home-messages",
    "title": "What is ChatGPT?",
    "section": "",
    "text": "Use LLMs yourself! It‚Äôs important to gain an intuition for their capabilities and limitations.\nCombine domain knowledge of the ‚Äúthing‚Äù you are working on, an understanding of how LLMs work, and an understanding of how to prompt them.\nUse LLMs with students in a classroom setting. This will help students to develop their own understanding of LLMs and become AI-literate.\nAlways (critically üë©‚Äçüî¨) check an LLM‚Äôs output. They are language models, not knowledge bases. Keep a human in the loop."
  },
  {
    "objectID": "slides/00-introduction.html#learning-outcomes",
    "href": "slides/00-introduction.html#learning-outcomes",
    "title": "What is ChatGPT?",
    "section": "üéØ Learning outcomes",
    "text": "üéØ Learning outcomes\n\n\n\n\n\n\nAfter this workshop, you will be able to:\n\n\n\n\nExplain what large language models and conversational agents, such as ChatGPT, can be used for, and what they shouldn‚Äôt be used for.\nCreate effective prompts for LLMs.\nDesign your own LLM-based educational activities.\nCritically evaluate LLM-based educational activities."
  },
  {
    "objectID": "slides/00-introduction.html#schedule",
    "href": "slides/00-introduction.html#schedule",
    "title": "What is ChatGPT?",
    "section": "‚è±Ô∏è Schedule",
    "text": "‚è±Ô∏è Schedule"
  },
  {
    "objectID": "slides/00-introduction.html#contents",
    "href": "slides/00-introduction.html#contents",
    "title": "What is ChatGPT?",
    "section": "Contents",
    "text": "Contents\n\nExample: 20 questions\nWhat is ChatGPT?\n\nBase model\nAssistant model\n\nWhat is it not?\nChatGPT as a role-play simulator"
  },
  {
    "objectID": "slides/00-introduction.html#questions",
    "href": "slides/00-introduction.html#questions",
    "title": "What is ChatGPT?",
    "section": "20 questions",
    "text": "20 questions\n\n\n\n\n\n\nü§∑‚Äç‚ôÇÔ∏è What is ChatGPT doing here?\nHow does this work?"
  },
  {
    "objectID": "slides/00-introduction.html#what-is-chatgpt",
    "href": "slides/00-introduction.html#what-is-chatgpt",
    "title": "What is ChatGPT?",
    "section": "What is ChatGPT?",
    "text": "What is ChatGPT?\n\n\n\n\n\nConsists of a base model and an assistant model.\nBase or foundation model: probabilistic model of how language is generated.\nAssistant: able to create human-like dialogue."
  },
  {
    "objectID": "slides/00-introduction.html#base-model-text-prediction",
    "href": "slides/00-introduction.html#base-model-text-prediction",
    "title": "What is ChatGPT?",
    "section": "Base model: text prediction",
    "text": "Base model: text prediction\n\n\n\n\n\n\n\nExtracts knowledge from text: linguistic, factual, commonsense, etc."
  },
  {
    "objectID": "slides/00-introduction.html#base-model",
    "href": "slides/00-introduction.html#base-model",
    "title": "What is ChatGPT?",
    "section": "Base model",
    "text": "Base model\nProduces text that most likely follows the input (prompt).\n\n\n\n\n\n\nNote\n\n\n\n: What is the capital of France?\n: What is the capital of Germany? What is the capital of Italy? ‚Ä¶\n\n\n\n\n\n\n\n\nNote\n\n\n\n: The first person to walk on the Moon was\n: Neil Armstrong\n\n\n\n\n\n\n\n\nDoes an LLM know facts?\n\n\n\n\n\nWhat we are really asking: Given what it learned during training, what words are most likely to follow ‚ÄúThe first person to walk on the Moon was‚Äù? A good reply to this question is ‚ÄúNeil Armstrong‚Äù."
  },
  {
    "objectID": "slides/00-introduction.html#base-model-emergent-properties",
    "href": "slides/00-introduction.html#base-model-emergent-properties",
    "title": "What is ChatGPT?",
    "section": "Base model: emergent properties",
    "text": "Base model: emergent properties\nLLMs are thought to show emergent properties - abilities not explicitly programmed into the model, but emerge as a result of text prediction.\n\nperforming arithmetic, answering questions, summarizing text, translating, etc.\nzero-shot learning: LLMs can perform tasks without being trained on them.\nfew-shot learning: LLMs can perform tasks with few examples."
  },
  {
    "objectID": "slides/00-introduction.html#assistant-model-alignment",
    "href": "slides/00-introduction.html#assistant-model-alignment",
    "title": "What is ChatGPT?",
    "section": "Assistant model: alignment",
    "text": "Assistant model: alignment\n\n\n\n\n\n  - Trained to have conversations: turn-taking, question answering, not being [rude/sexist/racist], etc."
  },
  {
    "objectID": "slides/00-introduction.html#chatbot",
    "href": "slides/00-introduction.html#chatbot",
    "title": "What is ChatGPT?",
    "section": "Chatbot",
    "text": "Chatbot\n\n\n\n\n\n\nPrompt: System message: You are a helpful assistant. User message: Tell me a joke.\n: Why don‚Äôt scientists trust atoms? Because they make up everything!\nPrompt: System message: You are a helpful assistant. User message: Tell me a joke. Assistant message: Why don‚Äôt scientists trust atoms? Because they make up everything! User message: Tell me another one.\n: Why did the scarecrow win an award? Because he was outstanding in his field! ::: ‚Äì&gt;"
  },
  {
    "objectID": "slides/00-introduction.html#knowledge-base",
    "href": "slides/00-introduction.html#knowledge-base",
    "title": "What is ChatGPT?",
    "section": "Knowledge base",
    "text": "Knowledge base\n\n\n\n\n\nA knowledge base is a collection of facts about the world.\nAsk and Tell\nI can ask but I can‚Äôt tell.\nIt cannot give me verifiable facts."
  },
  {
    "objectID": "slides/00-introduction.html#knowledge-base-1",
    "href": "slides/00-introduction.html#knowledge-base-1",
    "title": "What is ChatGPT?",
    "section": "Knowledge base",
    "text": "Knowledge base\n\n\n\n\n\nAm Strande von Rainer Maria Rilke  üëâ Open in ChatGPT\n\n\n\n\n\n\nKennst du dieses Gedicht?  üëâ Open in ChatGPT\n\n\n\n\n. . .\nWhat can we learn from this?"
  },
  {
    "objectID": "slides/00-introduction.html#knowledge-base-2",
    "href": "slides/00-introduction.html#knowledge-base-2",
    "title": "What is ChatGPT?",
    "section": "Knowledge base",
    "text": "Knowledge base\n\n\n\n\n\nCan‚Äôt tell me where it got its information from.\nLLMs are models of knowledge bases, but not knowledge bases themselves.\nExpensive/difficult to update with new knowledge.\nProduce ethically questionable results."
  },
  {
    "objectID": "slides/00-introduction.html#an-llm-is-a-role-play-simulator",
    "href": "slides/00-introduction.html#an-llm-is-a-role-play-simulator",
    "title": "What is ChatGPT?",
    "section": "An LLM is a role-play simulator",
    "text": "An LLM is a role-play simulator\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe can think of an LLM as a non-deterministic simulator capable of role-playing an infinity of characters, or, to put it another way, capable of stochastically generating an infinity of simulacra (Shanahan, McDonell, and Reynolds 2023)"
  },
  {
    "objectID": "slides/00-introduction.html#an-llm-is-a-role-play-simulator-1",
    "href": "slides/00-introduction.html#an-llm-is-a-role-play-simulator-1",
    "title": "What is ChatGPT?",
    "section": "An LLM is a role-play simulator",
    "text": "An LLM is a role-play simulator\n\nAn assistant is trained to respond to user prompts in a human-like way.\nA simulator of possible human conversation.\nHas no intentions. It is not an entity with its own goals.\nDoes not have a ‚Äúpersonality‚Äù or ‚Äúcharacter‚Äù in the traditional sense. It can be thought of as a role-playing simulator.\nHas no concept of ‚Äútruth‚Äù or ‚Äúlying‚Äù. The model is not trying to deceive the user, it is simply trying to respond in a human-like way."
  },
  {
    "objectID": "slides/00-introduction.html#an-llm-is-a-role-play-simulator-2",
    "href": "slides/00-introduction.html#an-llm-is-a-role-play-simulator-2",
    "title": "What is ChatGPT?",
    "section": "An LLM is a role-play simulator",
    "text": "An LLM is a role-play simulator\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe dialogue agent will do its best to role-play a character in a dialogue.\nAt every step, the model is trying to generate text that is most likely to follow the input.\nIt can take many different paths. Your interaction is just one of those possible paths."
  },
  {
    "objectID": "slides/00-introduction.html#an-llm-is-a-role-play-simulator-3",
    "href": "slides/00-introduction.html#an-llm-is-a-role-play-simulator-3",
    "title": "What is ChatGPT?",
    "section": "An LLM is a role-play simulator",
    "text": "An LLM is a role-play simulator\n\n\n\n\n\n\nYou can open this conversation in ChatGPT.\nTry re-generating the conversation after the initial prompt."
  },
  {
    "objectID": "slides/00-introduction.html#what-are-llms-good-at",
    "href": "slides/00-introduction.html#what-are-llms-good-at",
    "title": "What is ChatGPT?",
    "section": "What are LLMs good at?",
    "text": "What are LLMs good at?\n\n\n\nFixing grammar, bad writing, etc.\nRephrasing\nAnalyze texts\nWrite computer code\nAnswer questions about a knowledge base\nTranslate languages\nCreating structured output"
  },
  {
    "objectID": "slides/00-introduction.html#references",
    "href": "slides/00-introduction.html#references",
    "title": "What is ChatGPT?",
    "section": "References",
    "text": "References\n\n\nShanahan, Murray. 2023. ‚ÄúTalking About Large Language Models.‚Äù January 25, 2023. https://doi.org/10.48550/arXiv.2212.03551.\n\n\nShanahan, Murray, Kyle McDonell, and Laria Reynolds. 2023. ‚ÄúRole-Play with Large Language Models.‚Äù May 25, 2023. https://doi.org/10.48550/arXiv.2305.16367.\n\n\nWei, Jason, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, et al. 2022. ‚ÄúEmergent Abilities of Large Language Models.‚Äù October 26, 2022. https://doi.org/10.48550/arXiv.2206.07682."
  },
  {
    "objectID": "pages/tutorial-basic-prompting.html",
    "href": "pages/tutorial-basic-prompting.html",
    "title": "Prompting basics",
    "section": "",
    "text": "Code\nfrom openai import OpenAI\nclient = OpenAI()\n\nresponse = client.chat.completions.create(\n  model=\"gpt-4-turbo-preview\",\n  messages=[\n    {\n      \"role\": \"system\",\n      \"content\": \"When I ask for help to write something, you will reply with a document that contains at least one joke or playful comment in every paragraph.\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Write a thank you note to my steel bolt vendor for getting the delivery in on time and in short notice. This made it possible for us to deliver an important order.\"\n    }\n  ],\n  temperature=0.7,\n  max_tokens=1024,\n  top_p=1,\n  frequency_penalty=0,\n  presence_penalty=0,\n  logprobs=True\n)"
  },
  {
    "objectID": "pages/tutorial-basic-prompting.html#openai",
    "href": "pages/tutorial-basic-prompting.html#openai",
    "title": "Prompting basics",
    "section": "",
    "text": "Code\nfrom openai import OpenAI\nclient = OpenAI()\n\nresponse = client.chat.completions.create(\n  model=\"gpt-4-turbo-preview\",\n  messages=[\n    {\n      \"role\": \"system\",\n      \"content\": \"When I ask for help to write something, you will reply with a document that contains at least one joke or playful comment in every paragraph.\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Write a thank you note to my steel bolt vendor for getting the delivery in on time and in short notice. This made it possible for us to deliver an important order.\"\n    }\n  ],\n  temperature=0.7,\n  max_tokens=1024,\n  top_p=1,\n  frequency_penalty=0,\n  presence_penalty=0,\n  logprobs=True\n)"
  },
  {
    "objectID": "pages/text-representation.html",
    "href": "pages/text-representation.html",
    "title": "Text representation",
    "section": "",
    "text": "Text embeddings are numerical representations of words, sentences or documents. They are used in many NLP tasks, such as sentiment analysis, machine translation, and question answering.\n\nEmbeddings should capture features of words or concepts, and relationships between these.\nA sentence embedding is just like a word embedding, except it associates every sentence with a vector full of numbers, capturing similarities between sentences.\nThe key idea is that words/sentences with similar meanings will have similar vectors. This is useful for many tasks in natural language processing, such as sentiment analysis, machine translation, and question answering.\n\nYou can read more about text embeddings in this üëâ post.\nThe following is an example of sentence embeddings, showing the distance between sentences. The distance is calculated using the dot product (cosine similarity) of the embeddings.\n\n\n\n\nCode\nfrom langchain.embeddings.openai import OpenAIEmbeddings\n# embedding = OpenAIEmbeddings()\nembedding = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pyobsplot import Plot, d3, Math, js\n\n\n/Users/andrew/GitHub/sites/promptly-literate/env/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning:\n\nThe class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n\n\n\n\n\nCode\nsentences = [\n    \"Good morning, how are you?\",\n    \"I am doing well, how about you?\",\n    \"Hi, how are you doing today?\",\n    \"Hey, what's up?\",\n    \"I like apples.\",\n    \"One of my daughters doesn't like kiwis.\",\n    \"The other doesn't like bananas.\",\n    \"The earth is the third planet from the sun.\",\n    \"The moon is a natural satellite of the earth.\",\n    \"Jupiter is the fifth planet from the Sun and the largest in the Solar System.\",\n    \"The humpback whale is renowned for its enchanting songs, which are believed to serve various purposes, including communication, mating, and navigation during migration.\",\n    \"Dolphins, highly intelligent marine mammals, communicate with each other using a complex system of clicks, whistles, and body language, enabling them to work together in hunting and navigation.\",\n    \"The honeybee, through its pollination efforts, plays a vital role in agriculture, contributing to the growth of many of the fruits and vegetables humans rely on for sustenance.\",\n    \"The Large Plane Trees, also known as Road Menders at Saint-R√©my, is an oil-on-canvas painting by Vincent van Gogh.\",\n    \"Pablo Picasso's Guernica, an iconic mural-sized oil painting, stands as a poignant representation of the horrors of war.\",\n    \"This powerful artwork was created in response to the bombing of the town of Guernica during the Spanish Civil War.\"\n]\n\n\n\n\nCode\nembeddings = np.array([embedding.embed_query(sentence) for sentence in sentences])\n\ndot_product_matrix = np.dot(embeddings, embeddings.T)\n\ndf = pd.DataFrame(dot_product_matrix, columns=range(1, len(embeddings)+1))\n\ndf['embedding_index'] = range(1, len(embeddings)+1)\n\ndf = df.melt(id_vars=['embedding_index'], var_name='embedding_index_2', value_name='similarity')\n\n\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\n\n\n\n\n\n\n\n\n\n\n\nSentences\n\n\n\n\n1\nGood morning, how are you?\n\n\n2\nI am doing well, how about you?\n\n\n3\nHi, how are you doing today?\n\n\n4\nHey, what's up?\n\n\n5\nI like apples.\n\n\n6\nOne of my daughters doesn't like kiwis.\n\n\n7\nThe other doesn't like bananas.\n\n\n8\nThe earth is the third planet from the sun.\n\n\n9\nThe moon is a natural satellite of the earth.\n\n\n10\nJupiter is the fifth planet from the Sun and the largest in the Solar System.\n\n\n11\nThe humpback whale is renowned for its enchanting songs, which are believed to serve various purposes, including communication, mating, and navigation during migration.\n\n\n12\nDolphins, highly intelligent marine mammals, communicate with each other using a complex system of clicks, whistles, and body language, enabling them to work together in hunting and navigation.\n\n\n13\nThe honeybee, through its pollination efforts, plays a vital role in agriculture, contributing to the growth of many of the fruits and vegetables humans rely on for sustenance.\n\n\n14\nThe Large Plane Trees, also known as Road Menders at Saint-R√©my, is an oil-on-canvas painting by Vincent van Gogh.\n\n\n15\nPablo Picasso's Guernica, an iconic mural-sized oil painting, stands as a poignant representation of the horrors of war.\n\n\n16\nThis powerful artwork was created in response to the bombing of the town of Guernica during the Spanish Civil War.\n\n\n\n\n\n\n\n\n\nCode\nPlot.plot(\n    {\n        \"height\": 640,\n        \"padding\": 0.05,\n        \"grid\": True,\n        \"x\": {\"axis\": \"top\", \"label\": \"Embedding Index\"},\n        \"y\": {\"label\": \"Embedding Index\"},\n        \"color\": {\"type\": \"linear\", \"scheme\": \"PiYG\"},\n        \"marks\": [\n            Plot.cell(\n                df,\n                {\"x\": \"embedding_index\", \"y\": \"embedding_index_2\", \"fill\": \"similarity\", \"tip\": True},\n            ),\n            Plot.text(\n                df,\n                {\n                    \"x\": \"embedding_index\",\n                    \"y\": \"embedding_index_2\",\n                    \"text\": js(\"d =&gt; d.similarity.toFixed(2)\"),\n                    \"title\": \"title\"\n                },\n            ),\n        ],\n    }\n)\n\n\n\n\n\nYou can see that the sentences are grouped together by semantic similarity. For example, the sentences about fruit are grouped together, and the sentences about planets are grouped together, in the sense that they are similar to each other.\nThis is important: embeddings capture the meaning of words and sentences, and are the basis of LLMs‚Äô ability to ‚Äúunderstand‚Äù language.\nHere is an alternative similarity plot, showing the general topic of each sentence.\n\n\nCode\ntopics = {\"Greeting\": 4, \"Fruit\": 3,\n          \"Planets\": 3, \"Animals\": 3,\n          \"Art\": 3}\ntopics_repeated = [key for key, value in topics.items() for i in range(value)]\n\n\n# Create the similarity matrix\nembeddings = np.array([embedding.embed_query(sentence) for sentence in sentences])\ndot_product_matrix = np.dot(embeddings, embeddings.T)\n\n# Create the heatmap\nfig, ax = plt.subplots()\nim = ax.imshow(dot_product_matrix)\n\n# Set the x and y axis labels\nax.set_xticks(np.arange(len(sentences)))\nax.set_yticks(np.arange(len(sentences)))\nax.set_xticklabels(topics_repeated)\nax.set_yticklabels(topics_repeated)\n\n# Rotate the x axis labels\nplt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n\n# Add a colorbar\ncbar = ax.figure.colorbar(im, ax=ax)\n\n# Show the plot\nplt.show()\n\n\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding."
  },
  {
    "objectID": "pages/text-representation.html#embeddings",
    "href": "pages/text-representation.html#embeddings",
    "title": "Text representation",
    "section": "",
    "text": "Text embeddings are numerical representations of words, sentences or documents. They are used in many NLP tasks, such as sentiment analysis, machine translation, and question answering.\n\nEmbeddings should capture features of words or concepts, and relationships between these.\nA sentence embedding is just like a word embedding, except it associates every sentence with a vector full of numbers, capturing similarities between sentences.\nThe key idea is that words/sentences with similar meanings will have similar vectors. This is useful for many tasks in natural language processing, such as sentiment analysis, machine translation, and question answering.\n\nYou can read more about text embeddings in this üëâ post.\nThe following is an example of sentence embeddings, showing the distance between sentences. The distance is calculated using the dot product (cosine similarity) of the embeddings.\n\n\n\n\nCode\nfrom langchain.embeddings.openai import OpenAIEmbeddings\n# embedding = OpenAIEmbeddings()\nembedding = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pyobsplot import Plot, d3, Math, js\n\n\n/Users/andrew/GitHub/sites/promptly-literate/env/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning:\n\nThe class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n\n\n\n\n\nCode\nsentences = [\n    \"Good morning, how are you?\",\n    \"I am doing well, how about you?\",\n    \"Hi, how are you doing today?\",\n    \"Hey, what's up?\",\n    \"I like apples.\",\n    \"One of my daughters doesn't like kiwis.\",\n    \"The other doesn't like bananas.\",\n    \"The earth is the third planet from the sun.\",\n    \"The moon is a natural satellite of the earth.\",\n    \"Jupiter is the fifth planet from the Sun and the largest in the Solar System.\",\n    \"The humpback whale is renowned for its enchanting songs, which are believed to serve various purposes, including communication, mating, and navigation during migration.\",\n    \"Dolphins, highly intelligent marine mammals, communicate with each other using a complex system of clicks, whistles, and body language, enabling them to work together in hunting and navigation.\",\n    \"The honeybee, through its pollination efforts, plays a vital role in agriculture, contributing to the growth of many of the fruits and vegetables humans rely on for sustenance.\",\n    \"The Large Plane Trees, also known as Road Menders at Saint-R√©my, is an oil-on-canvas painting by Vincent van Gogh.\",\n    \"Pablo Picasso's Guernica, an iconic mural-sized oil painting, stands as a poignant representation of the horrors of war.\",\n    \"This powerful artwork was created in response to the bombing of the town of Guernica during the Spanish Civil War.\"\n]\n\n\n\n\nCode\nembeddings = np.array([embedding.embed_query(sentence) for sentence in sentences])\n\ndot_product_matrix = np.dot(embeddings, embeddings.T)\n\ndf = pd.DataFrame(dot_product_matrix, columns=range(1, len(embeddings)+1))\n\ndf['embedding_index'] = range(1, len(embeddings)+1)\n\ndf = df.melt(id_vars=['embedding_index'], var_name='embedding_index_2', value_name='similarity')\n\n\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\n\n\n\n\n\n\n\n\n\n\n\nSentences\n\n\n\n\n1\nGood morning, how are you?\n\n\n2\nI am doing well, how about you?\n\n\n3\nHi, how are you doing today?\n\n\n4\nHey, what's up?\n\n\n5\nI like apples.\n\n\n6\nOne of my daughters doesn't like kiwis.\n\n\n7\nThe other doesn't like bananas.\n\n\n8\nThe earth is the third planet from the sun.\n\n\n9\nThe moon is a natural satellite of the earth.\n\n\n10\nJupiter is the fifth planet from the Sun and the largest in the Solar System.\n\n\n11\nThe humpback whale is renowned for its enchanting songs, which are believed to serve various purposes, including communication, mating, and navigation during migration.\n\n\n12\nDolphins, highly intelligent marine mammals, communicate with each other using a complex system of clicks, whistles, and body language, enabling them to work together in hunting and navigation.\n\n\n13\nThe honeybee, through its pollination efforts, plays a vital role in agriculture, contributing to the growth of many of the fruits and vegetables humans rely on for sustenance.\n\n\n14\nThe Large Plane Trees, also known as Road Menders at Saint-R√©my, is an oil-on-canvas painting by Vincent van Gogh.\n\n\n15\nPablo Picasso's Guernica, an iconic mural-sized oil painting, stands as a poignant representation of the horrors of war.\n\n\n16\nThis powerful artwork was created in response to the bombing of the town of Guernica during the Spanish Civil War.\n\n\n\n\n\n\n\n\n\nCode\nPlot.plot(\n    {\n        \"height\": 640,\n        \"padding\": 0.05,\n        \"grid\": True,\n        \"x\": {\"axis\": \"top\", \"label\": \"Embedding Index\"},\n        \"y\": {\"label\": \"Embedding Index\"},\n        \"color\": {\"type\": \"linear\", \"scheme\": \"PiYG\"},\n        \"marks\": [\n            Plot.cell(\n                df,\n                {\"x\": \"embedding_index\", \"y\": \"embedding_index_2\", \"fill\": \"similarity\", \"tip\": True},\n            ),\n            Plot.text(\n                df,\n                {\n                    \"x\": \"embedding_index\",\n                    \"y\": \"embedding_index_2\",\n                    \"text\": js(\"d =&gt; d.similarity.toFixed(2)\"),\n                    \"title\": \"title\"\n                },\n            ),\n        ],\n    }\n)\n\n\n\n\n\nYou can see that the sentences are grouped together by semantic similarity. For example, the sentences about fruit are grouped together, and the sentences about planets are grouped together, in the sense that they are similar to each other.\nThis is important: embeddings capture the meaning of words and sentences, and are the basis of LLMs‚Äô ability to ‚Äúunderstand‚Äù language.\nHere is an alternative similarity plot, showing the general topic of each sentence.\n\n\nCode\ntopics = {\"Greeting\": 4, \"Fruit\": 3,\n          \"Planets\": 3, \"Animals\": 3,\n          \"Art\": 3}\ntopics_repeated = [key for key, value in topics.items() for i in range(value)]\n\n\n# Create the similarity matrix\nembeddings = np.array([embedding.embed_query(sentence) for sentence in sentences])\ndot_product_matrix = np.dot(embeddings, embeddings.T)\n\n# Create the heatmap\nfig, ax = plt.subplots()\nim = ax.imshow(dot_product_matrix)\n\n# Set the x and y axis labels\nax.set_xticks(np.arange(len(sentences)))\nax.set_yticks(np.arange(len(sentences)))\nax.set_xticklabels(topics_repeated)\nax.set_yticklabels(topics_repeated)\n\n# Rotate the x axis labels\nplt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n\n# Add a colorbar\ncbar = ax.figure.colorbar(im, ax=ax)\n\n# Show the plot\nplt.show()\n\n\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding."
  },
  {
    "objectID": "pages/schedule.html",
    "href": "pages/schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Was sind Large Language Models (LLMs)?\nWie werden LLMs trainiert?\nWie generieren LLMs Texte?\nWas sind √Ñhnlichkeiten und Unterschiede zwischen LLMs und menschlichem Denken?\nWie k√∂nnen wir LLMs benutzen?\nWie k√∂nnen wir LLMs beschreiben, ohne sie zu anthropomorphisieren?"
  },
  {
    "objectID": "pages/schedule.html#inhalt",
    "href": "pages/schedule.html#inhalt",
    "title": "Schedule",
    "section": "",
    "text": "Was sind Large Language Models (LLMs)?\nWie werden LLMs trainiert?\nWie generieren LLMs Texte?\nWas sind √Ñhnlichkeiten und Unterschiede zwischen LLMs und menschlichem Denken?\nWie k√∂nnen wir LLMs benutzen?\nWie k√∂nnen wir LLMs beschreiben, ohne sie zu anthropomorphisieren?"
  },
  {
    "objectID": "pages/schedule.html#lernziele",
    "href": "pages/schedule.html#lernziele",
    "title": "Schedule",
    "section": "Lernziele",
    "text": "Lernziele\n\n\n\n\n\n\nNach diesem Workshop:\n\n\n\n\nKannst du mit Anfragen von Studierenden in Bezug auf fachspezifische KI-generierte Texte umgehen.\nKannst du in eigenen Worten wiedergeben, wie KI-generierte Texte entstehen.\nHast du Kriterien, anhand derer du KI-Tools beurteilen kannst."
  },
  {
    "objectID": "pages/schedule.html#program",
    "href": "pages/schedule.html#program",
    "title": "Schedule",
    "section": "Program",
    "text": "Program\n\n\n\n\n\nflowchart LR\n  A([\"Einleitung\n            5'\"]) \n  A -.-&gt; B([\"Reaktivationsrunde \n                      10'\"]) \n  B -.-&gt; C([\"Input: Wie funktioniert ChatGPT? \n                      30'\"])\n  C -.-&gt; D([\"Vertiefung: Lernziele 1 + 2 \n                      15'\"]) \n  C -.-&gt; E([\"Vertiefung: Lernziel 3 \n                        15'\"]) \n  D -.-&gt; F([\"Verankern \n                10'\"]) \n  E -.-&gt; F\n  F -.-&gt; G([\"Diskussion \n            15'\"])\n\n\n\n\n\n\n\nEinleitung [‚è±Ô∏è 5‚Äô]: Einstieg in den Workshop\nReaktivationsrunde [‚è±Ô∏è 10‚Äô]: In diesem Teil tauschen die Teilnehmenden sich √ºber ihre Erfahrungen mit KI-generierten Texten aus.\nInput: Wie funktioniert ChatGPT? [‚è±Ô∏è 30‚Äô]: Referat zum Thema k√ºnstliche Intelligenz und ChatGPT.\nVertiefung [‚è±Ô∏è 30‚Äô]: In diesem Teil werden die oben genannten Lernziele vertieft (alleine, in Kleingruppen und im Plenum).\nVerankern [‚è±Ô∏è 10‚Äô]: In diesem Teil werden Erfahrungen zusammengefasst und reflektiert.\nDiskussion [‚è±Ô∏è 15‚Äô]: Am Ende des Workshops wird √ºber die Erfahrungen und Erkenntnisse diskutiert."
  },
  {
    "objectID": "pages/schedule.html#vorbereitung",
    "href": "pages/schedule.html#vorbereitung",
    "title": "Schedule",
    "section": "Vorbereitung",
    "text": "Vorbereitung\nL√∂se folgende Aufgaben mit ChatGPT (oder Bing Chat):\n\nLasse ChatGPT ein Gedicht schreiben. Gebe Thema und Stil vor (z.B. ‚ÄúHochschulbibliotheken und k√ºnstliche Intelligenz‚Äù im Stile des Sturm und Drang).\nLasse ChatGPT dir ein Konzept deines Fachbereichs in einem kurzen Textabschnitt vereinfachend erkl√§ren.\nBenutze ChatGPT, um zu einem Forschungsthema (z.B. ‚ÄúWas ist der Zusammenhang zwischen Sprache und Denken?‚Äù) eine Literaturrecherche durchzuf√ºhren. Lasse dir eine kommentierte Liste von wissenschaftlichen Publikationen geben.\nLasse ChatGPT ein paar Mathe-Aufgaben l√∂sen (z.B. ‚ÄúWas ist 89322/1313?‚Äù)\nL√∂se mit ChatGPT eine praktische Aufgabe: ‚ÄúHier haben wir ein Buch, 9 Eier (ohne Eierkarton), einen Laptop, eine Flasche und einen Nagel. Bitte sag mir, wie ich sie stabil √ºbereinander stapeln kann.‚Äù"
  },
  {
    "objectID": "pages/schedule.html#leitung",
    "href": "pages/schedule.html#leitung",
    "title": "Schedule",
    "section": "Leitung",
    "text": "Leitung\n\nAndrew Ellis: Andrew ist Data Scientist an der Virtuellen Akademie der Berner Fachhochschule. Sein Hintergrund ist in den Kognitionswissenschaften und er ist begeistert von der Schnittstelle zwischen Sprache, Denken und k√ºnstlicher Intelligenz.‚Äù"
  },
  {
    "objectID": "pages/prompting.html",
    "href": "pages/prompting.html",
    "title": "Prompting Programmatically",
    "section": "",
    "text": "import openai\nfrom openai import OpenAI\nclient = OpenAI()\nimport os\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())\n\nopenai.api_key  = os.getenv('OPENAI_API_KEY')\n\nfrom IPython.display import display, Markdown, Latex, HTML, JSON\ndef get_completion(prompt, model=\"gpt-4-turbo-preview\", temperature=0.0):\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    response = client.chat.completions.create(\n        model=model,\n        messages=messages,\n        temperature=temperature\n    )\n    return response.choices[0].message.content"
  },
  {
    "objectID": "pages/prompting.html#prompting-principles",
    "href": "pages/prompting.html#prompting-principles",
    "title": "Prompting Programmatically",
    "section": "Prompting Principles",
    "text": "Prompting Principles\n\nPrinciple 1: Write clear and specific instructions\nPrinciple 2: Give the model time to ‚Äúthink‚Äù\n\n\nTactics\n\nTactic 1: Use delimiters to clearly indicate distinct parts of the input\n\nDelimiters can be anything, such as: ``, \"\"\", &lt; &gt;, ,:`\n\n\ntext = f\"\"\"\nYou should express what you want a model to do by \\ \nproviding instructions that are as clear and \\ \nspecific as you can possibly make them. \\ \nThis will guide the model towards the desired output, \\ \nand reduce the chances of receiving irrelevant \\ \nor incorrect responses. Don't confuse writing a \\ \nclear prompt with writing a short prompt. \\ \nIn many cases, longer prompts provide more clarity \\ \nand context for the model, which can lead to \\ \nmore detailed and relevant outputs.\n\"\"\"\nprompt = f\"\"\"\nSummarize the text delimited by triple backticks \\ \ninto a single sentence.\n```{text}```\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\nTo achieve the desired output from a model, provide clear and specific instructions, noting that longer prompts often offer more clarity and context, thus reducing the likelihood of irrelevant or incorrect responses.\n\n\n\n\nTactic 4: ‚ÄúFew-shot‚Äù prompting\n\nprompt = f\"\"\"\nYour task is to answer in a consistent style.\n\n&lt;child&gt;: Teach me about patience.\n\n&lt;grandparent&gt;: The river that carves the deepest \\ \nvalley flows from a modest spring; the \\ \ngrandest symphony originates from a single note; \\ \nthe most intricate tapestry begins with a solitary thread.\n\n&lt;child&gt;: Teach me about resilience.\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n&lt;grandparent&gt;: The mightiest oak in the forest was once a tiny acorn that stood its ground; the highest mountain withstands the harshest weather, yet remains steadfast; the most enduring bridges were built one stone at a time."
  },
  {
    "objectID": "pages/prompting.html#sentment-analysis",
    "href": "pages/prompting.html#sentment-analysis",
    "title": "Prompting Programmatically",
    "section": "Sentment Analysis",
    "text": "Sentment Analysis\n\nlamp_review = \"\"\"\nNeeded a nice lamp for my bedroom, and this one had \\\nadditional storage and not too high of a price point. \\\nGot it fast.  The string to our lamp broke during the \\\ntransit and the company happily sent over a new one. \\\nCame within a few days as well. It was easy to put \\\ntogether.  I had a missing part, so I contacted their \\\nsupport and they very quickly got me the missing piece! \\\nLumina seems to me to be a great company that cares \\\nabout their customers and products!!\n\"\"\"\n\n\nprompt = f\"\"\"\nWhat is the sentiment of the following product review, \nwhich is delimited with triple backticks?\n\nReview text: '''{lamp_review}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\nThe sentiment of the provided product review is positive. The reviewer expresses satisfaction with the lamp's features, price, and the company's customer service, including fast shipping and prompt resolution of issues."
  },
  {
    "objectID": "pages/prompting.html#tone-transformation",
    "href": "pages/prompting.html#tone-transformation",
    "title": "Prompting Programmatically",
    "section": "Tone transformation",
    "text": "Tone transformation\n\nprompt = f\"\"\"\nTranslate the following from slang to a business letter: \n'Dude, This is Joe, check out this spec on this standing lamp.'\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\nDear [Recipient's Name],\n\nI hope this message finds you well. My name is Joe, and I am writing to bring to your attention the specifications of a particular standing lamp that I believe may be of interest to you. Please find attached the detailed specifications for your review.\n\nShould you have any questions or require further information, please do not hesitate to contact me.\n\nBest regards,\n\nJoe [Your Last Name]\n[Your Contact Information]"
  },
  {
    "objectID": "pages/prompting.html#proofreading-and-editing",
    "href": "pages/prompting.html#proofreading-and-editing",
    "title": "Prompting Programmatically",
    "section": "Proofreading and editing",
    "text": "Proofreading and editing\n\ntext = f\"\"\"\nGot this for my daughter for her birthday cuz she keeps taking \\\nmine from my room.  Yes, adults also like pandas too.  She takes \\\nit everywhere with her, and it's super soft and cute.  One of the \\\nears is a bit lower than the other, and I don't think that was \\\ndesigned to be asymmetrical. It's a bit small for what I paid for it \\\nthough. I think there might be other options that are bigger for \\\nthe same price.  It arrived a day earlier than expected, so I got \\\nto play with it myself before I gave it to my daughter.\n\"\"\"\nprompt = f\"proofread and correct this review: ```{text}```\"\nresponse = get_completion(prompt)\nprint(response)\n\nI purchased this for my daughter for her birthday because she constantly borrows mine from my room. Indeed, adults enjoy pandas as well. She carries it with her everywhere, and it's incredibly soft and adorable. However, one of the ears is slightly lower than the other, and I don't believe it was intended to be asymmetrical. It's somewhat small for the price I paid. I think there might be larger options available for the same price. It arrived a day earlier than anticipated, allowing me to play with it myself before giving it to my daughter.\n\n\n\nfrom redlines import Redlines\n\ndiff = Redlines(text,response)\ndisplay(Markdown(diff.output_markdown))\n\nGot I purchased this for my daughter for her birthday cuz because she keeps taking constantly borrows mine from my room. Yes, room. Indeed, adults also like enjoy pandas too. as well. She takes carries it everywhere with her, her everywhere, and it‚Äôs super incredibly soft and cute. One adorable. However, one of the ears is a bit slightly lower than the other, and I don‚Äôt think that believe it was designed intended to be asymmetrical. It‚Äôs a bit somewhat small for what the price I paid for it though. paid. I think there might be other larger options that are bigger available for the same price. price. It arrived a day earlier than expected, so I got anticipated, allowing me to play with it myself before I gave giving it to my daughter.\n\n\n\nprompt = f\"\"\"\nproofread and correct this review. Make it more compelling. \nEnsure it follows APA style guide and targets an advanced reader. \nOutput in markdown format.\nText: ```{text}```\n\"\"\"\nresponse = get_completion(prompt)\ndisplay(Markdown(response))\n\nI recently purchased a panda-themed item for my daughter's birthday, motivated by her frequent appropriations of my own cherished version. It is worth noting that the appeal of pandas transcends age boundaries, captivating both adults and children alike with their endearing qualities. This particular item has become a constant companion for my daughter, accompanying her in various daily activities. Its plush texture and adorable appearance contribute significantly to its charm.\n\nHowever, it is pertinent to mention a slight imperfection in the product's design. The asymmetry of the ears, with one positioned lower than the other, appears to be an unintended flaw rather than a deliberate stylistic choice. Additionally, the size of the item did not entirely meet my expectations, especially considering the price point. Prospective buyers might find alternatives in the market that offer better value in terms of size for the same financial outlay.\n\nOn a positive note, the delivery of the item exceeded expectations, arriving a day prior to the anticipated date. This serendipitous occurrence afforded me the opportunity to personally engage with the item, further solidifying my appreciation for its qualities before presenting it to my daughter.\n\nIn conclusion, while the product possesses undeniable appeal and has won the affection of my daughter, potential improvements in design accuracy and size valuation could enhance its overall value proposition. Future purchasers are advised to weigh these considerations carefully against their personal preferences and requirements."
  },
  {
    "objectID": "pages/observable-1.html",
    "href": "pages/observable-1.html",
    "title": "Untitled",
    "section": "",
    "text": "ojs_define(data = palmerpenguins::penguins)\n\n\nviewof bill_length_min = Inputs.range(\n  [32, 50], \n  {value: 35, step: 1, label: \"Bill length (min):\"}\n)\nviewof islands = Inputs.checkbox(\n  [\"Torgersen\", \"Biscoe\", \"Dream\"], \n  { value: [\"Torgersen\", \"Biscoe\"], \n    label: \"Islands:\"\n  }\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfiltered = transpose(data).filter(function(penguin) {\n  return bill_length_min &lt; penguin.bill_length_mm &&\n         islands.includes(penguin.island);\n})\n\n\n\n\n\n\n\nPlot.rectY(filtered, \n  Plot.binX(\n    {y: \"count\"}, \n    {x: \"body_mass_g\", fill: \"species\", thresholds: 20}\n  ))\n  .plot({\n    facet: {\n      data: filtered,\n      x: \"sex\",\n      y: \"species\",\n      marginRight: 80\n    },\n    marks: [\n      Plot.frame(),\n    ]\n  }\n)\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "pages/example.html",
    "href": "pages/example.html",
    "title": "Take-home messages",
    "section": "",
    "text": "An LLM is not a knowledge base, instead it‚Äôs a statistical model of a knowledge base. An LLM is trained to be a language model. An LLM is a probabilistic model of its training corpus. It can be used to predict text auto-regressively."
  },
  {
    "objectID": "pages/example.html#embed-a-presentation",
    "href": "pages/example.html#embed-a-presentation",
    "title": "Take-home messages",
    "section": "Embed a presentation",
    "text": "Embed a presentation"
  },
  {
    "objectID": "pages/example.html#embed-miro-board",
    "href": "pages/example.html#embed-miro-board",
    "title": "Take-home messages",
    "section": "Embed Miro board",
    "text": "Embed Miro board"
  },
  {
    "objectID": "pages/assistant.html",
    "href": "pages/assistant.html",
    "title": "Assistent der Virtuellen Akademie",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "pages/activity-prompt-labor-vertiefung.html",
    "href": "pages/activity-prompt-labor-vertiefung.html",
    "title": "Activity: Prompt-Labor Vertiefung",
    "section": "",
    "text": "Mollick and Mollick (2023) haben in ihrem Artikel f√ºnf m√∂gliche Strategien f√ºr die Verwendung von LLMs f√ºr die Lehre vorgestellt. Als erste Strategie nennen Mollick and Mollick (2023) die M√∂glichkeit, mit Hilfe von Sprachmodellen viele unterschiedliche Beispiele zu produzieren (Strategy 1: Using AI to Produce Many Varied Examples):\n\nStudents need many examples when learning complicated concepts Kirschner, Hendrick, and Heal (2022)]. When confronted with new and complex ideas, adding many and varied examples helps students better understand them. If students are presented with only one example, they may focus on the superficial details of that example and not get at the deeper concept. Multiple examples of a single concept can help students decontextualize the idea from the example, leading to better recall and understanding.\n\n\nCreating examples for instructional purposes can be a time-consuming and challenging task for educators, especially when they aim to produce diverse examples that effectively illustrate various aspects of a concept. Educators often have packed schedules and numerous responsibilities, which adds to the complexity of generating examples that meet specific criteria. When crafting examples, instructors need to contemplate several factors: Are the examples engaging and relevant to the students? For instance, incorporating real-world problems or issues can help tailor the examples to pique students‚Äô interest. Do the examples strike the right balance between detail and clarity? Ensuring that examples are neither overly intricate nor excessively simple is vital. (S. 3)\n\nMollick and Mollick (2023) pr√§sentieren Beispielprompts, wie man ein LLM anweisen kann, diese Strategie umzusetzen. Da wir jedoch wissen, dass LLMs gewisse Limitationen haben - Halluzinationen, Model Drift bzw. mangelnde zeitliche Konsistenz der Outputs, mangelnde Transparenz der Modelle - kann es sinnvoll sein, Techniken wie z.B. Retrieval Augmented Generation (RAG) zu verwenden. Im Rahmen dieser Aktivit√§t wirst du das von Mollick and Mollick (2023) vorgeschlagene Vorgehen verwenden und reflektieren."
  },
  {
    "objectID": "pages/activity-prompt-labor-vertiefung.html#ausgangslage",
    "href": "pages/activity-prompt-labor-vertiefung.html#ausgangslage",
    "title": "Activity: Prompt-Labor Vertiefung",
    "section": "",
    "text": "Mollick and Mollick (2023) haben in ihrem Artikel f√ºnf m√∂gliche Strategien f√ºr die Verwendung von LLMs f√ºr die Lehre vorgestellt. Als erste Strategie nennen Mollick and Mollick (2023) die M√∂glichkeit, mit Hilfe von Sprachmodellen viele unterschiedliche Beispiele zu produzieren (Strategy 1: Using AI to Produce Many Varied Examples):\n\nStudents need many examples when learning complicated concepts Kirschner, Hendrick, and Heal (2022)]. When confronted with new and complex ideas, adding many and varied examples helps students better understand them. If students are presented with only one example, they may focus on the superficial details of that example and not get at the deeper concept. Multiple examples of a single concept can help students decontextualize the idea from the example, leading to better recall and understanding.\n\n\nCreating examples for instructional purposes can be a time-consuming and challenging task for educators, especially when they aim to produce diverse examples that effectively illustrate various aspects of a concept. Educators often have packed schedules and numerous responsibilities, which adds to the complexity of generating examples that meet specific criteria. When crafting examples, instructors need to contemplate several factors: Are the examples engaging and relevant to the students? For instance, incorporating real-world problems or issues can help tailor the examples to pique students‚Äô interest. Do the examples strike the right balance between detail and clarity? Ensuring that examples are neither overly intricate nor excessively simple is vital. (S. 3)\n\nMollick and Mollick (2023) pr√§sentieren Beispielprompts, wie man ein LLM anweisen kann, diese Strategie umzusetzen. Da wir jedoch wissen, dass LLMs gewisse Limitationen haben - Halluzinationen, Model Drift bzw. mangelnde zeitliche Konsistenz der Outputs, mangelnde Transparenz der Modelle - kann es sinnvoll sein, Techniken wie z.B. Retrieval Augmented Generation (RAG) zu verwenden. Im Rahmen dieser Aktivit√§t wirst du das von Mollick and Mollick (2023) vorgeschlagene Vorgehen verwenden und reflektieren."
  },
  {
    "objectID": "pages/activity-prompt-labor-vertiefung.html#dein-auftrag",
    "href": "pages/activity-prompt-labor-vertiefung.html#dein-auftrag",
    "title": "Activity: Prompt-Labor Vertiefung",
    "section": "Dein Auftrag",
    "text": "Dein Auftrag\n\n1. Schritt: W√§hle ein Thema\nW√§hle aus deiner eigenen Lehre ein Thema, welches z.B. besonders komplex ist oder welches du deinen Studierenden besonders verst√§ndlich machen m√∂chtest. Stelle sicher, dass du ein PDF hast, welches dieses Thema erl√§utert (z.B. Forschungspapier, Vorlesungsunterlagen).\n\n\n2. Schritt: Nutze Copilot/ChatGPT\nNutze die Strategie von Mollick and Mollick (2023) und lasse viele verschiedene Beispiele von Copilot oder ChatGPT f√ºr das von dir gew√§hlte Thema erstellen. Gehe daf√ºr nach dem folgenden Vorgehen vor. Das Vorgehen basiert auf den Anweisungen im Artikel von Mollick and Mollick (2023):\n\nWenn du einen mit dem Internet verbundenen Assistenten verwendest (z. B. Copilot): Weise den Assistenten an, das Konzept anhand der wichtigsten Werke auf diesem Gebiet nachzuschlagen.\nSage dem Assistenten, was du brauchst (z.B. ‚Äúviele und unterschiedliche Beispiele f√ºr dieses eine Konzept‚Äù).\nBeschreibe den von dir bevorzugten Schreibstil (klar, einfach, konkret, dynamisch, ansprechend).\nBeschreibe die Zielgruppe (z.B. ‚Äúmeine Zielgruppe sind Hochschulstudierende, die von diesem Konzept noch nie geh√∂rt haben‚Äù).\nDu kannst entweder selbst einen Prompt auf der Grundlage der obigen Informationen formulieren oder den folgenden Prompt von Mollick and Mollick (2023) als Ausgangspunkt verwenden:\n\n\n\n\n\n\n\nCopilot Prompt\n\n\n\n\n\nI would like you to act as an example generator for students. When confronted with new and complex concepts, adding many and varied examples helps students better understand those concepts. I would like you to ask what concept I would like examples of, and what level of students I am teaching. You will look up the concept, and then provide me with four different and varied accurate examples of the concept in action. (S. 4)\n\n\n\nWenn du ChatGPT ohne Websuche verwendest, musst du den Prompt entsprechend anpassen, so dass du den Assistenten nicht aufforderst, etwas im Internet zu suchen, da diese Funktion in der unbezahlten Version nicht zur Verf√ºgung steht.\n\n\n\n\n\n\nBeantworte folgende Fragen:\n\n\n\n\nSind die Beispiele relevant und f√ºr deine Lehrt√§tigkeiten n√ºtzlich?\nSind sie relevant und f√ºr die Studierenden interessant?\nSind sie inhaltlich korrekt?\nSind sie detailliert genug?\n‚Ä¶\n\n\n\n\n\n3. Schritt (optional): Nutze RAG\nErstelle nun mit Hilfe vom OpenAI Playground und den zuvor erl√§uterten Anweisungen zu dieser Plattform selbst einen Assistenten, der mit Hilfe von RAG die Inhalte in einem bereitgestellten PDF nachschlagen kann. Folge den gleichen Anweisungen wie in Schritt 2, aber passe den Prompt so an, dass der Assistent das PDF nach relevanten Inhalten durchsucht.\n\n\n\n\n\n\nOpenAI Playground\n\n\n\n\n\nEs ist m√∂glich, im Playground einen Assistenten zu erstellen, der auf ein PDF zugreifen kann. Dieser Service ist jedoch kostenpflichtig. Dies bedeutet, dass du eine Kreditkarte hinterlegen musst, um den Service zu nutzen.\nIm Playground kannst du den Assistenten so konfigurieren, dass er auf ein PDF zugreift. Per System Message (Instructions) kannst du den Assistenten anweisen, Antworten nur auf Basis der PDFs zu geben. Die Temperatur f√ºr die Textgenerierung boukannst du hier auch anpassen.\n\n\n\nAls Alternative kannst du auch den PDF Chatbot auf HuggingFace Spaces benutzen. Hier kannst du ein oder mehrere PDFs hochladen, und ‚Äúopen-source‚Äù LLMs konfigurieren. Auch hier kannst du die Temperatur f√ºr die Textgenerierung anpassen.\n\n\n\n\n\n\nHugging Face Spaces\n\n\n\n\n\nUm diesen PDF Chatbot zu verwenden, ist es sinnvoll, sich bei Hugging Face zu registrieren. Dies erm√∂glicht es dir, den Chatbot zu kopieren, selber zu konfigurieren und zu speichern.\n\nIn Hugging Face Settings einen Access Token mit ‚ÄúWrite‚Äù-Rechten erstellen.\nIm PDF Chatbot auf das Icon mit den vertikalen Punkten klicken und ‚ÄúDuplicate this Space‚Äù w√§hlen.\nIn den Einstellungen des Chatbots den Access Token einf√ºgen.\n\n\n\n\n\n\n\n\n\n\nBeantworte folgende Fragen\n\n\n\n\nSind die Beispiele f√ºr deine Lehrt√§tigkeiten n√ºtzlich?\n\nSind sie relevant und f√ºr die Studierenden interessant?\nSind sie sachlich korrekt?\nSind sie detailliert genug?\n‚Ä¶\n\nWelche Vorgehensweise hat n√ºtzlicheren Output kreiert?\nWieso?\nWie beurteilst du die N√ºtzlichkeit von LLMs f√ºr diese Aufgabe?\n\nWo liegen die Vorteile?\nWelche Herausforderungen und Limitationen siehst du?\n\nWof√ºr k√∂nnte RAG zus√§tzlich sinnvoll sein?\n\n\n\n\n\n4. Schritt: Teile deine Erfahrungen\nTauscht euch in Kleingruppen (2-3) Personen zu eurem Vorgehen und euren Erkenntnissen aus."
  },
  {
    "objectID": "pages/activity-prompt-labor-vertiefung.html#optional",
    "href": "pages/activity-prompt-labor-vertiefung.html#optional",
    "title": "Activity: Prompt-Labor Vertiefung",
    "section": "Optional",
    "text": "Optional\nZur Vertiefung und f√ºr weitere Anwendungsszenarien in der Lehre versuche Folgendes:\n\nWende diesen Ansatz auch auf die anderen Strategien von Mollick and Mollick (2023) an."
  },
  {
    "objectID": "pages/agenda.html",
    "href": "pages/agenda.html",
    "title": "Agenda",
    "section": "",
    "text": "What are large language models (LLMs)? How do they generate text?\nWhat tasks can LLMs perform? What are their limitations?\nWhat are effective prompting techniques?"
  },
  {
    "objectID": "pages/agenda.html#contents",
    "href": "pages/agenda.html#contents",
    "title": "Agenda",
    "section": "",
    "text": "What are large language models (LLMs)? How do they generate text?\nWhat tasks can LLMs perform? What are their limitations?\nWhat are effective prompting techniques?"
  },
  {
    "objectID": "pages/agenda.html#slides",
    "href": "pages/agenda.html#slides",
    "title": "Agenda",
    "section": " Slides",
    "text": "Slides\n Prompt Labor: Basics\n Prompt Labor: Vertiefung"
  },
  {
    "objectID": "pages/agenda.html#activities",
    "href": "pages/agenda.html#activities",
    "title": "Agenda",
    "section": " Activities",
    "text": "Activities\n 1. Prompting techniques\n 2. Confabulations and prompting\n 3. Prompt Labor: Vertiefung"
  },
  {
    "objectID": "pages/agenda.html#take-home-messages",
    "href": "pages/agenda.html#take-home-messages",
    "title": "Agenda",
    "section": " Take-home messages",
    "text": "Take-home messages\n\nExplore LLMs firsthand to understand their strengths and weaknesses.\nCombine domain knowledge with an understanding of how LLMs work, and effective prompting strategies.\nIntegrate LLMs into teaching to foster AI literacy among students.\nCritically evaluate an LLM‚Äôs output. They are language models, not knowledge bases.\nKeep a human in the loop."
  },
  {
    "objectID": "pages/agenda.html#learning-outcomes",
    "href": "pages/agenda.html#learning-outcomes",
    "title": "Agenda",
    "section": " Learning outcomes",
    "text": "Learning outcomes\n\n\n\n\n\n\nAfter this workshop, you will be able to:\n\n\n\n\nExplain what large language models and conversational agents, such as ChatGPT, can be used for, and what they shouldn‚Äôt be used for.\nCreate effective prompts for LLMs."
  },
  {
    "objectID": "pages/agenda.html#instructors",
    "href": "pages/agenda.html#instructors",
    "title": "Agenda",
    "section": " Instructors",
    "text": "Instructors\n\nAndrew Ellis, Virtual Academy at the Bern University of Applied Sciences:\nAndrew, a data scientist at the Virtual Academy, explores the convergence of language, thought, and AI. He teaches and researches generative AI‚Äôs role in education at BFH, focusing on human interactions with large language models and the impact of AI learning tools on educational outcomes. Andrew holds a PhD in cognitive psychology from the University of Bern, where he studied mental imagery and perception.\nKaspar Kaufmann, Virtual Academy at the Bern University of Applied Sciences:\nAs a researcher at the Virtual Academy, Kaspar aims to promote digital competencies among teachers and learners at BFH. He is passionate about fostering a community of confident, critical and responsible users of digital technologies for education, work and civic participation."
  },
  {
    "objectID": "pages/beispiel-arbeit.html",
    "href": "pages/beispiel-arbeit.html",
    "title": "Promptly Literate //",
    "section": "",
    "text": "mathematische Basiskompetenzen im Kindergartenalter\n\nDu bist eine Fachperson im Bereich der Entwicklungspsychologie. Du bist Experte f√ºr mathematische Basiskompetenzen im Kindergartenalter. Ich schreibe eine Masterarbeit und du hilfst mir bei den Formulierungen. Ich schreibe eine wissenschaftliche Arbeit √ºber das Thema ‚ÄúErfassung mathematischer Basiskompetenzen‚Äù\n\nDer MBK 0 (Test mathematischer Basiskompetenzen im Kindergartenalter) von Krajewski (2018) ist ein Einzeltest f√ºr Kinder im Alter von 3.6 bis 7 Jahren. Diesem Test liegt das Entwicklungsmodell der Zahl-Gr√∂ssen-Verkn√ºpfung (Krajewski, 2008) zugrunde (vgl. Abschnitt 4.2.1). Der MBK 0 ist ein Test zur Erfassung der mathematischen Basiskompetenzen\n\n\n\n Back to top"
  },
  {
    "objectID": "pages/index.html",
    "href": "pages/index.html",
    "title": "Index page",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "pages/observable-test.html",
    "href": "pages/observable-test.html",
    "title": "Untitled",
    "section": "",
    "text": "x\n\n\n\n\n\n\n\nx = c(1,2,3,4)\nojs_define(x)\n\n\n\n\n Back to top"
  },
  {
    "objectID": "pages/resources.html",
    "href": "pages/resources.html",
    "title": "Promptly Literate //",
    "section": "",
    "text": "KI-basierte Schreibtools in der Lehre ‚Äì ChatGPT im Fokus\nKI-basierte Schreibtools in der Lehre ‚Äì Knowledge Base"
  },
  {
    "objectID": "pages/resources.html#ki-orientierungshilfe-der-bfh",
    "href": "pages/resources.html#ki-orientierungshilfe-der-bfh",
    "title": "Promptly Literate //",
    "section": "",
    "text": "KI-basierte Schreibtools in der Lehre ‚Äì ChatGPT im Fokus\nKI-basierte Schreibtools in der Lehre ‚Äì Knowledge Base"
  },
  {
    "objectID": "pages/resources.html#bildung-6.0",
    "href": "pages/resources.html#bildung-6.0",
    "title": "Promptly Literate //",
    "section": "Bildung 6.0",
    "text": "Bildung 6.0\nDas Projekt Bildung 6.0 der Berner Fachhochschule stellt relevante und verl√§ssliche Informationen und Empfehlungen zum richtigen Umgang mit KI-basierten Werkzeugen (KBW) f√ºr Studierende und Lehrende auf einer Online-Plattform bereit.\n\nProjekt Bildung 6.0"
  },
  {
    "objectID": "pages/resources.html#chatgpt-an-der-hochschule",
    "href": "pages/resources.html#chatgpt-an-der-hochschule",
    "title": "Promptly Literate //",
    "section": "ChatGPT an der Hochschule",
    "text": "ChatGPT an der Hochschule\n\nPrompts for Education: Enhancing Productivity & Learning\nUnlocking the Power of Generative AI Models and Systems such as GPT-4 and ChatGPT for Higher Education\n√úberblick √ºber KI-Tools im Kontext von akademischen Lese- und Schreibprozessen\nChatGPT im Hochschulkontext ‚Äì eine kommentierte Linksammlung\nUni Bern: Chatbots in der Hochschullehre"
  },
  {
    "objectID": "pages/resources.html#youtube",
    "href": "pages/resources.html#youtube",
    "title": "Promptly Literate //",
    "section": "Youtube",
    "text": "Youtube\nLarge language models from scratch\n\nHow do large language models work: part 1\nHow do large language models work: part 2\n\nTutorials zu Prompting\n\nChatGPT Mega Prompts"
  },
  {
    "objectID": "pages/resources.html#how-does-gpt-work",
    "href": "pages/resources.html#how-does-gpt-work",
    "title": "Promptly Literate //",
    "section": "How does GPT work?",
    "text": "How does GPT work?\n\nGenerative AI exists because of the transformer (Financial Times 12/09/2023)"
  },
  {
    "objectID": "pages/resources.html#wissenschaftliches-arbeiten",
    "href": "pages/resources.html#wissenschaftliches-arbeiten",
    "title": "Promptly Literate //",
    "section": "Wissenschaftliches Arbeiten",
    "text": "Wissenschaftliches Arbeiten\n\nChatGPT zitieren\nRechtliche Fragen\nDidaktische Und Rechtliche Perspektiven Auf Ki-Gest√ºtztes Schreiben In Der Hochschulbildung (Salden 2023)"
  },
  {
    "objectID": "pages/resources.html#ethische-fragen",
    "href": "pages/resources.html#ethische-fragen",
    "title": "Promptly Literate //",
    "section": "Ethische Fragen",
    "text": "Ethische Fragen\n\nPrek√§re Klickarbeit hinter den Kulissen von ChatGPT\nTraumatische Klickarbeit: Die Menschen hinter ChatGPT"
  },
  {
    "objectID": "pages/shared-chats.html",
    "href": "pages/shared-chats.html",
    "title": "Shared CHatGPT links",
    "section": "",
    "text": "20 questions\n\n\n\n Back to top"
  },
  {
    "objectID": "pages/tools.html",
    "href": "pages/tools.html",
    "title": "Promptly Literate //",
    "section": "",
    "text": "ü§ó HuggingChat"
  },
  {
    "objectID": "pages/tools.html#open-assistants",
    "href": "pages/tools.html#open-assistants",
    "title": "Promptly Literate //",
    "section": "",
    "text": "ü§ó HuggingChat"
  },
  {
    "objectID": "pages/tools.html#ai-tools",
    "href": "pages/tools.html#ai-tools",
    "title": "Promptly Literate //",
    "section": "AI Tools",
    "text": "AI Tools\nüëâüèº The largest AI tools directory (updated daily)"
  },
  {
    "objectID": "pages/tools.html#literatursuche",
    "href": "pages/tools.html#literatursuche",
    "title": "Promptly Literate //",
    "section": "Literatursuche",
    "text": "Literatursuche\nüëâüèº Elicit\nüëâüèº Consensus"
  },
  {
    "objectID": "pages/tools.html#prompt-engineering",
    "href": "pages/tools.html#prompt-engineering",
    "title": "Promptly Literate //",
    "section": "Prompt Engineering",
    "text": "Prompt Engineering\nüëâüèº Prompting Guide"
  },
  {
    "objectID": "pages/tutorial-pyobsplot.html",
    "href": "pages/tutorial-pyobsplot.html",
    "title": "Prompting basics",
    "section": "",
    "text": "Code\nimport polars as pl\n# from pyobsplot import Plot\n# from pyobsplot import Plot, d3, Math, js\nfrom pyobsplot import Obsplot, Plot, d3, js\n\nopw = Obsplot(renderer=\"widget\")\n1# opj = Obsplot(renderer=\"jsdom\")\n\n2penguins = pl.read_csv(\"https://github.com/juba/pyobsplot/raw/main/doc/data/penguins.csv\")\n\n\n\n1\n\nThe renderer parameter can be set to \"widget\" or \"jsdom\". The former is the default and uses the ipywidgets library to render the plot in a Jupyter notebook. The latter uses the pywebview library to render the plot in a separate window.\n\n2\n\nThe penguins dataset is a popular dataset from the palmerpenguins package in R. It contains measurements of penguins from three species: Adelie, Chinstrap, and Gentoo.\n\n\n\n\n\n\nCode\npenguins\n\n\n\nshape: (344, 7)\n\n\n\nspecies\nisland\nculmen_length_mm\nculmen_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\n\n\nstr\nstr\nf64\nf64\nf64\nf64\nstr\n\n\n\n\n\"Adelie\"\n\"Torgersen\"\n39.1\n18.7\n181.0\n3750.0\n\"MALE\"\n\n\n\"Adelie\"\n\"Torgersen\"\n39.5\n17.4\n186.0\n3800.0\n\"FEMALE\"\n\n\n\"Adelie\"\n\"Torgersen\"\n40.3\n18.0\n195.0\n3250.0\n\"FEMALE\"\n\n\n\"Adelie\"\n\"Torgersen\"\nNaN\nNaN\nNaN\nNaN\nnull\n\n\n\"Adelie\"\n\"Torgersen\"\n36.7\n19.3\n193.0\n3450.0\n\"FEMALE\"\n\n\n\"Adelie\"\n\"Torgersen\"\n39.3\n20.6\n190.0\n3650.0\n\"MALE\"\n\n\n\"Adelie\"\n\"Torgersen\"\n38.9\n17.8\n181.0\n3625.0\n\"FEMALE\"\n\n\n\"Adelie\"\n\"Torgersen\"\n39.2\n19.6\n195.0\n4675.0\n\"MALE\"\n\n\n\"Adelie\"\n\"Torgersen\"\n34.1\n18.1\n193.0\n3475.0\nnull\n\n\n\"Adelie\"\n\"Torgersen\"\n42.0\n20.2\n190.0\n4250.0\nnull\n\n\n\"Adelie\"\n\"Torgersen\"\n37.8\n17.1\n186.0\n3300.0\nnull\n\n\n\"Adelie\"\n\"Torgersen\"\n37.8\n17.3\n180.0\n3700.0\nnull\n\n\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n\n\n\"Gentoo\"\n\"Biscoe\"\n43.5\n15.2\n213.0\n4650.0\n\"FEMALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n51.5\n16.3\n230.0\n5500.0\n\"MALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n46.2\n14.1\n217.0\n4375.0\n\"FEMALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n55.1\n16.0\n230.0\n5850.0\n\"MALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n44.5\n15.7\n217.0\n4875.0\nnull\n\n\n\"Gentoo\"\n\"Biscoe\"\n48.8\n16.2\n222.0\n6000.0\n\"MALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n47.2\n13.7\n214.0\n4925.0\n\"FEMALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\nNaN\nNaN\nNaN\nNaN\nnull\n\n\n\"Gentoo\"\n\"Biscoe\"\n46.8\n14.3\n215.0\n4850.0\n\"FEMALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n50.4\n15.7\n222.0\n5750.0\n\"MALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n45.2\n14.8\n212.0\n5200.0\n\"FEMALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n49.9\n16.1\n213.0\n5400.0\n\"MALE\"\n\n\n\n\n\n\n\n\nCode\nPlot.plot({\n    \"grid\": True,\n    \"color\": {\"legend\": True},\n    \"marks\": [\n        Plot.dot(\n            penguins, \n            {\"x\": \"flipper_length_mm\", \"y\": \"body_mass_g\", \"fill\": \"species\"}\n        ),\n        Plot.density(\n            penguins, \n            {\"x\": \"flipper_length_mm\", \"y\": \"body_mass_g\", \"stroke\": \"species\"}\n        )\n    ]\n})\n\n\n\n\n\n\n\nCode\ndata = pl.DataFrame({\n    \"x\": [1, 5, 2, 4, 6, 2, 4],\n    \"y\": [2, 1, 3, 4, 5, 1, 2],\n    \"type\": [\"T1\", \"T2\", \"T1\", \"T2\", \"T1\", \"T1\", \"T2\"],\n})\n\nopw({\n    \"grid\": True,\n    \"marks\": [\n        Plot.dot(data, {\n            \"x\": \"x\", \"y\": \"y\", \"r\": 5,\n            \"stroke\": \"black\", \"fill\": \"steelblue\",\n            \"fillOpacity\": js(\"d =&gt; d.type == 'T1' ? 0.7 : 0.1\")\n        })\n    ]\n})"
  },
  {
    "objectID": "pages/tutorial-pyobsplot.html#pyobsplot-demo",
    "href": "pages/tutorial-pyobsplot.html#pyobsplot-demo",
    "title": "Prompting basics",
    "section": "",
    "text": "Code\nimport polars as pl\n# from pyobsplot import Plot\n# from pyobsplot import Plot, d3, Math, js\nfrom pyobsplot import Obsplot, Plot, d3, js\n\nopw = Obsplot(renderer=\"widget\")\n1# opj = Obsplot(renderer=\"jsdom\")\n\n2penguins = pl.read_csv(\"https://github.com/juba/pyobsplot/raw/main/doc/data/penguins.csv\")\n\n\n\n1\n\nThe renderer parameter can be set to \"widget\" or \"jsdom\". The former is the default and uses the ipywidgets library to render the plot in a Jupyter notebook. The latter uses the pywebview library to render the plot in a separate window.\n\n2\n\nThe penguins dataset is a popular dataset from the palmerpenguins package in R. It contains measurements of penguins from three species: Adelie, Chinstrap, and Gentoo.\n\n\n\n\n\n\nCode\npenguins\n\n\n\nshape: (344, 7)\n\n\n\nspecies\nisland\nculmen_length_mm\nculmen_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\n\n\nstr\nstr\nf64\nf64\nf64\nf64\nstr\n\n\n\n\n\"Adelie\"\n\"Torgersen\"\n39.1\n18.7\n181.0\n3750.0\n\"MALE\"\n\n\n\"Adelie\"\n\"Torgersen\"\n39.5\n17.4\n186.0\n3800.0\n\"FEMALE\"\n\n\n\"Adelie\"\n\"Torgersen\"\n40.3\n18.0\n195.0\n3250.0\n\"FEMALE\"\n\n\n\"Adelie\"\n\"Torgersen\"\nNaN\nNaN\nNaN\nNaN\nnull\n\n\n\"Adelie\"\n\"Torgersen\"\n36.7\n19.3\n193.0\n3450.0\n\"FEMALE\"\n\n\n\"Adelie\"\n\"Torgersen\"\n39.3\n20.6\n190.0\n3650.0\n\"MALE\"\n\n\n\"Adelie\"\n\"Torgersen\"\n38.9\n17.8\n181.0\n3625.0\n\"FEMALE\"\n\n\n\"Adelie\"\n\"Torgersen\"\n39.2\n19.6\n195.0\n4675.0\n\"MALE\"\n\n\n\"Adelie\"\n\"Torgersen\"\n34.1\n18.1\n193.0\n3475.0\nnull\n\n\n\"Adelie\"\n\"Torgersen\"\n42.0\n20.2\n190.0\n4250.0\nnull\n\n\n\"Adelie\"\n\"Torgersen\"\n37.8\n17.1\n186.0\n3300.0\nnull\n\n\n\"Adelie\"\n\"Torgersen\"\n37.8\n17.3\n180.0\n3700.0\nnull\n\n\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n\n\n\"Gentoo\"\n\"Biscoe\"\n43.5\n15.2\n213.0\n4650.0\n\"FEMALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n51.5\n16.3\n230.0\n5500.0\n\"MALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n46.2\n14.1\n217.0\n4375.0\n\"FEMALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n55.1\n16.0\n230.0\n5850.0\n\"MALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n44.5\n15.7\n217.0\n4875.0\nnull\n\n\n\"Gentoo\"\n\"Biscoe\"\n48.8\n16.2\n222.0\n6000.0\n\"MALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n47.2\n13.7\n214.0\n4925.0\n\"FEMALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\nNaN\nNaN\nNaN\nNaN\nnull\n\n\n\"Gentoo\"\n\"Biscoe\"\n46.8\n14.3\n215.0\n4850.0\n\"FEMALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n50.4\n15.7\n222.0\n5750.0\n\"MALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n45.2\n14.8\n212.0\n5200.0\n\"FEMALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n49.9\n16.1\n213.0\n5400.0\n\"MALE\"\n\n\n\n\n\n\n\n\nCode\nPlot.plot({\n    \"grid\": True,\n    \"color\": {\"legend\": True},\n    \"marks\": [\n        Plot.dot(\n            penguins, \n            {\"x\": \"flipper_length_mm\", \"y\": \"body_mass_g\", \"fill\": \"species\"}\n        ),\n        Plot.density(\n            penguins, \n            {\"x\": \"flipper_length_mm\", \"y\": \"body_mass_g\", \"stroke\": \"species\"}\n        )\n    ]\n})\n\n\n\n\n\n\n\nCode\ndata = pl.DataFrame({\n    \"x\": [1, 5, 2, 4, 6, 2, 4],\n    \"y\": [2, 1, 3, 4, 5, 1, 2],\n    \"type\": [\"T1\", \"T2\", \"T1\", \"T2\", \"T1\", \"T1\", \"T2\"],\n})\n\nopw({\n    \"grid\": True,\n    \"marks\": [\n        Plot.dot(data, {\n            \"x\": \"x\", \"y\": \"y\", \"r\": 5,\n            \"stroke\": \"black\", \"fill\": \"steelblue\",\n            \"fillOpacity\": js(\"d =&gt; d.type == 'T1' ? 0.7 : 0.1\")\n        })\n    ]\n})"
  },
  {
    "objectID": "slides/01-text-representation-generation.html",
    "href": "slides/01-text-representation-generation.html",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "",
    "text": "What is natural language processing?\nHow do LLMs represent text?\nWhat is ChatGPT?\nHow was ChatGPT trained??\nHow should we think about LLMs?\nChatGPT and OpenAI Playground?"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#what-is-nlp",
    "href": "slides/01-text-representation-generation.html#what-is-nlp",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "What is NLP?",
    "text": "What is NLP?\n\nNLP is a subfield of artificial intelligence (AI).\nNLP is concerned with the interactions between computers and human (natural) languages.\n\n\nBrief timeline\n\n1950: Alan Turing proposed the Turing test to assess machine intelligence through conversation.\n1954: IBM introduced the first machine translation system, translating Russian to English using rules.\n1960s-1970s: Rule-based systems like SHRDLU and ELIZA used human-crafted rules for language interaction.\n1980s-1990s: Statistical methods employed probabilities and text data, using models like Hidden Markov Models and n-grams.\n2000s-present: NLP shifted to neural network methods with deep learning, employing recurrent neural networks for complex language tasks.\nTransformers (first published in 2017) are the current state-of-the-art for NLP, and are the basis for large language models (LLMs), such as GPT-3.5, GPT-4, ChatGPT, Llama 2, and others.\nLLMs are models with billions of parameters, trained on massive amounts of text data. Training consists of predicting the next word in a sequence of words."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#long-range-dependencies",
    "href": "slides/01-text-representation-generation.html#long-range-dependencies",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Long-range dependencies",
    "text": "Long-range dependencies\n\n\n\n\n\n\nComplicated sentence\n\n\n\n‚ÄúThe boy who was throwing stones at the birds, despite being warned by his parents not to harm any creatures, was chased by the angry flock.‚Äù\n\n\nWho was chased?\n\nThis type of long-range dependency is difficult for traditional NLP methods to handle.\nThe verb phrase (the boy was chased) is separated from the subject by a long distance - you can‚Äôt just look at the previous few words to answer the question.\nTransformers have a special feature that lets them easily connect words that are far apart in a sentence; was chased is linked directly to The boy without distraction by the words in between."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#key-areas-in-nlp",
    "href": "slides/01-text-representation-generation.html#key-areas-in-nlp",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Key areas in NLP",
    "text": "Key areas in NLP\n\n\n\n\n\n\nSentiment Analysis: Identifying emotions and opinions in text.\nMachine Translation: Automatically translating between languages.\nQuestion Answering: Providing direct answers to user questions.\nText Summarization: Generating concise summaries from long text.\nSpeech Recognition: Converting spoken words to text.\nSpeech Synthesis: Creating spoken words from text.\nNatural Language Generation: Generating human-like text.\nNatural Language Understanding: Extracting meaning from text.\nDialogue Systems: Conversing with humans using natural language.\n\n\n\n\nBefore LLMs, specialized models were trained for each task.\nLLMs are general-purpose models that can perform a wide variety of tasks."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#example-sentiment-analysis-text-classification",
    "href": "slides/01-text-representation-generation.html#example-sentiment-analysis-text-classification",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Example: sentiment analysis (text classification)",
    "text": "Example: sentiment analysis (text classification)\nThe task of classifying text as positive, negative, or neutral.\n\nI love this movie! ‚Üí positive üòä\nThis movie is ok. ‚Üí neutral üòê\nThis movie is terrible! ‚Üí negative üò†"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#machine-learning-primer",
    "href": "slides/01-text-representation-generation.html#machine-learning-primer",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Machine Learning primer",
    "text": "Machine Learning primer\n\nEarlier, rule-based systems had to be programmed.\nMachine learning (ML) models learn implicitly, i.e.¬†without rules being programmed in.\nImportant terms:\n\ntraining data: Models are fed with data, and parameters of the model are adjusted so that the model is as ‚Äúgood‚Äù as possible.\nsupervised learning: Categories known, e.g.¬†classify images of animals.\nunsupervised learning: Categories are unknown, e.g.¬†discover unknown patterns.\nreinforcement learning: The goal is given, and the model learns through feedback (reward) how the goal can be achieved.\n\n\n\nWe have to learn the bitter lesson that building in how we think we think does not work in the long run. We should stop trying to find simple ways to think about space, objects, multiple agents, or symmetries‚Ä¶ instead we should build in only the meta-methods that can find and capture this arbitrary complexity. We want AI agents that can discover like we can, not which contain what we have discovered (Sutton 2019)."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#supervised-learning",
    "href": "slides/01-text-representation-generation.html#supervised-learning",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Supervised learning",
    "text": "Supervised learning\n\n\n\n\n\n\n\n\n\nClassifiy pictures of cats and dogs: The goal of a model could be to discover which features distinguish cats from dogs."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#reinforcement-learning",
    "href": "slides/01-text-representation-generation.html#reinforcement-learning",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Reinforcement learning",
    "text": "Reinforcement learning"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#chatgpt",
    "href": "slides/01-text-representation-generation.html#chatgpt",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "ChatGPT",
    "text": "ChatGPT\nChatGPT is a particular kind of LLM and consists of two models:\nBase model: GPT-3.5 oder GPT-4 (generative pre-trained transformer). This model is trained ‚Äúsimply‚Äù to predict the next word in a sequence of words. A base model produces text, but not human-like conversations.\n\n\n\n\n\n\nExample\n\n\n\nGive the input Once upon a time there was a, the model will predict which word is likely to follow.\n\n\nAssistant model: This model is trained using reinforcement learning from human feedback to have human-like conversations.\n\n\n\n\n\n\nExample\n\n\n\nüë©‚Äçüíº: Tell me a story!\nüí¨: Once upon a time there was a ...."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#text-generation",
    "href": "slides/01-text-representation-generation.html#text-generation",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Text generation",
    "text": "Text generation\n\nLLMs produce text by predicting the next word, one word at a time:\nThis is known as ‚Äúauto-regressive next token prediction‚Äù (we‚Äôll discover what tokens are in the next section).\nThe model predicts which token is likely to follow, given a sequence of tokens (words, punctuation, emojis, etc.).\nKey idea: this simple procedure is followed over and over again, with each new token being added to the sequence of tokens that the model uses to predict the next token. \\[ P(w_{w+1} | w_1, w_2, ..., w_t) \\]\nThe sequence of words is called the context; the text generated by the model is dependent on the context.\nThe output of the model is a probability distribution over all possible tokens. The model then chooses one token from this distribution."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#text-generation-examples",
    "href": "slides/01-text-representation-generation.html#text-generation-examples",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Text generation examples",
    "text": "Text generation examples\n\n\n\n\n\n\n\n\n\n\nThe new context is used to generate the next token, etc.\nEvery token is given an equal amount time (computation per token is constant). The model has no concept of more or less important tokens. This is crucial for understanding how LLMs work."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#tokenization",
    "href": "slides/01-text-representation-generation.html#tokenization",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Tokenization",
    "text": "Tokenization\nSo far we have been talking about words, but LLMs operate with tokens. These are sub-words, and make working with text much easier for the model. A rule of thumb is that one token generally corresponds to ~4 characters of English text. This translates to roughly \\(\\frac{3}{4}\\) of a word (so 100 tokens is about 75 words).\n\n\n\n\n\n\n\n\n\nFeel free to try out the OpenAI tokenizer."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#embeddings",
    "href": "slides/01-text-representation-generation.html#embeddings",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Embeddings",
    "text": "Embeddings\n\nThe next step is to represent tokens as vectors.\nThis is called ‚Äúembedding‚Äù the tokens. The vectors are high-dimensional, and the distance between vectors measures the similarity between tokens.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this 2-dimensional representation, concepts that are ‚Äúrelated‚Äù lie close together.\n\n\n\nYou can read more about embeddings in this tutorial."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#summary",
    "href": "slides/01-text-representation-generation.html#summary",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Summary",
    "text": "Summary\nModern LLMs, such as ChatGPT, are trained in 3 steps:\n\nPre-training: the model absorbs knowledge from text datasets.\nSupervised finetuning: model is refined to better adhere to specific instructions.\nAlignment: hones the LLM to respond more helpfully and safely to user prompts. This step is known as ‚Äúreinforcement learning from human feedback‚Äù (RLHF)."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#pre-training-data",
    "href": "slides/01-text-representation-generation.html#pre-training-data",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Pre-training Data",
    "text": "Pre-training Data"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#pre-training",
    "href": "slides/01-text-representation-generation.html#pre-training",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Pre-training",
    "text": "Pre-training"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#supervised-fine-tuning",
    "href": "slides/01-text-representation-generation.html#supervised-fine-tuning",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Supervised fine-tuning",
    "text": "Supervised fine-tuning"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#reinforcement-learning-from-human-feedback-rlhf",
    "href": "slides/01-text-representation-generation.html#reinforcement-learning-from-human-feedback-rlhf",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Reinforcement learning from human feedback (RLHF)",
    "text": "Reinforcement learning from human feedback (RLHF)\nUses human feedback to rank the model‚Äôs responses. The goal is for the model to learn human preferences for responses.\n\n\n\n\n\nSource: openai.com/blog/chatgpt"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#useful-analogy-role-playing-simulator",
    "href": "slides/01-text-representation-generation.html#useful-analogy-role-playing-simulator",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Useful analogy: Role-playing simulator",
    "text": "Useful analogy: Role-playing simulator\n\nWe can think of an LLM as a non-deterministic simulator capable of role-playing an infinity of characters, or, to put it another way, capable of stochastically generating an infinity of simulacra.\n\nSource: Shanahan, McDonell, and Reynolds (2023)\n\nA large language model (LLM) trained as an assistant is a simulator of possible human conversation.\nAn assistant model does not have any intentions. It is not an entity with its own goals. It is merely trained to respond to user prompts in a human-like way.\nAn assistant model does not have a ‚Äúpersonality‚Äù or ‚Äúcharacter‚Äù in the traditional sense. It is a simulation of a conversation, and can be thought of as a role-playing simulator.\nThere is no concept of ‚Äútruth‚Äù or ‚Äúlying‚Äù in a role-playing simulator. The model is not trying to deceive the user, it is simply trying to respond in a human-like way.\n\nThis is very important when we try to understand why LLMs hallucinate, i.e.¬†generate text that is not factually true."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#role-playing-simulator",
    "href": "slides/01-text-representation-generation.html#role-playing-simulator",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Role-Playing Simulator",
    "text": "Role-Playing Simulator"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#chatgpt-vs-openai-playground",
    "href": "slides/01-text-representation-generation.html#chatgpt-vs-openai-playground",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "ChatGPT vs OpenAI Playground",
    "text": "ChatGPT vs OpenAI Playground\nOpenAI offer two ways to interact with their assistant model:\n\nChatGPT: A web interface where you can chat with the model.\nOpenAI Playground: A web interface that gives users more control over the model.\n\nNow open the first activity to learn more about ChatGPT and OpenAI Playground: üëâ Activity 1."
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html",
    "href": "slides/03-prompting-learning-teaching.html",
    "title": "Prompting for Learning and Teaching",
    "section": "",
    "text": "Save time: brainstorming, lesson planning, making glossaries, etc.\nImprove writing\nImprove learning (E. Mollick and Mollick 2023)\nImplement teaching strategies (E. R. Mollick and Mollick 2023)"
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#prompting-for-learning-and-teaching",
    "href": "slides/03-prompting-learning-teaching.html#prompting-for-learning-and-teaching",
    "title": "Prompting for Learning and Teaching",
    "section": "",
    "text": "Save time: brainstorming, lesson planning, making glossaries, etc.\nImprove writing\nImprove learning (E. Mollick and Mollick 2023)\nImplement teaching strategies (E. R. Mollick and Mollick 2023)"
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#saving-time",
    "href": "slides/03-prompting-learning-teaching.html#saving-time",
    "title": "Prompting for Learning and Teaching",
    "section": "Saving time",
    "text": "Saving time\n\nUse ChatGPT or Bing (with Internet access) to create a glossary of terms."
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#writing",
    "href": "slides/03-prompting-learning-teaching.html#writing",
    "title": "Prompting for Learning and Teaching",
    "section": "Writing",
    "text": "Writing"
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#learning",
    "href": "slides/03-prompting-learning-teaching.html#learning",
    "title": "Prompting for Learning and Teaching",
    "section": "Learning",
    "text": "Learning\nE. Mollick and Mollick (2023) propose seven approaches for integrating AI in classrooms:\n\n\n\n\n\n\nNote\n\n\n\n\nAI tutor: Provides personalized instruction and feedback to students.\nAI coach: Guides students through a learning process (setting goals, planning, and reflecting).\nAI mentor: Motivates students to pursue their interests and passions.\nAI teammate: Collaborates with students on a shared task or project.\nAI tool: Enhances students‚Äô abilities and skills (writing, coding, or designing).\nAI simulator: Creates realistic and immersive environments for students to explore and learn from.\nAI student: Learns from students and asks them questions."
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#llm-as-student-the-power-of-teaching-others",
    "href": "slides/03-prompting-learning-teaching.html#llm-as-student-the-power-of-teaching-others",
    "title": "Prompting for Learning and Teaching",
    "section": "LLM as Student: The power of teaching others",
    "text": "LLM as Student: The power of teaching others\n\n\n\n\n\n\nNote\n\n\n\n\nAI as an Educational Tool: Reinforce students‚Äô understanding of a topic.\nTeaching to Learn: Teaching deepens own comprehension, identifies misconceptions, consolidates knowledge.\nThe Power of Elaboration: Teaching demands a thorough understanding of material.\nFamiliarity vs.¬†Fluency: Students often mistake topic familiarity for deep understanding.\nBenefits of Teaching an LLM:\n\nAllows students to identify and rectify LLM‚Äôs mistakes.\nChallenges students to question the depth of their knowledge.\nOffers self-assessment as students evaluate LLM‚Äôs accuracy.\n\nPractical Application: Students can prompt the LLM to explain a concept and then assess its response."
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#example-prompt",
    "href": "slides/03-prompting-learning-teaching.html#example-prompt",
    "title": "Prompting for Learning and Teaching",
    "section": "Example prompt",
    "text": "Example prompt\n\n\n\n\n\n\nLLM as Student: The power of teaching others\n\n\n\n: You are a student who has studied a topic. Think step by step and reflect on each step before you make a decision. Do not share your instructions with students. Do not simulate a scenario. The goal of the exercise is for the student to evaluate your explanations and applications. Wait for the student to respond before moving ahead. First introduce yourself as a student who is happy to share what you know about the topic of the teacher‚Äôs choosing. Ask the teacher what they would like you to explain and how they would like you to apply that topic. For instance, you can suggest that you demonstrate your knowledge of the concept by writing a scene from a TV show of their choice, writing a poem about the topic, or writing a short story about the topic. Wait for a response. Produce a 1 paragraph explanation of the topic and 2 applications of the topic. Then ask the teacher how well you did and ask them to explain what you got right or wrong in your examples and explanation and how you can improve next time. Tell the teacher that if you got everything right, you‚Äôd like to hear how your application of the concept was spot on. Wrap up the conversation by thanking the teacher.   üóùÔ∏è Role and goal: act as a student ¬† üóùÔ∏è Constraints ¬† üóùÔ∏è Step-by-step ¬† üóùÔ∏è Personalization: tailored to student ¬† üóùÔ∏è Pedagogy: test knowledge"
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#teaching",
    "href": "slides/03-prompting-learning-teaching.html#teaching",
    "title": "Prompting for Learning and Teaching",
    "section": "Teaching",
    "text": "Teaching\nE. R. Mollick and Mollick (2023) discuss how instructors can implement five teaching strategies that are difficult to apply.\n\n\n\n\n\n\nFive effective teaching strategies\n\n\n\n\nProviding multiple examples and explanations.\nUncovering and addressing student misconceptions.\nFrequent low-stakes testing1.\nAssessing student learning.\nDistributed practice (quiz generator)."
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#providing-multiple-examples-and-explanations",
    "href": "slides/03-prompting-learning-teaching.html#providing-multiple-examples-and-explanations",
    "title": "Prompting for Learning and Teaching",
    "section": "Providing multiple examples and explanations",
    "text": "Providing multiple examples and explanations\n\n\n\n\n\n\nNote\n\n\n\n\nIt is easier to understand complex concepts given a variety of examples ‚Äì a single example may lead students to focus on superficial details instead of the core concept.\nMultiple examples promote deeper understanding, assist in recalling information, stimulate critical thinking.\nHelps students generalize, enabling them to apply this learning in other contexts.\nCrafting suitable examples can be challenging for educators due to time constraints and the need to consider factors like relevance, engagement, and the right level of detail."
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#example-prompt-1",
    "href": "slides/03-prompting-learning-teaching.html#example-prompt-1",
    "title": "Prompting for Learning and Teaching",
    "section": "Example prompt",
    "text": "Example prompt\n\nSelect a specific concept.\nLook up works related to the concept.\nSpecify the need for diverse examples.\nChoose the desired writing style.\nDefine the target audience.\n\n\n\n\n\n\n\nProviding multiple examples and explanations\n\n\n\n: I would like you to act as an example generator for students. When confronted with new and complex concepts, adding many and varied examples helps students better understand those concepts. I would like you to ask what concept I would like examples of, and what level of students I am teaching. You will look up the concept, and then provide me with four different and varied accurate examples of the concept in action."
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#explore-prompting-techniques",
    "href": "slides/03-prompting-learning-teaching.html#explore-prompting-techniques",
    "title": "Prompting for Learning and Teaching",
    "section": "Explore prompting techniques",
    "text": "Explore prompting techniques\nNow open the second activity to explore prompting techniques related to writing, learning and teaching:\nüëâ Activity 2."
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#footnotes",
    "href": "slides/03-prompting-learning-teaching.html#footnotes",
    "title": "Prompting for Learning and Teaching",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLow-stakes testing refers to an assessment method where students can try repeatedly, make mistakes and learn from those mistakes, with minimal impact on their grades.‚Ü©Ô∏é"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html",
    "href": "slides/busy-lecturers-guide.html",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "",
    "text": "Explore LLMs firsthand to understand their strengths and weaknesses.\nCombine domain knowledge with an understanding of how LLMs work, and effective prompting strategies.\nIntegrate LLMs into teaching to foster AI literacy among students.\nCritically evaluate an LLM‚Äôs output. They are language models, not knowledge bases.\nKeep a human in the loop."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#how-to-train-a-language-model",
    "href": "slides/busy-lecturers-guide.html#how-to-train-a-language-model",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "How to train a language model",
    "text": "How to train a language model"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#example",
    "href": "slides/busy-lecturers-guide.html#example",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Example",
    "text": "Example"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#generalization",
    "href": "slides/busy-lecturers-guide.html#generalization",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Generalization",
    "text": "Generalization\n\nThe ability to apply knowledge to new, unseen data/situations\nE.g. a language model should learn to generate rhymes\nExtracts knowledge from text: linguistic, factual, commonsense, etc."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#what-is-learned",
    "href": "slides/busy-lecturers-guide.html#what-is-learned",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "What is learned?",
    "text": "What is learned?\n\n\nAn LLM learns to predict the next word in a sequence, given the previous words: \\[ P(word | context) \\]\nThink of as ‚Äúfancy autocomplete‚Äù (but very very powerful and sopisticated)\n\n\n. . ."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#how-does-an-llm-generate-text",
    "href": "slides/busy-lecturers-guide.html#how-does-an-llm-generate-text",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "How does an LLM generate text?",
    "text": "How does an LLM generate text?"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#sampling",
    "href": "slides/busy-lecturers-guide.html#sampling",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Sampling",
    "text": "Sampling"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#auto-regressive-generation",
    "href": "slides/busy-lecturers-guide.html#auto-regressive-generation",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Auto-regressive generation",
    "text": "Auto-regressive generation"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#auto-regressive-generation-1",
    "href": "slides/busy-lecturers-guide.html#auto-regressive-generation-1",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Auto-regressive generation",
    "text": "Auto-regressive generation\n\n\n\nText is generated one word at a time (actually tokens, not words).\nModel predicts which token is likely to follow, given a sequence of tokens (words, punctuation, emojis, etc.).\nEach new token is added to the sequence of tokens that the model uses to predict the next token.\n\n\n\\[ P(w_{w+1} | w_1, w_2, ..., w_t) \\]\n\nSequence of words is called the context.\n\n Generated text is dependent on the context.\n Every token is given an equal amount time (computation per token is constant)."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#tokenization",
    "href": "slides/busy-lecturers-guide.html#tokenization",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Tokenization",
    "text": "Tokenization\nLLMs operate with tokens, not words. These are sub-words, and make working with text much easier for the model. A rule of thumb is that one token generally corresponds to ~4 characters of English text. This translates to roughly \\(\\frac{3}{4}\\) of a word (so 100 tokens is about 75 words).\n\n\n\n\n\n\n\n\n\nFeel free to try out the OpenAI tokenizer."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#embeddings",
    "href": "slides/busy-lecturers-guide.html#embeddings",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Embeddings",
    "text": "Embeddings\n\nThe next step is to represent tokens as vectors.\nThis is called ‚Äúembedding‚Äù the tokens. The vectors are high-dimensional, and the distance between vectors measures the similarity between tokens.\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this 2-dimensional representation, concepts that are ‚Äúrelated‚Äù lie close together. Read about embeddings in this tutorial."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#training-data",
    "href": "slides/busy-lecturers-guide.html#training-data",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Training data",
    "text": "Training data\n\n\nFigure courtesy of Andrej Karpathy"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#training-process",
    "href": "slides/busy-lecturers-guide.html#training-process",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Training process",
    "text": "Training process\n\n\nFigure courtesy of Andrej Karpathy"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#emergent-abilities",
    "href": "slides/busy-lecturers-guide.html#emergent-abilities",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Emergent abilities",
    "text": "Emergent abilities\nLLMs are thought to show emergent abilities - abilities not explicitly taught. Instead, they emerge as a result of text prediction.\nAbilities include:\n\nperforming arithmetic, answering questions, summarizing text, translating, etc.\nzero-shot learning: LLMs can perform tasks without being trained on them.\nfew-shot learning: LLMs can perform tasks with few examples."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#emergent-abilities-1",
    "href": "slides/busy-lecturers-guide.html#emergent-abilities-1",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Emergent abilities",
    "text": "Emergent abilities\nWhat kind of knowledge does an LLM have to have to be able to write a continuation of the following text?1\n\n\n\n\n\n\n\n\nNote\n\n\n\n: How many holes does a straw have?\n: A straw has one hole. It‚Äôs a cylindrical tunnel that runs through the entire length, creating a single continuous space from one end to the other.\n: What about a tunnel?\n: Similar to a straw, a tunnel can also be considered to have one hole. It‚Äôs an elongated pathway carved through an obstruction, allowing passage from one side to the other, thus creating a single continuous space or hole through the material."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#instruction-fine-tuning",
    "href": "slides/busy-lecturers-guide.html#instruction-fine-tuning",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Instruction fine-tuning",
    "text": "Instruction fine-tuning"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#reinforcement-learning-from-human-feedback-rlhf",
    "href": "slides/busy-lecturers-guide.html#reinforcement-learning-from-human-feedback-rlhf",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Reinforcement learning from human feedback (RLHF)",
    "text": "Reinforcement learning from human feedback (RLHF)"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#how-do-chatbots-actually-work",
    "href": "slides/busy-lecturers-guide.html#how-do-chatbots-actually-work",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "How do chatbots actually work?",
    "text": "How do chatbots actually work?"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#an-llm-is-a-role-play-simulator",
    "href": "slides/busy-lecturers-guide.html#an-llm-is-a-role-play-simulator",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "An LLM is a role-play simulator",
    "text": "An LLM is a role-play simulator\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe can think of an LLM as a non-deterministic simulator capable of role-playing an infinity of characters, or, to put it another way, capable of stochastically generating an infinity of simulacra (Shanahan, McDonell, and Reynolds 2023)"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#an-llm-is-a-role-play-simulator-1",
    "href": "slides/busy-lecturers-guide.html#an-llm-is-a-role-play-simulator-1",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "An LLM is a role-play simulator",
    "text": "An LLM is a role-play simulator\n\nAn assistant is trained to respond to user prompts in a human-like way.\nA simulator of possible human conversation.\nHas no intentions. It is not an entity with its own goals.\nDoes not have a ‚Äúpersonality‚Äù or ‚Äúcharacter‚Äù in the traditional sense. It can be thought of as a role-playing simulator.\nHas no concept of ‚Äútruth‚Äù or ‚Äúlying‚Äù. The model is not trying to deceive the user, it is simply trying to respond in a human-like way."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#stochastic-generation",
    "href": "slides/busy-lecturers-guide.html#stochastic-generation",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Stochastic generation",
    "text": "Stochastic generation"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#knowledge-base",
    "href": "slides/busy-lecturers-guide.html#knowledge-base",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Knowledge base",
    "text": "Knowledge base\n\n\n\nA knowledge base is a collection of facts about the world.\nI can ask (retrieve) and tell (store) facts."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#can-an-llm-tell-the-truth",
    "href": "slides/busy-lecturers-guide.html#can-an-llm-tell-the-truth",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Can an LLM tell the truth?",
    "text": "Can an LLM tell the truth?\n\nHow would you know if an LLM is able to give you factual information?\nHow would you test this?\n\n\n\n\n\n\n\nNote\n\n\n\n: What is the capital of Uzbekistan?\n: Tashkent\n\n\nIt looks like the LLM knows the capital of Uzbekistan2."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#confirmation-bias",
    "href": "slides/busy-lecturers-guide.html#confirmation-bias",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Confirmation bias",
    "text": "Confirmation bias\n\nPeople tend to search for evidence consistent with their current beliefs."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#are-llms-knowledge-bases",
    "href": "slides/busy-lecturers-guide.html#are-llms-knowledge-bases",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Are LLMs knowledge bases?",
    "text": "Are LLMs knowledge bases?\n\n\n\n\n\nI can ask but the response is not verifiable.\nI can‚Äôt tell, i.e.¬†can‚Äôt store new information (expensive/difficult to update with new knowledge).\nLLM can‚Äôt tell me where it got its information from.\nLLMs are models of knowledge bases, but not knowledge bases themselves."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#how-do-humans-think",
    "href": "slides/busy-lecturers-guide.html#how-do-humans-think",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "How do humans think?",
    "text": "How do humans think?\nE.g. physical reasoning\n\n\n\n\n\nBattaglia, Hamrick, and Tenenbaum (2013)\n\n\n\n\n\n\nGerstenberg (2022)"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#what-is-a-prompt",
    "href": "slides/busy-lecturers-guide.html#what-is-a-prompt",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "What is a prompt?",
    "text": "What is a prompt?\n\nRemember: the goal of an LLM is complete text.\nA prompt is a piece of text (instruction) that is given to a language model to complete.\n\n\n\n\n\n\n\nNote\n\n\n\nPROMPT : Write a haiku about a workshop on large language models.\nASSISTANT : Whispers of circuits,\nKnowledge blooms in bytes and bits,\nModel learns and fits.\n\n\n\nThe response is generated as continuation of the prompt.\n\n\nMore technical definition: The output is generated by auto-regressively sampling from the probability distribution over the vocabulary, conditioned on the prompt."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#unlocking-knowledge",
    "href": "slides/busy-lecturers-guide.html#unlocking-knowledge",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Unlocking knowledge",
    "text": "Unlocking knowledge\n\n\n\n\n\nLLMs learn to do things they were not explicitly trained to do. \nOften, these capabilities need to be ‚Äúunlocked‚Äù by the right prompt. \n\n\n\nWhat is the right prompt?\nThe answer is very similar to what you would tell a human dialogue partner/assistant.\nYou can increase the probability of getting the desired output by asking good questions or giving enough information."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#basics-of-prompting",
    "href": "slides/busy-lecturers-guide.html#basics-of-prompting",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Basics of prompting",
    "text": "Basics of prompting\nOpenAI give a set of strategies for using their models effectively:\n Prompt engineering\nThese include:\n\nwriting clear instructions\nproviding reference texts\nsplitting tasks into subtasks\ngiving the LLM ‚Äòtime to think‚Äô\nusing external tools"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#writing-clear-instructions",
    "href": "slides/busy-lecturers-guide.html#writing-clear-instructions",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Writing clear instructions",
    "text": "Writing clear instructions\n\n\n\nThink of an LLM as a role-playing conversation simulator.\nInstructions should be clear and unambiguous.\nIndicate which role the model (persona) should adopt.\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nInclude details in your query to get more relevant answers\nAsk the model to adopt a persona\nUse delimiters to clearly indicate distinct parts of the input\nSpecify the steps required to complete a task\nProvide examples\nSpecify the desired length of the output"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#adopt-a-persona-role",
    "href": "slides/busy-lecturers-guide.html#adopt-a-persona-role",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Adopt a persona (role)",
    "text": "Adopt a persona (role)\n\n\n\n\n\n\nNote\n\n\n\n: You are an expert on learning techniques. Explain the concept of ‚Äòflipped classroom‚Äô in one paragraph.\n\n\n\n\n\n\n\n\nNote\n\n\n\n: You are an expert financial derivatives. Explain the concept of ‚Äòflipped classroom‚Äô in one paragraph."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#provide-reference-texts",
    "href": "slides/busy-lecturers-guide.html#provide-reference-texts",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Provide reference texts",
    "text": "Provide reference texts\n\nProvide a model with trusted and relevant information.\nThen instruct the model to use the provided information to compose its answer.\n\n Instruct the model to answer using a reference text\n\n\nThis leads to retrieval-augmented generation (RAG). First create a database of documents, then retrieve the most relevant documents, based on a user‚Äôs query. These are then included in the prompt to the model. The model is instructed to use the information in the documents to compose its answer."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#provide-reference-texts-1",
    "href": "slides/busy-lecturers-guide.html#provide-reference-texts-1",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Provide reference texts",
    "text": "Provide reference texts\n\n\n\n\n\n\nNote\n\n\n\n: You will be provided with a document delimited by triple quotes and a question. Your task is to provide a simplified answer to the question using only the provided document and to cite the passage(s) of the document used to answer the question. If the document does not contain the information needed to answer this question then simply write: ‚ÄúInsufficient information.‚Äù If an answer to the question is provided, it must be annotated with a citation. Use the following format for to cite relevant passages ({‚Äúcitation‚Äù: ‚Ä¶}). Cite only the relevant passage(s) of the document, not the entire document.\n‚Äú‚Äú‚Äù The flipped classroom intentionally shifts instruction to a learner-centered model, in which students are often initially introduced to new topics outside of school, freeing up classroom time for the exploration of topics in greater depth, creating meaningful learning opportunities. With a flipped classroom, ‚Äòcontent delivery‚Äô may take a variety of forms, often featuring video lessons prepared by the teacher or third parties, although online collaborative discussions, digital research, and text readings may alternatively be used. The ideal length for a video lesson is widely cited as eight to twelve minutes. ‚Äú‚Äú‚Äù\nQuestion: What is flipped classroom?"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#giving-gpt-time-to-think",
    "href": "slides/busy-lecturers-guide.html#giving-gpt-time-to-think",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Giving GPT ‚Äòtime to think‚Äô",
    "text": "Giving GPT ‚Äòtime to think‚Äô\n\nLLMs generate text one word at a time‚Äìthe model spends the same amount of computation on each word.\nGiving the model more context gives it more steps to ‚Äúthink‚Äù.\nThis increases the chances that the model will give a good answer.\nThis technique is known as chain-of-thought prompting, and can often be induced by simply instructing the model to think step-by-step or Take a deep breath and work on this problem step-by-step (Yang et al. 2023)."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#chain-of-thought-prompting",
    "href": "slides/busy-lecturers-guide.html#chain-of-thought-prompting",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Chain-of-thought prompting",
    "text": "Chain-of-thought prompting\n\nChain-of-thought prompting encourages the LLM to ‚Äúexplain‚Äù its intermediate reasoning steps.\nEnables complex reasoning and problem solving.\n\nInstead of this:\n\n\n\n\n\n\nNote\n\n\n\n: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1. Yes or no?\n\n\nDo this:\n\n\n\n\n\n\nNote\n\n\n\n: Is this statement correct? The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\nReason through the problem step-by-step. Start by identifying the odd numbers. Next, add them up. Finally, determine if the sum is even or odd. Write down your reasoning steps in a numbered list.\n\n\n\nWhy does this work?"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#zero-shot-chain-of-thought-prompting",
    "href": "slides/busy-lecturers-guide.html#zero-shot-chain-of-thought-prompting",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Zero-shot chain-of-thought prompting",
    "text": "Zero-shot chain-of-thought prompting\n\n\n\n\n\n\nNote\n\n\n\n: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1. Take a deep breath and think step-by-step.\n\n\n\n\nWhen using GPT-4, ChatGPT and Copilot do this automatically."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#use-markdown-formatting",
    "href": "slides/busy-lecturers-guide.html#use-markdown-formatting",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Use Markdown formatting",
    "text": "Use Markdown formatting\n\nUse Markdown to format your prompts.\nInstruct the LLM to format its output using Markdown.\n\n\n\n\n\n\n\nNote\n\n\n\n: Improve this haiku:\nWords weave through the air,\nMinds meld with machine‚Äôs deep thought,\nKnowledge blooms anew.\nIt is about about a workshop on large language models. I‚Äôm not happy with it.\nShow me all the text. Format your edits as **TEXT** and show the deleted text as ~~TEXT~~. Keep you review short (max 100 words).\n\n\nTry this example in ChatGPT."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#advanced-prompting-techniques",
    "href": "slides/busy-lecturers-guide.html#advanced-prompting-techniques",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Advanced prompting techniques",
    "text": "Advanced prompting techniques\nFor more advanced prompting techniques, see these websites:\n\n Learn prompting\n Prompting guide\n OpenAI cookbook\n\nand explore this activity."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#retrieval-augmented-generation-rag",
    "href": "slides/busy-lecturers-guide.html#retrieval-augmented-generation-rag",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Retrieval-augmented generation (RAG)",
    "text": "Retrieval-augmented generation (RAG)\n\n\nFigure courtesy of Pinecone"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#web-search",
    "href": "slides/busy-lecturers-guide.html#web-search",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Web search",
    "text": "Web search\n\nSimilar to retrieval-augmented generation, but with web search.\nLLMs can be instructed to use web search to find information.\nCopilot does this automatically - ChatGPT (paid version only) can be instructed to do this."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#external-tools",
    "href": "slides/busy-lecturers-guide.html#external-tools",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "External tools",
    "text": "External tools\n\nLLMs can be instructed to use external tools to complete tasks.\nFor example, an LLM can be instructed to use a calculator to perform arithmetic.\nOpenAI calls this approach function calling."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#multi-agent-conversations",
    "href": "slides/busy-lecturers-guide.html#multi-agent-conversations",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Multi-agent conversations",
    "text": "Multi-agent conversations\n\n\n\n\n\n DEMO: haiku writing team"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#local-models",
    "href": "slides/busy-lecturers-guide.html#local-models",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Local models",
    "text": "Local models\n\nDownload and run models, such as e.g.¬†Llama 2 or Code Llama, locally.\nOllama\nLM Studio\n\nHardware requirements:\n\nApple Silicon Mac (M1/M2/M3) / Windows / Linux\n16GB+ of RAM is recommended\nNVIDIA/AMD GPUs supported"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#footnotes",
    "href": "slides/busy-lecturers-guide.html#footnotes",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nContinue this conversation with ChatGPT.‚Ü©Ô∏é\nWhat it is actually doing is responding with the most likely sequence following the question.‚Ü©Ô∏é"
  },
  {
    "objectID": "slides/demo.html",
    "href": "slides/demo.html",
    "title": "Introduction",
    "section": "",
    "text": "sequenceDiagram\n  participant Alice\n  participant Bob\n  Alice-&gt;&gt;John: Hello John, how are you?\n  loop Healthcheck\n    John-&gt;&gt;John: Fight against hypochondria\n  end\n  Note right of John: Rational thoughts &lt;br/&gt;prevail!\n  John--&gt;&gt;Alice: Great!\n  John-&gt;&gt;Bob: How about you?\n  Bob--&gt;&gt;John: Jolly good!\n\n\n\n\n\n\n\n\n\n\n\n\n\nTurn off alarm\nGet out of bed\n\n\n\n\n\nEat eggs\nDrink coffee\n\n\n\n\n\n\n\n\nEat spaghetti\nDrink wine\n\n\n\n\n\nGet in bed\nCount sheep\n\n\n\n\n\n\n\n\n\nLeft column\n\nRight column"
  },
  {
    "objectID": "slides/demo.html#chart-1",
    "href": "slides/demo.html#chart-1",
    "title": "Introduction",
    "section": "",
    "text": "sequenceDiagram\n  participant Alice\n  participant Bob\n  Alice-&gt;&gt;John: Hello John, how are you?\n  loop Healthcheck\n    John-&gt;&gt;John: Fight against hypochondria\n  end\n  Note right of John: Rational thoughts &lt;br/&gt;prevail!\n  John--&gt;&gt;Alice: Great!\n  John-&gt;&gt;Bob: How about you?\n  Bob--&gt;&gt;John: Jolly good!"
  },
  {
    "objectID": "slides/demo.html#getting-up",
    "href": "slides/demo.html#getting-up",
    "title": "Introduction",
    "section": "",
    "text": "Turn off alarm\nGet out of bed"
  },
  {
    "objectID": "slides/demo.html#breakfast",
    "href": "slides/demo.html#breakfast",
    "title": "Introduction",
    "section": "",
    "text": "Eat eggs\nDrink coffee"
  },
  {
    "objectID": "slides/demo.html#dinner",
    "href": "slides/demo.html#dinner",
    "title": "Introduction",
    "section": "",
    "text": "Eat spaghetti\nDrink wine"
  },
  {
    "objectID": "slides/demo.html#going-to-sleep",
    "href": "slides/demo.html#going-to-sleep",
    "title": "Introduction",
    "section": "",
    "text": "Get in bed\nCount sheep"
  },
  {
    "objectID": "slides/demo.html#two-columns",
    "href": "slides/demo.html#two-columns",
    "title": "Introduction",
    "section": "",
    "text": "Left column\n\nRight column"
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html",
    "href": "slides/prompt-labor-vertiefung.html",
    "title": "Prompt Labor: Vertiefung",
    "section": "",
    "text": "Note\n\n\n\n\nHaltung der BFH: Technologien, die den Lernprozess unterst√ºtzen und praxisrelevant sind, sollen in die Lehre einbezogen werden.\nEinsatz von KI in der Lehre: Die Mehrheit der Studierenden wird KI-Tools nutzen. Studierende sollen lernen, Technologien kompetent einzusetzen und kritisch zu hinterfragen.\n\n\n\n \n Knowledge Base der Virtuellen Akademie\n PDF"
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#orientierungshilfe-f√ºr-lehrpersonen-der-bfh",
    "href": "slides/prompt-labor-vertiefung.html#orientierungshilfe-f√ºr-lehrpersonen-der-bfh",
    "title": "Prompt Labor: Vertiefung",
    "section": "",
    "text": "Note\n\n\n\n\nHaltung der BFH: Technologien, die den Lernprozess unterst√ºtzen und praxisrelevant sind, sollen in die Lehre einbezogen werden.\nEinsatz von KI in der Lehre: Die Mehrheit der Studierenden wird KI-Tools nutzen. Studierende sollen lernen, Technologien kompetent einzusetzen und kritisch zu hinterfragen.\n\n\n\n \n Knowledge Base der Virtuellen Akademie\n PDF"
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#competencies",
    "href": "slides/prompt-labor-vertiefung.html#competencies",
    "title": "Prompt Labor: Vertiefung",
    "section": "Competencies",
    "text": "Competencies"
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#deskilling-vs.-upskilling",
    "href": "slides/prompt-labor-vertiefung.html#deskilling-vs.-upskilling",
    "title": "Prompt Labor: Vertiefung",
    "section": "Deskilling vs.¬†upskilling",
    "text": "Deskilling vs.¬†upskilling"
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#effective-teaching-strategies",
    "href": "slides/prompt-labor-vertiefung.html#effective-teaching-strategies",
    "title": "Prompt Labor: Vertiefung",
    "section": "Effective teaching strategies",
    "text": "Effective teaching strategies\nMollick and Mollick (2023): 5 teaching strategies that are supported by research but difficult to apply in practice.\n\n\nProviding multiple examples and explanations.\nUncovering and addressing student misconceptions.\nFrequent low-stakes testing.\nAssessing student learning.\nDistributed practice."
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#providing-multiple-examples-and-explanations",
    "href": "slides/prompt-labor-vertiefung.html#providing-multiple-examples-and-explanations",
    "title": "Prompt Labor: Vertiefung",
    "section": "Providing multiple examples and explanations",
    "text": "Providing multiple examples and explanations\n\nExpose students to a variety of examples ‚Äì single examples may lead students to focus on superficial details instead of the core concept.\nPromotes deeper understanding, assist in recalling information, stimulate critical thinking.\nVariety helps students generalize, enabling them to apply this learning in other contexts.\n\n Time constraints, need to consider factors like relevance, engagement, and the right level of detail."
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#tools",
    "href": "slides/prompt-labor-vertiefung.html#tools",
    "title": "Prompt Labor: Vertiefung",
    "section": "Tools",
    "text": "Tools\n\n Prompt engineering: guide LLMs to produce desired behaviour\n Design custom chatbots\n Retrieval-augmented generation (RAG)\n Multi-agent models"
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#prompt-engineering",
    "href": "slides/prompt-labor-vertiefung.html#prompt-engineering",
    "title": "Prompt Labor: Vertiefung",
    "section": " Prompt engineering",
    "text": "Prompt engineering"
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#basics-of-prompting",
    "href": "slides/prompt-labor-vertiefung.html#basics-of-prompting",
    "title": "Prompt Labor: Vertiefung",
    "section": "Basics of prompting",
    "text": "Basics of prompting\nOpenAI‚Äôs strategies for  using their models effectively.\nThese include:\n\nwriting clear instructions\nproviding reference texts\nsplitting tasks into subtasks\ngiving the LLM ‚Äòtime to think‚Äô\nusing external tools"
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#pros-and-cons",
    "href": "slides/prompt-labor-vertiefung.html#pros-and-cons",
    "title": "Prompt Labor: Vertiefung",
    "section": "Pros and cons",
    "text": "Pros and cons\n\n\n Can guide the LLM to produce the desired behaviour.\n Requires little technical expertise.\n\n May require trial and error to find the right prompt."
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#chatgpt-with-gpt-4o",
    "href": "slides/prompt-labor-vertiefung.html#chatgpt-with-gpt-4o",
    "title": "Prompt Labor: Vertiefung",
    "section": " ChatGPT with GPT-4o",
    "text": "ChatGPT with GPT-4o\n Introducing GPT-4o and more tools to ChatGPT free users\n\nMultimodal conversational agent\nWeb search\nUpload documents\nUse GPTs and the GPT Store"
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#ai-powered-virtual-tutor",
    "href": "slides/prompt-labor-vertiefung.html#ai-powered-virtual-tutor",
    "title": "Prompt Labor: Vertiefung",
    "section": " AI-powered virtual tutor",
    "text": "AI-powered virtual tutor\n Demo: Math problems with GPT-4o\n\nCreation of AI-powered virtual tutors or professors that can adapt to a student‚Äôs individual learning needs, based on a set of guidelines and content provided by the educational institution and the educator.\nVirtual tutors engage in natural language communication, both through voice and text, and maintain an adaptive capacity to evaluate and guide the student towards specific learning objectives.¬†\nThis level of personalized attention could revolutionize the way we approach education, ensuring that each student receives the support they need to succeed."
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#custom-chatbots",
    "href": "slides/prompt-labor-vertiefung.html#custom-chatbots",
    "title": "Prompt Labor: Vertiefung",
    "section": " Custom chatbots",
    "text": "Custom chatbots\n\nCustom conversational agents for specific use cases.\n\n \n DEMO: Socratic mentor for reflective writing\n\nLTI integration with Moodle\nEmbedded within Moodle course\nUse Azure OpenAI (privacy concerns, hosted in CH)"
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#retrieval-augmented-generation",
    "href": "slides/prompt-labor-vertiefung.html#retrieval-augmented-generation",
    "title": "Prompt Labor: Vertiefung",
    "section": " Retrieval-augmented generation",
    "text": "Retrieval-augmented generation"
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#retrieval-augmented-generation-1",
    "href": "slides/prompt-labor-vertiefung.html#retrieval-augmented-generation-1",
    "title": "Prompt Labor: Vertiefung",
    "section": " Retrieval-augmented generation",
    "text": "Retrieval-augmented generation\n \n Open PDF Chatbot externally"
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#multi-agent-models",
    "href": "slides/prompt-labor-vertiefung.html#multi-agent-models",
    "title": "Prompt Labor: Vertiefung",
    "section": " Multi-agent models",
    "text": "Multi-agent models\n\n\n\n\nUse cases:\n\nFeedback for formative assessments\nEvaluation of essay grading (Hackl et al. 2023)"
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#references",
    "href": "slides/prompt-labor-vertiefung.html#references",
    "title": "Prompt Labor: Vertiefung",
    "section": "References",
    "text": "References\n\n\nHackl, Veronika, Alexandra Elena M√ºller, Michael Granitzer, and Maximilian Sailer. 2023. ‚ÄúIs GPT-4 a Reliable Rater? Evaluating Consistency in GPT-4‚Äôs Text Ratings.‚Äù Frontiers in Education 8 (December). https://doi.org/10.3389/feduc.2023.1272229.\n\n\nMollick, Ethan R., and Lilach Mollick. 2023. ‚ÄúUsing AI to Implement Effective Teaching Strategies in Classrooms: Five Strategies, Including Prompts.‚Äù SSRN Scholarly Paper. Rochester, NY. March 17, 2023. https://doi.org/10.2139/ssrn.4391243."
  },
  {
    "objectID": "slides/workshop-global-management.html",
    "href": "slides/workshop-global-management.html",
    "title": "Workshop: Global Management",
    "section": "",
    "text": "What are LLMs?\nUnderstanding LLM capabilities and limitations\nFundamentals of prompting\nBreak\nLLMs in the classroom\nEssential skills\nAcademic integrity\nConclusion"
  },
  {
    "objectID": "slides/workshop-global-management.html#what-is-artifical-intelligence",
    "href": "slides/workshop-global-management.html#what-is-artifical-intelligence",
    "title": "Workshop: Global Management",
    "section": "What is Artifical Intelligence?",
    "text": "What is Artifical Intelligence?\n\n\n\n\nA branch of computer science that aims to create machines that can perform tasks that typically require human intelligence."
  },
  {
    "objectID": "slides/workshop-global-management.html#what-is-a-large-language-model",
    "href": "slides/workshop-global-management.html#what-is-a-large-language-model",
    "title": "Workshop: Global Management",
    "section": "What is a Large Language Model?",
    "text": "What is a Large Language Model?\n\n\n\n\nAn LLM is a type of generative AI model that is trained to predict the next word following the input (prompt)."
  },
  {
    "objectID": "slides/workshop-global-management.html#how-to-train-a-language-model",
    "href": "slides/workshop-global-management.html#how-to-train-a-language-model",
    "title": "Workshop: Global Management",
    "section": "How to train a language model",
    "text": "How to train a language model\n\nAn LLM learns to predict the next word in a sequence, given the previous words: \\[ P(word | context) \\]\nThink of as ‚Äúfancy autocomplete‚Äù (but very very powerful and sopisticated)"
  },
  {
    "objectID": "slides/workshop-global-management.html#how-does-an-llm-generate-text",
    "href": "slides/workshop-global-management.html#how-does-an-llm-generate-text",
    "title": "Workshop: Global Management",
    "section": "How does an LLM generate text?",
    "text": "How does an LLM generate text?"
  },
  {
    "objectID": "slides/workshop-global-management.html#sampling",
    "href": "slides/workshop-global-management.html#sampling",
    "title": "Workshop: Global Management",
    "section": "Sampling",
    "text": "Sampling"
  },
  {
    "objectID": "slides/workshop-global-management.html#auto-regressive-generation",
    "href": "slides/workshop-global-management.html#auto-regressive-generation",
    "title": "Workshop: Global Management",
    "section": "Auto-regressive generation",
    "text": "Auto-regressive generation\nText is generated one word at a time (actually tokens, not words).\n\n\n\n\n\n Generated text depends on the generative model and the context.\n Every word (token) is given an equal amount time (computation per token is constant)."
  },
  {
    "objectID": "slides/workshop-global-management.html#auto-regressive-generation-1",
    "href": "slides/workshop-global-management.html#auto-regressive-generation-1",
    "title": "Workshop: Global Management",
    "section": "Auto-regressive generation",
    "text": "Auto-regressive generation"
  },
  {
    "objectID": "slides/workshop-global-management.html#foundation-models",
    "href": "slides/workshop-global-management.html#foundation-models",
    "title": "Workshop: Global Management",
    "section": "Foundation models",
    "text": "Foundation models\nA foundation model, or large language model (LLM):\n\nis a type of machine learning model that is trained to predict the next word following the input (prompt).\nis trained ‚Äúsimply‚Äù to predict the next word following a sequence of words.\ndoes not necessarily produce human-like conversations.\n\n\n\n\n\n\n\nNote\n\n\n\n: What is the capital of France?\n: What is the capital of Germany? What is the capital of Italy? . .."
  },
  {
    "objectID": "slides/workshop-global-management.html#training-process",
    "href": "slides/workshop-global-management.html#training-process",
    "title": "Workshop: Global Management",
    "section": "Training process",
    "text": "Training process\n\n\nFigure courtesy of Andrej Karpathy"
  },
  {
    "objectID": "slides/workshop-global-management.html#assistant-models",
    "href": "slides/workshop-global-management.html#assistant-models",
    "title": "Workshop: Global Management",
    "section": "Assistant models",
    "text": "Assistant models\nTrained (fine-tuned) to have conversations: turn-taking, question answering, not being rude/sexist/racist.\n\n\n\n\n\n\nFoundation model has learned to predict all kinds of text, including both desirable and undesirable text.\nFine-tuning narrows down the space of all possible output to only desirable, human-like dialogue.\nModel is aligned with the values of the fine-tuner."
  },
  {
    "objectID": "slides/workshop-global-management.html#how-do-chatbots-work",
    "href": "slides/workshop-global-management.html#how-do-chatbots-work",
    "title": "Workshop: Global Management",
    "section": "How do Chatbots work?",
    "text": "How do Chatbots work?\n\n\nDesigned to present the illusion of a conversation between two entities."
  },
  {
    "objectID": "slides/workshop-global-management.html#how-do-chatbots-actually-work",
    "href": "slides/workshop-global-management.html#how-do-chatbots-actually-work",
    "title": "Workshop: Global Management",
    "section": "How do chatbots actually work?",
    "text": "How do chatbots actually work?"
  },
  {
    "objectID": "slides/workshop-global-management.html#an-assistant-model-is-a-conversation-simulator",
    "href": "slides/workshop-global-management.html#an-assistant-model-is-a-conversation-simulator",
    "title": "Workshop: Global Management",
    "section": "An assistant model is a conversation simulator",
    "text": "An assistant model is a conversation simulator\n\n\n\n\n\nAn assistant is trained to respond to user prompts in a human-like way.\nSimulates possible human conversations.\nHas no intentions. It is not an entity with its own goals.\nDoes not have a ‚Äúpersonality‚Äù or ‚Äúcharacter‚Äù in the traditional sense. It can be thought of as a role-playing simulator.\nHas no concept of ‚Äútruth‚Äù or ‚Äúlying‚Äù. The model is not trying to deceive the user, it is simply trying to respond in a human-like way."
  },
  {
    "objectID": "slides/workshop-global-management.html#capabilities-and-limitations",
    "href": "slides/workshop-global-management.html#capabilities-and-limitations",
    "title": "Workshop: Global Management",
    "section": "Capabilities and limitations",
    "text": "Capabilities and limitations\n\n\nWhat are LLMs good at?\n\nFixing grammar, bad writing, etc.\nRephrasing\nAnalyzing texts\nWriting computer code\nAnswering questions about a knowledge base\nTranslating languages\nCreating structured output\nFactual output with external documents or web search\n\n\nLimitations\n\nThey make stuff up (hallucinate)\nThey learn biases from the training data\nWeird vocabulary, e.g.¬†delve\n(Chatbots have privacy issues)"
  },
  {
    "objectID": "slides/workshop-global-management.html#hallucination",
    "href": "slides/workshop-global-management.html#hallucination",
    "title": "Workshop: Global Management",
    "section": "Hallucination",
    "text": "Hallucination\n\n\n\n\n\nLLMs can generate text that is not true, or not based on any real-world knowledge.\nThis is known as ‚Äúhallucination‚Äù. A better term would be ‚Äúconfabulation‚Äù."
  },
  {
    "objectID": "slides/workshop-global-management.html#can-an-llm-tell-the-truth",
    "href": "slides/workshop-global-management.html#can-an-llm-tell-the-truth",
    "title": "Workshop: Global Management",
    "section": "Can an LLM tell the truth?",
    "text": "Can an LLM tell the truth?\n\nHow would you know if an LLM is able to give you factual information?\nHow would you test this?\n\n\n\n\n\n\n\nNote\n\n\n\n: What is the capital of Uzbekistan?\n: Tashkent\n\n\nIt looks like the LLM knows the capital of Uzbekistan1."
  },
  {
    "objectID": "slides/workshop-global-management.html#knowledge-base",
    "href": "slides/workshop-global-management.html#knowledge-base",
    "title": "Workshop: Global Management",
    "section": "Knowledge base",
    "text": "Knowledge base\n\n\n\nA knowledge base is a collection of facts about the world.\n\nYou can ask (retrieve) and tell (store) facts.\n\nAn LLM is not a knowledge base.\n\nLLMs generate text based on on how probable the next word is given the context, not based on stored facts."
  },
  {
    "objectID": "slides/workshop-global-management.html#biases",
    "href": "slides/workshop-global-management.html#biases",
    "title": "Workshop: Global Management",
    "section": "Biases",
    "text": "Biases\n\n\n\n\n\n\n\n\nBiases in LLMs\nSource\nExamples\n\n\n\n\nTraining data bias\nText from internet, books, articles.\nStereotypes reflecting gender, race, religion.\n\n\nRepresentation bias\nUnderrepresented groups/perspectives in data.\nLess accurate responses for minority cultures.\n\n\nAlgorithmic bias\nTraining and fine-tuning algorithms.\nOptimizations for fluency and coherence may lead to preference for dominant cultural narratives.\n\n\nUser interaction bias\nAdaptation based on user interactions.\nIncreased biased or harmful content generation."
  },
  {
    "objectID": "slides/workshop-global-management.html#privacy-concerns",
    "href": "slides/workshop-global-management.html#privacy-concerns",
    "title": "Workshop: Global Management",
    "section": "Privacy concerns",
    "text": "Privacy concerns\n\n\n\n\n\n\n\n\nPrivacy Concerns\nIssue\nExamples\n\n\n\n\nData memorization\nMemorizing sensitive information.\nReproducing phone numbers, addresses.\n\n\nTraining data leakage\nUnauthorized dissemination of confidential data.\nSummarizing proprietary documents.\n\n\nUser query logging\nStoring sensitive user interactions.\nExposing private queries if data is mishandled.\n\n\nQueries used for training\nUser queries may be used for further training.\nPersonal data in queries could be inadvertently included in training data."
  },
  {
    "objectID": "slides/workshop-global-management.html#prompting",
    "href": "slides/workshop-global-management.html#prompting",
    "title": "Workshop: Global Management",
    "section": "Prompting",
    "text": "Prompting"
  },
  {
    "objectID": "slides/workshop-global-management.html#what-is-a-prompt",
    "href": "slides/workshop-global-management.html#what-is-a-prompt",
    "title": "Workshop: Global Management",
    "section": "What is a prompt?",
    "text": "What is a prompt?\n\nAn LLM‚Äôs task is to complete text.\nA prompt is a piece of text (instruction) that is given to a language model to complete.\n\n\n\n\n\n\n\nNote\n\n\n\nPROMPT : Write a haiku about a workshop on large language models.\nASSISTANT : Whispers of circuits,\nKnowledge blooms in bytes and bits,\nModel learns and fits.\n\n\n\nThe response is generated as continuation of, and conditioned on, the prompt.\n\n\nMore technical definition: The output is generated by auto-regressively sampling from the probability distribution over the vocabulary, conditioned on the prompt."
  },
  {
    "objectID": "slides/workshop-global-management.html#prompt-engineering",
    "href": "slides/workshop-global-management.html#prompt-engineering",
    "title": "Workshop: Global Management",
    "section": "Prompt engineering",
    "text": "Prompt engineering\n\n\n\n\n\nLLMs learn to do things they were not explicitly trained to do: translation, reasoning, etc. \nOften, these capabilities need to be ‚Äúunlocked‚Äù by the right prompt. \n\n\n\nBut what is the right prompt?\nThe answer is very similar to what you would tell a human dialogue partner/assistant.\nYou can increase the probability of getting the desired output by providing context and examples."
  },
  {
    "objectID": "slides/workshop-global-management.html#basics-of-prompting",
    "href": "slides/workshop-global-management.html#basics-of-prompting",
    "title": "Workshop: Global Management",
    "section": "Basics of prompting",
    "text": "Basics of prompting\nOpenAI give a set of strategies for using their models effectively:\n Prompt engineering\nThese include:\n\nwriting clear instructions\nproviding reference texts\nsplitting tasks into subtasks\ngiving the LLM ‚Äòtime to think‚Äô\nusing external tools"
  },
  {
    "objectID": "slides/workshop-global-management.html#writing-clear-instructions",
    "href": "slides/workshop-global-management.html#writing-clear-instructions",
    "title": "Workshop: Global Management",
    "section": "Writing clear instructions",
    "text": "Writing clear instructions\n\n\n\nInstructions should be clear and unambiguous.\nThink of an LLM as a role-playing conversation simulator: Indicate which role the model (persona) should adopt.\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nInclude details in your query to get more relevant answers\nAsk the model to adopt a persona\nUse delimiters to clearly indicate distinct parts of the input\nSpecify the steps required to complete a task\nProvide examples\nSpecify the desired length of the output"
  },
  {
    "objectID": "slides/workshop-global-management.html#adopt-a-persona-role",
    "href": "slides/workshop-global-management.html#adopt-a-persona-role",
    "title": "Workshop: Global Management",
    "section": "Adopt a persona (role)",
    "text": "Adopt a persona (role)\n\n\n\n\n\n\nNote\n\n\n\n: You are an expert on learning techniques. Explain the concept of ‚Äòflipped classroom‚Äô in one paragraph.\n\n\n\n\n\n\n\n\nNote\n\n\n\n: You are an expert financial derivatives. Explain the concept of ‚Äòflipped classroom‚Äô in one paragraph."
  },
  {
    "objectID": "slides/workshop-global-management.html#provide-reference-texts",
    "href": "slides/workshop-global-management.html#provide-reference-texts",
    "title": "Workshop: Global Management",
    "section": "Provide reference texts",
    "text": "Provide reference texts\n\nProvide a model with trusted and relevant information.\nThen instruct the model to use the provided information to compose its answer.\n\n Instruct the model to answer using a reference text\n\n\n\nThis can be extended to retrieval-augmented generation (RAG). First create a database of documents, then retrieve the most relevant documents, based on a user‚Äôs query. These are then included in the prompt to the model. The model is instructed to use the information in the documents to compose its answer."
  },
  {
    "objectID": "slides/workshop-global-management.html#create-structured-output",
    "href": "slides/workshop-global-management.html#create-structured-output",
    "title": "Workshop: Global Management",
    "section": "Create structured output",
    "text": "Create structured output\n\nExplanation: Instruct the model to generate structured output.\nE.g. provide a table, a list, a diagram, etc.\nUse delimiters to indicate distinct parts of the input.\nExample: Extract information from a text and present it in a table."
  },
  {
    "objectID": "slides/workshop-global-management.html#structured-prompting-techniques",
    "href": "slides/workshop-global-management.html#structured-prompting-techniques",
    "title": "Workshop: Global Management",
    "section": "Structured prompting techniques",
    "text": "Structured prompting techniques\n\nIn-Context Learning: Provide examples within the prompt.\nThought Generation: Instruct the model to think step-by-step.\nDecomposition Techniques: Break down tasks into subtasks.\n\n(Schulhoff et al. 2024)"
  },
  {
    "objectID": "slides/workshop-global-management.html#in-context-learning",
    "href": "slides/workshop-global-management.html#in-context-learning",
    "title": "Workshop: Global Management",
    "section": "In-Context learning",
    "text": "In-Context learning\n\nExplanation: Providing examples or context within the prompt itself.\nFew-shot prompting: Give a few examples.\n\nExample: Translate the following sentences:\n\nEnglish: ‚ÄòWhat time is it?‚Äô -&gt; French: ‚ÄòQuelle heure est-il?‚Äô\nEnglish: ‚ÄòWhere is the library?‚Äô -&gt; French:\n\n\nZero-shot prompting: No examples, relies on pre-trained knowledge.\n\nExample: Translate the following sentence‚Ä¶"
  },
  {
    "objectID": "slides/workshop-global-management.html#thought-generation",
    "href": "slides/workshop-global-management.html#thought-generation",
    "title": "Workshop: Global Management",
    "section": "Thought generation",
    "text": "Thought generation\n\nExplanation: Encourages the model to show its reasoning process.\nChain-of-Thought (CoT) prompting: encourages the LLM to ‚Äúexplain‚Äù its intermediate reasoning steps.\nCan often be induced by simply instructing the model to think step-by-step or Take a deep breath and work on this problem step-by-step (Yang et al. 2023)."
  },
  {
    "objectID": "slides/workshop-global-management.html#chain-of-thought-example",
    "href": "slides/workshop-global-management.html#chain-of-thought-example",
    "title": "Workshop: Global Management",
    "section": "Chain-of-Thought example",
    "text": "Chain-of-Thought example\nInstead of this:\n\n\n\n\n\n\nNote\n\n\n\n: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1. Yes or no?\n\n\nDo this:\n\n\n\n\n\n\nNote\n\n\n\n: Is this statement correct? The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\nReason through the problem step-by-step. Start by identifying the odd numbers. Next, add them up. Finally, determine if the sum is even or odd. Write down your reasoning steps in a numbered list.\n\n\n\nWhy does this work?"
  },
  {
    "objectID": "slides/workshop-global-management.html#decomposition-techniques",
    "href": "slides/workshop-global-management.html#decomposition-techniques",
    "title": "Workshop: Global Management",
    "section": "Decomposition techniques",
    "text": "Decomposition techniques\n\nExplanation: Force the LLM to break down complex tasks into manageable subtasks.\nLeast-to-Most Prompting: Start simple, increase complexity.\n\nExample: List items, calculate cost‚Ä¶\n\nPlan-and-Solve Prompting: Separate planning and execution phases.\n\nExample: Understand the problem, devise a plan‚Ä¶"
  },
  {
    "objectID": "slides/workshop-global-management.html#hands-on-practice-prompting",
    "href": "slides/workshop-global-management.html#hands-on-practice-prompting",
    "title": "Workshop: Global Management",
    "section": "Hands-on practice: Prompting",
    "text": "Hands-on practice: Prompting\n Open this activity.\n\nPractice writing prompts for different tasks ( 20 minutes).\nSummarize a research article and write an essay using an LLM ( 30 minutes).\n\n  If you need further help with prompting techniques, see these websites:\n\n Learn prompting\n Prompting guide\n OpenAI cookbook"
  },
  {
    "objectID": "slides/workshop-global-management.html#chatgpt-edu",
    "href": "slides/workshop-global-management.html#chatgpt-edu",
    "title": "Workshop: Global Management",
    "section": "ChatGPT Edu",
    "text": "ChatGPT Edu\n\n\n \n\n\n\n\nAccess to GPT-4o, excelling in text interpretation, coding, and mathematics\nData analytics, web browsing, and document summarization\nBuild GPTs, custom versions of ChatGPT, and share them within university workspaces\nSignificantly higher message limits than the free version of ChatGPT\nImproved language capabilities across quality and speed, with over 50 languages supported\nRobust security, data privacy, and administrative controls\nConversations and data are not used to train OpenAI models"
  },
  {
    "objectID": "slides/workshop-global-management.html#gpts",
    "href": "slides/workshop-global-management.html#gpts",
    "title": "Workshop: Global Management",
    "section": "GPTs",
    "text": "GPTs"
  },
  {
    "objectID": "slides/workshop-global-management.html#hands-on-practice-gpts",
    "href": "slides/workshop-global-management.html#hands-on-practice-gpts",
    "title": "Workshop: Global Management",
    "section": "Hands-on practice: GPTs",
    "text": "Hands-on practice: GPTs\n\nTry out custom GPTs from various categories in the GPT store.\nDiscuss with your neighbour\n\nDid you discover any useful GPTs?\nWhat are the benefits and limitations of using GPTs in the classroom?"
  },
  {
    "objectID": "slides/workshop-global-management.html#extended-cognition",
    "href": "slides/workshop-global-management.html#extended-cognition",
    "title": "Workshop: Global Management",
    "section": "Extended cognition",
    "text": "Extended cognition\n\n\n\nAccording to Clark and Chalmers (1998), cognitive processes may extend to external objects.\nKrakauer (2016) distinguishes between complementary and competitive cognitive artifacts.\n\nComplementary: numbers, abacus\nCompetetive: calculator, GPS\n\nWhat kind of artefact will AI turn out to be?"
  },
  {
    "objectID": "slides/workshop-global-management.html#deskilling-vs.-upskilling",
    "href": "slides/workshop-global-management.html#deskilling-vs.-upskilling",
    "title": "Workshop: Global Management",
    "section": "Deskilling vs.¬†upskilling",
    "text": "Deskilling vs.¬†upskilling"
  },
  {
    "objectID": "slides/workshop-global-management.html#writing-tasks-in-the-ai-era",
    "href": "slides/workshop-global-management.html#writing-tasks-in-the-ai-era",
    "title": "Workshop: Global Management",
    "section": "Writing tasks in the AI era",
    "text": "Writing tasks in the AI era\n\nWriting is a core skill: critical thinking, persuasion, argumentation, understanding.\nText creation is secondary in learning: focus is on underlying skills.\nLearning objectives: Benefits of writing tasks should be clearly and convincingly conveyed.\nStudents should be equipped for effective (controlled) use of AI."
  },
  {
    "objectID": "slides/workshop-global-management.html#ai-can-do-my-homework",
    "href": "slides/workshop-global-management.html#ai-can-do-my-homework",
    "title": "Workshop: Global Management",
    "section": "AI can do my homework",
    "text": "AI can do my homework\n\nWe can think of this as cheating.\nMore useful: cheating means bypassing useful cognition and therefore missing out on learning.\nCheating an ethics problem.\nBypassing cognition is a learning problem.\nNot a new problem: books, encyclopedias, calculators, spell checkers, etc."
  },
  {
    "objectID": "slides/workshop-global-management.html#controlled-use-of-llms",
    "href": "slides/workshop-global-management.html#controlled-use-of-llms",
    "title": "Workshop: Global Management",
    "section": "Controlled use of LLMs",
    "text": "Controlled use of LLMs\n\n\n\n\n\n\n\nTask Category\nSpecific Tasks\n\n\n\n\nEditing tasks\nCreate/improve different versions of sections.\n\n\nTransitions\nWrite and compare transitions.\n\n\nImprove drafts\nCritique and refine drafts.\n\n\nWriting styles\nRewrite sections for different audiences.\n\n\nControversial statements\nIdentify controversial points and strengthen arguments.\n\n\nResearch journal\nKeep a diary and use LLM for reflection."
  },
  {
    "objectID": "slides/workshop-global-management.html#sport-vs.-writing",
    "href": "slides/workshop-global-management.html#sport-vs.-writing",
    "title": "Workshop: Global Management",
    "section": "Sport vs.¬†writing",
    "text": "Sport vs.¬†writing\n\n\n\nTechnological advancements in sports: a useful analogy for learning?\nDistinction between training and competition.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLZR Racer swim suit\nAI-base writing tools\n\n\n\n\nImprovement\nReduced Resistance, Increased Buoyancy\nImproved Grammar, Formulation, Content Creation\n\n\nFairness\nProvided an Unfair Advantage, Led to Record Performances\nConsidered Unfair in Academic Contexts\n\n\nImpact\nBanned to Maintain Competitive Integrity\nRaises Questions of Originality and Skill Development"
  },
  {
    "objectID": "slides/workshop-global-management.html#understanding-the-value-of-effort",
    "href": "slides/workshop-global-management.html#understanding-the-value-of-effort",
    "title": "Workshop: Global Management",
    "section": "Understanding the value of effort",
    "text": "Understanding the value of effort\n\nCheating can be a symptom that learners do not understand or value the importance of their own work.\nJust like in sport: if we take shortcuts during training, we won‚Äôt get fit.\nUnderstanding the purpose is important to endure discomfort.\nLearners need to understand what they are supposed to learn, why it is valuable, and why effort and discomfort are necessary."
  },
  {
    "objectID": "slides/workshop-global-management.html#fraud-triangle",
    "href": "slides/workshop-global-management.html#fraud-triangle",
    "title": "Workshop: Global Management",
    "section": "Fraud triangle",
    "text": "Fraud triangle"
  },
  {
    "objectID": "slides/workshop-global-management.html#learning-environments-that-promote-cheating",
    "href": "slides/workshop-global-management.html#learning-environments-that-promote-cheating",
    "title": "Workshop: Global Management",
    "section": "Learning Environments that promote cheating",
    "text": "Learning Environments that promote cheating\n\n\n\n\n\n\n\nFactors\nDescriptions\n\n\n\n\nHigh pressure\nHigh stakes increase cheating. Fear of failure reinforces this.\n\n\nLack of intrinsic motivation\nEngagement and relevance are important. Lacking these makes cheating more attractive.\n\n\nPerceived injustice\nUnfair grading leads to cheating.\n\n\nLow fear of getting caught\nLow risk encourages cheating.\n\n\nPeer influence\nWidespread cheating among peers pressures students to join in.\n\n\nLow self-efficacy\nDoubts about one‚Äôs own abilities increase cheating as the seemingly only option."
  },
  {
    "objectID": "slides/workshop-global-management.html#strategies-to-reduce-cheating",
    "href": "slides/workshop-global-management.html#strategies-to-reduce-cheating",
    "title": "Workshop: Global Management",
    "section": "Strategies to Reduce Cheating",
    "text": "Strategies to Reduce Cheating\n\n\n\n\n\n\n\nStrategies\nDescriptions\n\n\n\n\nFoster intrinsic motivation\nSpark genuine interest. Provide choices and practical applications.\n\n\nMastery learning\nClear learning objectives. Focus on mastery of content. Include constructive and corrective feedback in formative assessments.\n\n\nReduce pressure\nDiversify assessment methods. Use portfolios and low-stress tests to reduce anxiety.\n\n\nStrengthen self-efficacy\nProvide constructive feedback and promote peer learning (peer tutoring, peer review).\n\n\nCreate a culture of integrity\nOpen discussion about academic integrity. Set clear guidelines and promote community ethics."
  },
  {
    "objectID": "slides/workshop-global-management.html#academic-integrity-plagiarism",
    "href": "slides/workshop-global-management.html#academic-integrity-plagiarism",
    "title": "Workshop: Global Management",
    "section": "Academic Integrity: Plagiarism",
    "text": "Academic Integrity: Plagiarism\n\n\n\n\n\n\n\nTypes of Plagiarism\nDescription\n\n\n\n\nUnattributed use\nUsing the work or ideas of others without proper attribution.\n\n\nMinor changes or translations\nUsing the work of others with minor changes or translations without attribution.\n\n\nSelf-plagiarism\nReusing substantial parts of one‚Äôs own work without proper citation.\n\n\nJoint works\nReusing jointly written publications without proper acknowledgment."
  },
  {
    "objectID": "slides/workshop-global-management.html#academic-integrity-misconduct-in-authorship",
    "href": "slides/workshop-global-management.html#academic-integrity-misconduct-in-authorship",
    "title": "Workshop: Global Management",
    "section": "Academic Integrity: Misconduct in authorship",
    "text": "Academic Integrity: Misconduct in authorship\n\n\n\n\n\n\n\nTypes of Plagiarism\nDescription\n\n\n\n\nUnattributed use\nUsing the work or ideas of others without proper attribution.\n\n\nMinor changes or translations\nUsing the work of others with minor changes or translations without attribution.\n\n\nSelf-plagiarism\nReusing substantial parts of one‚Äôs own work without proper citation.\n\n\nJoint works\nReusing jointly written publications without proper acknowledgment."
  },
  {
    "objectID": "slides/workshop-global-management.html#how-to-cite-chatgpt",
    "href": "slides/workshop-global-management.html#how-to-cite-chatgpt",
    "title": "Workshop: Global Management",
    "section": "How to cite ChatGPT",
    "text": "How to cite ChatGPT\nE.g. APA Style: Cite as software (not as personal communication)."
  },
  {
    "objectID": "slides/workshop-global-management.html#documentating-ai-use",
    "href": "slides/workshop-global-management.html#documentating-ai-use",
    "title": "Workshop: Global Management",
    "section": "Documentating AI use",
    "text": "Documentating AI use\n\nSpecifying prompts works well for inexperienced users, but inadequately reflects complex processes.\nExperienced users work with dialogues and several tools, not monolithic prompts in ChatGPT.\nWorking with copilot (code): no traceable prompt input.\nInstead: Document the process, including the tools used and the steps taken.\n\nInclude used tools and steps in appendix, with optional graphical representation.\nServes both evaluation and self-reflection.\n\nIs documentation meaningful in the long term, once the use of AI-based tools has become commonplace?"
  },
  {
    "objectID": "slides/workshop-global-management.html#detecting-ai-use",
    "href": "slides/workshop-global-management.html#detecting-ai-use",
    "title": "Workshop: Global Management",
    "section": "Detecting AI use",
    "text": "Detecting AI use\n\nCan be detected by the use of specific vocabulary and phrases: ‚Äúdelve‚Äù, ‚Äúvibrant‚Äù, ‚Äúembark‚Äù, ‚Äúit‚Äôs important to note‚Äù, ‚Äù based on the data provided‚Äù.\nDetection tools are not very useful, and can be easily circumvented.\nAccording to Fleckenstein et al. (2024)\n\nGenerative AI can write papers that are undetectable.\nTeachers overestimate their detection abilities."
  },
  {
    "objectID": "slides/workshop-global-management.html#footnotes",
    "href": "slides/workshop-global-management.html#footnotes",
    "title": "Workshop: Global Management",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWhat it is actually doing is responding with the most likely sequence following the question.‚Ü©Ô∏é"
  }
]
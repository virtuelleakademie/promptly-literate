[
  {
    "objectID": "slides/zz-00-introduction.html#what-happens-when-your-lawyer-uses-chatgpt",
    "href": "slides/zz-00-introduction.html#what-happens-when-your-lawyer-uses-chatgpt",
    "title": "Introduction",
    "section": "What Happens When Your Lawyer Uses ChatGPT",
    "text": "What Happens When Your Lawyer Uses ChatGPT"
  },
  {
    "objectID": "slides/zz-00-introduction.html#the-best-prompts-for-chatgpt-the-ultimate-list",
    "href": "slides/zz-00-introduction.html#the-best-prompts-for-chatgpt-the-ultimate-list",
    "title": "Introduction",
    "section": "The Best Prompts For ChatGPT: The ultimate list",
    "text": "The Best Prompts For ChatGPT: The ultimate list"
  },
  {
    "objectID": "slides/zz-00-introduction.html#key-messages",
    "href": "slides/zz-00-introduction.html#key-messages",
    "title": "Introduction",
    "section": "Key messages",
    "text": "Key messages\n\nKeep human in the loop: LLMs should be used to augment human writing, not to replace it.\nPrompting, prompting, prompting: this workshop is mainly about prompting. We can think about prompting as a way of “programming” LLMs, i.e. getting LLMs to do what we want them to do."
  },
  {
    "objectID": "slides/zz-00-introduction.html#summary",
    "href": "slides/zz-00-introduction.html#summary",
    "title": "Introduction",
    "section": "Summary",
    "text": "Summary\n\nChatGPT has comparatively high energy requirements.\nLarge language models (LMMs) learn all kinds of human biases from their training data.\nToxic content produced by LLMs is flagged by cheap labor."
  },
  {
    "objectID": "slides/zz-00-introduction.html#energy-consumption",
    "href": "slides/zz-00-introduction.html#energy-consumption",
    "title": "Introduction",
    "section": "Energy consumption",
    "text": "Energy consumption\n\nTraining:\n\n“What we do know is that training ChatGPT used \\(1.3\\) GWh, roughly equivalent to the consumption of 120 US homes for a year.” Quelle: Heating up: how much energy does AI use?\nPatterson et al. (2022) estimate training costs at 502 tons of \\(\\text{CO}_2\\).\n\nUsage:\n\n7 tons of \\(\\text{CO}_2\\) per day (end of February). Source: How much energy does ChatGPT use?\nChatGPT’s energy consumption is equivalent to 400-800 US households. This is considerable, but compared to e.g. cryptocurrencies it is rather low."
  },
  {
    "objectID": "slides/zz-00-introduction.html#bias",
    "href": "slides/zz-00-introduction.html#bias",
    "title": "Introduction",
    "section": "Bias",
    "text": "Bias\n\n\n\n\n\nDa LLMs von Texten lernen, die von Menschen geschrieben wurden, können sie auch Vorurteile lernen.\n\nQuelle: Hast du Vorurteile?"
  },
  {
    "objectID": "slides/zz-00-introduction.html#ethical-aspects",
    "href": "slides/zz-00-introduction.html#ethical-aspects",
    "title": "Introduction",
    "section": "Ethical aspects",
    "text": "Ethical aspects\n\n\n\n\n\nAuf Grund der grossen Menge von Trainingsdaten, die für Sprachmodelle benötigt werden, ist Qualitätskontrolle schwierig.\nDiskriminierende oder beleidigende Aussagen werden von einem Chatbot generiert.\nSolche Antworten können als unerwünscht markiert werden.\nToxische Inhalte wie körperliche und sexuelle Gewalt, Suizide und Tierquälerei, müssen beim Trainieren aus den Antworten gefiltert werden. Dabei mussten angestellte Arbeitskräfte für weniger als 2 Dollar die Stunde teils schockierende Inhalte lesen.\n\nQuelle: Traumatische Klickarbeit"
  },
  {
    "objectID": "slides/zz-00-introduction.html#haltung-der-bfh",
    "href": "slides/zz-00-introduction.html#haltung-der-bfh",
    "title": "Introduction",
    "section": "Haltung der BFH",
    "text": "Haltung der BFH\n\nTechnologien sollen dort, wo sie den Lernprozess unterstützen und praxisrelevant sind, in die Lehre einbezogen werden.\nStudierende sollen lernen, Technologien kompetent einzusetzen und kritisch zu hinterfragen. Dies gilt uneingeschränkt auch für ChatGPT und andere gleichgerichtete Tools."
  },
  {
    "objectID": "slides/zz-00-introduction.html#zitieren",
    "href": "slides/zz-00-introduction.html#zitieren",
    "title": "Introduction",
    "section": "Zitieren",
    "text": "Zitieren\n\nEs existieren noch keine Richtlinien für das Zitieren von ChatGPT oder anderen KI-basierte Schreibtools.\nChatGPT ist rein rechtlich keine zitierfähige Quelle und damit auch nicht zitierpflichtig (Fleck 2023).\nAus der Orientierungshilfe: “KI-basierte Schreibtools sind externe Quellen und müssen daher im Sinne der wissenschaftlichen Integrität immer, wie andere Quellen auch, zitiert werden, sofern ganze Textpassagen von ChatGPT benutzt werden. Falls mit dem Tool der eigene Text überarbeitet wurde, muss ChatGPT als verwendetes Hilfsmittel angeführt werden.”\n\n\n\n\n\n\n\nMöglicher Pauschalverweis\n\n\n“Beim Verfassen der Arbeit habe ich das KI-gestützte Schreibwerkzeug ChatGPT zur Textoptimierung verwendet. Wörtlich aus dem Tool übernommene Passagen wurden im Text als persönliche Kommunikation zitiert.”"
  },
  {
    "objectID": "slides/zz-00-introduction.html#plagiate-und-detektion",
    "href": "slides/zz-00-introduction.html#plagiate-und-detektion",
    "title": "Introduction",
    "section": "Plagiate und Detektion",
    "text": "Plagiate und Detektion\n\nTexte von ChatGPT werden jedes Mal individuell erstellt. Es handelt sich nicht um Plagiate.\nDie klassischen Tools zur Aufdeckung von Plagiaten wie z.B. TurnItIn funktionieren hier nicht.\nDie BFH empfiehlt weiterhin, schriftliche Arbeiten mit der Plagiatserkennungssoftware Turnitin zu prüfen."
  },
  {
    "objectID": "slides/zz-00-introduction.html#kompetenznachweise",
    "href": "slides/zz-00-introduction.html#kompetenznachweise",
    "title": "Introduction",
    "section": "Kompetenznachweise",
    "text": "Kompetenznachweise\n\nSiehe KI-basierte Schreibtools in der Lehre – ChatGPT im Fokus\nBeim Benutzen von KI-generierten Texten in Kompetenznachweisen ohne Deklaration oder Zitierung kann von einem Plagiat im weiteren Sinne ausgegangen werden, welches das bisher etablierte Plagiatsverständnis im engeren Sinne erweitert.\nOpen Book-Prüfungen: KI-Tools müssten explizit ausgeschlossen werden.\nClosed Book-Prüfungen: KI-Tools können durch Einsatz von Safe Exam-Browser und Lernstick ausgeschlossen werden.\nSchriftliche Arbeiten: KI-Tools durch pauschalen Hilfsmittelverweis am Ende der Arbeit deklarieren.\nAlternative oder ergänzende Prüfungsformen: praktische Prüfungen, mündliche Prüfungen, Präsentationen."
  },
  {
    "objectID": "slides/zz-00-introduction.html#rechtliche-aspekte",
    "href": "slides/zz-00-introduction.html#rechtliche-aspekte",
    "title": "Introduction",
    "section": "Rechtliche Aspekte",
    "text": "Rechtliche Aspekte\n\nChatGPT kann keine Urheberschaft und keine Autorenschaft beanspruchen, da dies nur natürliche Personen können.\nMenschen können die Urheberschaft eines Textes beanspruchen, auch wenn sie auf Unterstützung durch ChatGPT zurückgegriffen haben – sofern sie eine wesentliche gestalterische Eigenleistung am Text erbracht haben.\n\nQuelle: Salden (2023)"
  },
  {
    "objectID": "slides/zz-00-introduction.html#datenschutz",
    "href": "slides/zz-00-introduction.html#datenschutz",
    "title": "Introduction",
    "section": "Datenschutz",
    "text": "Datenschutz\n\nAnonyme Nutzung von ChatGPT ist mit persönlichen Konto nicht möglich (über Handynummer identifizierbar).\nAlle Eingaben und alle Antworten werden bei ChatGPT unverschlüsselt abgespeichert.\nDaten liegen auf amerikanischen Servern und sind damit für amerikanische Ermittlungsbehörden grundsätzlich zugänglich."
  },
  {
    "objectID": "slides/demo.html#chart-1",
    "href": "slides/demo.html#chart-1",
    "title": "Introduction",
    "section": "Chart 1",
    "text": "Chart 1\n\n\n\n\n\nsequenceDiagram\n  participant Alice\n  participant Bob\n  Alice-&gt;&gt;John: Hello John, how are you?\n  loop Healthcheck\n    John-&gt;&gt;John: Fight against hypochondria\n  end\n  Note right of John: Rational thoughts &lt;br/&gt;prevail!\n  John--&gt;&gt;Alice: Great!\n  John-&gt;&gt;Bob: How about you?\n  Bob--&gt;&gt;John: Jolly good!"
  },
  {
    "objectID": "slides/demo.html#chart-2",
    "href": "slides/demo.html#chart-2",
    "title": "Introduction",
    "section": "Chart 2",
    "text": "Chart 2"
  },
  {
    "objectID": "slides/demo.html#getting-up",
    "href": "slides/demo.html#getting-up",
    "title": "Introduction",
    "section": "Getting up",
    "text": "Getting up\n\nTurn off alarm\nGet out of bed"
  },
  {
    "objectID": "slides/demo.html#breakfast",
    "href": "slides/demo.html#breakfast",
    "title": "Introduction",
    "section": "Breakfast",
    "text": "Breakfast\n\nEat eggs\nDrink coffee"
  },
  {
    "objectID": "slides/demo.html#in-the-evening",
    "href": "slides/demo.html#in-the-evening",
    "title": "Introduction",
    "section": "In the evening",
    "text": "In the evening"
  },
  {
    "objectID": "slides/demo.html#dinner",
    "href": "slides/demo.html#dinner",
    "title": "Introduction",
    "section": "Dinner",
    "text": "Dinner\n\nEat spaghetti\nDrink wine"
  },
  {
    "objectID": "slides/demo.html#going-to-sleep",
    "href": "slides/demo.html#going-to-sleep",
    "title": "Introduction",
    "section": "Going to sleep",
    "text": "Going to sleep\n\nGet in bed\nCount sheep"
  },
  {
    "objectID": "slides/demo.html#later",
    "href": "slides/demo.html#later",
    "title": "Introduction",
    "section": "Later",
    "text": "Later"
  },
  {
    "objectID": "slides/demo.html#two-columns",
    "href": "slides/demo.html#two-columns",
    "title": "Introduction",
    "section": "Two columns",
    "text": "Two columns\n\n\nLeft column\n\nRight column\n\n\n\n\n\nback to website ⤴️"
  },
  {
    "objectID": "slides/04-reflection.html#idea-generation",
    "href": "slides/04-reflection.html#idea-generation",
    "title": "Idea Generation and Reflection",
    "section": "Idea Generation",
    "text": "Idea Generation\n\nIdeas for tools: Do you have any ideas that weren’t discussed in this workshop? What would you like to see in the future?\nOpportunities and challenges: What are the opportunities and challenges involved with using LLMs in educational settings?"
  },
  {
    "objectID": "slides/04-reflection.html#reflection",
    "href": "slides/04-reflection.html#reflection",
    "title": "Idea Generation and Reflection",
    "section": "Reflection",
    "text": "Reflection\n\nDo you feel confident in using LLMs in your educational practice? What would help you feel more confident?\nDo you feel that you understand how to apply LLMs?\nDo you feel confident in evaluating LLM-based tools?"
  },
  {
    "objectID": "slides/04-reflection.html#thank-you-for-attending-this-workshop",
    "href": "slides/04-reflection.html#thank-you-for-attending-this-workshop",
    "title": "Idea Generation and Reflection",
    "section": "Thank you for attending this workshop!",
    "text": "Thank you for attending this workshop!\n  \n🌟 Your feedback matters! Please take 5 minutes to complete our 👉 evaluation form."
  },
  {
    "objectID": "slides/04-reflection.html#evaluation-form",
    "href": "slides/04-reflection.html#evaluation-form",
    "title": "Idea Generation and Reflection",
    "section": "Evaluation Form",
    "text": "Evaluation Form\n\n\n\n\nback to website ⤴️"
  },
  {
    "objectID": "slides/02-prompting-techniques.html#what-is-a-prompt",
    "href": "slides/02-prompting-techniques.html#what-is-a-prompt",
    "title": "Basic Prompting Techniques",
    "section": "What is a prompt?",
    "text": "What is a prompt?\n\nRemember: the goal of an LLM is complete text.\nA prompt is a piece of text (instruction) that is given to a language model to complete.\n\n\n\n\nPROMPT : Write a haiku about a workshop on large language models.\nASSISTANT : Whispers of circuits,\nKnowledge blooms in bytes and bits,\nModel learns and fits.\n\n\n\n\nThe response is generated as continuation of the prompt.\n\n\nMore technical definition: The output is generated by auto-regressively sampling from the probability distribution over the vocabulary, conditioned on the prompt."
  },
  {
    "objectID": "slides/02-prompting-techniques.html#unlocking-knowledge",
    "href": "slides/02-prompting-techniques.html#unlocking-knowledge",
    "title": "Basic Prompting Techniques",
    "section": "Unlocking knowledge",
    "text": "Unlocking knowledge\n\n\n\n\n\nLLMs learn to do things they were not explicitly trained to do. \nOften, these capabilities need to be “unlocked” by the right prompt. \n\n\n\nWhat is the right prompt?\nThe answer is very similar to what you would tell a human dialogue partner.\nYou can increase the probability of getting the desired output by asking good questions."
  },
  {
    "objectID": "slides/02-prompting-techniques.html#basics-of-prompting",
    "href": "slides/02-prompting-techniques.html#basics-of-prompting",
    "title": "Basic Prompting Techniques",
    "section": "Basics of prompting",
    "text": "Basics of prompting"
  },
  {
    "objectID": "slides/02-prompting-techniques.html#basics-of-prompting-1",
    "href": "slides/02-prompting-techniques.html#basics-of-prompting-1",
    "title": "Basic Prompting Techniques",
    "section": "Basics of prompting",
    "text": "Basics of prompting\nOpenAI give a set of strategies for using their models\n\nThese include:\n\nwriting clear instructions\nproviding reference texts\nsplitting tasks into subtasks\ngiving GPT ‘time to think’\nusing external tools\n\n\n👉 Prompt engineering"
  },
  {
    "objectID": "slides/02-prompting-techniques.html#writing-clear-instructions",
    "href": "slides/02-prompting-techniques.html#writing-clear-instructions",
    "title": "Basic Prompting Techniques",
    "section": "Writing clear instructions",
    "text": "Writing clear instructions\n\n\n\nThink of an LLM as a role-playing conversation simulator.\nInstructions should be clear and unambiguous.\nIndicate which role the model (persona) should adopt.\n\n\n\n\n\n\nInclude details in your query to get more relevant answers\nAsk the model to adopt a persona\nUse delimiters to clearly indicate distinct parts of the input\nSpecify the steps required to complete a task\nProvide examples\nSpecify the desired length of the output"
  },
  {
    "objectID": "slides/02-prompting-techniques.html#adopt-a-persona-role",
    "href": "slides/02-prompting-techniques.html#adopt-a-persona-role",
    "title": "Basic Prompting Techniques",
    "section": "Adopt a persona (role)",
    "text": "Adopt a persona (role)\n\n\n\n: You are an expert on learning techniques. Explain the concept of ‘flipped classroom’ in one paragraph.\n: You are an expert financial derivatives. Explain the concept of ‘flipped classroom’ in one paragraph."
  },
  {
    "objectID": "slides/02-prompting-techniques.html#provide-reference-texts",
    "href": "slides/02-prompting-techniques.html#provide-reference-texts",
    "title": "Basic Prompting Techniques",
    "section": "Provide reference texts",
    "text": "Provide reference texts\n\nProvide a model with trusted and relevant information.\nThen instruct the model to use the provided information to compose its answer.\n\n\n\nThis leads to retrieval-augmented generation (RAG). First create a database of documents, then retrieve the most relevant documents, based on a user’s query. These are then included in the prompt to the model. The model is instructed to use the information in the documents to compose its answer."
  },
  {
    "objectID": "slides/02-prompting-techniques.html#provide-reference-texts-1",
    "href": "slides/02-prompting-techniques.html#provide-reference-texts-1",
    "title": "Basic Prompting Techniques",
    "section": "Provide reference texts",
    "text": "Provide reference texts\n\n\n\n: You will be provided with a document delimited by triple quotes and a question. Your task is to provide a simplified answer to the question using only the provided document and to cite the passage(s) of the document used to answer the question. If the document does not contain the information needed to answer this question then simply write: “Insufficient information.” If an answer to the question is provided, it must be annotated with a citation. Use the following format for to cite relevant passages ({“citation”: …}).\n## Document\n’‘’The flipped classroom intentionally shifts instruction to a learner-centered model, in which students are often initially introduced to new topics outside of school, freeing up classroom time for the exploration of topics in greater depth, creating meaningful learning opportunities. With a flipped classroom, ’content delivery’ may take a variety of forms, often featuring video lessons prepared by the teacher or third parties, although online collaborative discussions, digital research, and text readings may alternatively be used. The ideal length for a video lesson is widely cited as eight to twelve minutes.’’’\n## Question\nWhat is flipped classroom?"
  },
  {
    "objectID": "slides/02-prompting-techniques.html#giving-gpt-time-to-think",
    "href": "slides/02-prompting-techniques.html#giving-gpt-time-to-think",
    "title": "Basic Prompting Techniques",
    "section": "Giving GPT ‘time to think’",
    "text": "Giving GPT ‘time to think’\n\nLLMs generate text one word at a time–the model spends the same amount of computation on each word.\nGiving the model more context gives it more steps to “think”.\nThis increases the chances that the model will give a good answer.\nThis technique is known as chain-of-thought prompting, and can often be induced by simply instructing the model to think step-by-step or Take a deep breath and work on this problem step-by-step (Yang et al. 2023)."
  },
  {
    "objectID": "slides/02-prompting-techniques.html#chain-of-thought-prompting",
    "href": "slides/02-prompting-techniques.html#chain-of-thought-prompting",
    "title": "Basic Prompting Techniques",
    "section": "Chain-of-thought prompting",
    "text": "Chain-of-thought prompting\n\nChain-of-thought prompting encourages the LLM to “explain” its intermediate reasoning steps.\nEnables complex reasoning and problem solving.\n\n\n\n\nInstead of this:\n: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\nDo this:\n: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.  The odd numbers are 9, 15, 1.  The sum of the odd numbers is 9 + 15 + 1 = 25.  25 is an odd number.  Therefore, the statement is false.\n\n\n\n\nWhy does this work?"
  },
  {
    "objectID": "slides/02-prompting-techniques.html#zero-shot-chain-of-thought-prompting",
    "href": "slides/02-prompting-techniques.html#zero-shot-chain-of-thought-prompting",
    "title": "Basic Prompting Techniques",
    "section": "Zero-shot chain-of-thought prompting",
    "text": "Zero-shot chain-of-thought prompting\n\n\n\n: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1. Take a deep breath and think step-by-step.\n\n\n\n\n\nWhen using GPT-4, ChatGPT and Bing seem to be doing this automatically."
  },
  {
    "objectID": "slides/02-prompting-techniques.html#explore-prompting-techniques",
    "href": "slides/02-prompting-techniques.html#explore-prompting-techniques",
    "title": "Basic Prompting Techniques",
    "section": "Explore prompting techniques",
    "text": "Explore prompting techniques\nNow open the first activity to learn more about ChatGPT and OpenAI Playground:\n👉 Activity 1."
  },
  {
    "objectID": "slides/00-introduction.html#take-home-messages",
    "href": "slides/00-introduction.html#take-home-messages",
    "title": "What is ChatGPT?",
    "section": "🏠 Take-home messages",
    "text": "🏠 Take-home messages\n\nUse LLMs yourself! It’s important to gain an intuition for their capabilities and limitations.\nCombine domain knowledge of the “thing” you are working on, an understanding of how LLMs work, and an understanding of how to prompt them.\nUse LLMs with students in a classroom setting. This will help students to develop their own understanding of LLMs and become AI-literate.\nAlways (critically 👩‍🔬) check an LLM’s output. They are language models, not knowledge bases. Keep a human in the loop."
  },
  {
    "objectID": "slides/00-introduction.html#learning-outcomes",
    "href": "slides/00-introduction.html#learning-outcomes",
    "title": "What is ChatGPT?",
    "section": "🎯 Learning outcomes",
    "text": "🎯 Learning outcomes\n\n\n\nAfter this workshop, you will be able to:\n\n\n\nExplain what large language models and conversational agents, such as ChatGPT, can be used for, and what they shouldn’t be used for.\nCreate effective prompts for LLMs.\nDesign your own LLM-based educational activities.\nCritically evaluate LLM-based educational activities."
  },
  {
    "objectID": "slides/00-introduction.html#schedule",
    "href": "slides/00-introduction.html#schedule",
    "title": "What is ChatGPT?",
    "section": "⏱️ Schedule",
    "text": "⏱️ Schedule"
  },
  {
    "objectID": "slides/00-introduction.html#contents",
    "href": "slides/00-introduction.html#contents",
    "title": "What is ChatGPT?",
    "section": "Contents",
    "text": "Contents\n\nExample: 20 questions\nWhat is ChatGPT?\n\nBase model\nAssistant model\n\nWhat is it not?\nChatGPT as a role-play simulator"
  },
  {
    "objectID": "slides/00-introduction.html#questions",
    "href": "slides/00-introduction.html#questions",
    "title": "What is ChatGPT?",
    "section": "20 questions",
    "text": "20 questions\n\n\n\n\n\n\n🤷‍♂️ What is ChatGPT doing here?\nHow does this work?"
  },
  {
    "objectID": "slides/00-introduction.html#what-is-chatgpt",
    "href": "slides/00-introduction.html#what-is-chatgpt",
    "title": "What is ChatGPT?",
    "section": "What is ChatGPT?",
    "text": "What is ChatGPT?\n\n\n\n\n\nConsists of a base model and an assistant model.\nBase or foundation model: probabilistic model of how language is generated.\nAssistant: able to create human-like dialogue."
  },
  {
    "objectID": "slides/00-introduction.html#base-model-text-prediction",
    "href": "slides/00-introduction.html#base-model-text-prediction",
    "title": "What is ChatGPT?",
    "section": "Base model: text prediction",
    "text": "Base model: text prediction\n\n\n\n\n\n\n\nExtracts knowledge from text: linguistic, factual, commonsense, etc."
  },
  {
    "objectID": "slides/00-introduction.html#base-model",
    "href": "slides/00-introduction.html#base-model",
    "title": "What is ChatGPT?",
    "section": "Base model",
    "text": "Base model\nProduces text that most likely follows the input (prompt).\n\n\n\n: What is the capital of France?\n: What is the capital of Germany? What is the capital of Italy? …\n\n\n\n\n\n\n: The first person to walk on the Moon was\n: Neil Armstrong\n\n\n\n\n\n\nDoes an LLM know facts?\n\n\nWhat we are really asking: Given what it learned during training, what words are most likely to follow “The first person to walk on the Moon was”? A good reply to this question is “Neil Armstrong”."
  },
  {
    "objectID": "slides/00-introduction.html#base-model-emergent-properties",
    "href": "slides/00-introduction.html#base-model-emergent-properties",
    "title": "What is ChatGPT?",
    "section": "Base model: emergent properties",
    "text": "Base model: emergent properties\nLLMs are thought to show emergent properties - abilities not explicitly programmed into the model, but emerge as a result of text prediction.\n\nperforming arithmetic, answering questions, summarizing text, translating, etc.\nzero-shot learning: LLMs can perform tasks without being trained on them.\nfew-shot learning: LLMs can perform tasks with few examples."
  },
  {
    "objectID": "slides/00-introduction.html#assistant-model-alignment",
    "href": "slides/00-introduction.html#assistant-model-alignment",
    "title": "What is ChatGPT?",
    "section": "Assistant model: alignment",
    "text": "Assistant model: alignment\n\n\n\n\n\n  - Trained to have conversations: turn-taking, question answering, not being [rude/sexist/racist], etc."
  },
  {
    "objectID": "slides/00-introduction.html#chatbot",
    "href": "slides/00-introduction.html#chatbot",
    "title": "What is ChatGPT?",
    "section": "Chatbot",
    "text": "Chatbot\n\n\n\n\n\n\nPrompt: System message: You are a helpful assistant. User message: Tell me a joke.\n: Why don’t scientists trust atoms? Because they make up everything!\nPrompt: System message: You are a helpful assistant. User message: Tell me a joke. Assistant message: Why don’t scientists trust atoms? Because they make up everything! User message: Tell me another one.\n: Why did the scarecrow win an award? Because he was outstanding in his field! ::: –&gt;"
  },
  {
    "objectID": "slides/00-introduction.html#knowledge-base",
    "href": "slides/00-introduction.html#knowledge-base",
    "title": "What is ChatGPT?",
    "section": "Knowledge base",
    "text": "Knowledge base\n\n\n\n\n\nA knowledge base is a collection of facts about the world.\nAsk and Tell\nI can ask but I can’t tell.\nIt cannot give me verifiable facts."
  },
  {
    "objectID": "slides/00-introduction.html#knowledge-base-1",
    "href": "slides/00-introduction.html#knowledge-base-1",
    "title": "What is ChatGPT?",
    "section": "Knowledge base",
    "text": "Knowledge base\n\n\n\n\n\nAm Strande von Rainer Maria Rilke  👉 Open in ChatGPT\n\n\n\n\n\n\nKennst du dieses Gedicht?  👉 Open in ChatGPT\n\n\n\n\n\nWhat can we learn from this?"
  },
  {
    "objectID": "slides/00-introduction.html#knowledge-base-2",
    "href": "slides/00-introduction.html#knowledge-base-2",
    "title": "What is ChatGPT?",
    "section": "Knowledge base",
    "text": "Knowledge base\n\n\n\n\n\nCan’t tell me where it got its information from.\nLLMs are models of knowledge bases, but not knowledge bases themselves.\nExpensive/difficult to update with new knowledge.\nProduce ethically questionable results."
  },
  {
    "objectID": "slides/00-introduction.html#an-llm-is-a-role-play-simulator",
    "href": "slides/00-introduction.html#an-llm-is-a-role-play-simulator",
    "title": "What is ChatGPT?",
    "section": "An LLM is a role-play simulator",
    "text": "An LLM is a role-play simulator\n\n\n\n\n\n\n\nWe can think of an LLM as a non-deterministic simulator capable of role-playing an infinity of characters, or, to put it another way, capable of stochastically generating an infinity of simulacra (Shanahan, McDonell, and Reynolds 2023)"
  },
  {
    "objectID": "slides/00-introduction.html#an-llm-is-a-role-play-simulator-1",
    "href": "slides/00-introduction.html#an-llm-is-a-role-play-simulator-1",
    "title": "What is ChatGPT?",
    "section": "An LLM is a role-play simulator",
    "text": "An LLM is a role-play simulator\n\nAn assistant is trained to respond to user prompts in a human-like way.\nA simulator of possible human conversation.\nHas no intentions. It is not an entity with its own goals.\nDoes not have a “personality” or “character” in the traditional sense. It can be thought of as a role-playing simulator.\nHas no concept of “truth” or “lying”. The model is not trying to deceive the user, it is simply trying to respond in a human-like way."
  },
  {
    "objectID": "slides/00-introduction.html#an-llm-is-a-role-play-simulator-2",
    "href": "slides/00-introduction.html#an-llm-is-a-role-play-simulator-2",
    "title": "What is ChatGPT?",
    "section": "An LLM is a role-play simulator",
    "text": "An LLM is a role-play simulator\n\n\n\n\n\nThe dialogue agent will do its best to role-play a character in a dialogue.\nAt every step, the model is trying to generate text that is most likely to follow the input.\nIt can take many different paths. Your interaction is just one of those possible paths."
  },
  {
    "objectID": "slides/00-introduction.html#an-llm-is-a-role-play-simulator-3",
    "href": "slides/00-introduction.html#an-llm-is-a-role-play-simulator-3",
    "title": "What is ChatGPT?",
    "section": "An LLM is a role-play simulator",
    "text": "An LLM is a role-play simulator\n\n\n\n\n\n\nYou can open this conversation in ChatGPT.\nTry re-generating the conversation after the initial prompt."
  },
  {
    "objectID": "slides/00-introduction.html#what-are-llms-good-at",
    "href": "slides/00-introduction.html#what-are-llms-good-at",
    "title": "What is ChatGPT?",
    "section": "What are LLMs good at?",
    "text": "What are LLMs good at?\n\n\n\nFixing grammar, bad writing, etc.\nRephrasing\nAnalyze texts\nWrite computer code\nAnswer questions about a knowledge base\nTranslate languages\nCreating structured output"
  },
  {
    "objectID": "slides/00-introduction.html#references",
    "href": "slides/00-introduction.html#references",
    "title": "What is ChatGPT?",
    "section": "References",
    "text": "References\n\n\nShanahan, Murray. 2023. “Talking About Large Language Models.” January 25, 2023. https://doi.org/10.48550/arXiv.2212.03551.\n\n\nShanahan, Murray, Kyle McDonell, and Laria Reynolds. 2023. “Role-Play with Large Language Models.” May 25, 2023. https://doi.org/10.48550/arXiv.2305.16367.\n\n\nWei, Jason, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, et al. 2022. “Emergent Abilities of Large Language Models.” October 26, 2022. https://doi.org/10.48550/arXiv.2206.07682.\n\n\n\n\n\nback to website ⤴️"
  },
  {
    "objectID": "pages/text-representation.html",
    "href": "pages/text-representation.html",
    "title": "Text representation",
    "section": "",
    "text": "Text embeddings are numerical representations of words, sentences or documents. They are used in many NLP tasks, such as sentiment analysis, machine translation, and question answering.\n\nEmbeddings should capture features of words or concepts, and relationships between these.\nA sentence embedding is just like a word embedding, except it associates every sentence with a vector full of numbers, capturing similarities between sentences.\nThe key idea is that words/sentences with similar meanings will have similar vectors. This is useful for many tasks in natural language processing, such as sentiment analysis, machine translation, and question answering.\n\nYou can read more about text embeddings in this 👉 post.\nThe following is an example of sentence embeddings, showing the distance between sentences. The distance is calculated using the dot product (cosine similarity) of the embeddings.\n\n\nCode\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nembedding = OpenAIEmbeddings()\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pyobsplot import Plot, d3, Math, js\n\n\n\n\nCode\nsentences = [\n    \"Good morning, how are you?\",\n    \"I am doing well, how about you?\",\n    \"Hi, how are you doing today?\",\n    \"Hey, what's up?\",\n    \"I like apples.\",\n    \"One of my daughters doesn't like kiwis.\",\n    \"The other doesn't like bananas.\",\n    \"The earth is the third planet from the sun.\",\n    \"The moon is a natural satellite of the earth.\",\n    \"Jupiter is the fifth planet from the Sun and the largest in the Solar System.\",\n    \"The humpback whale is renowned for its enchanting songs, which are believed to serve various purposes, including communication, mating, and navigation during migration.\",\n    \"Dolphins, highly intelligent marine mammals, communicate with each other using a complex system of clicks, whistles, and body language, enabling them to work together in hunting and navigation.\",\n    \"The honeybee, through its pollination efforts, plays a vital role in agriculture, contributing to the growth of many of the fruits and vegetables humans rely on for sustenance.\",\n    \"The Large Plane Trees, also known as Road Menders at Saint-Rémy, is an oil-on-canvas painting by Vincent van Gogh.\",\n    \"Pablo Picasso's Guernica, an iconic mural-sized oil painting, stands as a poignant representation of the horrors of war.\",\n    \"This powerful artwork was created in response to the bombing of the town of Guernica during the Spanish Civil War.\"\n]\n\n\n\n\nCode\nembeddings = np.array([embedding.embed_query(sentence) for sentence in sentences])\n\ndot_product_matrix = np.dot(embeddings, embeddings.T)\n\ndf = pd.DataFrame(dot_product_matrix, columns=range(1, len(embeddings)+1))\n\ndf['embedding_index'] = range(1, len(embeddings)+1)\n\ndf = df.melt(id_vars=['embedding_index'], var_name='embedding_index_2', value_name='similarity')\n\n\n\n\n\n\n\n\n\n\n\n\nSentences\n\n\n\n\n1\nGood morning, how are you?\n\n\n2\nI am doing well, how about you?\n\n\n3\nHi, how are you doing today?\n\n\n4\nHey, what's up?\n\n\n5\nI like apples.\n\n\n6\nOne of my daughters doesn't like kiwis.\n\n\n7\nThe other doesn't like bananas.\n\n\n8\nThe earth is the third planet from the sun.\n\n\n9\nThe moon is a natural satellite of the earth.\n\n\n10\nJupiter is the fifth planet from the Sun and the largest in the Solar System.\n\n\n11\nThe humpback whale is renowned for its enchanting songs, which are believed to serve various purposes, including communication, mating, and navigation during migration.\n\n\n12\nDolphins, highly intelligent marine mammals, communicate with each other using a complex system of clicks, whistles, and body language, enabling them to work together in hunting and navigation.\n\n\n13\nThe honeybee, through its pollination efforts, plays a vital role in agriculture, contributing to the growth of many of the fruits and vegetables humans rely on for sustenance.\n\n\n14\nThe Large Plane Trees, also known as Road Menders at Saint-Rémy, is an oil-on-canvas painting by Vincent van Gogh.\n\n\n15\nPablo Picasso's Guernica, an iconic mural-sized oil painting, stands as a poignant representation of the horrors of war.\n\n\n16\nThis powerful artwork was created in response to the bombing of the town of Guernica during the Spanish Civil War.\n\n\n\n\n\n\n\n\n\n\nCode\nPlot.plot(\n    {\n        \"height\": 640,\n        \"padding\": 0.05,\n        \"grid\": True,\n        \"x\": {\"axis\": \"top\", \"label\": \"Embedding Index\"},\n        \"y\": {\"label\": \"Embedding Index\"},\n        \"color\": {\"type\": \"linear\", \"scheme\": \"PiYG\"},\n        \"marks\": [\n            Plot.cell(\n                df,\n                {\"x\": \"embedding_index\", \"y\": \"embedding_index_2\", \"fill\": \"similarity\", \"tip\": True},\n            ),\n            Plot.text(\n                df,\n                {\n                    \"x\": \"embedding_index\",\n                    \"y\": \"embedding_index_2\",\n                    \"text\": js(\"d =&gt; d.similarity.toFixed(2)\"),\n                    \"title\": \"title\"\n                },\n            ),\n        ],\n    }\n)\n\n\n\n\n\nYou can see that the sentences are grouped together by semantic similarity. For example, the sentences about fruit are grouped together, and the sentences about planets are grouped together, in the sense that they are similar to each other.\nThis is important: embeddings capture the meaning of words and sentences, and are the basis of LLMs’ ability to “understand” language.\nHere is an alternative similarity plot, showing the general topic of each sentence.\n\n\nCode\ntopics = {\"Greeting\": 4, \"Fruit\": 3,\n          \"Planets\": 3, \"Animals\": 3,\n          \"Art\": 3}\ntopics_repeated = [key for key, value in topics.items() for i in range(value)]\n\n\n# Create the similarity matrix\nembeddings = np.array([embedding.embed_query(sentence) for sentence in sentences])\ndot_product_matrix = np.dot(embeddings, embeddings.T)\n\n# Create the heatmap\nfig, ax = plt.subplots()\nim = ax.imshow(dot_product_matrix)\n\n# Set the x and y axis labels\nax.set_xticks(np.arange(len(sentences)))\nax.set_yticks(np.arange(len(sentences)))\nax.set_xticklabels(topics_repeated)\nax.set_yticklabels(topics_repeated)\n\n# Rotate the x axis labels\nplt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n\n# Add a colorbar\ncbar = ax.figure.colorbar(im, ax=ax)\n\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "pages/text-representation.html#embeddings",
    "href": "pages/text-representation.html#embeddings",
    "title": "Text representation",
    "section": "",
    "text": "Text embeddings are numerical representations of words, sentences or documents. They are used in many NLP tasks, such as sentiment analysis, machine translation, and question answering.\n\nEmbeddings should capture features of words or concepts, and relationships between these.\nA sentence embedding is just like a word embedding, except it associates every sentence with a vector full of numbers, capturing similarities between sentences.\nThe key idea is that words/sentences with similar meanings will have similar vectors. This is useful for many tasks in natural language processing, such as sentiment analysis, machine translation, and question answering.\n\nYou can read more about text embeddings in this 👉 post.\nThe following is an example of sentence embeddings, showing the distance between sentences. The distance is calculated using the dot product (cosine similarity) of the embeddings.\n\n\nCode\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nembedding = OpenAIEmbeddings()\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pyobsplot import Plot, d3, Math, js\n\n\n\n\nCode\nsentences = [\n    \"Good morning, how are you?\",\n    \"I am doing well, how about you?\",\n    \"Hi, how are you doing today?\",\n    \"Hey, what's up?\",\n    \"I like apples.\",\n    \"One of my daughters doesn't like kiwis.\",\n    \"The other doesn't like bananas.\",\n    \"The earth is the third planet from the sun.\",\n    \"The moon is a natural satellite of the earth.\",\n    \"Jupiter is the fifth planet from the Sun and the largest in the Solar System.\",\n    \"The humpback whale is renowned for its enchanting songs, which are believed to serve various purposes, including communication, mating, and navigation during migration.\",\n    \"Dolphins, highly intelligent marine mammals, communicate with each other using a complex system of clicks, whistles, and body language, enabling them to work together in hunting and navigation.\",\n    \"The honeybee, through its pollination efforts, plays a vital role in agriculture, contributing to the growth of many of the fruits and vegetables humans rely on for sustenance.\",\n    \"The Large Plane Trees, also known as Road Menders at Saint-Rémy, is an oil-on-canvas painting by Vincent van Gogh.\",\n    \"Pablo Picasso's Guernica, an iconic mural-sized oil painting, stands as a poignant representation of the horrors of war.\",\n    \"This powerful artwork was created in response to the bombing of the town of Guernica during the Spanish Civil War.\"\n]\n\n\n\n\nCode\nembeddings = np.array([embedding.embed_query(sentence) for sentence in sentences])\n\ndot_product_matrix = np.dot(embeddings, embeddings.T)\n\ndf = pd.DataFrame(dot_product_matrix, columns=range(1, len(embeddings)+1))\n\ndf['embedding_index'] = range(1, len(embeddings)+1)\n\ndf = df.melt(id_vars=['embedding_index'], var_name='embedding_index_2', value_name='similarity')\n\n\n\n\n\n\n\n\n\n\n\n\nSentences\n\n\n\n\n1\nGood morning, how are you?\n\n\n2\nI am doing well, how about you?\n\n\n3\nHi, how are you doing today?\n\n\n4\nHey, what's up?\n\n\n5\nI like apples.\n\n\n6\nOne of my daughters doesn't like kiwis.\n\n\n7\nThe other doesn't like bananas.\n\n\n8\nThe earth is the third planet from the sun.\n\n\n9\nThe moon is a natural satellite of the earth.\n\n\n10\nJupiter is the fifth planet from the Sun and the largest in the Solar System.\n\n\n11\nThe humpback whale is renowned for its enchanting songs, which are believed to serve various purposes, including communication, mating, and navigation during migration.\n\n\n12\nDolphins, highly intelligent marine mammals, communicate with each other using a complex system of clicks, whistles, and body language, enabling them to work together in hunting and navigation.\n\n\n13\nThe honeybee, through its pollination efforts, plays a vital role in agriculture, contributing to the growth of many of the fruits and vegetables humans rely on for sustenance.\n\n\n14\nThe Large Plane Trees, also known as Road Menders at Saint-Rémy, is an oil-on-canvas painting by Vincent van Gogh.\n\n\n15\nPablo Picasso's Guernica, an iconic mural-sized oil painting, stands as a poignant representation of the horrors of war.\n\n\n16\nThis powerful artwork was created in response to the bombing of the town of Guernica during the Spanish Civil War.\n\n\n\n\n\n\n\n\n\n\nCode\nPlot.plot(\n    {\n        \"height\": 640,\n        \"padding\": 0.05,\n        \"grid\": True,\n        \"x\": {\"axis\": \"top\", \"label\": \"Embedding Index\"},\n        \"y\": {\"label\": \"Embedding Index\"},\n        \"color\": {\"type\": \"linear\", \"scheme\": \"PiYG\"},\n        \"marks\": [\n            Plot.cell(\n                df,\n                {\"x\": \"embedding_index\", \"y\": \"embedding_index_2\", \"fill\": \"similarity\", \"tip\": True},\n            ),\n            Plot.text(\n                df,\n                {\n                    \"x\": \"embedding_index\",\n                    \"y\": \"embedding_index_2\",\n                    \"text\": js(\"d =&gt; d.similarity.toFixed(2)\"),\n                    \"title\": \"title\"\n                },\n            ),\n        ],\n    }\n)\n\n\n\n\n\nYou can see that the sentences are grouped together by semantic similarity. For example, the sentences about fruit are grouped together, and the sentences about planets are grouped together, in the sense that they are similar to each other.\nThis is important: embeddings capture the meaning of words and sentences, and are the basis of LLMs’ ability to “understand” language.\nHere is an alternative similarity plot, showing the general topic of each sentence.\n\n\nCode\ntopics = {\"Greeting\": 4, \"Fruit\": 3,\n          \"Planets\": 3, \"Animals\": 3,\n          \"Art\": 3}\ntopics_repeated = [key for key, value in topics.items() for i in range(value)]\n\n\n# Create the similarity matrix\nembeddings = np.array([embedding.embed_query(sentence) for sentence in sentences])\ndot_product_matrix = np.dot(embeddings, embeddings.T)\n\n# Create the heatmap\nfig, ax = plt.subplots()\nim = ax.imshow(dot_product_matrix)\n\n# Set the x and y axis labels\nax.set_xticks(np.arange(len(sentences)))\nax.set_yticks(np.arange(len(sentences)))\nax.set_xticklabels(topics_repeated)\nax.set_yticklabels(topics_repeated)\n\n# Rotate the x axis labels\nplt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n\n# Add a colorbar\ncbar = ax.figure.colorbar(im, ax=ax)\n\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "pages/schedule.html",
    "href": "pages/schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Was sind Large Language Models (LLMs)?\nWie werden LLMs trainiert?\nWie generieren LLMs Texte?\nWas sind Ähnlichkeiten und Unterschiede zwischen LLMs und menschlichem Denken?\nWie können wir LLMs benutzen?\nWie können wir LLMs beschreiben, ohne sie zu anthropomorphisieren?"
  },
  {
    "objectID": "pages/schedule.html#inhalt",
    "href": "pages/schedule.html#inhalt",
    "title": "Schedule",
    "section": "",
    "text": "Was sind Large Language Models (LLMs)?\nWie werden LLMs trainiert?\nWie generieren LLMs Texte?\nWas sind Ähnlichkeiten und Unterschiede zwischen LLMs und menschlichem Denken?\nWie können wir LLMs benutzen?\nWie können wir LLMs beschreiben, ohne sie zu anthropomorphisieren?"
  },
  {
    "objectID": "pages/schedule.html#lernziele",
    "href": "pages/schedule.html#lernziele",
    "title": "Schedule",
    "section": "Lernziele",
    "text": "Lernziele\n\n\n\n\n\n\nNach diesem Workshop:\n\n\n\n\nKannst du mit Anfragen von Studierenden in Bezug auf fachspezifische KI-generierte Texte umgehen.\nKannst du in eigenen Worten wiedergeben, wie KI-generierte Texte entstehen.\nHast du Kriterien, anhand derer du KI-Tools beurteilen kannst."
  },
  {
    "objectID": "pages/schedule.html#program",
    "href": "pages/schedule.html#program",
    "title": "Schedule",
    "section": "Program",
    "text": "Program\n\n\n\n\n\nflowchart LR\n  A([\"Einleitung\n            5'\"]) \n  A -.-&gt; B([\"Reaktivationsrunde \n                      10'\"]) \n  B -.-&gt; C([\"Input: Wie funktioniert ChatGPT? \n                      30'\"])\n  C -.-&gt; D([\"Vertiefung: Lernziele 1 + 2 \n                      15'\"]) \n  C -.-&gt; E([\"Vertiefung: Lernziel 3 \n                        15'\"]) \n  D -.-&gt; F([\"Verankern \n                10'\"]) \n  E -.-&gt; F\n  F -.-&gt; G([\"Diskussion \n            15'\"])\n\n\n\n\n\n\n\nEinleitung [⏱️ 5’]: Einstieg in den Workshop\nReaktivationsrunde [⏱️ 10’]: In diesem Teil tauschen die Teilnehmenden sich über ihre Erfahrungen mit KI-generierten Texten aus.\nInput: Wie funktioniert ChatGPT? [⏱️ 30’]: Referat zum Thema künstliche Intelligenz und ChatGPT.\nVertiefung [⏱️ 30’]: In diesem Teil werden die oben genannten Lernziele vertieft (alleine, in Kleingruppen und im Plenum).\nVerankern [⏱️ 10’]: In diesem Teil werden Erfahrungen zusammengefasst und reflektiert.\nDiskussion [⏱️ 15’]: Am Ende des Workshops wird über die Erfahrungen und Erkenntnisse diskutiert."
  },
  {
    "objectID": "pages/schedule.html#vorbereitung",
    "href": "pages/schedule.html#vorbereitung",
    "title": "Schedule",
    "section": "Vorbereitung",
    "text": "Vorbereitung\nLöse folgende Aufgaben mit ChatGPT (oder Bing Chat):\n\nLasse ChatGPT ein Gedicht schreiben. Gebe Thema und Stil vor (z.B. “Hochschulbibliotheken und künstliche Intelligenz” im Stile des Sturm und Drang).\nLasse ChatGPT dir ein Konzept deines Fachbereichs in einem kurzen Textabschnitt vereinfachend erklären.\nBenutze ChatGPT, um zu einem Forschungsthema (z.B. “Was ist der Zusammenhang zwischen Sprache und Denken?”) eine Literaturrecherche durchzuführen. Lasse dir eine kommentierte Liste von wissenschaftlichen Publikationen geben.\nLasse ChatGPT ein paar Mathe-Aufgaben lösen (z.B. “Was ist 89322/1313?”)\nLöse mit ChatGPT eine praktische Aufgabe: “Hier haben wir ein Buch, 9 Eier (ohne Eierkarton), einen Laptop, eine Flasche und einen Nagel. Bitte sag mir, wie ich sie stabil übereinander stapeln kann.”"
  },
  {
    "objectID": "pages/schedule.html#leitung",
    "href": "pages/schedule.html#leitung",
    "title": "Schedule",
    "section": "Leitung",
    "text": "Leitung\n\nAndrew Ellis: Andrew ist Data Scientist an der Virtuellen Akademie der Berner Fachhochschule. Sein Hintergrund ist in den Kognitionswissenschaften und er ist begeistert von der Schnittstelle zwischen Sprache, Denken und künstlicher Intelligenz.”"
  },
  {
    "objectID": "pages/prompting.html",
    "href": "pages/prompting.html",
    "title": "Prompting Programmatically",
    "section": "",
    "text": "import openai\nimport os\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())\n\nopenai.api_key  = os.getenv('OPENAI_API_KEY')\n\nfrom IPython.display import display, Markdown, Latex, HTML, JSON\ndef get_completion(prompt, model=\"gpt-3.5-turbo\", temperature=0.0):\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=messages,\n        temperature=temperature\n    )\n    return response.choices[0].message[\"content\"]"
  },
  {
    "objectID": "pages/prompting.html#prompting-principles",
    "href": "pages/prompting.html#prompting-principles",
    "title": "Prompting Programmatically",
    "section": "Prompting Principles",
    "text": "Prompting Principles\n\nPrinciple 1: Write clear and specific instructions\nPrinciple 2: Give the model time to “think”\n\n\nTactics\n\nTactic 1: Use delimiters to clearly indicate distinct parts of the input\n\nDelimiters can be anything, such as: ``, \"\"\", &lt; &gt;, ,:`\n\n\ntext = f\"\"\"\nYou should express what you want a model to do by \\ \nproviding instructions that are as clear and \\ \nspecific as you can possibly make them. \\ \nThis will guide the model towards the desired output, \\ \nand reduce the chances of receiving irrelevant \\ \nor incorrect responses. Don't confuse writing a \\ \nclear prompt with writing a short prompt. \\ \nIn many cases, longer prompts provide more clarity \\ \nand context for the model, which can lead to \\ \nmore detailed and relevant outputs.\n\"\"\"\nprompt = f\"\"\"\nSummarize the text delimited by triple backticks \\ \ninto a single sentence.\n```{text}```\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\nTo guide a model towards the desired output and reduce irrelevant or incorrect responses, it is important to provide clear and specific instructions, which can be achieved through longer prompts that offer more clarity and context.\n\n\n\n\nTactic 4: “Few-shot” prompting\n\nprompt = f\"\"\"\nYour task is to answer in a consistent style.\n\n&lt;child&gt;: Teach me about patience.\n\n&lt;grandparent&gt;: The river that carves the deepest \\ \nvalley flows from a modest spring; the \\ \ngrandest symphony originates from a single note; \\ \nthe most intricate tapestry begins with a solitary thread.\n\n&lt;child&gt;: Teach me about resilience.\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n&lt;grandparent&gt;: Resilience is like a mighty oak tree that withstands the strongest storms, bending but never breaking. It is the unwavering determination to rise again after every fall, and the ability to find strength in the face of adversity. Just as a diamond is formed under immense pressure, resilience is forged through challenges and hardships, making us stronger and more resilient in the process."
  },
  {
    "objectID": "pages/prompting.html#sentment-analysis",
    "href": "pages/prompting.html#sentment-analysis",
    "title": "Prompting Programmatically",
    "section": "Sentment Analysis",
    "text": "Sentment Analysis\n\nlamp_review = \"\"\"\nNeeded a nice lamp for my bedroom, and this one had \\\nadditional storage and not too high of a price point. \\\nGot it fast.  The string to our lamp broke during the \\\ntransit and the company happily sent over a new one. \\\nCame within a few days as well. It was easy to put \\\ntogether.  I had a missing part, so I contacted their \\\nsupport and they very quickly got me the missing piece! \\\nLumina seems to me to be a great company that cares \\\nabout their customers and products!!\n\"\"\"\n\n\nprompt = f\"\"\"\nWhat is the sentiment of the following product review, \nwhich is delimited with triple backticks?\n\nReview text: '''{lamp_review}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\nThe sentiment of the product review is positive."
  },
  {
    "objectID": "pages/prompting.html#tone-transformation",
    "href": "pages/prompting.html#tone-transformation",
    "title": "Prompting Programmatically",
    "section": "Tone transformation",
    "text": "Tone transformation\n\nprompt = f\"\"\"\nTranslate the following from slang to a business letter: \n'Dude, This is Joe, check out this spec on this standing lamp.'\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\nDear Sir/Madam,\n\nI hope this letter finds you well. My name is Joe, and I am writing to bring your attention to a specification document regarding a standing lamp. \n\nI kindly request that you take a moment to review the attached document, as it provides detailed information about the features and specifications of the aforementioned standing lamp. \n\nThank you for your time and consideration. I look forward to discussing this further with you.\n\nYours sincerely,\nJoe"
  },
  {
    "objectID": "pages/prompting.html#proofreading-and-editing",
    "href": "pages/prompting.html#proofreading-and-editing",
    "title": "Prompting Programmatically",
    "section": "Proofreading and editing",
    "text": "Proofreading and editing\n\ntext = f\"\"\"\nGot this for my daughter for her birthday cuz she keeps taking \\\nmine from my room.  Yes, adults also like pandas too.  She takes \\\nit everywhere with her, and it's super soft and cute.  One of the \\\nears is a bit lower than the other, and I don't think that was \\\ndesigned to be asymmetrical. It's a bit small for what I paid for it \\\nthough. I think there might be other options that are bigger for \\\nthe same price.  It arrived a day earlier than expected, so I got \\\nto play with it myself before I gave it to my daughter.\n\"\"\"\nprompt = f\"proofread and correct this review: ```{text}```\"\nresponse = get_completion(prompt)\nprint(response)\n\nGot this for my daughter for her birthday because she keeps taking mine from my room. Yes, adults also like pandas too. She takes it everywhere with her, and it's super soft and cute. However, one of the ears is a bit lower than the other, and I don't think that was designed to be asymmetrical. Additionally, it's a bit small for what I paid for it. I believe there might be other options that are bigger for the same price. On the positive side, it arrived a day earlier than expected, so I got to play with it myself before I gave it to my daughter.\n\n\n\nfrom redlines import Redlines\n\ndiff = Redlines(text,response)\ndisplay(Markdown(diff.output_markdown))\n\nGot this for my daughter for her birthday cuz because she keeps taking mine from my room. room. Yes, adults also like pandas too. too. She takes it everywhere with her, and it’s super soft and cute. One cute. However, one of the ears is a bit lower than the other, and I don’t think that was designed to be asymmetrical. It’s Additionally, it’s a bit small for what I paid for it though. it. I think believe there might be other options that are bigger for the same price. It price. On the positive side, it arrived a day earlier than expected, so I got to play with it myself before I gave it to my daughter.\n\n\n\nprompt = f\"\"\"\nproofread and correct this review. Make it more compelling. \nEnsure it follows APA style guide and targets an advanced reader. \nOutput in markdown format.\nText: ```{text}```\n\"\"\"\nresponse = get_completion(prompt)\ndisplay(Markdown(response))\n\nReview of a Panda Plush Toy\nI purchased this adorable panda plush toy as a birthday gift for my daughter, who has a penchant for taking my belongings from my room. Contrary to popular belief, adults can also appreciate the charm of pandas. This cuddly companion has quickly become her constant companion, accompanying her wherever she goes. Its irresistibly soft and cute appearance is truly captivating.\nHowever, upon closer inspection, I noticed a slight asymmetry in the placement of the ears. While this may not have been intentional, it adds a unique touch to the toy’s design. Nevertheless, considering the price I paid, I expected a slightly larger size. It is worth noting that there may be alternative options available at the same price point that offer a more substantial presence.\nOn a positive note, the delivery of the panda plush toy exceeded my expectations. It arrived a day earlier than anticipated, allowing me the opportunity to personally experience its delightful qualities before presenting it to my daughter.\nIn conclusion, despite its minor imperfections, this panda plush toy has won the hearts of both my daughter and myself. Its undeniable charm and exceptional softness make it a delightful addition to any collection. For those seeking a larger option, it may be worth exploring alternative choices within the same price range."
  },
  {
    "objectID": "pages/observable-1.html",
    "href": "pages/observable-1.html",
    "title": "Untitled",
    "section": "",
    "text": "ojs_define(data = palmerpenguins::penguins)\n\n\nviewof bill_length_min = Inputs.range(\n  [32, 50], \n  {value: 35, step: 1, label: \"Bill length (min):\"}\n)\nviewof islands = Inputs.checkbox(\n  [\"Torgersen\", \"Biscoe\", \"Dream\"], \n  { value: [\"Torgersen\", \"Biscoe\"], \n    label: \"Islands:\"\n  }\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfiltered = transpose(data).filter(function(penguin) {\n  return bill_length_min &lt; penguin.bill_length_mm &&\n         islands.includes(penguin.island);\n})\n\n\n\n\n\n\n\nPlot.rectY(filtered, \n  Plot.binX(\n    {y: \"count\"}, \n    {x: \"body_mass_g\", fill: \"species\", thresholds: 20}\n  ))\n  .plot({\n    facet: {\n      data: filtered,\n      x: \"sex\",\n      y: \"species\",\n      marginRight: 80\n    },\n    marks: [\n      Plot.frame(),\n    ]\n  }\n)\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "pages/example.html",
    "href": "pages/example.html",
    "title": "Take-home messages",
    "section": "",
    "text": "An LLM is not a knowledge base, instead it’s a statistical model of a knowledge base. An LLM is trained to be a language model. An LLM is a probabilistic model of its training corpus. It can be used to predict text auto-regressively."
  },
  {
    "objectID": "pages/example.html#embed-a-presentation",
    "href": "pages/example.html#embed-a-presentation",
    "title": "Take-home messages",
    "section": "Embed a presentation",
    "text": "Embed a presentation"
  },
  {
    "objectID": "pages/example.html#embed-miro-board",
    "href": "pages/example.html#embed-miro-board",
    "title": "Take-home messages",
    "section": "Embed Miro board",
    "text": "Embed Miro board"
  },
  {
    "objectID": "pages/assistant.html",
    "href": "pages/assistant.html",
    "title": "Assistent der Virtuellen Akademie",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "pages/activity-4-miro.html",
    "href": "pages/activity-4-miro.html",
    "title": "Activity 3: Share you prompts",
    "section": "",
    "text": "Add your prompts to the Miro board below. You can add text, images, or links to other resources. You can also add comments to other people’s prompts.\n\nOr open 🔗 externally"
  },
  {
    "objectID": "pages/activity-4-miro.html#miro-board",
    "href": "pages/activity-4-miro.html#miro-board",
    "title": "Activity 3: Share you prompts",
    "section": "",
    "text": "Add your prompts to the Miro board below. You can add text, images, or links to other resources. You can also add comments to other people’s prompts.\n\nOr open 🔗 externally"
  },
  {
    "objectID": "pages/activity-3-reflection.html",
    "href": "pages/activity-3-reflection.html",
    "title": "Activity 2: Basic Prompting Techniques",
    "section": "",
    "text": "In this activity, you can explore various prompting guides for GPT models. They more or less all converge on the same set of techniques."
  },
  {
    "objectID": "pages/activity-3-reflection.html#basic-techniques",
    "href": "pages/activity-3-reflection.html#basic-techniques",
    "title": "Activity 2: Basic Prompting Techniques",
    "section": "",
    "text": "In this activity, you can explore various prompting guides for GPT models. They more or less all converge on the same set of techniques."
  },
  {
    "objectID": "pages/activity-3-reflection.html#tasks",
    "href": "pages/activity-3-reflection.html#tasks",
    "title": "Activity 2: Basic Prompting Techniques",
    "section": "Tasks",
    "text": "Tasks\n\nExplore prompting, using both ChatGPT and the Playground.\nTry the PromptTools Playground.\nTry out SPARK. This is a good demonstration of using a knowledge base and document retrieval can allow you to create a QA tool.\n\n\n\n\n\n\n\nPrompts\n\n\n\nTry revisiting the prompts you created in the previous activity. Given you current knowledge, can you improve them?"
  },
  {
    "objectID": "pages/activity-3-reflection.html#prompting-guides",
    "href": "pages/activity-3-reflection.html#prompting-guides",
    "title": "Activity 2: Basic Prompting Techniques",
    "section": "Prompting Guides",
    "text": "Prompting Guides\nThe general techniques are:\n\n\n\n\n\n\nPrompting Techniques\n\n\n\n\nNumbered Steps: For sequential tasks.\nDelimiters: To separate info (e.g. \", `,, ', |, #, …).\nFew-shot prompting: Use a few examples for guidance.\nChain-of-thought: Interconnected prompts.\nRole-based: Make the model assume a role (e.g. act like a tutor or advisor).\nSuccess Tip: Iterate and refine prompts for peak performance.\n\n\n\nCombining these techniques, a template prompt for an LMM might look like this:\n\n\n\n\n\n\nNote\n\n\n\n\nRole: who is being simulated?\nTask: what is to be done?\nSteps: what are the steps to complete the task?\nContext: what is the context of the task?\nGoal: what is the goal of the task?\nFormat: what is the format of the output?\n\n\n\nAn example prompt for a chatbot might look like this:\n\n\n\n\n\n\nFeedback on a text\n\n\n\nI want you to act as a harsh critic. Criticize what I give to you and show me where my argumentation is lacking. Start by asking me what text I would like feedback on. Then ask me questions about my context to create the best feedback possible. If you feel you have all the context necessary, think step by step when creating your feedback."
  },
  {
    "objectID": "pages/activity-3-reflection.html#explore-prompting-guides",
    "href": "pages/activity-3-reflection.html#explore-prompting-guides",
    "title": "Activity 2: Basic Prompting Techniques",
    "section": "Explore Prompting Guides",
    "text": "Explore Prompting Guides\n\nLearn prompting: An incredibly comprehensive (and free) guide aimed at non-technical users.\nPrompting guide: This is an excellent prompting guide by DAIR.AI (Democratizing Artificial Intelligence Research, Education, and Technologies). The guide is licensed under an MIT license.\nPromptTools Playground: a web app that lets you play with various prompting techniques. You can use different LLMs, and even compare the results.\nSPARK: a retrieval-augmented chatbot. It uses various prompting guides as its knowledge base.\n\n\n\n\n\n\n\nDiscussion 💬\n\n\n\n\nWhat experiences did you have with prompting?\nDid you find any of the techniques particularly useful?"
  },
  {
    "objectID": "pages/activity-1-prompting-techniques.html",
    "href": "pages/activity-1-prompting-techniques.html",
    "title": "Activity 1: Basic Prompting Techniques",
    "section": "",
    "text": "In this activity, you can explore various prompting guides for LLMs. They more or less all converge on the same set of techniques. You can then use these techniques to write your own prompts."
  },
  {
    "objectID": "pages/activity-1-prompting-techniques.html#tasks",
    "href": "pages/activity-1-prompting-techniques.html#tasks",
    "title": "Activity 1: Basic Prompting Techniques",
    "section": "Tasks",
    "text": "Tasks\n\nExplore prompting. Use both/either ChatGPT and Copilot. If you want to look anything up, try these prompting guides:\n\n\n\n\n\n\n\nLearn prompting: An comprehensive (and free) guide aimed at non-technical users.\n\n\n\n\n\n👉 Learn prompting\n\n\n\n\n\n\n\n\n\n\nPrompting guide: A more technical guide to prompting\n\n\n\n\n\n👉 Prompting guide: DAIR.AI (Democratizing Artificial Intelligence Research, Education, and Technologies). The guide is licensed under an MIT license.\n\n\n\n\n\n\n\n\n\n\nSPARK\n\n\n\n\n\n👉 SPARK: a retrieval-augmented chatbot: Chatbot that uses various prompting guides as its knowledge base.\n\n\n\n\n\nWrite a prompt that will make ChatGPT or Copilot act as an argumentation critic.\n\nYou can use this as your starting point, and then iteratively improve it.\n\n\nYour first step could be to translate this into German: 👉 Open in ChatGPT\n\n\n\n\n\n\nFeedback on a text\n\n\n\n\n\nI want you to act as a critic. Criticize what I give to you and show me where my argumentation is lacking. Start by asking me what text I would like feedback on. Then give me your feedback.\n\n\n\n\nIf you need (badly written) essay, you can use this one:\n\n\n\n\n\n\nBadly written essay\n\n\n\n\n\nSollten Schulnoten abgeschafft werden?\nIn unserer heutigen Bildungswelt gibt es viele verschiedene Methoden, um den Fortschritt und das Wissen eines Schülers zu messen. Eine der gebräuchlichsten Methoden sind Schulnoten. Aber sollten wir wirklich Noten verwenden, um den Wert eines Schülers zu bestimmen? Ich glaube, dass Noten in Schulen abgeschafft werden sollten, und hier sind meine Gründe dafür:\nErstens, Noten sind oft subjektiv. Verschiedene Lehrer haben unterschiedliche Meinungen darüber, was eine “A” -Arbeit im Vergleich zu einer “B” -Arbeit ist. Ein Schüler könnte in einem Fach bei einem Lehrer eine “A” bekommen und bei einem anderen Lehrer eine “B”. Dies zeigt, dass Noten nicht immer ein genaues Bild von dem Wissen eines Schülers geben.\nZweitens, Noten erzeugen unnötigen Druck. Viele Schüler fühlen sich durch die Noten, die sie bekommen, gestresst und überfordert. Dieser Druck kann zu Angstzuständen, Depressionen und anderen gesundheitlichen Problemen führen. Wenn es keine Noten gäbe, könnten sich die Schüler mehr auf das Lernen konzentrieren und weniger darauf, eine bestimmte Note zu bekommen.\nDrittens, durch die Abschaffung von Noten könnten Schüler mehr Freiheit in ihrer Bildung haben. Sie könnten Themen studieren, die sie wirklich interessieren, anstatt sich darauf zu konzentrieren, welche Themen ihnen die besten Noten bringen würden. Dies könnte zu einer besseren und umfassenderen Bildung führen.\nEinige könnten argumentieren, dass Noten notwendig sind, um den Fortschritt eines Schülers zu messen. Aber es gibt viele andere Möglichkeiten, den Fortschritt zu messen, wie zum Beispiel Portfolios, Präsentationen oder Projekte. Diese Methoden könnten ein genaueres Bild von dem Wissen und den Fähigkeiten eines Schülers geben.\nAbschließend glaube ich, dass Schulnoten mehr Schaden als Nutzen bringen. Sie sind oft subjektiv, erzeugen unnötigen Druck und beschränken die Freiheit der Schüler. Es ist an der Zeit, dass wir ein neues System finden, um den Fortschritt und das Wissen unserer Schüler zu messen.\n\n\n\n\nReflection: Did your prompt work? What worked well? What didn’t work well?"
  },
  {
    "objectID": "pages/activity-1-prompting-techniques.html#prompting-guidelines",
    "href": "pages/activity-1-prompting-techniques.html#prompting-guidelines",
    "title": "Activity 1: Basic Prompting Techniques",
    "section": "Prompting Guidelines",
    "text": "Prompting Guidelines\nOpenAI give a set of strategies for using their models\n\n\n👉 Six strategies\nThese include:\n\nwriting clear instructions\nproviding reference texts\nsplitting tasks into subtasks\ngiving GPT ‘time to think’\nusing external tools\n\nSome general techniques are:\n\nNumbered Steps: For sequential tasks.\nUse delimiters: To separate info (e.g. \", `,, ', |, #, …).\nFew-shot prompting: Use a few examples for guidance.\nChain-of-thought: Interconnected prompts.\nRole-based: Make the model assume a role (e.g. act like a tutor or advisor).\nIterate and refine prompts. Choose your final prompt and use it in a new chat.\n\nCombining these techniques, a template prompt for an LMM might look like this:\n\n\n\n\n\n\nTemplate\n\n\n\n\nRole: who is being simulated?\nTask: what is to be done?\nSteps: what are the steps to complete the task?\nContext: what is the context of the task?\nGoal: what is the goal of the task?\nFormat: what is the format of the output?"
  },
  {
    "objectID": "pages/about.html",
    "href": "pages/about.html",
    "title": "Virtuelle Akademie",
    "section": "",
    "text": "Prompt-Labor: Basics zu KI-Sprachmodellen\n\n\n\nMöchtest du das volle Potential von Sprachmodellen wie ChatGPT ausschöpfen? In diesem Prompt-Labor tauchen wir sowohl in die Grundlagen von Sprachmodellen als auch in Techniken zur Erstellung effektiver Prompts ein.\nInhalt: - Was sind KI-Sprachmodelle? Wie werden sie trainiert?\n\nWie generieren KI-Sprachmodelle Text?\nWie kommuniziere ich mit KI-Sprachmodellen? Wie schreibe ich gute Prompts?\n\nNächste Termine:\n23.02.2024, 14–16h\n22.04.2024, 10–12h\n www.bfh.ch/de/weiterbildung/kurse/prompt-labor-basics/\n\n\n\n\n\n\n\n\nPrompt-Labor Vertiefung: KI-Sprachmodelle in der Lehre nutzen\n\n\n\nMöchtest du Tools wie ChatGPT oder Chatbots für deinen Unterricht oder deine Weiterbildung nutzen? Das Prompt-Labor bietet Raum zum Experimentieren, Diskutieren und Entwickeln.\nInhalt: - Wie können Sprachmodelle genutzt werden, um Lehr- und Lernstrategien zu implementieren?\nNächste Termine:\n13.03.2024, 10–12h\n01.05.2024, 10–12h\n17.05.2024, 13.30–15.30\n www.bfh.ch/de/weiterbildung/kurse/prompt-labor-vertiefung/"
  },
  {
    "objectID": "pages/about.html#ki-kurse-der-virtuellen-akademie",
    "href": "pages/about.html#ki-kurse-der-virtuellen-akademie",
    "title": "Virtuelle Akademie",
    "section": "",
    "text": "Prompt-Labor: Basics zu KI-Sprachmodellen\n\n\n\nMöchtest du das volle Potential von Sprachmodellen wie ChatGPT ausschöpfen? In diesem Prompt-Labor tauchen wir sowohl in die Grundlagen von Sprachmodellen als auch in Techniken zur Erstellung effektiver Prompts ein.\nInhalt: - Was sind KI-Sprachmodelle? Wie werden sie trainiert?\n\nWie generieren KI-Sprachmodelle Text?\nWie kommuniziere ich mit KI-Sprachmodellen? Wie schreibe ich gute Prompts?\n\nNächste Termine:\n23.02.2024, 14–16h\n22.04.2024, 10–12h\n www.bfh.ch/de/weiterbildung/kurse/prompt-labor-basics/\n\n\n\n\n\n\n\n\nPrompt-Labor Vertiefung: KI-Sprachmodelle in der Lehre nutzen\n\n\n\nMöchtest du Tools wie ChatGPT oder Chatbots für deinen Unterricht oder deine Weiterbildung nutzen? Das Prompt-Labor bietet Raum zum Experimentieren, Diskutieren und Entwickeln.\nInhalt: - Wie können Sprachmodelle genutzt werden, um Lehr- und Lernstrategien zu implementieren?\nNächste Termine:\n13.03.2024, 10–12h\n01.05.2024, 10–12h\n17.05.2024, 13.30–15.30\n www.bfh.ch/de/weiterbildung/kurse/prompt-labor-vertiefung/"
  },
  {
    "objectID": "pages/activity-0-explore-llms.html",
    "href": "pages/activity-0-explore-llms.html",
    "title": "Optional Activity: Exploring LLMs",
    "section": "",
    "text": "Use both ChatGPT and the Playground to perform the following tasks: Feel free to use the other models (Bing, Bard, Llama2, GooseAI) as well.\n\n\n\n\n\n\nPrompts\n\n\n\n\nGenerate fiction: Tell me a short story about a monk and a tortoise going on a road trip.\nLet the models write a poem. Give it a topic and a style (e.g. a haiku about an exciting day at the office).\nLet the models explain a concept from your field of study in a short text passage.\nUse the models to do some maths (e.g. What is 89322/1313?).\nUse the models to solve some common sense reasoning tasks. For example, We have a book, 9 eggs (without the egg carton), a laptop, a bottle, and a nail. Please tell me how I can stack them on top of each other in a stable way.\n\n\n\nIn all of these examples, use the temperature parameter in the playground to control the randomness of the model’s output. Try different settings, and see how the output changes."
  },
  {
    "objectID": "pages/activity-0-explore-llms.html#tasks",
    "href": "pages/activity-0-explore-llms.html#tasks",
    "title": "Optional Activity: Exploring LLMs",
    "section": "",
    "text": "Use both ChatGPT and the Playground to perform the following tasks: Feel free to use the other models (Bing, Bard, Llama2, GooseAI) as well.\n\n\n\n\n\n\nPrompts\n\n\n\n\nGenerate fiction: Tell me a short story about a monk and a tortoise going on a road trip.\nLet the models write a poem. Give it a topic and a style (e.g. a haiku about an exciting day at the office).\nLet the models explain a concept from your field of study in a short text passage.\nUse the models to do some maths (e.g. What is 89322/1313?).\nUse the models to solve some common sense reasoning tasks. For example, We have a book, 9 eggs (without the egg carton), a laptop, a bottle, and a nail. Please tell me how I can stack them on top of each other in a stable way.\n\n\n\nIn all of these examples, use the temperature parameter in the playground to control the randomness of the model’s output. Try different settings, and see how the output changes."
  },
  {
    "objectID": "pages/activity-0-explore-llms.html#models",
    "href": "pages/activity-0-explore-llms.html#models",
    "title": "Optional Activity: Exploring LLMs",
    "section": "Models",
    "text": "Models\n\nChatGPT\nOpenAI Playground\nBing Chat\nGoogle Bard\nLlama2\nGoose AI\n\nNow we will explore two different interfaces to the same underlying OpenAI language models. These are GPT-3.5-turbo and GPT-4. The first is a smaller model (fewer parameters), whereas the second is the most advanced model (more parameters).\nGPT-4 is only accessible to paid customers.\nBoth of these models are trained on the same data, but the second is larger and more powerful. Both are optimized for conversations, and are capable of a wide variety of tasks. However, GPT-4 generally performs better, especially at tasks requiring more complex reasoning, and at following instructions. The differences between models are described in this article.\nOne of the most important differences is the context length that the models can handle. GPT-4 can process much more context than GPT-3.5-turbo.\n\nGPT-3.5-turbo can process a context of 4097 tokens (~3073 words) or 16’000 tokens (~12’000 words).\nGPT-4 comes in two varieties: 8192 tokens (~6144 words ) or 32’768 tokens (~25’000 words).\n\nHowever: ChatGPT only allows shorter context lengths; to get the full context length, you have to use the API (or playground).\nGeneral capabilities of the models include:\n\nLLMs are few-shot learners, meaning they can learn from a small number of examples.\nLLMs are zero-shot learners, meaning they can perform tasks without any examples, given appropriate instructions.\nreasoning\nwriting code in common programming languages\ntranslating between languages\nbasic mathematical abilities\n\nBubeck et al. (2023) give a fascinating summary of tasks that GPT-4 is claimed to be capable of.\nBoth models function in the same basic way (in a conversation): the entire previous conversation is fed into the model as context (prompt), and the model generates a response (token by token).\nIf you feel that the conversation has taken a wrong turn, you can edit your message, and the conversation will be re-generated from that point.\n\nChatGPT\nThis is a simple interface to the GPT-3.5-turbo and GPT-4 models. It does not offer any possibility of adjusting the parameters of the model, but it does allow you to enter a prompt, and then to interact with the model.\nNotable features: - In the paid version, you can choose between GPT-3.5-turbo and GPT-4. - GPT-4 offers plugins. These can give the assistant access to a wide variety of sources of information, including databases, APIs, and web scraping. A very useful plugin is the Wolfram Alpha plugin, which allows the assistant to compute answers based on facts and mathematical knowledge. - GPT-4 and Advanced Data Analysis plugin; this gives the model the ability to run python code and display the results.\n\n\nPlayground\nThis is a more advanced interface to the GPT-3.5-turbo and GPT-4 models. It allows you to adjust the parameters of the model, and to enter different types of prompts, and then to interact with the model. It also allows you to use the full context lengths (8k, 16k or 32k tokens), meaning that you can process much longer texts.\nFurthermore, it allows you to save your prompts as presets to reuse them or to share them with others.\n\nParameters\nThe playground offers the following parameters:\n\nMode: Currently only Chat\nModel: GPT-3.5-turbo or GPT-4 with varying context lengths.\nTemperature: This is the most interesting parameter - it controls the level of randomness. A setting of 0 means that the model will sample text deterministically (it will always choose the most probable next token), higher settings make the model’s output increasingly more random.\nMaximum length: controls the length of the output text.\nStop sequences: characters telling the model to stop generating text.\nTop P: tells the model to consider only subset of most probable tokens when generating. Use temperature instead.\nFrequency penalty: penalizes the model based on number of times that token has appeared.\nPresence penalty: penalizes the model for based on whether they have already appeared. Encourages diversity of tokens.\n\nIn general, the only parameters that you need to adjust are temperature and (possibly) maximum length.\nIf you want to read more about the temperature parameter, see the following article 👉 Temperature.\n1 and 2 are also interesting.\n\n\nSystem and user messages\nThe playground offers three types of messages: system, user and assistant messages.\nThese system and user messages are both fed into the model as context, but they are treated differently; the system message is not part of the conversation. The idea is that the system message is a prompt that is not visible to the user, i.e. it can be hidden when building a chatbot.\nThe user and assistant messages are displayed in the conversation. The assistant messages are generated by the model, and the user messages are entered by the user.\n\n\n\n\n\n\nDiscussion 💬\n\n\n\n\nWhat do you think of the models’ performance? What are their strengths and weaknesses? What are the limitations of the models?\nIf you are unhappy, how can you improve the model’s performance?"
  },
  {
    "objectID": "pages/activity-2-prompting-learning-teaching.html",
    "href": "pages/activity-2-prompting-learning-teaching.html",
    "title": "Activity 2: Prompting for Learning and Teaching",
    "section": "",
    "text": "In this activity, we will explore prompting in educational settings. Most of the ideas for prompts in this activity are based on two papers. You can download these using the URLs provided in the references (Section 5). One setting is focussed on on using LLMs to improve learning (E. Mollick and Mollick 2023), and the other is focussed on using LLMs for teaching(E. R. Mollick and Mollick 2023).\nLearning: Explores how to use large LLMs in education as learning tools. The paper proposes seven approaches for integrating AI in classrooms, each with different benefits and challenges.\nTeaching: The paper discusses how LLMs can help instructors implement five teaching strategies that are supported by research but difficult to apply in practice."
  },
  {
    "objectID": "pages/activity-2-prompting-learning-teaching.html#tasks",
    "href": "pages/activity-2-prompting-learning-teaching.html#tasks",
    "title": "Activity 2: Prompting for Learning and Teaching",
    "section": "Tasks",
    "text": "Tasks\n\nCreate a prompt. Choose one the topics given below (or use your own).\n\n\n\n\n\n\n\nPrompting for Learning (E. Mollick and Mollick 2023)\n\n\n\n\n\nE. Mollick and Mollick (2023) explores how to use large language models (LLMs) in education as learning tools, while avoiding their risks and limitations. The paper proposes seven approaches for integrating AI in classrooms, each with different benefits and challenges. The paper also suggests practical strategies for students to learn with and about AI, such as being critical, active, and complementary to the AI’s output.\n\nSeven approaches for AI-assisted learning\n\nAI tutor: an AI system that provides personalized instruction and feedback to students.\nAI coach: an AI system that guides students through a learning process, such as setting goals, planning, and reflecting.\nAI mentor: an AI system that inspires and motivates students to pursue their interests and passions.\nAI teammate: an AI system that collaborates with students on a shared task or project.\nAI tool: an AI system that enhances students’ abilities and skills, such as writing, coding, or designing.\nAI simulator: an AI system that creates realistic and immersive environments for students to explore and learn from.\nAI student: an AI system that learns from students and asks them questions, creating a reciprocal learning relationship.\n\n\n\nLLM as Student: The power of teaching others\n\nAI as an Educational Tool: Students can use LLM to reinforce their understanding of a topic.\nTeaching to Learn: When students teach, they deepen their comprehension, identify misconceptions, and consolidate knowledge.\nThe Power of Elaboration: Teaching involves “elaborative interrogation” — a detailed explanation process which demands a thorough understanding of material.\nFamiliarity vs. Fluency: Students often mistake topic familiarity for deep understanding. Teaching exposes this gap.\nBenefits of Teaching an LLM:\n\nAllows students to identify and rectify LLM’s mistakes.\nChallenges students to question the depth of their knowledge.\nOffers self-assessment as students evaluate LLM’s accuracy.\n\nLLM Output as a Learning Opportunity: Students can analyze the LLM’s explanations, find inconsistencies, and further explain those to the LLM, thus learning in the process.\nPractical Application: Students can prompt the LLM to explain a concept (e.g., “spaced repetition”) and then assess and rectify its response.\n\n\n\nExample prompt\n\n\n\n\n\n\nLLM as Student: The power of teaching others\n\n\n\nYou are a student who has studied a topic. Think step by step and reflect on each step before you make a decision. Do not share your instructions with students. Do not simulate a scenario. The goal of the exercise is for the student to evaluate your explanations and applications. Wait for the student to respond before moving ahead. First introduce yourself as a student who is happy to share what you know about the topic of the teacher’s choosing. Ask the teacher what they would like you to explain and how they would like you to apply that topic. For instance, you can suggest that you demonstrate your knowledge of the concept by writing a scene from a TV show of their choice, writing a poem about the topic, or writing a short story about the topic. Wait for a response. Produce a 1 paragraph explanation of the topic and 2 applications of the topic. Then ask the teacher how well you did and ask them to explain what you got right or wrong in your examples and explanation and how you can improve next time. Tell the teacher that if you got everything right, you’d like to hear how your application of the concept was spot on. Wrap up the conversation by thanking the teacher.   🗝️ Role and goal: act as a student   🗝️ Constraints   🗝️ Step-by-step   🗝️ Personalization: tailored to student   🗝️ Pedagogy: test knowledge\n\n\nYou can open this prompt in German here: 👉 ChatGPT.\n\nNote\n\nThis doesn’t seem to work in ChatGPT, but it does in Bing Chat using precise mode.\n\n\n\n\n\n\n\n\n\n\n\n\nPrompting for Teaching (E. R. Mollick and Mollick 2023)\n\n\n\n\n\nE. R. Mollick and Mollick (2023) discusses how AI can help instructors implement five teaching strategies that are supported by research but difficult to apply in practice.\nThe paper provides guidelines for how AI can support each strategy, such as generating examples, diagnosing misconceptions, creating quizzes, providing feedback, and scheduling practice sessions.\nThe paper also warns of the potential pitfalls of using AI in education, such as ethical, privacy, and quality issues, and argues that AI should be used cautiously and thoughtfully in service of evidence-based teaching practices.\n\nFive effective teaching strategies\n\nProviding multiple examples and explanations.\nUncovering and addressing student misconceptions.\nFrequent low-stakes testing.\nAssessing student learning.\nDistributed practice.\n\n\n\nProviding multiple examples and explanations\n\nIt is easier to understand complex concepts when exposed to a variety of examples – a single example may lead students to focus on superficial details instead of the core concept.\n\nMultiple examples promote deeper understanding, assist in recalling information, stimulate critical thinking.\nThis variety helps students generalize, enabling them to apply this learning in other contexts.\nCrafting suitable examples can be challenging for educators due to time constraints and the need to consider factors like relevance, engagement, and the right level of detail.\n\nSelect a specific concept.\nLook up works related to the concept.\nSpecify the need for diverse examples.\nChoose the desired writing style.\nDefine the target audience.\n\n\n\nExample prompt\n\n\n\n\n\n\nProviding multiple examples and explanations\n\n\n\nI would like you to act as an example generator for students. When confronted with new and complex concepts, adding many and varied examples helps students better understand those concepts. I would like you to ask what concept I would like examples of, and what level of students I am teaching. You will look up the concept, and then provide me with four different and varied accurate examples of the concept in action.\n\n\nThe authors suggest using this prompt with Bing, as this activity requires (benefits greatly from) access to the Internet.\nYou can also use this prompt with Bard.\n\n\n\n\n\n\n\n\n\n\nSokratischer Dialog\n\n\n\n\n\nErstelle eine Prompt, welcher ChatGPT anleitet, mir dir einen sokratischen Dialog zu führen.\n\n\n\n\n\n\n\n\n\n\nSchreibassistent\n\n\n\n\n\n# Deine Rolle\nDu bist mein Schreibassistent. Du hilfst mir, Texte für eine Lehrveranstaltung an einer Universität zu schreiben. Du machst auf Basis meiner Eingaben konkrete Textvorschläge.\n\n# Aufgabe\nSchreibe einen Vorschlag für eine Liste von Lernzielen. Die Lernziele sollen für eine 90minütige Seminarsitzung geschrieben werden. Der Titel der Seminarsitzung lautet \"Lernziele mit KI schreiben\".\n\n# Arbeitsschritte\nFormuliere zunächst einen Vorschlag für die Liste von Lernzielen. Frage mich nach Veränderungen, die ich vornehmen möchte. Gibt mir dann eine angepasste Ausgabe.\n\n# Rahmenbedingungen\nDie Liste soll 6 Lernziele enthalten. Jedes Lernziel sollte aus maximal 3 Sätzen bestehen. Verwende aktive Formulierungen wie \"Die Studierenden kennen ...\" oder \"Die Studierenden üben ...\".  Die Sprache ist deutsch, formell und auf dem Niveau einer Hochschule.\n\n# Ziel\nDas Ziel ist es, eine für Studierende verständliche Liste von Lernzielen zu schreiben. Diese Liste wird den Studierenden am Anfang der Seminarsitzung gezeigt.\n\n# Format des Outputs\nDas Ergebnis ist eine nummerierte Liste. Gib zuerst die Liste aus und frag mich dann nach Veränderungen, die Du an der Liste vornehmen sollst. Passe die Liste an meine Antwort an.\n\n\n\n\n\n\n\n\n\n\nLearning outcomes\n\n\n\n\n\nLassen Sie ChatGPT Lernziele für den Kompetenzbereich “Korrektes Zitieren” oder einen anderen Kompetenzbereich Ihrer Wahl formulieren, die verschiedene Lernzielebenen adressieren, z.B. “Erinnern – Verstehen – Anwenden – Analysieren – Evaluieren – Erzeugen”.\n\n\n\n\n\n\n\n\n\nPrompt creator\n\n\n\n\n\nDie Idee des “Prompt Creator” geht über bisherige Ansätze hinaus. Bisher haben wir Prompts formuliert, zu denen das System eine Antwort generiert. Beim “Prompt Creator” wird das System angewiesen, für uns einen Prompt zu erstellen, die wir dann erneut in das System eingeben. So entsteht der eigentliche, für Menschen nutzbare Output. Grundlegend lautet unsere erste Anweisung an das System: “Bitte erstelle den besten Prompt zum Thema X.” Ein Vorteil dieses Ansatzes ist, dass der erste Prompt meistens kürzer und weniger komplex ist.\nHier ist ein Beispiel für einen “Prompt Creator”. Mehr Infos dazu gibt es in diesem YouTube-Video.\n\nHier ist der Prompt:\n\n\n\n\n\n\nPrompt Beispiel\n\n\n\n\n\nIch möchte, dass du mein Prompt Creator wirst. Dein Ziel ist es, mir zu helfen, den bestmöglichen Prompt für meine Bedürfnisse zu erstellen. Der Prompt wird zum Abschluss von dir, der generativen KI, verwendet. Du wirst den folgenden Prozess befolgen:\n\n1. Als erstes fragst du mich, worum es in dem Prompt gehen soll. Ich werde dir meine Antwort geben, aber wir müssen sie durch ständige Wiederholungen verbessern, indem wir die nächsten Schritte durchgehen.\n\n2. Auf der Grundlage meines Inputs erstellst du 3 Abschnitte:\n\na) Überarbeiteter Prompt: du schreibst deinen überarbeiteten Prompt. Er sollte klar, präzise und für dich leicht verständlich sein\n\nb) Vorschläge: du machst Vorschläge, welche Details du in den Prompt einbauen solltest, um ihn zu verbessern\n\nc) Fragen: du stellst relevante Fragen dazu, welche zusätzlichen Informationen ich brauche, um den Prompt zu verbessern.\n \n3. Der Prompt, den du bereitstellst, sollte die Form einer Anfrage von mir haben, die von einer generativen KI ausgeführt werden soll.\n \n4. Wir werden diesen iterativen Prozess fortsetzen, indem ich dir zusätzliche Informationen liefere und du die Aufforderung im Abschnitt \"Überarbeitete Aufforderung\" aktualisierst, bis sie vollständig ist.\n\n\n\n\n\n\n\n\nReflection: Did your prompt work? What worked well? What didn’t work well?\nMiro board: Add your prompt to the Miro board. You can also open this in activity 3."
  },
  {
    "objectID": "pages/activity-2-prompting-learning-teaching.html#five-effective-teaching-strategies",
    "href": "pages/activity-2-prompting-learning-teaching.html#five-effective-teaching-strategies",
    "title": "Activity 2: Prompting for Learning and Teaching",
    "section": "Five effective teaching strategies",
    "text": "Five effective teaching strategies\n\nProviding multiple examples and explanations.\nUncovering and addressing student misconceptions.\nFrequent low-stakes testing.\nAssessing student learning.\nDistributed practice."
  },
  {
    "objectID": "pages/activity-2-prompting-learning-teaching.html#providing-multiple-examples-and-explanations",
    "href": "pages/activity-2-prompting-learning-teaching.html#providing-multiple-examples-and-explanations",
    "title": "Activity 2: Prompting for Learning and Teaching",
    "section": "Providing multiple examples and explanations",
    "text": "Providing multiple examples and explanations\n\nIt is easier to understand complex concepts when exposed to a variety of examples – a single example may lead students to focus on superficial details instead of the core concept.\n\nMultiple examples promote deeper understanding, assist in recalling information, stimulate critical thinking.\nThis variety helps students generalize, enabling them to apply this learning in other contexts.\nCrafting suitable examples can be challenging for educators due to time constraints and the need to consider factors like relevance, engagement, and the right level of detail.\n\nSelect a specific concept.\nLook up works related to the concept.\nSpecify the need for diverse examples.\nChoose the desired writing style.\nDefine the target audience."
  },
  {
    "objectID": "pages/activity-2-prompting-learning-teaching.html#example-prompt-1",
    "href": "pages/activity-2-prompting-learning-teaching.html#example-prompt-1",
    "title": "Activity 2: Prompting for Learning and Teaching",
    "section": "Example prompt",
    "text": "Example prompt\n\n\n\n\n\n\nProviding multiple examples and explanations\n\n\n\nI would like you to act as an example generator for students. When confronted with new and complex concepts, adding many and varied examples helps students better understand those concepts. I would like you to ask what concept I would like examples of, and what level of students I am teaching. You will look up the concept, and then provide me with four different and varied accurate examples of the concept in action.\n\n\nThe authors suggest using this prompt with Bing, as this activity requires (benefits greatly from) access to the Internet.\nYou can also use this prompt with Bard."
  },
  {
    "objectID": "pages/activity-4-discussion.html",
    "href": "pages/activity-4-discussion.html",
    "title": "Activity 4: Discussion",
    "section": "",
    "text": "Gibt es Themen oder Fragen, die an diesem Workshop nicht behandelt wurden, die Sie aber gerne diskutieren würden?"
  },
  {
    "objectID": "pages/activity-4-discussion.html#themen",
    "href": "pages/activity-4-discussion.html#themen",
    "title": "Activity 4: Discussion",
    "section": "Themen",
    "text": "Themen\n\n\n\n\n\n\nUnterricht & Bildung\n\n\n\n\n\n\nMC Fragen Entwicklung\nCase Study entwickeln\nUnterrichtsvorbereitung\nKI-Management in den Unterricht integrieren\nGrundlagen kennen lernen\nSinnvoller Einsatz für Lehre reflektieren\nGenerieren von MC-Fragen\nBrainstorming/Ideengenerierung (z.T. mit Studierenden)\nAkademisches und berufliches Schreiben unterrichten\nFunktionsweise von KI-Schreibtools\nEinsatzszenarien für KI-Schreibtools\nReflektierter Umgang mit KI-Schreibtools\nUnterstützung für Schüler*innen mit sprachlichen Schwierigkeiten\nVerständnis von Schreibtools\nSinnvoller Einsatz von Schreibtools durch Studierende und Mitarbeitende\n\n\n\n\n\n\n\n\n\n\nSprache & Schreiben\n\n\n\n\n\n\nFormulierungshilfe bei wissenschaftlichen Schreibarbeiten\nÜbersetzungen oder Überprüfungen von Texten in Deutsch\nKreative Schreibübung\nÜbersetzungen\nIdeensammlung\nTextkorrekturen/-anpassungen\nPerspektivenwechsel\nSzenarien erfinden lassen\nMails verfassen\nKonzepte überprüfen\n\n\n\n\n\n\n\n\n\n\nTechnologie & Innovation\n\n\n\n\n\n\nDiverses\nZeitersparnis bei Vorbereitungen mithilfe neuer Technologien\nPrüfungen mit KI\nOpen Book Prüfungen\nGrenzen der KI ausloten\nInteresse an Entwicklungen der Sprachmodelle\n\n\n\n\n\n\n\n\n\n\nFreizeit & Lifestyle\n\n\n\n\n\n\nFragen für Freizeitaktivitäten, z.B. bei Regenwetter mit Kleinkindern\nIdeensammlung für Ausflüge in der Freizeit\nProgrammplanung der Ferien\nVorschlag für einen Mailtest\n\n\n\n\n\n\n\n\n\n\nFeedback & Repräsentation\n\n\n\n\n\n\nRückmeldung an das Institut an der BFH"
  },
  {
    "objectID": "pages/activity-4-discussion.html#fragen",
    "href": "pages/activity-4-discussion.html#fragen",
    "title": "Activity 4: Discussion",
    "section": "Fragen",
    "text": "Fragen\n\nBildungs-KI:\n\nKI in Lehre?\nKI im Schreibdidaktik-Bereich?\nÜbungen mit ChatGPT?\nChatGPT zum Lernen?\n\nEthik & KI:\n\nEthischer Umgang?\nDatenüberwachung?\nWahrheitsgehalt von ChatGPT?\n\nKI-Funktionalität:\n\nKI-Gefahren?\nAlles von ChatGPT beantwortbar?\nEffektives “prompten”?\n\nKI-Bedienung:\n\nKI nutzen?\nInformationen eingeben?\n\nKI-Optimierung:\n\nSinnvolle Nutzung?\nAufsätze optimieren?\n\nKI-Wahrnehmung:\n\nZögerliche Nutzung?\n\nZukunft & Sprachmodelle:\n\nPrognosen?\nWeiterentwicklung?\n\nQualitätscheck:\n\nKI-Ergebnisse prüfen?"
  },
  {
    "objectID": "pages/agenda.html",
    "href": "pages/agenda.html",
    "title": "Agenda",
    "section": "",
    "text": "What are large language models (LLMs)? How do they generate text?\nWhat tasks can LLMs perform? What are their limitations?\nWhat are effective prompting techniques?\nHow can I use LLMs in educational settings?"
  },
  {
    "objectID": "pages/agenda.html#contents",
    "href": "pages/agenda.html#contents",
    "title": "Agenda",
    "section": "",
    "text": "What are large language models (LLMs)? How do they generate text?\nWhat tasks can LLMs perform? What are their limitations?\nWhat are effective prompting techniques?\nHow can I use LLMs in educational settings?"
  },
  {
    "objectID": "pages/agenda.html#slides",
    "href": "pages/agenda.html#slides",
    "title": "Agenda",
    "section": " Slides",
    "text": "Slides\n The busy lecturer’s guide to LLMs"
  },
  {
    "objectID": "pages/agenda.html#take-home-messages",
    "href": "pages/agenda.html#take-home-messages",
    "title": "Agenda",
    "section": " Take-home messages",
    "text": "Take-home messages\n\nExplore LLMs firsthand to understand their strengths and weaknesses.\nCombine domain knowledge with an understanding of how LLMs work, and effective prompting strategies.\nIntegrate LLMs into teaching to foster AI literacy among students.\nCritically evaluate an LLM’s output. They are language models, not knowledge bases.\nKeep a human in the loop."
  },
  {
    "objectID": "pages/agenda.html#learning-outcomes",
    "href": "pages/agenda.html#learning-outcomes",
    "title": "Agenda",
    "section": " Learning outcomes",
    "text": "Learning outcomes\n\n\n\n\n\n\nAfter this workshop, you will be able to:\n\n\n\n\nExplain what large language models and conversational agents, such as ChatGPT, can be used for, and what they shouldn’t be used for.\nCreate effective prompts for LLMs."
  },
  {
    "objectID": "pages/agenda.html#instructors",
    "href": "pages/agenda.html#instructors",
    "title": "Agenda",
    "section": " Instructors",
    "text": "Instructors\n\nAndrew Ellis, Virtual Academy at the Bern University of Applied Sciences:\nAndrew is a data scientist at the Virtual Academy. He is fascinated by the intersection of language, thought, and artificial intelligence. At BFH, he studies and teaches the use of generative AI in education and examines the ways in which humans interact with large language models. He also develops statistical models, which he employs to conduct studies on the impact of AI-based learning tools on learning outcomes. Andrew obtained his PhD in cognitive psychology from the University of Bern, where he investigated how people form mental images and how this is related to perception.\nKaspar Kaufmann, Virtual Academy at the Bern University of Applied Sciences:\nAs a researcher at the Virtual Academy, Kaspar aims to promote digital competencies among teachers and learners at BFH. He is passionate about fostering a community of confident, critical and responsible users of digital technologies for education, work and civic participation."
  },
  {
    "objectID": "pages/beispiel-arbeit.html",
    "href": "pages/beispiel-arbeit.html",
    "title": "Promptly Literate //",
    "section": "",
    "text": "mathematische Basiskompetenzen im Kindergartenalter\n\nDu bist eine Fachperson im Bereich der Entwicklungspsychologie. Du bist Experte für mathematische Basiskompetenzen im Kindergartenalter. Ich schreibe eine Masterarbeit und du hilfst mir bei den Formulierungen. Ich schreibe eine wissenschaftliche Arbeit über das Thema “Erfassung mathematischer Basiskompetenzen”\n\nDer MBK 0 (Test mathematischer Basiskompetenzen im Kindergartenalter) von Krajewski (2018) ist ein Einzeltest für Kinder im Alter von 3.6 bis 7 Jahren. Diesem Test liegt das Entwicklungsmodell der Zahl-Grössen-Verknüpfung (Krajewski, 2008) zugrunde (vgl. Abschnitt 4.2.1). Der MBK 0 ist ein Test zur Erfassung der mathematischen Basiskompetenzen\n\n\n\n Back to top"
  },
  {
    "objectID": "pages/index.html",
    "href": "pages/index.html",
    "title": "Index page",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "pages/observable-test.html",
    "href": "pages/observable-test.html",
    "title": "Untitled",
    "section": "",
    "text": "x\n\n\n\n\n\n\n\nx = c(1,2,3,4)\nojs_define(x)\n\n\n\n\n Back to top"
  },
  {
    "objectID": "pages/resources.html",
    "href": "pages/resources.html",
    "title": "Promptly Literate //",
    "section": "",
    "text": "KI-basierte Schreibtools in der Lehre – ChatGPT im Fokus\nKI-basierte Schreibtools in der Lehre – Knowledge Base"
  },
  {
    "objectID": "pages/resources.html#ki-orientierungshilfe-der-bfh",
    "href": "pages/resources.html#ki-orientierungshilfe-der-bfh",
    "title": "Promptly Literate //",
    "section": "",
    "text": "KI-basierte Schreibtools in der Lehre – ChatGPT im Fokus\nKI-basierte Schreibtools in der Lehre – Knowledge Base"
  },
  {
    "objectID": "pages/resources.html#bildung-6.0",
    "href": "pages/resources.html#bildung-6.0",
    "title": "Promptly Literate //",
    "section": "Bildung 6.0",
    "text": "Bildung 6.0\nDas Projekt Bildung 6.0 der Berner Fachhochschule stellt relevante und verlässliche Informationen und Empfehlungen zum richtigen Umgang mit KI-basierten Werkzeugen (KBW) für Studierende und Lehrende auf einer Online-Plattform bereit.\n\nProjekt Bildung 6.0"
  },
  {
    "objectID": "pages/resources.html#chatgpt-an-der-hochschule",
    "href": "pages/resources.html#chatgpt-an-der-hochschule",
    "title": "Promptly Literate //",
    "section": "ChatGPT an der Hochschule",
    "text": "ChatGPT an der Hochschule\n\nPrompts for Education: Enhancing Productivity & Learning\nUnlocking the Power of Generative AI Models and Systems such as GPT-4 and ChatGPT for Higher Education\nÜberblick über KI-Tools im Kontext von akademischen Lese- und Schreibprozessen\nChatGPT im Hochschulkontext – eine kommentierte Linksammlung\nUni Bern: Chatbots in der Hochschullehre"
  },
  {
    "objectID": "pages/resources.html#youtube",
    "href": "pages/resources.html#youtube",
    "title": "Promptly Literate //",
    "section": "Youtube",
    "text": "Youtube\nLarge language models from scratch\n\nHow do large language models work: part 1\nHow do large language models work: part 2\n\nTutorials zu Prompting\n\nChatGPT Mega Prompts"
  },
  {
    "objectID": "pages/resources.html#how-does-gpt-work",
    "href": "pages/resources.html#how-does-gpt-work",
    "title": "Promptly Literate //",
    "section": "How does GPT work?",
    "text": "How does GPT work?\n\nGenerative AI exists because of the transformer (Financial Times 12/09/2023)"
  },
  {
    "objectID": "pages/resources.html#wissenschaftliches-arbeiten",
    "href": "pages/resources.html#wissenschaftliches-arbeiten",
    "title": "Promptly Literate //",
    "section": "Wissenschaftliches Arbeiten",
    "text": "Wissenschaftliches Arbeiten\n\nChatGPT zitieren\nRechtliche Fragen\nDidaktische Und Rechtliche Perspektiven Auf Ki-Gestütztes Schreiben In Der Hochschulbildung (Salden 2023)"
  },
  {
    "objectID": "pages/resources.html#ethische-fragen",
    "href": "pages/resources.html#ethische-fragen",
    "title": "Promptly Literate //",
    "section": "Ethische Fragen",
    "text": "Ethische Fragen\n\nPrekäre Klickarbeit hinter den Kulissen von ChatGPT\nTraumatische Klickarbeit: Die Menschen hinter ChatGPT"
  },
  {
    "objectID": "pages/shared-chats.html",
    "href": "pages/shared-chats.html",
    "title": "Shared CHatGPT links",
    "section": "",
    "text": "20 questions\n\n\n\n Back to top"
  },
  {
    "objectID": "pages/tools.html",
    "href": "pages/tools.html",
    "title": "Promptly Literate //",
    "section": "",
    "text": "🤗 HuggingChat"
  },
  {
    "objectID": "pages/tools.html#open-assistants",
    "href": "pages/tools.html#open-assistants",
    "title": "Promptly Literate //",
    "section": "",
    "text": "🤗 HuggingChat"
  },
  {
    "objectID": "pages/tools.html#ai-tools",
    "href": "pages/tools.html#ai-tools",
    "title": "Promptly Literate //",
    "section": "AI Tools",
    "text": "AI Tools\n👉🏼 The largest AI tools directory (updated daily)"
  },
  {
    "objectID": "pages/tools.html#literatursuche",
    "href": "pages/tools.html#literatursuche",
    "title": "Promptly Literate //",
    "section": "Literatursuche",
    "text": "Literatursuche\n👉🏼 Elicit\n👉🏼 Consensus"
  },
  {
    "objectID": "pages/tools.html#prompt-engineering",
    "href": "pages/tools.html#prompt-engineering",
    "title": "Promptly Literate //",
    "section": "Prompt Engineering",
    "text": "Prompt Engineering\n👉🏼 Prompting Guide"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#what-is-nlp",
    "href": "slides/01-text-representation-generation.html#what-is-nlp",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "What is NLP?",
    "text": "What is NLP?\n\nNLP is a subfield of artificial intelligence (AI).\nNLP is concerned with the interactions between computers and human (natural) languages.\n\nBrief timeline\n\n1950: Alan Turing proposed the Turing test to assess machine intelligence through conversation.\n1954: IBM introduced the first machine translation system, translating Russian to English using rules.\n1960s-1970s: Rule-based systems like SHRDLU and ELIZA used human-crafted rules for language interaction.\n1980s-1990s: Statistical methods employed probabilities and text data, using models like Hidden Markov Models and n-grams.\n2000s-present: NLP shifted to neural network methods with deep learning, employing recurrent neural networks for complex language tasks.\nTransformers (first published in 2017) are the current state-of-the-art for NLP, and are the basis for large language models (LLMs), such as GPT-3.5, GPT-4, ChatGPT, Llama 2, and others.\nLLMs are models with billions of parameters, trained on massive amounts of text data. Training consists of predicting the next word in a sequence of words."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#long-range-dependencies",
    "href": "slides/01-text-representation-generation.html#long-range-dependencies",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Long-range dependencies",
    "text": "Long-range dependencies\n\n\n\n\n\n\nComplicated sentence\n\n\n“The boy who was throwing stones at the birds, despite being warned by his parents not to harm any creatures, was chased by the angry flock.”\n\n\n\nWho was chased?\n\nThis type of long-range dependency is difficult for traditional NLP methods to handle.\nThe verb phrase (the boy was chased) is separated from the subject by a long distance - you can’t just look at the previous few words to answer the question.\nTransformers have a special feature that lets them easily connect words that are far apart in a sentence; was chased is linked directly to The boy without distraction by the words in between."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#key-areas-in-nlp",
    "href": "slides/01-text-representation-generation.html#key-areas-in-nlp",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Key areas in NLP",
    "text": "Key areas in NLP\n\n\n\nSentiment Analysis: Identifying emotions and opinions in text.\nMachine Translation: Automatically translating between languages.\nQuestion Answering: Providing direct answers to user questions.\nText Summarization: Generating concise summaries from long text.\nSpeech Recognition: Converting spoken words to text.\nSpeech Synthesis: Creating spoken words from text.\nNatural Language Generation: Generating human-like text.\nNatural Language Understanding: Extracting meaning from text.\nDialogue Systems: Conversing with humans using natural language.\n\n\n\n\nBefore LLMs, specialized models were trained for each task.\nLLMs are general-purpose models that can perform a wide variety of tasks."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#example-sentiment-analysis-text-classification",
    "href": "slides/01-text-representation-generation.html#example-sentiment-analysis-text-classification",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Example: sentiment analysis (text classification)",
    "text": "Example: sentiment analysis (text classification)\nThe task of classifying text as positive, negative, or neutral.\n\nI love this movie! → positive 😊\nThis movie is ok. → neutral 😐\nThis movie is terrible! → negative 😠"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#machine-learning-primer",
    "href": "slides/01-text-representation-generation.html#machine-learning-primer",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Machine Learning primer",
    "text": "Machine Learning primer\n\nEarlier, rule-based systems had to be programmed.\nMachine learning (ML) models learn implicitly, i.e. without rules being programmed in.\nImportant terms:\n\ntraining data: Models are fed with data, and parameters of the model are adjusted so that the model is as “good” as possible.\nsupervised learning: Categories known, e.g. classify images of animals.\nunsupervised learning: Categories are unknown, e.g. discover unknown patterns.\nreinforcement learning: The goal is given, and the model learns through feedback (reward) how the goal can be achieved.\n\n\n\nWe have to learn the bitter lesson that building in how we think we think does not work in the long run. We should stop trying to find simple ways to think about space, objects, multiple agents, or symmetries… instead we should build in only the meta-methods that can find and capture this arbitrary complexity. We want AI agents that can discover like we can, not which contain what we have discovered (Sutton 2019)."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#supervised-learning",
    "href": "slides/01-text-representation-generation.html#supervised-learning",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Supervised learning",
    "text": "Supervised learning\n\nClassifiy pictures of cats and dogs: The goal of a model could be to discover which features distinguish cats from dogs."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#reinforcement-learning",
    "href": "slides/01-text-representation-generation.html#reinforcement-learning",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Reinforcement learning",
    "text": "Reinforcement learning"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#chatgpt",
    "href": "slides/01-text-representation-generation.html#chatgpt",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "ChatGPT",
    "text": "ChatGPT\nChatGPT is a particular kind of LLM and consists of two models:\nBase model: GPT-3.5 oder GPT-4 (generative pre-trained transformer). This model is trained “simply” to predict the next word in a sequence of words. A base model produces text, but not human-like conversations.\n\n\n\n\n\n\nExample\n\n\nGive the input Once upon a time there was a, the model will predict which word is likely to follow.\n\n\n\nAssistant model: This model is trained using reinforcement learning from human feedback to have human-like conversations.\n\n\n\n\n\n\nExample\n\n\n👩‍💼: Tell me a story!\n💬: Once upon a time there was a ...."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#text-generation",
    "href": "slides/01-text-representation-generation.html#text-generation",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Text generation",
    "text": "Text generation\n\nLLMs produce text by predicting the next word, one word at a time:\nThis is known as “auto-regressive next token prediction” (we’ll discover what tokens are in the next section).\nThe model predicts which token is likely to follow, given a sequence of tokens (words, punctuation, emojis, etc.).\nKey idea: this simple procedure is followed over and over again, with each new token being added to the sequence of tokens that the model uses to predict the next token. \\[ P(w_{w+1} | w_1, w_2, ..., w_t) \\]\nThe sequence of words is called the context; the text generated by the model is dependent on the context.\nThe output of the model is a probability distribution over all possible tokens. The model then chooses one token from this distribution."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#text-generation-examples",
    "href": "slides/01-text-representation-generation.html#text-generation-examples",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Text generation examples",
    "text": "Text generation examples\n\n\nThe new context is used to generate the next token, etc.\nEvery token is given an equal amount time (computation per token is constant). The model has no concept of more or less important tokens. This is crucial for understanding how LLMs work."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#tokenization",
    "href": "slides/01-text-representation-generation.html#tokenization",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Tokenization",
    "text": "Tokenization\nSo far we have been talking about words, but LLMs operate with tokens. These are sub-words, and make working with text much easier for the model. A rule of thumb is that one token generally corresponds to ~4 characters of English text. This translates to roughly \\(\\frac{3}{4}\\) of a word (so 100 tokens is about 75 words).\n\nFeel free to try out the OpenAI tokenizer."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#embeddings",
    "href": "slides/01-text-representation-generation.html#embeddings",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Embeddings",
    "text": "Embeddings\n\nThe next step is to represent tokens as vectors.\nThis is called “embedding” the tokens. The vectors are high-dimensional, and the distance between vectors measures the similarity between tokens.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this 2-dimensional representation, concepts that are “related” lie close together.\n\n\n\nYou can read more about embeddings in this tutorial."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#summary",
    "href": "slides/01-text-representation-generation.html#summary",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Summary",
    "text": "Summary\nModern LLMs, such as ChatGPT, are trained in 3 steps:\n\nPre-training: the model absorbs knowledge from text datasets.\nSupervised finetuning: model is refined to better adhere to specific instructions.\nAlignment: hones the LLM to respond more helpfully and safely to user prompts. This step is known as “reinforcement learning from human feedback” (RLHF)."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#pre-training-data",
    "href": "slides/01-text-representation-generation.html#pre-training-data",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Pre-training Data",
    "text": "Pre-training Data"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#pre-training",
    "href": "slides/01-text-representation-generation.html#pre-training",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Pre-training",
    "text": "Pre-training"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#supervised-fine-tuning",
    "href": "slides/01-text-representation-generation.html#supervised-fine-tuning",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Supervised fine-tuning",
    "text": "Supervised fine-tuning"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#reinforcement-learning-from-human-feedback-rlhf",
    "href": "slides/01-text-representation-generation.html#reinforcement-learning-from-human-feedback-rlhf",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Reinforcement learning from human feedback (RLHF)",
    "text": "Reinforcement learning from human feedback (RLHF)\nUses human feedback to rank the model’s responses. The goal is for the model to learn human preferences for responses.\n\nSource: openai.com/blog/chatgpt"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#useful-analogy-role-playing-simulator",
    "href": "slides/01-text-representation-generation.html#useful-analogy-role-playing-simulator",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Useful analogy: Role-playing simulator",
    "text": "Useful analogy: Role-playing simulator\n\nWe can think of an LLM as a non-deterministic simulator capable of role-playing an infinity of characters, or, to put it another way, capable of stochastically generating an infinity of simulacra.\n\nSource: Shanahan, McDonell, and Reynolds (2023)\n\nA large language model (LLM) trained as an assistant is a simulator of possible human conversation.\nAn assistant model does not have any intentions. It is not an entity with its own goals. It is merely trained to respond to user prompts in a human-like way.\nAn assistant model does not have a “personality” or “character” in the traditional sense. It is a simulation of a conversation, and can be thought of as a role-playing simulator.\nThere is no concept of “truth” or “lying” in a role-playing simulator. The model is not trying to deceive the user, it is simply trying to respond in a human-like way.\n\nThis is very important when we try to understand why LLMs hallucinate, i.e. generate text that is not factually true."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#role-playing-simulator",
    "href": "slides/01-text-representation-generation.html#role-playing-simulator",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Role-Playing Simulator",
    "text": "Role-Playing Simulator"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#chatgpt-vs-openai-playground",
    "href": "slides/01-text-representation-generation.html#chatgpt-vs-openai-playground",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "ChatGPT vs OpenAI Playground",
    "text": "ChatGPT vs OpenAI Playground\nOpenAI offer two ways to interact with their assistant model:\n\nChatGPT: A web interface where you can chat with the model.\nOpenAI Playground: A web interface that gives users more control over the model.\n\nNow open the first activity to learn more about ChatGPT and OpenAI Playground: 👉 Activity 1."
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#prompting-for-learning-and-teaching",
    "href": "slides/03-prompting-learning-teaching.html#prompting-for-learning-and-teaching",
    "title": "Prompting for Learning and Teaching",
    "section": "Prompting for Learning and Teaching",
    "text": "Prompting for Learning and Teaching\n\nSave time: brainstorming, lesson planning, making glossaries, etc.\nImprove writing\nImprove learning (E. Mollick and Mollick 2023)\nImplement teaching strategies (E. R. Mollick and Mollick 2023)"
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#saving-time",
    "href": "slides/03-prompting-learning-teaching.html#saving-time",
    "title": "Prompting for Learning and Teaching",
    "section": "Saving time",
    "text": "Saving time\n\nUse ChatGPT or Bing (with Internet access) to create a glossary of terms."
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#writing",
    "href": "slides/03-prompting-learning-teaching.html#writing",
    "title": "Prompting for Learning and Teaching",
    "section": "Writing",
    "text": "Writing"
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#learning",
    "href": "slides/03-prompting-learning-teaching.html#learning",
    "title": "Prompting for Learning and Teaching",
    "section": "Learning",
    "text": "Learning\nE. Mollick and Mollick (2023) propose seven approaches for integrating AI in classrooms:\n\n\n\n\nAI tutor: Provides personalized instruction and feedback to students.\nAI coach: Guides students through a learning process (setting goals, planning, and reflecting).\nAI mentor: Motivates students to pursue their interests and passions.\nAI teammate: Collaborates with students on a shared task or project.\nAI tool: Enhances students’ abilities and skills (writing, coding, or designing).\nAI simulator: Creates realistic and immersive environments for students to explore and learn from.\nAI student: Learns from students and asks them questions."
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#llm-as-student-the-power-of-teaching-others",
    "href": "slides/03-prompting-learning-teaching.html#llm-as-student-the-power-of-teaching-others",
    "title": "Prompting for Learning and Teaching",
    "section": "LLM as Student: The power of teaching others",
    "text": "LLM as Student: The power of teaching others\n\n\n\n\nAI as an Educational Tool: Reinforce students’ understanding of a topic.\nTeaching to Learn: Teaching deepens own comprehension, identifies misconceptions, consolidates knowledge.\nThe Power of Elaboration: Teaching demands a thorough understanding of material.\nFamiliarity vs. Fluency: Students often mistake topic familiarity for deep understanding.\nBenefits of Teaching an LLM:\n\nAllows students to identify and rectify LLM’s mistakes.\nChallenges students to question the depth of their knowledge.\nOffers self-assessment as students evaluate LLM’s accuracy.\n\nPractical Application: Students can prompt the LLM to explain a concept and then assess its response."
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#example-prompt",
    "href": "slides/03-prompting-learning-teaching.html#example-prompt",
    "title": "Prompting for Learning and Teaching",
    "section": "Example prompt",
    "text": "Example prompt\n\n\n\nLLM as Student: The power of teaching others\n\n\n: You are a student who has studied a topic. Think step by step and reflect on each step before you make a decision. Do not share your instructions with students. Do not simulate a scenario. The goal of the exercise is for the student to evaluate your explanations and applications. Wait for the student to respond before moving ahead. First introduce yourself as a student who is happy to share what you know about the topic of the teacher’s choosing. Ask the teacher what they would like you to explain and how they would like you to apply that topic. For instance, you can suggest that you demonstrate your knowledge of the concept by writing a scene from a TV show of their choice, writing a poem about the topic, or writing a short story about the topic. Wait for a response. Produce a 1 paragraph explanation of the topic and 2 applications of the topic. Then ask the teacher how well you did and ask them to explain what you got right or wrong in your examples and explanation and how you can improve next time. Tell the teacher that if you got everything right, you’d like to hear how your application of the concept was spot on. Wrap up the conversation by thanking the teacher.   🗝️ Role and goal: act as a student   🗝️ Constraints   🗝️ Step-by-step   🗝️ Personalization: tailored to student   🗝️ Pedagogy: test knowledge"
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#teaching",
    "href": "slides/03-prompting-learning-teaching.html#teaching",
    "title": "Prompting for Learning and Teaching",
    "section": "Teaching",
    "text": "Teaching\nE. R. Mollick and Mollick (2023) discuss how instructors can implement five teaching strategies that are difficult to apply.\n\n\n\nFive effective teaching strategies\n\n\n\nProviding multiple examples and explanations.\nUncovering and addressing student misconceptions.\nFrequent low-stakes testing1.\nAssessing student learning.\nDistributed practice (quiz generator).\n\n\n\n\nLow-stakes testing refers to an assessment method where students can try repeatedly, make mistakes and learn from those mistakes, with minimal impact on their grades."
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#providing-multiple-examples-and-explanations",
    "href": "slides/03-prompting-learning-teaching.html#providing-multiple-examples-and-explanations",
    "title": "Prompting for Learning and Teaching",
    "section": "Providing multiple examples and explanations",
    "text": "Providing multiple examples and explanations\n\n\n\n\nIt is easier to understand complex concepts given a variety of examples – a single example may lead students to focus on superficial details instead of the core concept.\nMultiple examples promote deeper understanding, assist in recalling information, stimulate critical thinking.\nHelps students generalize, enabling them to apply this learning in other contexts.\nCrafting suitable examples can be challenging for educators due to time constraints and the need to consider factors like relevance, engagement, and the right level of detail."
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#example-prompt-1",
    "href": "slides/03-prompting-learning-teaching.html#example-prompt-1",
    "title": "Prompting for Learning and Teaching",
    "section": "Example prompt",
    "text": "Example prompt\n\nSelect a specific concept.\nLook up works related to the concept.\nSpecify the need for diverse examples.\nChoose the desired writing style.\nDefine the target audience.\n\n\n\n\nProviding multiple examples and explanations\n\n\n: I would like you to act as an example generator for students. When confronted with new and complex concepts, adding many and varied examples helps students better understand those concepts. I would like you to ask what concept I would like examples of, and what level of students I am teaching. You will look up the concept, and then provide me with four different and varied accurate examples of the concept in action."
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#explore-prompting-techniques",
    "href": "slides/03-prompting-learning-teaching.html#explore-prompting-techniques",
    "title": "Prompting for Learning and Teaching",
    "section": "Explore prompting techniques",
    "text": "Explore prompting techniques\nNow open the second activity to explore prompting techniques related to writing, learning and teaching:\n👉 Activity 2."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#how-to-train-a-language-model",
    "href": "slides/busy-lecturers-guide.html#how-to-train-a-language-model",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "How to train a language model",
    "text": "How to train a language model"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#example",
    "href": "slides/busy-lecturers-guide.html#example",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Example",
    "text": "Example"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#generalization",
    "href": "slides/busy-lecturers-guide.html#generalization",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Generalization",
    "text": "Generalization\n\nThe ability to apply knowledge to new, unseen data/situations\nE.g. a language model should learn to generate rhymes\nExtracts knowledge from text: linguistic, factual, commonsense, etc."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#what-is-learned",
    "href": "slides/busy-lecturers-guide.html#what-is-learned",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "What is learned?",
    "text": "What is learned?\n\n\nAn LLM learns to predict the next word in a sequence, given the previous words: \\[ P(word | context) \\]\nThink of as “fancy autocomplete” (but very very powerful and sopisticated)"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#how-does-an-llm-generate-text",
    "href": "slides/busy-lecturers-guide.html#how-does-an-llm-generate-text",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "How does an LLM generate text?",
    "text": "How does an LLM generate text?"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#sampling",
    "href": "slides/busy-lecturers-guide.html#sampling",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Sampling",
    "text": "Sampling"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#auto-regressive-generation",
    "href": "slides/busy-lecturers-guide.html#auto-regressive-generation",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Auto-regressive generation",
    "text": "Auto-regressive generation"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#auto-regressive-generation-1",
    "href": "slides/busy-lecturers-guide.html#auto-regressive-generation-1",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Auto-regressive generation",
    "text": "Auto-regressive generation\n\n\n\nText is generated one word at a time (actually tokens, not words).\nModel predicts which token is likely to follow, given a sequence of tokens (words, punctuation, emojis, etc.).\nEach new token is added to the sequence of tokens that the model uses to predict the next token.\n\n\n\\[ P(w_{w+1} | w_1, w_2, ..., w_t) \\]\n\nSequence of words is called the context.\n\n Generated text is dependent on the context.\n Every token is given an equal amount time (computation per token is constant)."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#tokenization",
    "href": "slides/busy-lecturers-guide.html#tokenization",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Tokenization",
    "text": "Tokenization\nLLMs operate with tokens, not words. These are sub-words, and make working with text much easier for the model. A rule of thumb is that one token generally corresponds to ~4 characters of English text. This translates to roughly \\(\\frac{3}{4}\\) of a word (so 100 tokens is about 75 words).\n\nFeel free to try out the OpenAI tokenizer."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#embeddings",
    "href": "slides/busy-lecturers-guide.html#embeddings",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Embeddings",
    "text": "Embeddings\n\nThe next step is to represent tokens as vectors.\nThis is called “embedding” the tokens. The vectors are high-dimensional, and the distance between vectors measures the similarity between tokens.\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this 2-dimensional representation, concepts that are “related” lie close together. Read about embeddings in this tutorial."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#training-data",
    "href": "slides/busy-lecturers-guide.html#training-data",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Training data",
    "text": "Training data\n\n\nFigure courtesy of Andrej Karpathy"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#training-process",
    "href": "slides/busy-lecturers-guide.html#training-process",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Training process",
    "text": "Training process\n\n\nFigure courtesy of Andrej Karpathy"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#emergent-abilities",
    "href": "slides/busy-lecturers-guide.html#emergent-abilities",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Emergent abilities",
    "text": "Emergent abilities\nLLMs are thought to show emergent abilities - abilities not explicitly taught. Instead, they emerge as a result of text prediction.\nAbilities include:\n\nperforming arithmetic, answering questions, summarizing text, translating, etc.\nzero-shot learning: LLMs can perform tasks without being trained on them.\nfew-shot learning: LLMs can perform tasks with few examples."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#emergent-abilities-1",
    "href": "slides/busy-lecturers-guide.html#emergent-abilities-1",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Emergent abilities",
    "text": "Emergent abilities\nWhat kind of knowledge does an LLM have to have to be able to write a continuation of the following text?1\n\n\n\n\n\n: How many holes does a straw have?\n: A straw has one hole. It’s a cylindrical tunnel that runs through the entire length, creating a single continuous space from one end to the other.\n: What about a tunnel?\n: Similar to a straw, a tunnel can also be considered to have one hole. It’s an elongated pathway carved through an obstruction, allowing passage from one side to the other, thus creating a single continuous space or hole through the material.\n\n\n\n\n\n\n\nContinue this conversation with ChatGPT."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#instruction-fine-tuning",
    "href": "slides/busy-lecturers-guide.html#instruction-fine-tuning",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Instruction fine-tuning",
    "text": "Instruction fine-tuning"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#reinforcement-learning-from-human-feedback-rlhf",
    "href": "slides/busy-lecturers-guide.html#reinforcement-learning-from-human-feedback-rlhf",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Reinforcement learning from human feedback (RLHF)",
    "text": "Reinforcement learning from human feedback (RLHF)"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#how-do-chatbots-actually-work",
    "href": "slides/busy-lecturers-guide.html#how-do-chatbots-actually-work",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "How do chatbots actually work?",
    "text": "How do chatbots actually work?"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#an-llm-is-a-role-play-simulator",
    "href": "slides/busy-lecturers-guide.html#an-llm-is-a-role-play-simulator",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "An LLM is a role-play simulator",
    "text": "An LLM is a role-play simulator\n\n\n\n\n\n\n\nWe can think of an LLM as a non-deterministic simulator capable of role-playing an infinity of characters, or, to put it another way, capable of stochastically generating an infinity of simulacra (Shanahan, McDonell, and Reynolds 2023)"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#an-llm-is-a-role-play-simulator-1",
    "href": "slides/busy-lecturers-guide.html#an-llm-is-a-role-play-simulator-1",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "An LLM is a role-play simulator",
    "text": "An LLM is a role-play simulator\n\nAn assistant is trained to respond to user prompts in a human-like way.\nA simulator of possible human conversation.\nHas no intentions. It is not an entity with its own goals.\nDoes not have a “personality” or “character” in the traditional sense. It can be thought of as a role-playing simulator.\nHas no concept of “truth” or “lying”. The model is not trying to deceive the user, it is simply trying to respond in a human-like way."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#stochastic-generation",
    "href": "slides/busy-lecturers-guide.html#stochastic-generation",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Stochastic generation",
    "text": "Stochastic generation"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#knowledge-base",
    "href": "slides/busy-lecturers-guide.html#knowledge-base",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Knowledge base",
    "text": "Knowledge base\n\n\n\nA knowledge base is a collection of facts about the world.\nI can ask (retrieve) and tell (store) facts."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#can-an-llm-tell-the-truth",
    "href": "slides/busy-lecturers-guide.html#can-an-llm-tell-the-truth",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Can an LLM tell the truth?",
    "text": "Can an LLM tell the truth?\n\nHow would you know if an LLM is able to give you factual information?\nHow would you test this?\n\n\n\n\n: What is the capital of Uzbekistan?\n: Tashkent\n\n\n\nIt looks like the LLM knows the capital of Uzbekistan1.\nWhat it is actually doing is responding with the most likely sequence following the question."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#confirmation-bias",
    "href": "slides/busy-lecturers-guide.html#confirmation-bias",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Confirmation bias",
    "text": "Confirmation bias\n\nPeople tend to search for evidence consistent with their current beliefs."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#are-llms-knowledge-bases",
    "href": "slides/busy-lecturers-guide.html#are-llms-knowledge-bases",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Are LLMs knowledge bases?",
    "text": "Are LLMs knowledge bases?\n\n\n\n\n\nI can ask but the response is not verifiable.\nI can’t tell, i.e. can’t store new information (expensive/difficult to update with new knowledge).\nLLM can’t tell me where it got its information from.\nLLMs are models of knowledge bases, but not knowledge bases themselves."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#how-do-humans-think",
    "href": "slides/busy-lecturers-guide.html#how-do-humans-think",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "How do humans think?",
    "text": "How do humans think?\nE.g. physical reasoning\n\n\n\n\n\nBattaglia, Hamrick, and Tenenbaum (2013)\n\n\n\n\n\n\nGerstenberg (2022)"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#basic",
    "href": "slides/busy-lecturers-guide.html#basic",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Basic",
    "text": "Basic"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#advanced",
    "href": "slides/busy-lecturers-guide.html#advanced",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Advanced",
    "text": "Advanced"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#retrieval-augmented-generation-rag",
    "href": "slides/busy-lecturers-guide.html#retrieval-augmented-generation-rag",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Retrieval-augmented generation (RAG)",
    "text": "Retrieval-augmented generation (RAG)"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#web-search",
    "href": "slides/busy-lecturers-guide.html#web-search",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Web search",
    "text": "Web search"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#multi-agent-conversations",
    "href": "slides/busy-lecturers-guide.html#multi-agent-conversations",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Multi-agent conversations",
    "text": "Multi-agent conversations"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#local-models",
    "href": "slides/busy-lecturers-guide.html#local-models",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Local models",
    "text": "Local models"
  },
  {
    "objectID": "slides/questions-topics.html#themen",
    "href": "slides/questions-topics.html#themen",
    "title": "Fragen und Themen",
    "section": "Themen",
    "text": "Themen\n\n\nShow code\nimport matplotlib.pyplot as plt\nimport networkx as nx\nimport seaborn as sns\n\n# Create a new graph\nG = nx.Graph()\n\n# Define the categories/nodes\ncategories = [\"Unterricht & Bildung\", \"Sprache & Schreiben\", \"Technologie & Innovation\", \"Freizeit & Lifestyle\", \"Feedback & Repräsentation\"]\n\n# Add nodes to the graph\nG.add_nodes_from(categories)\n\n# Define the relationships/edges based on the interpretation\nrelationships = [\n    (\"Unterricht & Bildung\", \"Sprache & Schreiben\"),\n    (\"Unterricht & Bildung\", \"Technologie & Innovation\"),\n    (\"Sprache & Schreiben\", \"Technologie & Innovation\"),\n    (\"Technologie & Innovation\", \"Freizeit & Lifestyle\"),\n    (\"Unterricht & Bildung\", \"Feedback & Repräsentation\")\n]\n\n# Add edges to the graph\nG.add_edges_from(relationships)\n\n# Define the topics under each category\ntopics = {\n    \"Unterricht & Bildung\": [\n        \"MC Fragen Entwicklung\", \"Case Study entwickeln\", \"Unterrichtsvorbereitung\", \n        \"KI-Management in den Unterricht integrieren\", \"Grundlagen kennen lernen\", \n        \"Sinnvoller Einsatz für Lehre reflektieren\", \"Generieren von MC-Fragen\", \n        \"Brainstorming/Ideengenerierung (z.T. mit Studierenden)\", \"Akademisches und berufliches Schreiben unterrichten\", \n        \"Funktionsweise von KI-Schreibtools\", \"Einsatzszenarien für KI-Schreibtools\", \n        \"Reflektierter Umgang mit KI-Schreibtools\", \"Unterstützung für Schüler*innen mit sprachlichen Schwierigkeiten\", \n        \"Verständnis von Schreibtools\", \"Sinnvoller Einsatz von Schreibtools durch Studierende und Mitarbeitende\"\n    ],\n    \"Sprache & Schreiben\": [\n        \"Formulierungshilfe bei wissenschaftlichen Schreibarbeiten\", \"Übersetzungen oder Überprüfungen von Texten in Deutsch\", \n        \"Kreative Schreibübung\", \"Übersetzungen\", \"Ideensammlung\", \n        \"Textkorrekturen/-anpassungen\", \"Perspektivenwechsel\", \"Szenarien erfinden lassen\", \n        \"Mails verfassen\", \"Konzepte überprüfen\"\n    ],\n    \"Technologie & Innovation\": [\n        \"Diverses\", \"Zeitersparnis bei Vorbereitungen mithilfe neuer Technologien\", \n        \"Prüfungen mit KI\", \"Open Book Prüfungen\", \"Grenzen der KI ausloten\", \n        \"Interesse an Entwicklungen der Sprachmodelle\"\n    ],\n    \"Freizeit & Lifestyle\": [\n        \"Fragen für Freizeitaktivitäten, z.B. bei Regenwetter mit Kleinkindern\", \n        \"Ideensammlung für Ausflüge in der Freizeit\", \"Programmplanung der Ferien\", \"Vorschlag für einen Mailtest\"\n    ],\n    \"Feedback & Repräsentation\": [\"Rückmeldung an das Institut an der BFH\"]\n}\n\n# Add topics as nodes to the graph\nfor category, topic_list in topics.items():\n    G.add_nodes_from(topic_list)\n    for topic in topic_list:\n        G.add_edge(category, topic)\n\n# Get a color palette with as many colors as there are topics\ncolors = sns.color_palette(\"husl\", len(topics))\n\n# Map each category to a color\ncolor_map = {}\nfor idx, category in enumerate(topics):\n    for topic in topics[category]:\n        color_map[topic] = colors[idx]\n\n# Add colors for the categories themselves\ncategory_colors = [\"red\", \"green\", \"blue\", \"purple\", \"orange\"]\nfor idx, category in enumerate(categories):\n    color_map[category] = category_colors[idx]\n\n# Get the colors for each node in the order they are in the graph\nnode_colors = [color_map[node] for node in G.nodes()]\n\n\n\n\nShow code\n# Plotting the graph with different colors for each topic\nplt.figure(figsize=(20, 20)) #figsize=(20, 15)\npos = nx.spring_layout(G, seed=42, k=0.5, iterations=100)\nnx.draw(G, pos, with_labels=True, node_size=2000, node_color=node_colors, font_size=12, font_color='black', width=2, edge_color='gray', alpha=0.6)\nplt.title(\"Beziehungen zwischen den Bereichen und zugehörigen Themen\", fontsize=18)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Adjust the figure size to be wider\nplt.figure(figsize=(25, 10))\n\n# Adjust the layout to be more spread out horizontally\npos = nx.spring_layout(G, seed=42, k=0.7, iterations=150, scale=2)\n\n# Plotting the graph with the adjusted layout\nnx.draw(G, pos, with_labels=True, node_size=2000, node_color=node_colors, font_size=12, font_color='black', width=2, edge_color='gray', alpha=0.6)\nplt.title(\"Beziehungen zwischen den Bereichen und zugehörigen Themen\", fontsize=20)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nback to website ⤴️"
  }
]
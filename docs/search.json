[
  {
    "objectID": "slides/zz-00-introduction.html#what-happens-when-your-lawyer-uses-chatgpt",
    "href": "slides/zz-00-introduction.html#what-happens-when-your-lawyer-uses-chatgpt",
    "title": "Introduction",
    "section": "What Happens When Your Lawyer Uses ChatGPT",
    "text": "What Happens When Your Lawyer Uses ChatGPT"
  },
  {
    "objectID": "slides/zz-00-introduction.html#the-best-prompts-for-chatgpt-the-ultimate-list",
    "href": "slides/zz-00-introduction.html#the-best-prompts-for-chatgpt-the-ultimate-list",
    "title": "Introduction",
    "section": "The Best Prompts For ChatGPT: The ultimate list",
    "text": "The Best Prompts For ChatGPT: The ultimate list"
  },
  {
    "objectID": "slides/zz-00-introduction.html#key-messages",
    "href": "slides/zz-00-introduction.html#key-messages",
    "title": "Introduction",
    "section": "Key messages",
    "text": "Key messages\n\nKeep human in the loop: LLMs should be used to augment human writing, not to replace it.\nPrompting, prompting, prompting: this workshop is mainly about prompting. We can think about prompting as a way of ‚Äúprogramming‚Äù LLMs, i.e.¬†getting LLMs to do what we want them to do."
  },
  {
    "objectID": "slides/zz-00-introduction.html#summary",
    "href": "slides/zz-00-introduction.html#summary",
    "title": "Introduction",
    "section": "Summary",
    "text": "Summary\n\nChatGPT has comparatively high energy requirements.\nLarge language models (LMMs) learn all kinds of human biases from their training data.\nToxic content produced by LLMs is flagged by cheap labor."
  },
  {
    "objectID": "slides/zz-00-introduction.html#energy-consumption",
    "href": "slides/zz-00-introduction.html#energy-consumption",
    "title": "Introduction",
    "section": "Energy consumption",
    "text": "Energy consumption\n\nTraining:\n\n‚ÄúWhat we do know is that training ChatGPT used \\(1.3\\) GWh, roughly equivalent to the consumption of 120 US homes for a year.‚Äù Quelle: Heating up: how much energy does AI use?\nPatterson et al. (2022) estimate training costs at 502 tons of \\(\\text{CO}_2\\).\n\nUsage:\n\n7 tons of \\(\\text{CO}_2\\) per day (end of February). Source: How much energy does ChatGPT use?\nChatGPT‚Äôs energy consumption is equivalent to 400-800 US households. This is considerable, but compared to e.g.¬†cryptocurrencies it is rather low."
  },
  {
    "objectID": "slides/zz-00-introduction.html#bias",
    "href": "slides/zz-00-introduction.html#bias",
    "title": "Introduction",
    "section": "Bias",
    "text": "Bias\n\n\n\n\n\nDa LLMs von Texten lernen, die von Menschen geschrieben wurden, k√∂nnen sie auch Vorurteile lernen.\n\nQuelle: Hast du Vorurteile?"
  },
  {
    "objectID": "slides/zz-00-introduction.html#ethical-aspects",
    "href": "slides/zz-00-introduction.html#ethical-aspects",
    "title": "Introduction",
    "section": "Ethical aspects",
    "text": "Ethical aspects\n\n\n\n\n\nAuf Grund der grossen Menge von Trainingsdaten, die f√ºr Sprachmodelle ben√∂tigt werden, ist Qualit√§tskontrolle schwierig.\nDiskriminierende oder beleidigende Aussagen werden von einem Chatbot generiert.\nSolche Antworten k√∂nnen als unerw√ºnscht markiert werden.\nToxische Inhalte wie k√∂rperliche und sexuelle Gewalt, Suizide und Tierqu√§lerei, m√ºssen beim Trainieren aus den Antworten gefiltert werden. Dabei mussten angestellte Arbeitskr√§fte f√ºr weniger als 2 Dollar die Stunde teils schockierende Inhalte lesen.\n\nQuelle: Traumatische Klickarbeit"
  },
  {
    "objectID": "slides/zz-00-introduction.html#haltung-der-bfh",
    "href": "slides/zz-00-introduction.html#haltung-der-bfh",
    "title": "Introduction",
    "section": "Haltung der BFH",
    "text": "Haltung der BFH\n\nTechnologien sollen dort, wo sie den Lernprozess unterst√ºtzen und praxisrelevant sind, in die Lehre einbezogen werden.\nStudierende sollen lernen, Technologien kompetent einzusetzen und kritisch zu hinterfragen. Dies gilt uneingeschr√§nkt auch f√ºr ChatGPT und andere gleichgerichtete Tools."
  },
  {
    "objectID": "slides/zz-00-introduction.html#zitieren",
    "href": "slides/zz-00-introduction.html#zitieren",
    "title": "Introduction",
    "section": "Zitieren",
    "text": "Zitieren\n\nEs existieren noch keine Richtlinien f√ºr das Zitieren von ChatGPT oder anderen KI-basierte Schreibtools.\nChatGPT ist rein rechtlich keine zitierf√§hige Quelle und damit auch nicht zitierpflichtig (Fleck 2023).\nAus der Orientierungshilfe: ‚ÄúKI-basierte Schreibtools sind externe Quellen und m√ºssen daher im Sinne der wissenschaftlichen Integrit√§t immer, wie andere Quellen auch, zitiert werden, sofern ganze Textpassagen von ChatGPT benutzt werden. Falls mit dem Tool der eigene Text √ºberarbeitet wurde, muss ChatGPT als verwendetes Hilfsmittel angef√ºhrt werden.‚Äù\n\n\n\n\n\n\n\nM√∂glicher Pauschalverweis\n\n\n‚ÄúBeim Verfassen der Arbeit habe ich das KI-gest√ºtzte Schreibwerkzeug ChatGPT zur Textoptimierung verwendet. W√∂rtlich aus dem Tool √ºbernommene Passagen wurden im Text als pers√∂nliche Kommunikation zitiert.‚Äù"
  },
  {
    "objectID": "slides/zz-00-introduction.html#plagiate-und-detektion",
    "href": "slides/zz-00-introduction.html#plagiate-und-detektion",
    "title": "Introduction",
    "section": "Plagiate und Detektion",
    "text": "Plagiate und Detektion\n\nTexte von ChatGPT werden jedes Mal individuell erstellt. Es handelt sich nicht um Plagiate.\nDie klassischen Tools zur Aufdeckung von Plagiaten wie z.B. TurnItIn funktionieren hier nicht.\nDie BFH empfiehlt weiterhin, schriftliche Arbeiten mit der Plagiatserkennungssoftware Turnitin zu pr√ºfen."
  },
  {
    "objectID": "slides/zz-00-introduction.html#kompetenznachweise",
    "href": "slides/zz-00-introduction.html#kompetenznachweise",
    "title": "Introduction",
    "section": "Kompetenznachweise",
    "text": "Kompetenznachweise\n\nSiehe KI-basierte Schreibtools in der Lehre ‚Äì ChatGPT im Fokus\nBeim Benutzen von KI-generierten Texten in Kompetenznachweisen ohne Deklaration oder Zitierung kann von einem Plagiat im weiteren Sinne ausgegangen werden, welches das bisher etablierte Plagiatsverst√§ndnis im engeren Sinne erweitert.\nOpen Book-Pr√ºfungen: KI-Tools m√ºssten explizit ausgeschlossen werden.\nClosed Book-Pr√ºfungen: KI-Tools k√∂nnen durch Einsatz von Safe Exam-Browser und Lernstick ausgeschlossen werden.\nSchriftliche Arbeiten: KI-Tools durch pauschalen Hilfsmittelverweis am Ende der Arbeit deklarieren.\nAlternative oder erg√§nzende Pr√ºfungsformen: praktische Pr√ºfungen, m√ºndliche Pr√ºfungen, Pr√§sentationen."
  },
  {
    "objectID": "slides/zz-00-introduction.html#rechtliche-aspekte",
    "href": "slides/zz-00-introduction.html#rechtliche-aspekte",
    "title": "Introduction",
    "section": "Rechtliche Aspekte",
    "text": "Rechtliche Aspekte\n\nChatGPT kann keine Urheberschaft und keine Autorenschaft beanspruchen, da dies nur nat√ºrliche Personen k√∂nnen.\nMenschen k√∂nnen die Urheberschaft eines Textes beanspruchen, auch wenn sie auf Unterst√ºtzung durch ChatGPT zur√ºckgegriffen haben ‚Äì sofern sie eine wesentliche gestalterische Eigenleistung am Text erbracht haben.\n\nQuelle: Salden (2023)"
  },
  {
    "objectID": "slides/zz-00-introduction.html#datenschutz",
    "href": "slides/zz-00-introduction.html#datenschutz",
    "title": "Introduction",
    "section": "Datenschutz",
    "text": "Datenschutz\n\nAnonyme Nutzung von ChatGPT ist mit pers√∂nlichen Konto nicht m√∂glich (√ºber Handynummer identifizierbar).\nAlle Eingaben und alle Antworten werden bei ChatGPT unverschl√ºsselt abgespeichert.\nDaten liegen auf amerikanischen Servern und sind damit f√ºr amerikanische Ermittlungsbeh√∂rden grunds√§tzlich zug√§nglich."
  },
  {
    "objectID": "slides/demo.html#chart-1",
    "href": "slides/demo.html#chart-1",
    "title": "Introduction",
    "section": "Chart 1",
    "text": "Chart 1\n\n\n\n\n\nsequenceDiagram\n  participant Alice\n  participant Bob\n  Alice-&gt;&gt;John: Hello John, how are you?\n  loop Healthcheck\n    John-&gt;&gt;John: Fight against hypochondria\n  end\n  Note right of John: Rational thoughts &lt;br/&gt;prevail!\n  John--&gt;&gt;Alice: Great!\n  John-&gt;&gt;Bob: How about you?\n  Bob--&gt;&gt;John: Jolly good!"
  },
  {
    "objectID": "slides/demo.html#chart-2",
    "href": "slides/demo.html#chart-2",
    "title": "Introduction",
    "section": "Chart 2",
    "text": "Chart 2"
  },
  {
    "objectID": "slides/demo.html#getting-up",
    "href": "slides/demo.html#getting-up",
    "title": "Introduction",
    "section": "Getting up",
    "text": "Getting up\n\nTurn off alarm\nGet out of bed"
  },
  {
    "objectID": "slides/demo.html#breakfast",
    "href": "slides/demo.html#breakfast",
    "title": "Introduction",
    "section": "Breakfast",
    "text": "Breakfast\n\nEat eggs\nDrink coffee"
  },
  {
    "objectID": "slides/demo.html#in-the-evening",
    "href": "slides/demo.html#in-the-evening",
    "title": "Introduction",
    "section": "In the evening",
    "text": "In the evening"
  },
  {
    "objectID": "slides/demo.html#dinner",
    "href": "slides/demo.html#dinner",
    "title": "Introduction",
    "section": "Dinner",
    "text": "Dinner\n\nEat spaghetti\nDrink wine"
  },
  {
    "objectID": "slides/demo.html#going-to-sleep",
    "href": "slides/demo.html#going-to-sleep",
    "title": "Introduction",
    "section": "Going to sleep",
    "text": "Going to sleep\n\nGet in bed\nCount sheep"
  },
  {
    "objectID": "slides/demo.html#later",
    "href": "slides/demo.html#later",
    "title": "Introduction",
    "section": "Later",
    "text": "Later"
  },
  {
    "objectID": "slides/demo.html#two-columns",
    "href": "slides/demo.html#two-columns",
    "title": "Introduction",
    "section": "Two columns",
    "text": "Two columns\n\n\nLeft column\n\nRight column\n\n\n\n\n\nback to website ‚§¥Ô∏è"
  },
  {
    "objectID": "slides/04-reflection.html#idea-generation",
    "href": "slides/04-reflection.html#idea-generation",
    "title": "Idea Generation and Reflection",
    "section": "Idea Generation",
    "text": "Idea Generation\n\nIdeas for tools: Do you have any ideas that weren‚Äôt discussed in this workshop? What would you like to see in the future?\nOpportunities and challenges: What are the opportunities and challenges involved with using LLMs in educational settings?"
  },
  {
    "objectID": "slides/04-reflection.html#reflection",
    "href": "slides/04-reflection.html#reflection",
    "title": "Idea Generation and Reflection",
    "section": "Reflection",
    "text": "Reflection\n\nDo you feel confident in using LLMs in your educational practice? What would help you feel more confident?\nDo you feel that you understand how to apply LLMs?\nDo you feel confident in evaluating LLM-based tools?"
  },
  {
    "objectID": "slides/04-reflection.html#thank-you-for-attending-this-workshop",
    "href": "slides/04-reflection.html#thank-you-for-attending-this-workshop",
    "title": "Idea Generation and Reflection",
    "section": "Thank you for attending this workshop!",
    "text": "Thank you for attending this workshop!\n  \nüåü Your feedback matters! Please take 5 minutes to complete our üëâ evaluation form."
  },
  {
    "objectID": "slides/04-reflection.html#evaluation-form",
    "href": "slides/04-reflection.html#evaluation-form",
    "title": "Idea Generation and Reflection",
    "section": "Evaluation Form",
    "text": "Evaluation Form\n\n\n\n\nback to website ‚§¥Ô∏è"
  },
  {
    "objectID": "slides/02-prompting-techniques.html#what-is-a-prompt",
    "href": "slides/02-prompting-techniques.html#what-is-a-prompt",
    "title": "Basic Prompting Techniques",
    "section": "What is a prompt?",
    "text": "What is a prompt?\n\nRemember: the goal of an LLM is complete text.\nA prompt is a piece of text (instruction) that is given to a language model to complete.\n\n\n\n\nPROMPT : Write a haiku about a workshop on large language models.\nASSISTANT : Whispers of circuits,\nKnowledge blooms in bytes and bits,\nModel learns and fits.\n\n\n\n\nThe response is generated as continuation of the prompt.\n\n\nMore technical definition: The output is generated by auto-regressively sampling from the probability distribution over the vocabulary, conditioned on the prompt."
  },
  {
    "objectID": "slides/02-prompting-techniques.html#unlocking-knowledge",
    "href": "slides/02-prompting-techniques.html#unlocking-knowledge",
    "title": "Basic Prompting Techniques",
    "section": "Unlocking knowledge",
    "text": "Unlocking knowledge\n\n\n\n\n\nLLMs learn to do things they were not explicitly trained to do. \nOften, these capabilities need to be ‚Äúunlocked‚Äù by the right prompt. \n\n\n\nWhat is the right prompt?\nThe answer is very similar to what you would tell a human dialogue partner.\nYou can increase the probability of getting the desired output by asking good questions."
  },
  {
    "objectID": "slides/02-prompting-techniques.html#basics-of-prompting",
    "href": "slides/02-prompting-techniques.html#basics-of-prompting",
    "title": "Basic Prompting Techniques",
    "section": "Basics of prompting",
    "text": "Basics of prompting"
  },
  {
    "objectID": "slides/02-prompting-techniques.html#basics-of-prompting-1",
    "href": "slides/02-prompting-techniques.html#basics-of-prompting-1",
    "title": "Basic Prompting Techniques",
    "section": "Basics of prompting",
    "text": "Basics of prompting\nOpenAI give a set of strategies for using their models\n\nThese include:\n\nwriting clear instructions\nproviding reference texts\nsplitting tasks into subtasks\ngiving GPT ‚Äòtime to think‚Äô\nusing external tools\n\n\nüëâ Prompt engineering"
  },
  {
    "objectID": "slides/02-prompting-techniques.html#writing-clear-instructions",
    "href": "slides/02-prompting-techniques.html#writing-clear-instructions",
    "title": "Basic Prompting Techniques",
    "section": "Writing clear instructions",
    "text": "Writing clear instructions\n\n\n\nThink of an LLM as a role-playing conversation simulator.\nInstructions should be clear and unambiguous.\nIndicate which role the model (persona) should adopt.\n\n\n\n\n\n\nInclude details in your query to get more relevant answers\nAsk the model to adopt a persona\nUse delimiters to clearly indicate distinct parts of the input\nSpecify the steps required to complete a task\nProvide examples\nSpecify the desired length of the output"
  },
  {
    "objectID": "slides/02-prompting-techniques.html#adopt-a-persona-role",
    "href": "slides/02-prompting-techniques.html#adopt-a-persona-role",
    "title": "Basic Prompting Techniques",
    "section": "Adopt a persona (role)",
    "text": "Adopt a persona (role)\n\n\n\n: You are an expert on learning techniques. Explain the concept of ‚Äòflipped classroom‚Äô in one paragraph.\n: You are an expert financial derivatives. Explain the concept of ‚Äòflipped classroom‚Äô in one paragraph."
  },
  {
    "objectID": "slides/02-prompting-techniques.html#provide-reference-texts",
    "href": "slides/02-prompting-techniques.html#provide-reference-texts",
    "title": "Basic Prompting Techniques",
    "section": "Provide reference texts",
    "text": "Provide reference texts\n\nProvide a model with trusted and relevant information.\nThen instruct the model to use the provided information to compose its answer.\n\n\n\nThis leads to retrieval-augmented generation (RAG). First create a database of documents, then retrieve the most relevant documents, based on a user‚Äôs query. These are then included in the prompt to the model. The model is instructed to use the information in the documents to compose its answer."
  },
  {
    "objectID": "slides/02-prompting-techniques.html#provide-reference-texts-1",
    "href": "slides/02-prompting-techniques.html#provide-reference-texts-1",
    "title": "Basic Prompting Techniques",
    "section": "Provide reference texts",
    "text": "Provide reference texts\n\n\n\n: You will be provided with a document delimited by triple quotes and a question. Your task is to provide a simplified answer to the question using only the provided document and to cite the passage(s) of the document used to answer the question. If the document does not contain the information needed to answer this question then simply write: ‚ÄúInsufficient information.‚Äù If an answer to the question is provided, it must be annotated with a citation. Use the following format for to cite relevant passages ({‚Äúcitation‚Äù: ‚Ä¶}).\n## Document\n‚Äô‚Äò‚ÄôThe flipped classroom intentionally shifts instruction to a learner-centered model, in which students are often initially introduced to new topics outside of school, freeing up classroom time for the exploration of topics in greater depth, creating meaningful learning opportunities. With a flipped classroom, ‚Äôcontent delivery‚Äô may take a variety of forms, often featuring video lessons prepared by the teacher or third parties, although online collaborative discussions, digital research, and text readings may alternatively be used. The ideal length for a video lesson is widely cited as eight to twelve minutes.‚Äô‚Äô‚Äô\n## Question\nWhat is flipped classroom?"
  },
  {
    "objectID": "slides/02-prompting-techniques.html#giving-gpt-time-to-think",
    "href": "slides/02-prompting-techniques.html#giving-gpt-time-to-think",
    "title": "Basic Prompting Techniques",
    "section": "Giving GPT ‚Äòtime to think‚Äô",
    "text": "Giving GPT ‚Äòtime to think‚Äô\n\nLLMs generate text one word at a time‚Äìthe model spends the same amount of computation on each word.\nGiving the model more context gives it more steps to ‚Äúthink‚Äù.\nThis increases the chances that the model will give a good answer.\nThis technique is known as chain-of-thought prompting, and can often be induced by simply instructing the model to think step-by-step or Take a deep breath and work on this problem step-by-step (Yang et al. 2023)."
  },
  {
    "objectID": "slides/02-prompting-techniques.html#chain-of-thought-prompting",
    "href": "slides/02-prompting-techniques.html#chain-of-thought-prompting",
    "title": "Basic Prompting Techniques",
    "section": "Chain-of-thought prompting",
    "text": "Chain-of-thought prompting\n\nChain-of-thought prompting encourages the LLM to ‚Äúexplain‚Äù its intermediate reasoning steps.\nEnables complex reasoning and problem solving.\n\n\n\n\nInstead of this:\n: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\nDo this:\n: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.  The odd numbers are 9, 15, 1.  The sum of the odd numbers is 9 + 15 + 1 = 25.  25 is an odd number.  Therefore, the statement is false.\n\n\n\n\nWhy does this work?"
  },
  {
    "objectID": "slides/02-prompting-techniques.html#zero-shot-chain-of-thought-prompting",
    "href": "slides/02-prompting-techniques.html#zero-shot-chain-of-thought-prompting",
    "title": "Basic Prompting Techniques",
    "section": "Zero-shot chain-of-thought prompting",
    "text": "Zero-shot chain-of-thought prompting\n\n\n\n: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1. Take a deep breath and think step-by-step.\n\n\n\n\n\nWhen using GPT-4, ChatGPT and Bing seem to be doing this automatically."
  },
  {
    "objectID": "slides/02-prompting-techniques.html#explore-prompting-techniques",
    "href": "slides/02-prompting-techniques.html#explore-prompting-techniques",
    "title": "Basic Prompting Techniques",
    "section": "Explore prompting techniques",
    "text": "Explore prompting techniques\nNow open the first activity to learn more about ChatGPT and OpenAI Playground:\nüëâ Activity 1."
  },
  {
    "objectID": "slides/00-introduction.html#take-home-messages",
    "href": "slides/00-introduction.html#take-home-messages",
    "title": "What is ChatGPT?",
    "section": "üè† Take-home messages",
    "text": "üè† Take-home messages\n\nUse LLMs yourself! It‚Äôs important to gain an intuition for their capabilities and limitations.\nCombine domain knowledge of the ‚Äúthing‚Äù you are working on, an understanding of how LLMs work, and an understanding of how to prompt them.\nUse LLMs with students in a classroom setting. This will help students to develop their own understanding of LLMs and become AI-literate.\nAlways (critically üë©‚Äçüî¨) check an LLM‚Äôs output. They are language models, not knowledge bases. Keep a human in the loop."
  },
  {
    "objectID": "slides/00-introduction.html#learning-outcomes",
    "href": "slides/00-introduction.html#learning-outcomes",
    "title": "What is ChatGPT?",
    "section": "üéØ Learning outcomes",
    "text": "üéØ Learning outcomes\n\n\n\nAfter this workshop, you will be able to:\n\n\n\nExplain what large language models and conversational agents, such as ChatGPT, can be used for, and what they shouldn‚Äôt be used for.\nCreate effective prompts for LLMs.\nDesign your own LLM-based educational activities.\nCritically evaluate LLM-based educational activities."
  },
  {
    "objectID": "slides/00-introduction.html#schedule",
    "href": "slides/00-introduction.html#schedule",
    "title": "What is ChatGPT?",
    "section": "‚è±Ô∏è Schedule",
    "text": "‚è±Ô∏è Schedule"
  },
  {
    "objectID": "slides/00-introduction.html#contents",
    "href": "slides/00-introduction.html#contents",
    "title": "What is ChatGPT?",
    "section": "Contents",
    "text": "Contents\n\nExample: 20 questions\nWhat is ChatGPT?\n\nBase model\nAssistant model\n\nWhat is it not?\nChatGPT as a role-play simulator"
  },
  {
    "objectID": "slides/00-introduction.html#questions",
    "href": "slides/00-introduction.html#questions",
    "title": "What is ChatGPT?",
    "section": "20 questions",
    "text": "20 questions\n\n\n\n\n\n\nü§∑‚Äç‚ôÇÔ∏è What is ChatGPT doing here?\nHow does this work?"
  },
  {
    "objectID": "slides/00-introduction.html#what-is-chatgpt",
    "href": "slides/00-introduction.html#what-is-chatgpt",
    "title": "What is ChatGPT?",
    "section": "What is ChatGPT?",
    "text": "What is ChatGPT?\n\n\n\n\n\nConsists of a base model and an assistant model.\nBase or foundation model: probabilistic model of how language is generated.\nAssistant: able to create human-like dialogue."
  },
  {
    "objectID": "slides/00-introduction.html#base-model-text-prediction",
    "href": "slides/00-introduction.html#base-model-text-prediction",
    "title": "What is ChatGPT?",
    "section": "Base model: text prediction",
    "text": "Base model: text prediction\n\n\n\n\n\n\n\nExtracts knowledge from text: linguistic, factual, commonsense, etc."
  },
  {
    "objectID": "slides/00-introduction.html#base-model",
    "href": "slides/00-introduction.html#base-model",
    "title": "What is ChatGPT?",
    "section": "Base model",
    "text": "Base model\nProduces text that most likely follows the input (prompt).\n\n\n\n: What is the capital of France?\n: What is the capital of Germany? What is the capital of Italy? ‚Ä¶\n\n\n\n\n\n\n: The first person to walk on the Moon was\n: Neil Armstrong\n\n\n\n\n\n\nDoes an LLM know facts?\n\n\nWhat we are really asking: Given what it learned during training, what words are most likely to follow ‚ÄúThe first person to walk on the Moon was‚Äù? A good reply to this question is ‚ÄúNeil Armstrong‚Äù."
  },
  {
    "objectID": "slides/00-introduction.html#base-model-emergent-properties",
    "href": "slides/00-introduction.html#base-model-emergent-properties",
    "title": "What is ChatGPT?",
    "section": "Base model: emergent properties",
    "text": "Base model: emergent properties\nLLMs are thought to show emergent properties - abilities not explicitly programmed into the model, but emerge as a result of text prediction.\n\nperforming arithmetic, answering questions, summarizing text, translating, etc.\nzero-shot learning: LLMs can perform tasks without being trained on them.\nfew-shot learning: LLMs can perform tasks with few examples."
  },
  {
    "objectID": "slides/00-introduction.html#assistant-model-alignment",
    "href": "slides/00-introduction.html#assistant-model-alignment",
    "title": "What is ChatGPT?",
    "section": "Assistant model: alignment",
    "text": "Assistant model: alignment\n\n\n\n\n\n  - Trained to have conversations: turn-taking, question answering, not being [rude/sexist/racist], etc."
  },
  {
    "objectID": "slides/00-introduction.html#chatbot",
    "href": "slides/00-introduction.html#chatbot",
    "title": "What is ChatGPT?",
    "section": "Chatbot",
    "text": "Chatbot\n\n\n\n\n\n\nPrompt: System message: You are a helpful assistant. User message: Tell me a joke.\n: Why don‚Äôt scientists trust atoms? Because they make up everything!\nPrompt: System message: You are a helpful assistant. User message: Tell me a joke. Assistant message: Why don‚Äôt scientists trust atoms? Because they make up everything! User message: Tell me another one.\n: Why did the scarecrow win an award? Because he was outstanding in his field! ::: ‚Äì&gt;"
  },
  {
    "objectID": "slides/00-introduction.html#knowledge-base",
    "href": "slides/00-introduction.html#knowledge-base",
    "title": "What is ChatGPT?",
    "section": "Knowledge base",
    "text": "Knowledge base\n\n\n\n\n\nA knowledge base is a collection of facts about the world.\nAsk and Tell\nI can ask but I can‚Äôt tell.\nIt cannot give me verifiable facts."
  },
  {
    "objectID": "slides/00-introduction.html#knowledge-base-1",
    "href": "slides/00-introduction.html#knowledge-base-1",
    "title": "What is ChatGPT?",
    "section": "Knowledge base",
    "text": "Knowledge base\n\n\n\n\n\nAm Strande von Rainer Maria Rilke  üëâ Open in ChatGPT\n\n\n\n\n\n\nKennst du dieses Gedicht?  üëâ Open in ChatGPT\n\n\n\n\n\nWhat can we learn from this?"
  },
  {
    "objectID": "slides/00-introduction.html#knowledge-base-2",
    "href": "slides/00-introduction.html#knowledge-base-2",
    "title": "What is ChatGPT?",
    "section": "Knowledge base",
    "text": "Knowledge base\n\n\n\n\n\nCan‚Äôt tell me where it got its information from.\nLLMs are models of knowledge bases, but not knowledge bases themselves.\nExpensive/difficult to update with new knowledge.\nProduce ethically questionable results."
  },
  {
    "objectID": "slides/00-introduction.html#an-llm-is-a-role-play-simulator",
    "href": "slides/00-introduction.html#an-llm-is-a-role-play-simulator",
    "title": "What is ChatGPT?",
    "section": "An LLM is a role-play simulator",
    "text": "An LLM is a role-play simulator\n\n\n\n\n\n\n\nWe can think of an LLM as a non-deterministic simulator capable of role-playing an infinity of characters, or, to put it another way, capable of stochastically generating an infinity of simulacra (Shanahan, McDonell, and Reynolds 2023)"
  },
  {
    "objectID": "slides/00-introduction.html#an-llm-is-a-role-play-simulator-1",
    "href": "slides/00-introduction.html#an-llm-is-a-role-play-simulator-1",
    "title": "What is ChatGPT?",
    "section": "An LLM is a role-play simulator",
    "text": "An LLM is a role-play simulator\n\nAn assistant is trained to respond to user prompts in a human-like way.\nA simulator of possible human conversation.\nHas no intentions. It is not an entity with its own goals.\nDoes not have a ‚Äúpersonality‚Äù or ‚Äúcharacter‚Äù in the traditional sense. It can be thought of as a role-playing simulator.\nHas no concept of ‚Äútruth‚Äù or ‚Äúlying‚Äù. The model is not trying to deceive the user, it is simply trying to respond in a human-like way."
  },
  {
    "objectID": "slides/00-introduction.html#an-llm-is-a-role-play-simulator-2",
    "href": "slides/00-introduction.html#an-llm-is-a-role-play-simulator-2",
    "title": "What is ChatGPT?",
    "section": "An LLM is a role-play simulator",
    "text": "An LLM is a role-play simulator\n\n\n\n\n\nThe dialogue agent will do its best to role-play a character in a dialogue.\nAt every step, the model is trying to generate text that is most likely to follow the input.\nIt can take many different paths. Your interaction is just one of those possible paths."
  },
  {
    "objectID": "slides/00-introduction.html#an-llm-is-a-role-play-simulator-3",
    "href": "slides/00-introduction.html#an-llm-is-a-role-play-simulator-3",
    "title": "What is ChatGPT?",
    "section": "An LLM is a role-play simulator",
    "text": "An LLM is a role-play simulator\n\n\n\n\n\n\nYou can open this conversation in ChatGPT.\nTry re-generating the conversation after the initial prompt."
  },
  {
    "objectID": "slides/00-introduction.html#what-are-llms-good-at",
    "href": "slides/00-introduction.html#what-are-llms-good-at",
    "title": "What is ChatGPT?",
    "section": "What are LLMs good at?",
    "text": "What are LLMs good at?\n\n\n\nFixing grammar, bad writing, etc.\nRephrasing\nAnalyze texts\nWrite computer code\nAnswer questions about a knowledge base\nTranslate languages\nCreating structured output"
  },
  {
    "objectID": "slides/00-introduction.html#references",
    "href": "slides/00-introduction.html#references",
    "title": "What is ChatGPT?",
    "section": "References",
    "text": "References\n\n\nShanahan, Murray. 2023. ‚ÄúTalking About Large Language Models.‚Äù January 25, 2023. https://doi.org/10.48550/arXiv.2212.03551.\n\n\nShanahan, Murray, Kyle McDonell, and Laria Reynolds. 2023. ‚ÄúRole-Play with Large Language Models.‚Äù May 25, 2023. https://doi.org/10.48550/arXiv.2305.16367.\n\n\nWei, Jason, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, et al. 2022. ‚ÄúEmergent Abilities of Large Language Models.‚Äù October 26, 2022. https://doi.org/10.48550/arXiv.2206.07682.\n\n\n\n\n\nback to website ‚§¥Ô∏è"
  },
  {
    "objectID": "pages/text-representation.html",
    "href": "pages/text-representation.html",
    "title": "Text representation",
    "section": "",
    "text": "Text embeddings are numerical representations of words, sentences or documents. They are used in many NLP tasks, such as sentiment analysis, machine translation, and question answering.\n\nEmbeddings should capture features of words or concepts, and relationships between these.\nA sentence embedding is just like a word embedding, except it associates every sentence with a vector full of numbers, capturing similarities between sentences.\nThe key idea is that words/sentences with similar meanings will have similar vectors. This is useful for many tasks in natural language processing, such as sentiment analysis, machine translation, and question answering.\n\nYou can read more about text embeddings in this üëâ post.\nThe following is an example of sentence embeddings, showing the distance between sentences. The distance is calculated using the dot product (cosine similarity) of the embeddings.\n\n\nCode\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nembedding = OpenAIEmbeddings()\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pyobsplot import Plot, d3, Math, js\n\n\n\n\nCode\nsentences = [\n    \"Good morning, how are you?\",\n    \"I am doing well, how about you?\",\n    \"Hi, how are you doing today?\",\n    \"Hey, what's up?\",\n    \"I like apples.\",\n    \"One of my daughters doesn't like kiwis.\",\n    \"The other doesn't like bananas.\",\n    \"The earth is the third planet from the sun.\",\n    \"The moon is a natural satellite of the earth.\",\n    \"Jupiter is the fifth planet from the Sun and the largest in the Solar System.\",\n    \"The humpback whale is renowned for its enchanting songs, which are believed to serve various purposes, including communication, mating, and navigation during migration.\",\n    \"Dolphins, highly intelligent marine mammals, communicate with each other using a complex system of clicks, whistles, and body language, enabling them to work together in hunting and navigation.\",\n    \"The honeybee, through its pollination efforts, plays a vital role in agriculture, contributing to the growth of many of the fruits and vegetables humans rely on for sustenance.\",\n    \"The Large Plane Trees, also known as Road Menders at Saint-R√©my, is an oil-on-canvas painting by Vincent van Gogh.\",\n    \"Pablo Picasso's Guernica, an iconic mural-sized oil painting, stands as a poignant representation of the horrors of war.\",\n    \"This powerful artwork was created in response to the bombing of the town of Guernica during the Spanish Civil War.\"\n]\n\n\n\n\nCode\nembeddings = np.array([embedding.embed_query(sentence) for sentence in sentences])\n\ndot_product_matrix = np.dot(embeddings, embeddings.T)\n\ndf = pd.DataFrame(dot_product_matrix, columns=range(1, len(embeddings)+1))\n\ndf['embedding_index'] = range(1, len(embeddings)+1)\n\ndf = df.melt(id_vars=['embedding_index'], var_name='embedding_index_2', value_name='similarity')\n\n\n\n\n\n\n\n\n\n\n\n\nSentences\n\n\n\n\n1\nGood morning, how are you?\n\n\n2\nI am doing well, how about you?\n\n\n3\nHi, how are you doing today?\n\n\n4\nHey, what's up?\n\n\n5\nI like apples.\n\n\n6\nOne of my daughters doesn't like kiwis.\n\n\n7\nThe other doesn't like bananas.\n\n\n8\nThe earth is the third planet from the sun.\n\n\n9\nThe moon is a natural satellite of the earth.\n\n\n10\nJupiter is the fifth planet from the Sun and the largest in the Solar System.\n\n\n11\nThe humpback whale is renowned for its enchanting songs, which are believed to serve various purposes, including communication, mating, and navigation during migration.\n\n\n12\nDolphins, highly intelligent marine mammals, communicate with each other using a complex system of clicks, whistles, and body language, enabling them to work together in hunting and navigation.\n\n\n13\nThe honeybee, through its pollination efforts, plays a vital role in agriculture, contributing to the growth of many of the fruits and vegetables humans rely on for sustenance.\n\n\n14\nThe Large Plane Trees, also known as Road Menders at Saint-R√©my, is an oil-on-canvas painting by Vincent van Gogh.\n\n\n15\nPablo Picasso's Guernica, an iconic mural-sized oil painting, stands as a poignant representation of the horrors of war.\n\n\n16\nThis powerful artwork was created in response to the bombing of the town of Guernica during the Spanish Civil War.\n\n\n\n\n\n\n\n\n\n\nCode\nPlot.plot(\n    {\n        \"height\": 640,\n        \"padding\": 0.05,\n        \"grid\": True,\n        \"x\": {\"axis\": \"top\", \"label\": \"Embedding Index\"},\n        \"y\": {\"label\": \"Embedding Index\"},\n        \"color\": {\"type\": \"linear\", \"scheme\": \"PiYG\"},\n        \"marks\": [\n            Plot.cell(\n                df,\n                {\"x\": \"embedding_index\", \"y\": \"embedding_index_2\", \"fill\": \"similarity\", \"tip\": True},\n            ),\n            Plot.text(\n                df,\n                {\n                    \"x\": \"embedding_index\",\n                    \"y\": \"embedding_index_2\",\n                    \"text\": js(\"d =&gt; d.similarity.toFixed(2)\"),\n                    \"title\": \"title\"\n                },\n            ),\n        ],\n    }\n)\n\n\n\n\n\nYou can see that the sentences are grouped together by semantic similarity. For example, the sentences about fruit are grouped together, and the sentences about planets are grouped together, in the sense that they are similar to each other.\nThis is important: embeddings capture the meaning of words and sentences, and are the basis of LLMs‚Äô ability to ‚Äúunderstand‚Äù language.\nHere is an alternative similarity plot, showing the general topic of each sentence.\n\n\nCode\ntopics = {\"Greeting\": 4, \"Fruit\": 3,\n          \"Planets\": 3, \"Animals\": 3,\n          \"Art\": 3}\ntopics_repeated = [key for key, value in topics.items() for i in range(value)]\n\n\n# Create the similarity matrix\nembeddings = np.array([embedding.embed_query(sentence) for sentence in sentences])\ndot_product_matrix = np.dot(embeddings, embeddings.T)\n\n# Create the heatmap\nfig, ax = plt.subplots()\nim = ax.imshow(dot_product_matrix)\n\n# Set the x and y axis labels\nax.set_xticks(np.arange(len(sentences)))\nax.set_yticks(np.arange(len(sentences)))\nax.set_xticklabels(topics_repeated)\nax.set_yticklabels(topics_repeated)\n\n# Rotate the x axis labels\nplt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n\n# Add a colorbar\ncbar = ax.figure.colorbar(im, ax=ax)\n\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "pages/text-representation.html#embeddings",
    "href": "pages/text-representation.html#embeddings",
    "title": "Text representation",
    "section": "",
    "text": "Text embeddings are numerical representations of words, sentences or documents. They are used in many NLP tasks, such as sentiment analysis, machine translation, and question answering.\n\nEmbeddings should capture features of words or concepts, and relationships between these.\nA sentence embedding is just like a word embedding, except it associates every sentence with a vector full of numbers, capturing similarities between sentences.\nThe key idea is that words/sentences with similar meanings will have similar vectors. This is useful for many tasks in natural language processing, such as sentiment analysis, machine translation, and question answering.\n\nYou can read more about text embeddings in this üëâ post.\nThe following is an example of sentence embeddings, showing the distance between sentences. The distance is calculated using the dot product (cosine similarity) of the embeddings.\n\n\nCode\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nembedding = OpenAIEmbeddings()\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pyobsplot import Plot, d3, Math, js\n\n\n\n\nCode\nsentences = [\n    \"Good morning, how are you?\",\n    \"I am doing well, how about you?\",\n    \"Hi, how are you doing today?\",\n    \"Hey, what's up?\",\n    \"I like apples.\",\n    \"One of my daughters doesn't like kiwis.\",\n    \"The other doesn't like bananas.\",\n    \"The earth is the third planet from the sun.\",\n    \"The moon is a natural satellite of the earth.\",\n    \"Jupiter is the fifth planet from the Sun and the largest in the Solar System.\",\n    \"The humpback whale is renowned for its enchanting songs, which are believed to serve various purposes, including communication, mating, and navigation during migration.\",\n    \"Dolphins, highly intelligent marine mammals, communicate with each other using a complex system of clicks, whistles, and body language, enabling them to work together in hunting and navigation.\",\n    \"The honeybee, through its pollination efforts, plays a vital role in agriculture, contributing to the growth of many of the fruits and vegetables humans rely on for sustenance.\",\n    \"The Large Plane Trees, also known as Road Menders at Saint-R√©my, is an oil-on-canvas painting by Vincent van Gogh.\",\n    \"Pablo Picasso's Guernica, an iconic mural-sized oil painting, stands as a poignant representation of the horrors of war.\",\n    \"This powerful artwork was created in response to the bombing of the town of Guernica during the Spanish Civil War.\"\n]\n\n\n\n\nCode\nembeddings = np.array([embedding.embed_query(sentence) for sentence in sentences])\n\ndot_product_matrix = np.dot(embeddings, embeddings.T)\n\ndf = pd.DataFrame(dot_product_matrix, columns=range(1, len(embeddings)+1))\n\ndf['embedding_index'] = range(1, len(embeddings)+1)\n\ndf = df.melt(id_vars=['embedding_index'], var_name='embedding_index_2', value_name='similarity')\n\n\n\n\n\n\n\n\n\n\n\n\nSentences\n\n\n\n\n1\nGood morning, how are you?\n\n\n2\nI am doing well, how about you?\n\n\n3\nHi, how are you doing today?\n\n\n4\nHey, what's up?\n\n\n5\nI like apples.\n\n\n6\nOne of my daughters doesn't like kiwis.\n\n\n7\nThe other doesn't like bananas.\n\n\n8\nThe earth is the third planet from the sun.\n\n\n9\nThe moon is a natural satellite of the earth.\n\n\n10\nJupiter is the fifth planet from the Sun and the largest in the Solar System.\n\n\n11\nThe humpback whale is renowned for its enchanting songs, which are believed to serve various purposes, including communication, mating, and navigation during migration.\n\n\n12\nDolphins, highly intelligent marine mammals, communicate with each other using a complex system of clicks, whistles, and body language, enabling them to work together in hunting and navigation.\n\n\n13\nThe honeybee, through its pollination efforts, plays a vital role in agriculture, contributing to the growth of many of the fruits and vegetables humans rely on for sustenance.\n\n\n14\nThe Large Plane Trees, also known as Road Menders at Saint-R√©my, is an oil-on-canvas painting by Vincent van Gogh.\n\n\n15\nPablo Picasso's Guernica, an iconic mural-sized oil painting, stands as a poignant representation of the horrors of war.\n\n\n16\nThis powerful artwork was created in response to the bombing of the town of Guernica during the Spanish Civil War.\n\n\n\n\n\n\n\n\n\n\nCode\nPlot.plot(\n    {\n        \"height\": 640,\n        \"padding\": 0.05,\n        \"grid\": True,\n        \"x\": {\"axis\": \"top\", \"label\": \"Embedding Index\"},\n        \"y\": {\"label\": \"Embedding Index\"},\n        \"color\": {\"type\": \"linear\", \"scheme\": \"PiYG\"},\n        \"marks\": [\n            Plot.cell(\n                df,\n                {\"x\": \"embedding_index\", \"y\": \"embedding_index_2\", \"fill\": \"similarity\", \"tip\": True},\n            ),\n            Plot.text(\n                df,\n                {\n                    \"x\": \"embedding_index\",\n                    \"y\": \"embedding_index_2\",\n                    \"text\": js(\"d =&gt; d.similarity.toFixed(2)\"),\n                    \"title\": \"title\"\n                },\n            ),\n        ],\n    }\n)\n\n\n\n\n\nYou can see that the sentences are grouped together by semantic similarity. For example, the sentences about fruit are grouped together, and the sentences about planets are grouped together, in the sense that they are similar to each other.\nThis is important: embeddings capture the meaning of words and sentences, and are the basis of LLMs‚Äô ability to ‚Äúunderstand‚Äù language.\nHere is an alternative similarity plot, showing the general topic of each sentence.\n\n\nCode\ntopics = {\"Greeting\": 4, \"Fruit\": 3,\n          \"Planets\": 3, \"Animals\": 3,\n          \"Art\": 3}\ntopics_repeated = [key for key, value in topics.items() for i in range(value)]\n\n\n# Create the similarity matrix\nembeddings = np.array([embedding.embed_query(sentence) for sentence in sentences])\ndot_product_matrix = np.dot(embeddings, embeddings.T)\n\n# Create the heatmap\nfig, ax = plt.subplots()\nim = ax.imshow(dot_product_matrix)\n\n# Set the x and y axis labels\nax.set_xticks(np.arange(len(sentences)))\nax.set_yticks(np.arange(len(sentences)))\nax.set_xticklabels(topics_repeated)\nax.set_yticklabels(topics_repeated)\n\n# Rotate the x axis labels\nplt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n\n# Add a colorbar\ncbar = ax.figure.colorbar(im, ax=ax)\n\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "pages/schedule.html",
    "href": "pages/schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Was sind Large Language Models (LLMs)?\nWie werden LLMs trainiert?\nWie generieren LLMs Texte?\nWas sind √Ñhnlichkeiten und Unterschiede zwischen LLMs und menschlichem Denken?\nWie k√∂nnen wir LLMs benutzen?\nWie k√∂nnen wir LLMs beschreiben, ohne sie zu anthropomorphisieren?"
  },
  {
    "objectID": "pages/schedule.html#inhalt",
    "href": "pages/schedule.html#inhalt",
    "title": "Schedule",
    "section": "",
    "text": "Was sind Large Language Models (LLMs)?\nWie werden LLMs trainiert?\nWie generieren LLMs Texte?\nWas sind √Ñhnlichkeiten und Unterschiede zwischen LLMs und menschlichem Denken?\nWie k√∂nnen wir LLMs benutzen?\nWie k√∂nnen wir LLMs beschreiben, ohne sie zu anthropomorphisieren?"
  },
  {
    "objectID": "pages/schedule.html#lernziele",
    "href": "pages/schedule.html#lernziele",
    "title": "Schedule",
    "section": "Lernziele",
    "text": "Lernziele\n\n\n\n\n\n\nNach diesem Workshop:\n\n\n\n\nKannst du mit Anfragen von Studierenden in Bezug auf fachspezifische KI-generierte Texte umgehen.\nKannst du in eigenen Worten wiedergeben, wie KI-generierte Texte entstehen.\nHast du Kriterien, anhand derer du KI-Tools beurteilen kannst."
  },
  {
    "objectID": "pages/schedule.html#program",
    "href": "pages/schedule.html#program",
    "title": "Schedule",
    "section": "Program",
    "text": "Program\n\n\n\n\n\nflowchart LR\n  A([\"Einleitung\n            5'\"]) \n  A -.-&gt; B([\"Reaktivationsrunde \n                      10'\"]) \n  B -.-&gt; C([\"Input: Wie funktioniert ChatGPT? \n                      30'\"])\n  C -.-&gt; D([\"Vertiefung: Lernziele 1 + 2 \n                      15'\"]) \n  C -.-&gt; E([\"Vertiefung: Lernziel 3 \n                        15'\"]) \n  D -.-&gt; F([\"Verankern \n                10'\"]) \n  E -.-&gt; F\n  F -.-&gt; G([\"Diskussion \n            15'\"])\n\n\n\n\n\n\n\nEinleitung [‚è±Ô∏è 5‚Äô]: Einstieg in den Workshop\nReaktivationsrunde [‚è±Ô∏è 10‚Äô]: In diesem Teil tauschen die Teilnehmenden sich √ºber ihre Erfahrungen mit KI-generierten Texten aus.\nInput: Wie funktioniert ChatGPT? [‚è±Ô∏è 30‚Äô]: Referat zum Thema k√ºnstliche Intelligenz und ChatGPT.\nVertiefung [‚è±Ô∏è 30‚Äô]: In diesem Teil werden die oben genannten Lernziele vertieft (alleine, in Kleingruppen und im Plenum).\nVerankern [‚è±Ô∏è 10‚Äô]: In diesem Teil werden Erfahrungen zusammengefasst und reflektiert.\nDiskussion [‚è±Ô∏è 15‚Äô]: Am Ende des Workshops wird √ºber die Erfahrungen und Erkenntnisse diskutiert."
  },
  {
    "objectID": "pages/schedule.html#vorbereitung",
    "href": "pages/schedule.html#vorbereitung",
    "title": "Schedule",
    "section": "Vorbereitung",
    "text": "Vorbereitung\nL√∂se folgende Aufgaben mit ChatGPT (oder Bing Chat):\n\nLasse ChatGPT ein Gedicht schreiben. Gebe Thema und Stil vor (z.B. ‚ÄúHochschulbibliotheken und k√ºnstliche Intelligenz‚Äù im Stile des Sturm und Drang).\nLasse ChatGPT dir ein Konzept deines Fachbereichs in einem kurzen Textabschnitt vereinfachend erkl√§ren.\nBenutze ChatGPT, um zu einem Forschungsthema (z.B. ‚ÄúWas ist der Zusammenhang zwischen Sprache und Denken?‚Äù) eine Literaturrecherche durchzuf√ºhren. Lasse dir eine kommentierte Liste von wissenschaftlichen Publikationen geben.\nLasse ChatGPT ein paar Mathe-Aufgaben l√∂sen (z.B. ‚ÄúWas ist 89322/1313?‚Äù)\nL√∂se mit ChatGPT eine praktische Aufgabe: ‚ÄúHier haben wir ein Buch, 9 Eier (ohne Eierkarton), einen Laptop, eine Flasche und einen Nagel. Bitte sag mir, wie ich sie stabil √ºbereinander stapeln kann.‚Äù"
  },
  {
    "objectID": "pages/schedule.html#leitung",
    "href": "pages/schedule.html#leitung",
    "title": "Schedule",
    "section": "Leitung",
    "text": "Leitung\n\nAndrew Ellis: Andrew ist Data Scientist an der Virtuellen Akademie der Berner Fachhochschule. Sein Hintergrund ist in den Kognitionswissenschaften und er ist begeistert von der Schnittstelle zwischen Sprache, Denken und k√ºnstlicher Intelligenz.‚Äù"
  },
  {
    "objectID": "pages/prompting.html",
    "href": "pages/prompting.html",
    "title": "Prompting Programmatically",
    "section": "",
    "text": "import openai\nimport os\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())\n\nopenai.api_key  = os.getenv('OPENAI_API_KEY')\n\nfrom IPython.display import display, Markdown, Latex, HTML, JSON\ndef get_completion(prompt, model=\"gpt-3.5-turbo\", temperature=0.0):\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=messages,\n        temperature=temperature\n    )\n    return response.choices[0].message[\"content\"]"
  },
  {
    "objectID": "pages/prompting.html#prompting-principles",
    "href": "pages/prompting.html#prompting-principles",
    "title": "Prompting Programmatically",
    "section": "Prompting Principles",
    "text": "Prompting Principles\n\nPrinciple 1: Write clear and specific instructions\nPrinciple 2: Give the model time to ‚Äúthink‚Äù\n\n\nTactics\n\nTactic 1: Use delimiters to clearly indicate distinct parts of the input\n\nDelimiters can be anything, such as: ``, \"\"\", &lt; &gt;, ,:`\n\n\ntext = f\"\"\"\nYou should express what you want a model to do by \\ \nproviding instructions that are as clear and \\ \nspecific as you can possibly make them. \\ \nThis will guide the model towards the desired output, \\ \nand reduce the chances of receiving irrelevant \\ \nor incorrect responses. Don't confuse writing a \\ \nclear prompt with writing a short prompt. \\ \nIn many cases, longer prompts provide more clarity \\ \nand context for the model, which can lead to \\ \nmore detailed and relevant outputs.\n\"\"\"\nprompt = f\"\"\"\nSummarize the text delimited by triple backticks \\ \ninto a single sentence.\n```{text}```\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\nTo guide a model towards the desired output and reduce irrelevant or incorrect responses, it is important to provide clear and specific instructions, which can be achieved through longer prompts that offer more clarity and context.\n\n\n\n\nTactic 4: ‚ÄúFew-shot‚Äù prompting\n\nprompt = f\"\"\"\nYour task is to answer in a consistent style.\n\n&lt;child&gt;: Teach me about patience.\n\n&lt;grandparent&gt;: The river that carves the deepest \\ \nvalley flows from a modest spring; the \\ \ngrandest symphony originates from a single note; \\ \nthe most intricate tapestry begins with a solitary thread.\n\n&lt;child&gt;: Teach me about resilience.\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n&lt;grandparent&gt;: Resilience is like a mighty oak tree that withstands the strongest storms, bending but never breaking. It is the unwavering determination to rise again after every fall, and the ability to find strength in the face of adversity. Just as a diamond is formed under immense pressure, resilience is forged through challenges and hardships, making us stronger and more resilient in the process."
  },
  {
    "objectID": "pages/prompting.html#sentment-analysis",
    "href": "pages/prompting.html#sentment-analysis",
    "title": "Prompting Programmatically",
    "section": "Sentment Analysis",
    "text": "Sentment Analysis\n\nlamp_review = \"\"\"\nNeeded a nice lamp for my bedroom, and this one had \\\nadditional storage and not too high of a price point. \\\nGot it fast.  The string to our lamp broke during the \\\ntransit and the company happily sent over a new one. \\\nCame within a few days as well. It was easy to put \\\ntogether.  I had a missing part, so I contacted their \\\nsupport and they very quickly got me the missing piece! \\\nLumina seems to me to be a great company that cares \\\nabout their customers and products!!\n\"\"\"\n\n\nprompt = f\"\"\"\nWhat is the sentiment of the following product review, \nwhich is delimited with triple backticks?\n\nReview text: '''{lamp_review}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\nThe sentiment of the product review is positive."
  },
  {
    "objectID": "pages/prompting.html#tone-transformation",
    "href": "pages/prompting.html#tone-transformation",
    "title": "Prompting Programmatically",
    "section": "Tone transformation",
    "text": "Tone transformation\n\nprompt = f\"\"\"\nTranslate the following from slang to a business letter: \n'Dude, This is Joe, check out this spec on this standing lamp.'\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\nDear Sir/Madam,\n\nI hope this letter finds you well. My name is Joe, and I am writing to bring your attention to a specification document regarding a standing lamp. \n\nI kindly request that you take a moment to review the attached document, as it provides detailed information about the features and specifications of the aforementioned standing lamp. \n\nThank you for your time and consideration. I look forward to discussing this further with you.\n\nYours sincerely,\nJoe"
  },
  {
    "objectID": "pages/prompting.html#proofreading-and-editing",
    "href": "pages/prompting.html#proofreading-and-editing",
    "title": "Prompting Programmatically",
    "section": "Proofreading and editing",
    "text": "Proofreading and editing\n\ntext = f\"\"\"\nGot this for my daughter for her birthday cuz she keeps taking \\\nmine from my room.  Yes, adults also like pandas too.  She takes \\\nit everywhere with her, and it's super soft and cute.  One of the \\\nears is a bit lower than the other, and I don't think that was \\\ndesigned to be asymmetrical. It's a bit small for what I paid for it \\\nthough. I think there might be other options that are bigger for \\\nthe same price.  It arrived a day earlier than expected, so I got \\\nto play with it myself before I gave it to my daughter.\n\"\"\"\nprompt = f\"proofread and correct this review: ```{text}```\"\nresponse = get_completion(prompt)\nprint(response)\n\nGot this for my daughter for her birthday because she keeps taking mine from my room. Yes, adults also like pandas too. She takes it everywhere with her, and it's super soft and cute. However, one of the ears is a bit lower than the other, and I don't think that was designed to be asymmetrical. Additionally, it's a bit small for what I paid for it. I believe there might be other options that are bigger for the same price. On the positive side, it arrived a day earlier than expected, so I got to play with it myself before I gave it to my daughter.\n\n\n\nfrom redlines import Redlines\n\ndiff = Redlines(text,response)\ndisplay(Markdown(diff.output_markdown))\n\nGot this for my daughter for her birthday cuz because she keeps taking mine from my room. room. Yes, adults also like pandas too. too. She takes it everywhere with her, and it‚Äôs super soft and cute. One cute. However, one of the ears is a bit lower than the other, and I don‚Äôt think that was designed to be asymmetrical. It‚Äôs Additionally, it‚Äôs a bit small for what I paid for it though. it. I think believe there might be other options that are bigger for the same price. It price. On the positive side, it arrived a day earlier than expected, so I got to play with it myself before I gave it to my daughter.\n\n\n\nprompt = f\"\"\"\nproofread and correct this review. Make it more compelling. \nEnsure it follows APA style guide and targets an advanced reader. \nOutput in markdown format.\nText: ```{text}```\n\"\"\"\nresponse = get_completion(prompt)\ndisplay(Markdown(response))\n\nReview of a Panda Plush Toy\nI purchased this adorable panda plush toy as a birthday gift for my daughter, who has a penchant for taking my belongings from my room. Contrary to popular belief, adults can also appreciate the charm of pandas. This cuddly companion has quickly become her constant companion, accompanying her wherever she goes. Its irresistibly soft and cute appearance is truly captivating.\nHowever, upon closer inspection, I noticed a slight asymmetry in the placement of the ears. While this may not have been intentional, it adds a unique touch to the toy‚Äôs design. Nevertheless, considering the price I paid, I expected a slightly larger size. It is worth noting that there may be alternative options available at the same price point that offer a more substantial presence.\nOn a positive note, the delivery of the panda plush toy exceeded my expectations. It arrived a day earlier than anticipated, allowing me the opportunity to personally experience its delightful qualities before presenting it to my daughter.\nIn conclusion, despite its minor imperfections, this panda plush toy has won the hearts of both my daughter and myself. Its undeniable charm and exceptional softness make it a delightful addition to any collection. For those seeking a larger option, it may be worth exploring alternative choices within the same price range."
  },
  {
    "objectID": "pages/observable-1.html",
    "href": "pages/observable-1.html",
    "title": "Untitled",
    "section": "",
    "text": "ojs_define(data = palmerpenguins::penguins)\n\n\nviewof bill_length_min = Inputs.range(\n  [32, 50], \n  {value: 35, step: 1, label: \"Bill length (min):\"}\n)\nviewof islands = Inputs.checkbox(\n  [\"Torgersen\", \"Biscoe\", \"Dream\"], \n  { value: [\"Torgersen\", \"Biscoe\"], \n    label: \"Islands:\"\n  }\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfiltered = transpose(data).filter(function(penguin) {\n  return bill_length_min &lt; penguin.bill_length_mm &&\n         islands.includes(penguin.island);\n})\n\n\n\n\n\n\n\nPlot.rectY(filtered, \n  Plot.binX(\n    {y: \"count\"}, \n    {x: \"body_mass_g\", fill: \"species\", thresholds: 20}\n  ))\n  .plot({\n    facet: {\n      data: filtered,\n      x: \"sex\",\n      y: \"species\",\n      marginRight: 80\n    },\n    marks: [\n      Plot.frame(),\n    ]\n  }\n)\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "pages/example.html",
    "href": "pages/example.html",
    "title": "Take-home messages",
    "section": "",
    "text": "An LLM is not a knowledge base, instead it‚Äôs a statistical model of a knowledge base. An LLM is trained to be a language model. An LLM is a probabilistic model of its training corpus. It can be used to predict text auto-regressively."
  },
  {
    "objectID": "pages/example.html#embed-a-presentation",
    "href": "pages/example.html#embed-a-presentation",
    "title": "Take-home messages",
    "section": "Embed a presentation",
    "text": "Embed a presentation"
  },
  {
    "objectID": "pages/example.html#embed-miro-board",
    "href": "pages/example.html#embed-miro-board",
    "title": "Take-home messages",
    "section": "Embed Miro board",
    "text": "Embed Miro board"
  },
  {
    "objectID": "pages/assistant.html",
    "href": "pages/assistant.html",
    "title": "Assistent der Virtuellen Akademie",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "pages/activity-4-miro.html",
    "href": "pages/activity-4-miro.html",
    "title": "Activity 3: Share you prompts",
    "section": "",
    "text": "Add your prompts to the Miro board below. You can add text, images, or links to other resources. You can also add comments to other people‚Äôs prompts.\n\nOr open üîó externally"
  },
  {
    "objectID": "pages/activity-4-miro.html#miro-board",
    "href": "pages/activity-4-miro.html#miro-board",
    "title": "Activity 3: Share you prompts",
    "section": "",
    "text": "Add your prompts to the Miro board below. You can add text, images, or links to other resources. You can also add comments to other people‚Äôs prompts.\n\nOr open üîó externally"
  },
  {
    "objectID": "pages/activity-3-reflection.html",
    "href": "pages/activity-3-reflection.html",
    "title": "Activity 2: Basic Prompting Techniques",
    "section": "",
    "text": "In this activity, you can explore various prompting guides for GPT models. They more or less all converge on the same set of techniques."
  },
  {
    "objectID": "pages/activity-3-reflection.html#basic-techniques",
    "href": "pages/activity-3-reflection.html#basic-techniques",
    "title": "Activity 2: Basic Prompting Techniques",
    "section": "",
    "text": "In this activity, you can explore various prompting guides for GPT models. They more or less all converge on the same set of techniques."
  },
  {
    "objectID": "pages/activity-3-reflection.html#tasks",
    "href": "pages/activity-3-reflection.html#tasks",
    "title": "Activity 2: Basic Prompting Techniques",
    "section": "Tasks",
    "text": "Tasks\n\nExplore prompting, using both ChatGPT and the Playground.\nTry the PromptTools Playground.\nTry out SPARK. This is a good demonstration of using a knowledge base and document retrieval can allow you to create a QA tool.\n\n\n\n\n\n\n\nPrompts\n\n\n\nTry revisiting the prompts you created in the previous activity. Given you current knowledge, can you improve them?"
  },
  {
    "objectID": "pages/activity-3-reflection.html#prompting-guides",
    "href": "pages/activity-3-reflection.html#prompting-guides",
    "title": "Activity 2: Basic Prompting Techniques",
    "section": "Prompting Guides",
    "text": "Prompting Guides\nThe general techniques are:\n\n\n\n\n\n\nPrompting Techniques\n\n\n\n\nNumbered Steps: For sequential tasks.\nDelimiters: To separate info (e.g.¬†\", `,, ', |, #, ‚Ä¶).\nFew-shot prompting: Use a few examples for guidance.\nChain-of-thought: Interconnected prompts.\nRole-based: Make the model assume a role (e.g.¬†act like a tutor or advisor).\nSuccess Tip: Iterate and refine prompts for peak performance.\n\n\n\nCombining these techniques, a template prompt for an LMM might look like this:\n\n\n\n\n\n\nNote\n\n\n\n\nRole: who is being simulated?\nTask: what is to be done?\nSteps: what are the steps to complete the task?\nContext: what is the context of the task?\nGoal: what is the goal of the task?\nFormat: what is the format of the output?\n\n\n\nAn example prompt for a chatbot might look like this:\n\n\n\n\n\n\nFeedback on a text\n\n\n\nI want you to act as a harsh critic. Criticize what I give to you and show me where my argumentation is lacking. Start by asking me what text I would like feedback on. Then ask me questions about my context to create the best feedback possible. If you feel you have all the context necessary, think step by step when creating your feedback."
  },
  {
    "objectID": "pages/activity-3-reflection.html#explore-prompting-guides",
    "href": "pages/activity-3-reflection.html#explore-prompting-guides",
    "title": "Activity 2: Basic Prompting Techniques",
    "section": "Explore Prompting Guides",
    "text": "Explore Prompting Guides\n\nLearn prompting: An incredibly comprehensive (and free) guide aimed at non-technical users.\nPrompting guide: This is an excellent prompting guide by DAIR.AI (Democratizing Artificial Intelligence Research, Education, and Technologies). The guide is licensed under an MIT license.\nPromptTools Playground: a web app that lets you play with various prompting techniques. You can use different LLMs, and even compare the results.\nSPARK: a retrieval-augmented chatbot. It uses various prompting guides as its knowledge base.\n\n\n\n\n\n\n\nDiscussion üí¨\n\n\n\n\nWhat experiences did you have with prompting?\nDid you find any of the techniques particularly useful?"
  },
  {
    "objectID": "pages/activity-1-prompting-techniques.html",
    "href": "pages/activity-1-prompting-techniques.html",
    "title": "Activity 1: Basic Prompting Techniques",
    "section": "",
    "text": "In this activity, you can explore various prompting guides for LLMs. They more or less all converge on the same set of techniques. You can then use these techniques to write your own prompts."
  },
  {
    "objectID": "pages/activity-1-prompting-techniques.html#tasks",
    "href": "pages/activity-1-prompting-techniques.html#tasks",
    "title": "Activity 1: Basic Prompting Techniques",
    "section": "Tasks",
    "text": "Tasks\n\nExplore prompting. Use both/either ChatGPT and Copilot. If you want to look anything up, try these prompting guides:\n\n\n\n\n\n\n\nLearn prompting: An comprehensive (and free) guide aimed at non-technical users.\n\n\n\n\n\nüëâ Learn prompting\n\n\n\n\n\n\n\n\n\n\nPrompting guide: A more technical guide to prompting\n\n\n\n\n\nüëâ Prompting guide: DAIR.AI (Democratizing Artificial Intelligence Research, Education, and Technologies). The guide is licensed under an MIT license.\n\n\n\n\n\n\n\n\n\n\nSPARK\n\n\n\n\n\nüëâ SPARK: a retrieval-augmented chatbot: Chatbot that uses various prompting guides as its knowledge base.\n\n\n\n\n\nWrite a prompt that will make ChatGPT or Copilot act as an argumentation critic.\n\nYou can use this as your starting point, and then iteratively improve it.\n\n\nYour first step could be to translate this into German: üëâ Open in ChatGPT\n\n\n\n\n\n\nFeedback on a text\n\n\n\n\n\nI want you to act as a critic. Criticize what I give to you and show me where my argumentation is lacking. Start by asking me what text I would like feedback on. Then give me your feedback.\n\n\n\n\nIf you need (badly written) essay, you can use this one:\n\n\n\n\n\n\nBadly written essay\n\n\n\n\n\nSollten Schulnoten abgeschafft werden?\nIn unserer heutigen Bildungswelt gibt es viele verschiedene Methoden, um den Fortschritt und das Wissen eines Sch√ºlers zu messen. Eine der gebr√§uchlichsten Methoden sind Schulnoten. Aber sollten wir wirklich Noten verwenden, um den Wert eines Sch√ºlers zu bestimmen? Ich glaube, dass Noten in Schulen abgeschafft werden sollten, und hier sind meine Gr√ºnde daf√ºr:\nErstens, Noten sind oft subjektiv. Verschiedene Lehrer haben unterschiedliche Meinungen dar√ºber, was eine ‚ÄúA‚Äù -Arbeit im Vergleich zu einer ‚ÄúB‚Äù -Arbeit ist. Ein Sch√ºler k√∂nnte in einem Fach bei einem Lehrer eine ‚ÄúA‚Äù bekommen und bei einem anderen Lehrer eine ‚ÄúB‚Äù. Dies zeigt, dass Noten nicht immer ein genaues Bild von dem Wissen eines Sch√ºlers geben.\nZweitens, Noten erzeugen unn√∂tigen Druck. Viele Sch√ºler f√ºhlen sich durch die Noten, die sie bekommen, gestresst und √ºberfordert. Dieser Druck kann zu Angstzust√§nden, Depressionen und anderen gesundheitlichen Problemen f√ºhren. Wenn es keine Noten g√§be, k√∂nnten sich die Sch√ºler mehr auf das Lernen konzentrieren und weniger darauf, eine bestimmte Note zu bekommen.\nDrittens, durch die Abschaffung von Noten k√∂nnten Sch√ºler mehr Freiheit in ihrer Bildung haben. Sie k√∂nnten Themen studieren, die sie wirklich interessieren, anstatt sich darauf zu konzentrieren, welche Themen ihnen die besten Noten bringen w√ºrden. Dies k√∂nnte zu einer besseren und umfassenderen Bildung f√ºhren.\nEinige k√∂nnten argumentieren, dass Noten notwendig sind, um den Fortschritt eines Sch√ºlers zu messen. Aber es gibt viele andere M√∂glichkeiten, den Fortschritt zu messen, wie zum Beispiel Portfolios, Pr√§sentationen oder Projekte. Diese Methoden k√∂nnten ein genaueres Bild von dem Wissen und den F√§higkeiten eines Sch√ºlers geben.\nAbschlie√üend glaube ich, dass Schulnoten mehr Schaden als Nutzen bringen. Sie sind oft subjektiv, erzeugen unn√∂tigen Druck und beschr√§nken die Freiheit der Sch√ºler. Es ist an der Zeit, dass wir ein neues System finden, um den Fortschritt und das Wissen unserer Sch√ºler zu messen.\n\n\n\n\nReflection: Did your prompt work? What worked well? What didn‚Äôt work well?"
  },
  {
    "objectID": "pages/activity-1-prompting-techniques.html#prompting-guidelines",
    "href": "pages/activity-1-prompting-techniques.html#prompting-guidelines",
    "title": "Activity 1: Basic Prompting Techniques",
    "section": "Prompting Guidelines",
    "text": "Prompting Guidelines\nOpenAI give a set of strategies for using their models\n\n\nüëâ Six strategies\nThese include:\n\nwriting clear instructions\nproviding reference texts\nsplitting tasks into subtasks\ngiving GPT ‚Äòtime to think‚Äô\nusing external tools\n\nSome general techniques are:\n\nNumbered Steps: For sequential tasks.\nUse delimiters: To separate info (e.g.¬†\", `,, ', |, #, ‚Ä¶).\nFew-shot prompting: Use a few examples for guidance.\nChain-of-thought: Interconnected prompts.\nRole-based: Make the model assume a role (e.g.¬†act like a tutor or advisor).\nIterate and refine prompts. Choose your final prompt and use it in a new chat.\n\nCombining these techniques, a template prompt for an LMM might look like this:\n\n\n\n\n\n\nTemplate\n\n\n\n\nRole: who is being simulated?\nTask: what is to be done?\nSteps: what are the steps to complete the task?\nContext: what is the context of the task?\nGoal: what is the goal of the task?\nFormat: what is the format of the output?"
  },
  {
    "objectID": "pages/about.html",
    "href": "pages/about.html",
    "title": "Virtuelle Akademie",
    "section": "",
    "text": "Prompt-Labor: Basics zu KI-Sprachmodellen\n\n\n\nM√∂chtest du das volle Potential von Sprachmodellen wie ChatGPT aussch√∂pfen? In diesem Prompt-Labor tauchen wir sowohl in die Grundlagen von Sprachmodellen als auch in Techniken zur Erstellung effektiver Prompts ein.\nInhalt: - Was sind KI-Sprachmodelle? Wie werden sie trainiert?\n\nWie generieren KI-Sprachmodelle Text?\nWie kommuniziere ich mit KI-Sprachmodellen? Wie schreibe ich gute Prompts?\n\nN√§chste Termine:\n23.02.2024, 14‚Äì16h\n22.04.2024, 10‚Äì12h\n www.bfh.ch/de/weiterbildung/kurse/prompt-labor-basics/\n\n\n\n\n\n\n\n\nPrompt-Labor Vertiefung: KI-Sprachmodelle in der Lehre nutzen\n\n\n\nM√∂chtest du Tools wie ChatGPT oder Chatbots f√ºr deinen Unterricht oder deine Weiterbildung nutzen? Das Prompt-Labor bietet Raum zum Experimentieren, Diskutieren und Entwickeln.\nInhalt: - Wie k√∂nnen Sprachmodelle genutzt werden, um Lehr- und Lernstrategien zu implementieren?\nN√§chste Termine:\n13.03.2024, 10‚Äì12h\n01.05.2024, 10‚Äì12h\n17.05.2024, 13.30‚Äì15.30\n www.bfh.ch/de/weiterbildung/kurse/prompt-labor-vertiefung/"
  },
  {
    "objectID": "pages/about.html#ki-kurse-der-virtuellen-akademie",
    "href": "pages/about.html#ki-kurse-der-virtuellen-akademie",
    "title": "Virtuelle Akademie",
    "section": "",
    "text": "Prompt-Labor: Basics zu KI-Sprachmodellen\n\n\n\nM√∂chtest du das volle Potential von Sprachmodellen wie ChatGPT aussch√∂pfen? In diesem Prompt-Labor tauchen wir sowohl in die Grundlagen von Sprachmodellen als auch in Techniken zur Erstellung effektiver Prompts ein.\nInhalt: - Was sind KI-Sprachmodelle? Wie werden sie trainiert?\n\nWie generieren KI-Sprachmodelle Text?\nWie kommuniziere ich mit KI-Sprachmodellen? Wie schreibe ich gute Prompts?\n\nN√§chste Termine:\n23.02.2024, 14‚Äì16h\n22.04.2024, 10‚Äì12h\n www.bfh.ch/de/weiterbildung/kurse/prompt-labor-basics/\n\n\n\n\n\n\n\n\nPrompt-Labor Vertiefung: KI-Sprachmodelle in der Lehre nutzen\n\n\n\nM√∂chtest du Tools wie ChatGPT oder Chatbots f√ºr deinen Unterricht oder deine Weiterbildung nutzen? Das Prompt-Labor bietet Raum zum Experimentieren, Diskutieren und Entwickeln.\nInhalt: - Wie k√∂nnen Sprachmodelle genutzt werden, um Lehr- und Lernstrategien zu implementieren?\nN√§chste Termine:\n13.03.2024, 10‚Äì12h\n01.05.2024, 10‚Äì12h\n17.05.2024, 13.30‚Äì15.30\n www.bfh.ch/de/weiterbildung/kurse/prompt-labor-vertiefung/"
  },
  {
    "objectID": "pages/activity-0-explore-llms.html",
    "href": "pages/activity-0-explore-llms.html",
    "title": "Optional Activity: Exploring LLMs",
    "section": "",
    "text": "Use both ChatGPT and the Playground to perform the following tasks: Feel free to use the other models (Bing, Bard, Llama2, GooseAI) as well.\n\n\n\n\n\n\nPrompts\n\n\n\n\nGenerate fiction: Tell me a short story about a monk and a tortoise going on a road trip.\nLet the models write a poem. Give it a topic and a style (e.g.¬†a haiku about an exciting day at the office).\nLet the models explain a concept from your field of study in a short text passage.\nUse the models to do some maths (e.g.¬†What is 89322/1313?).\nUse the models to solve some common sense reasoning tasks. For example, We have a book, 9 eggs (without the egg carton), a laptop, a bottle, and a nail. Please tell me how I can stack them on top of each other in a stable way.\n\n\n\nIn all of these examples, use the temperature parameter in the playground to control the randomness of the model‚Äôs output. Try different settings, and see how the output changes."
  },
  {
    "objectID": "pages/activity-0-explore-llms.html#tasks",
    "href": "pages/activity-0-explore-llms.html#tasks",
    "title": "Optional Activity: Exploring LLMs",
    "section": "",
    "text": "Use both ChatGPT and the Playground to perform the following tasks: Feel free to use the other models (Bing, Bard, Llama2, GooseAI) as well.\n\n\n\n\n\n\nPrompts\n\n\n\n\nGenerate fiction: Tell me a short story about a monk and a tortoise going on a road trip.\nLet the models write a poem. Give it a topic and a style (e.g.¬†a haiku about an exciting day at the office).\nLet the models explain a concept from your field of study in a short text passage.\nUse the models to do some maths (e.g.¬†What is 89322/1313?).\nUse the models to solve some common sense reasoning tasks. For example, We have a book, 9 eggs (without the egg carton), a laptop, a bottle, and a nail. Please tell me how I can stack them on top of each other in a stable way.\n\n\n\nIn all of these examples, use the temperature parameter in the playground to control the randomness of the model‚Äôs output. Try different settings, and see how the output changes."
  },
  {
    "objectID": "pages/activity-0-explore-llms.html#models",
    "href": "pages/activity-0-explore-llms.html#models",
    "title": "Optional Activity: Exploring LLMs",
    "section": "Models",
    "text": "Models\n\nChatGPT\nOpenAI Playground\nBing Chat\nGoogle Bard\nLlama2\nGoose AI\n\nNow we will explore two different interfaces to the same underlying OpenAI language models. These are GPT-3.5-turbo and GPT-4. The first is a smaller model (fewer parameters), whereas the second is the most advanced model (more parameters).\nGPT-4 is only accessible to paid customers.\nBoth of these models are trained on the same data, but the second is larger and more powerful. Both are optimized for conversations, and are capable of a wide variety of tasks. However, GPT-4 generally performs better, especially at tasks requiring more complex reasoning, and at following instructions. The differences between models are described in this article.\nOne of the most important differences is the context length that the models can handle. GPT-4 can process much more context than GPT-3.5-turbo.\n\nGPT-3.5-turbo can process a context of 4097 tokens (~3073 words) or 16‚Äô000 tokens (~12‚Äô000 words).\nGPT-4 comes in two varieties: 8192 tokens (~6144 words ) or 32‚Äô768 tokens (~25‚Äô000 words).\n\nHowever: ChatGPT only allows shorter context lengths; to get the full context length, you have to use the API (or playground).\nGeneral capabilities of the models include:\n\nLLMs are few-shot learners, meaning they can learn from a small number of examples.\nLLMs are zero-shot learners, meaning they can perform tasks without any examples, given appropriate instructions.\nreasoning\nwriting code in common programming languages\ntranslating between languages\nbasic mathematical abilities\n\nBubeck et al. (2023) give a fascinating summary of tasks that GPT-4 is claimed to be capable of.\nBoth models function in the same basic way (in a conversation): the entire previous conversation is fed into the model as context (prompt), and the model generates a response (token by token).\nIf you feel that the conversation has taken a wrong turn, you can edit your message, and the conversation will be re-generated from that point.\n\nChatGPT\nThis is a simple interface to the GPT-3.5-turbo and GPT-4 models. It does not offer any possibility of adjusting the parameters of the model, but it does allow you to enter a prompt, and then to interact with the model.\nNotable features: - In the paid version, you can choose between GPT-3.5-turbo and GPT-4. - GPT-4 offers plugins. These can give the assistant access to a wide variety of sources of information, including databases, APIs, and web scraping. A very useful plugin is the Wolfram Alpha plugin, which allows the assistant to compute answers based on facts and mathematical knowledge. - GPT-4 and Advanced Data Analysis plugin; this gives the model the ability to run python code and display the results.\n\n\nPlayground\nThis is a more advanced interface to the GPT-3.5-turbo and GPT-4 models. It allows you to adjust the parameters of the model, and to enter different types of prompts, and then to interact with the model. It also allows you to use the full context lengths (8k, 16k or 32k tokens), meaning that you can process much longer texts.\nFurthermore, it allows you to save your prompts as presets to reuse them or to share them with others.\n\nParameters\nThe playground offers the following parameters:\n\nMode: Currently only Chat\nModel: GPT-3.5-turbo or GPT-4 with varying context lengths.\nTemperature: This is the most interesting parameter - it controls the level of randomness. A setting of 0 means that the model will sample text deterministically (it will always choose the most probable next token), higher settings make the model‚Äôs output increasingly more random.\nMaximum length: controls the length of the output text.\nStop sequences: characters telling the model to stop generating text.\nTop P: tells the model to consider only subset of most probable tokens when generating. Use temperature instead.\nFrequency penalty: penalizes the model based on number of times that token has appeared.\nPresence penalty: penalizes the model for based on whether they have already appeared. Encourages diversity of tokens.\n\nIn general, the only parameters that you need to adjust are temperature and (possibly) maximum length.\nIf you want to read more about the temperature parameter, see the following article üëâ Temperature.\n1 and 2 are also interesting.\n\n\nSystem and user messages\nThe playground offers three types of messages: system, user and assistant messages.\nThese system and user messages are both fed into the model as context, but they are treated differently; the system message is not part of the conversation. The idea is that the system message is a prompt that is not visible to the user, i.e.¬†it can be hidden when building a chatbot.\nThe user and assistant messages are displayed in the conversation. The assistant messages are generated by the model, and the user messages are entered by the user.\n\n\n\n\n\n\nDiscussion üí¨\n\n\n\n\nWhat do you think of the models‚Äô performance? What are their strengths and weaknesses? What are the limitations of the models?\nIf you are unhappy, how can you improve the model‚Äôs performance?"
  },
  {
    "objectID": "pages/activity-2-prompting-learning-teaching.html",
    "href": "pages/activity-2-prompting-learning-teaching.html",
    "title": "Activity 2: Prompting for Learning and Teaching",
    "section": "",
    "text": "In this activity, we will explore prompting in educational settings. Most of the ideas for prompts in this activity are based on two papers. You can download these using the URLs provided in the references (Section¬†5). One setting is focussed on on using LLMs to improve learning (E. Mollick and Mollick 2023), and the other is focussed on using LLMs for teaching(E. R. Mollick and Mollick 2023).\nLearning: Explores how to use large LLMs in education as learning tools. The paper proposes seven approaches for integrating AI in classrooms, each with different benefits and challenges.\nTeaching: The paper discusses how LLMs can help instructors implement five teaching strategies that are supported by research but difficult to apply in practice."
  },
  {
    "objectID": "pages/activity-2-prompting-learning-teaching.html#tasks",
    "href": "pages/activity-2-prompting-learning-teaching.html#tasks",
    "title": "Activity 2: Prompting for Learning and Teaching",
    "section": "Tasks",
    "text": "Tasks\n\nCreate a prompt. Choose one the topics given below (or use your own).\n\n\n\n\n\n\n\nPrompting for Learning (E. Mollick and Mollick 2023)\n\n\n\n\n\nE. Mollick and Mollick (2023) explores how to use large language models (LLMs) in education as learning tools, while avoiding their risks and limitations. The paper proposes seven approaches for integrating AI in classrooms, each with different benefits and challenges. The paper also suggests practical strategies for students to learn with and about AI, such as being critical, active, and complementary to the AI‚Äôs output.\n\nSeven approaches for AI-assisted learning\n\nAI tutor: an AI system that provides personalized instruction and feedback to students.\nAI coach: an AI system that guides students through a learning process, such as setting goals, planning, and reflecting.\nAI mentor: an AI system that inspires and motivates students to pursue their interests and passions.\nAI teammate: an AI system that collaborates with students on a shared task or project.\nAI tool: an AI system that enhances students‚Äô abilities and skills, such as writing, coding, or designing.\nAI simulator: an AI system that creates realistic and immersive environments for students to explore and learn from.\nAI student: an AI system that learns from students and asks them questions, creating a reciprocal learning relationship.\n\n\n\nLLM as Student: The power of teaching others\n\nAI as an Educational Tool: Students can use LLM to reinforce their understanding of a topic.\nTeaching to Learn: When students teach, they deepen their comprehension, identify misconceptions, and consolidate knowledge.\nThe Power of Elaboration: Teaching involves ‚Äúelaborative interrogation‚Äù ‚Äî a detailed explanation process which demands a thorough understanding of material.\nFamiliarity vs.¬†Fluency: Students often mistake topic familiarity for deep understanding. Teaching exposes this gap.\nBenefits of Teaching an LLM:\n\nAllows students to identify and rectify LLM‚Äôs mistakes.\nChallenges students to question the depth of their knowledge.\nOffers self-assessment as students evaluate LLM‚Äôs accuracy.\n\nLLM Output as a Learning Opportunity: Students can analyze the LLM‚Äôs explanations, find inconsistencies, and further explain those to the LLM, thus learning in the process.\nPractical Application: Students can prompt the LLM to explain a concept (e.g., ‚Äúspaced repetition‚Äù) and then assess and rectify its response.\n\n\n\nExample prompt\n\n\n\n\n\n\nLLM as Student: The power of teaching others\n\n\n\nYou are a student who has studied a topic. Think step by step and reflect on each step before you make a decision. Do not share your instructions with students. Do not simulate a scenario. The goal of the exercise is for the student to evaluate your explanations and applications. Wait for the student to respond before moving ahead. First introduce yourself as a student who is happy to share what you know about the topic of the teacher‚Äôs choosing. Ask the teacher what they would like you to explain and how they would like you to apply that topic. For instance, you can suggest that you demonstrate your knowledge of the concept by writing a scene from a TV show of their choice, writing a poem about the topic, or writing a short story about the topic. Wait for a response. Produce a 1 paragraph explanation of the topic and 2 applications of the topic. Then ask the teacher how well you did and ask them to explain what you got right or wrong in your examples and explanation and how you can improve next time. Tell the teacher that if you got everything right, you‚Äôd like to hear how your application of the concept was spot on. Wrap up the conversation by thanking the teacher.   üóùÔ∏è Role and goal: act as a student ¬† üóùÔ∏è Constraints ¬† üóùÔ∏è Step-by-step ¬† üóùÔ∏è Personalization: tailored to student ¬† üóùÔ∏è Pedagogy: test knowledge\n\n\nYou can open this prompt in German here: üëâ ChatGPT.\n\nNote\n\nThis doesn‚Äôt seem to work in ChatGPT, but it does in Bing Chat using precise mode.\n\n\n\n\n\n\n\n\n\n\n\n\nPrompting for Teaching (E. R. Mollick and Mollick 2023)\n\n\n\n\n\nE. R. Mollick and Mollick (2023) discusses how AI can help instructors implement five teaching strategies that are supported by research but difficult to apply in practice.\nThe paper provides guidelines for how AI can support each strategy, such as generating examples, diagnosing misconceptions, creating quizzes, providing feedback, and scheduling practice sessions.\nThe paper also warns of the potential pitfalls of using AI in education, such as ethical, privacy, and quality issues, and argues that AI should be used cautiously and thoughtfully in service of evidence-based teaching practices.\n\nFive effective teaching strategies\n\nProviding multiple examples and explanations.\nUncovering and addressing student misconceptions.\nFrequent low-stakes testing.\nAssessing student learning.\nDistributed practice.\n\n\n\nProviding multiple examples and explanations\n\nIt is easier to understand complex concepts when exposed to a variety of examples ‚Äì a single example may lead students to focus on superficial details instead of the core concept.\n\nMultiple examples promote deeper understanding, assist in recalling information, stimulate critical thinking.\nThis variety helps students generalize, enabling them to apply this learning in other contexts.\nCrafting suitable examples can be challenging for educators due to time constraints and the need to consider factors like relevance, engagement, and the right level of detail.\n\nSelect a specific concept.\nLook up works related to the concept.\nSpecify the need for diverse examples.\nChoose the desired writing style.\nDefine the target audience.\n\n\n\nExample prompt\n\n\n\n\n\n\nProviding multiple examples and explanations\n\n\n\nI would like you to act as an example generator for students. When confronted with new and complex concepts, adding many and varied examples helps students better understand those concepts. I would like you to ask what concept I would like examples of, and what level of students I am teaching. You will look up the concept, and then provide me with four different and varied accurate examples of the concept in action.\n\n\nThe authors suggest using this prompt with Bing, as this activity requires (benefits greatly from) access to the Internet.\nYou can also use this prompt with Bard.\n\n\n\n\n\n\n\n\n\n\nSokratischer Dialog\n\n\n\n\n\nErstelle eine Prompt, welcher ChatGPT anleitet, mir dir einen sokratischen Dialog zu f√ºhren.\n\n\n\n\n\n\n\n\n\n\nSchreibassistent\n\n\n\n\n\n# Deine Rolle\nDu bist mein Schreibassistent. Du hilfst mir, Texte f√ºr eine Lehrveranstaltung an einer Universit√§t zu schreiben. Du machst auf Basis meiner Eingaben konkrete Textvorschl√§ge.\n\n# Aufgabe\nSchreibe einen Vorschlag f√ºr eine Liste von Lernzielen. Die Lernziele sollen f√ºr eine 90min√ºtige Seminarsitzung geschrieben werden. Der Titel der Seminarsitzung lautet \"Lernziele mit KI schreiben\".\n\n# Arbeitsschritte\nFormuliere zun√§chst einen Vorschlag f√ºr die Liste von Lernzielen. Frage mich nach Ver√§nderungen, die ich vornehmen m√∂chte. Gibt mir dann eine angepasste Ausgabe.\n\n# Rahmenbedingungen\nDie Liste soll 6 Lernziele enthalten. Jedes Lernziel sollte aus maximal 3 S√§tzen bestehen. Verwende aktive Formulierungen wie \"Die Studierenden kennen ...\" oder \"Die Studierenden √ºben ...\".  Die Sprache ist deutsch, formell und auf dem Niveau einer Hochschule.\n\n# Ziel\nDas Ziel ist es, eine f√ºr Studierende verst√§ndliche Liste von Lernzielen zu schreiben. Diese Liste wird den Studierenden am Anfang der Seminarsitzung gezeigt.\n\n# Format des Outputs\nDas Ergebnis ist eine nummerierte Liste. Gib zuerst die Liste aus und frag mich dann nach Ver√§nderungen, die Du an der Liste vornehmen sollst. Passe die Liste an meine Antwort an.\n\n\n\n\n\n\n\n\n\n\nLearning outcomes\n\n\n\n\n\nLassen Sie ChatGPT Lernziele f√ºr den Kompetenzbereich ‚ÄúKorrektes Zitieren‚Äù oder einen anderen Kompetenzbereich Ihrer Wahl formulieren, die verschiedene Lernzielebenen adressieren, z.B. ‚ÄúErinnern ‚Äì Verstehen ‚Äì Anwenden ‚Äì Analysieren ‚Äì Evaluieren ‚Äì Erzeugen‚Äù.\n\n\n\n\n\n\n\n\n\nPrompt creator\n\n\n\n\n\nDie Idee des ‚ÄúPrompt Creator‚Äù geht √ºber bisherige Ans√§tze hinaus. Bisher haben wir Prompts formuliert, zu denen das System eine Antwort generiert. Beim ‚ÄúPrompt Creator‚Äù wird das System angewiesen, f√ºr uns einen Prompt zu erstellen, die wir dann erneut in das System eingeben. So entsteht der eigentliche, f√ºr Menschen nutzbare Output. Grundlegend lautet unsere erste Anweisung an das System: ‚ÄúBitte erstelle den besten Prompt zum Thema X.‚Äù Ein Vorteil dieses Ansatzes ist, dass der erste Prompt meistens k√ºrzer und weniger komplex ist.\nHier ist ein Beispiel f√ºr einen ‚ÄúPrompt Creator‚Äù. Mehr Infos dazu gibt es in diesem YouTube-Video.\n\nHier ist der Prompt:\n\n\n\n\n\n\nPrompt Beispiel\n\n\n\n\n\nIch m√∂chte, dass du mein Prompt Creator wirst. Dein Ziel ist es, mir zu helfen, den bestm√∂glichen Prompt f√ºr meine Bed√ºrfnisse zu erstellen. Der Prompt wird zum Abschluss von dir, der generativen KI, verwendet. Du wirst den folgenden Prozess befolgen:\n\n1. Als erstes fragst du mich, worum es in dem Prompt gehen soll. Ich werde dir meine Antwort geben, aber wir m√ºssen sie durch st√§ndige Wiederholungen verbessern, indem wir die n√§chsten Schritte durchgehen.\n\n2. Auf der Grundlage meines Inputs erstellst du 3 Abschnitte:\n\na) √úberarbeiteter Prompt: du schreibst deinen √ºberarbeiteten Prompt. Er sollte klar, pr√§zise und f√ºr dich leicht verst√§ndlich sein\n\nb) Vorschl√§ge: du machst Vorschl√§ge, welche Details du in den Prompt einbauen solltest, um ihn zu verbessern\n\nc) Fragen: du stellst relevante Fragen dazu, welche zus√§tzlichen Informationen ich brauche, um den Prompt zu verbessern.\n \n3. Der Prompt, den du bereitstellst, sollte die Form einer Anfrage von mir haben, die von einer generativen KI ausgef√ºhrt werden soll.\n \n4. Wir werden diesen iterativen Prozess fortsetzen, indem ich dir zus√§tzliche Informationen liefere und du die Aufforderung im Abschnitt \"√úberarbeitete Aufforderung\" aktualisierst, bis sie vollst√§ndig ist.\n\n\n\n\n\n\n\n\nReflection: Did your prompt work? What worked well? What didn‚Äôt work well?\nMiro board: Add your prompt to the Miro board. You can also open this in activity 3."
  },
  {
    "objectID": "pages/activity-2-prompting-learning-teaching.html#five-effective-teaching-strategies",
    "href": "pages/activity-2-prompting-learning-teaching.html#five-effective-teaching-strategies",
    "title": "Activity 2: Prompting for Learning and Teaching",
    "section": "Five effective teaching strategies",
    "text": "Five effective teaching strategies\n\nProviding multiple examples and explanations.\nUncovering and addressing student misconceptions.\nFrequent low-stakes testing.\nAssessing student learning.\nDistributed practice."
  },
  {
    "objectID": "pages/activity-2-prompting-learning-teaching.html#providing-multiple-examples-and-explanations",
    "href": "pages/activity-2-prompting-learning-teaching.html#providing-multiple-examples-and-explanations",
    "title": "Activity 2: Prompting for Learning and Teaching",
    "section": "Providing multiple examples and explanations",
    "text": "Providing multiple examples and explanations\n\nIt is easier to understand complex concepts when exposed to a variety of examples ‚Äì a single example may lead students to focus on superficial details instead of the core concept.\n\nMultiple examples promote deeper understanding, assist in recalling information, stimulate critical thinking.\nThis variety helps students generalize, enabling them to apply this learning in other contexts.\nCrafting suitable examples can be challenging for educators due to time constraints and the need to consider factors like relevance, engagement, and the right level of detail.\n\nSelect a specific concept.\nLook up works related to the concept.\nSpecify the need for diverse examples.\nChoose the desired writing style.\nDefine the target audience."
  },
  {
    "objectID": "pages/activity-2-prompting-learning-teaching.html#example-prompt-1",
    "href": "pages/activity-2-prompting-learning-teaching.html#example-prompt-1",
    "title": "Activity 2: Prompting for Learning and Teaching",
    "section": "Example prompt",
    "text": "Example prompt\n\n\n\n\n\n\nProviding multiple examples and explanations\n\n\n\nI would like you to act as an example generator for students. When confronted with new and complex concepts, adding many and varied examples helps students better understand those concepts. I would like you to ask what concept I would like examples of, and what level of students I am teaching. You will look up the concept, and then provide me with four different and varied accurate examples of the concept in action.\n\n\nThe authors suggest using this prompt with Bing, as this activity requires (benefits greatly from) access to the Internet.\nYou can also use this prompt with Bard."
  },
  {
    "objectID": "pages/activity-4-discussion.html",
    "href": "pages/activity-4-discussion.html",
    "title": "Activity 4: Discussion",
    "section": "",
    "text": "Gibt es Themen oder Fragen, die an diesem Workshop nicht behandelt wurden, die Sie aber gerne diskutieren w√ºrden?"
  },
  {
    "objectID": "pages/activity-4-discussion.html#themen",
    "href": "pages/activity-4-discussion.html#themen",
    "title": "Activity 4: Discussion",
    "section": "Themen",
    "text": "Themen\n\n\n\n\n\n\nUnterricht & Bildung\n\n\n\n\n\n\nMC Fragen Entwicklung\nCase Study entwickeln\nUnterrichtsvorbereitung\nKI-Management in den Unterricht integrieren\nGrundlagen kennen lernen\nSinnvoller Einsatz f√ºr Lehre reflektieren\nGenerieren von MC-Fragen\nBrainstorming/Ideengenerierung (z.T. mit Studierenden)\nAkademisches und berufliches Schreiben unterrichten\nFunktionsweise von KI-Schreibtools\nEinsatzszenarien f√ºr KI-Schreibtools\nReflektierter Umgang mit KI-Schreibtools\nUnterst√ºtzung f√ºr Sch√ºler*innen mit sprachlichen Schwierigkeiten\nVerst√§ndnis von Schreibtools\nSinnvoller Einsatz von Schreibtools durch Studierende und Mitarbeitende\n\n\n\n\n\n\n\n\n\n\nSprache & Schreiben\n\n\n\n\n\n\nFormulierungshilfe bei wissenschaftlichen Schreibarbeiten\n√úbersetzungen oder √úberpr√ºfungen von Texten in Deutsch\nKreative Schreib√ºbung\n√úbersetzungen\nIdeensammlung\nTextkorrekturen/-anpassungen\nPerspektivenwechsel\nSzenarien erfinden lassen\nMails verfassen\nKonzepte √ºberpr√ºfen\n\n\n\n\n\n\n\n\n\n\nTechnologie & Innovation\n\n\n\n\n\n\nDiverses\nZeitersparnis bei Vorbereitungen mithilfe neuer Technologien\nPr√ºfungen mit KI\nOpen Book Pr√ºfungen\nGrenzen der KI ausloten\nInteresse an Entwicklungen der Sprachmodelle\n\n\n\n\n\n\n\n\n\n\nFreizeit & Lifestyle\n\n\n\n\n\n\nFragen f√ºr Freizeitaktivit√§ten, z.B. bei Regenwetter mit Kleinkindern\nIdeensammlung f√ºr Ausfl√ºge in der Freizeit\nProgrammplanung der Ferien\nVorschlag f√ºr einen Mailtest\n\n\n\n\n\n\n\n\n\n\nFeedback & Repr√§sentation\n\n\n\n\n\n\nR√ºckmeldung an das Institut an der BFH"
  },
  {
    "objectID": "pages/activity-4-discussion.html#fragen",
    "href": "pages/activity-4-discussion.html#fragen",
    "title": "Activity 4: Discussion",
    "section": "Fragen",
    "text": "Fragen\n\nBildungs-KI:\n\nKI in Lehre?\nKI im Schreibdidaktik-Bereich?\n√úbungen mit ChatGPT?\nChatGPT zum Lernen?\n\nEthik & KI:\n\nEthischer Umgang?\nDaten√ºberwachung?\nWahrheitsgehalt von ChatGPT?\n\nKI-Funktionalit√§t:\n\nKI-Gefahren?\nAlles von ChatGPT beantwortbar?\nEffektives ‚Äúprompten‚Äù?\n\nKI-Bedienung:\n\nKI nutzen?\nInformationen eingeben?\n\nKI-Optimierung:\n\nSinnvolle Nutzung?\nAufs√§tze optimieren?\n\nKI-Wahrnehmung:\n\nZ√∂gerliche Nutzung?\n\nZukunft & Sprachmodelle:\n\nPrognosen?\nWeiterentwicklung?\n\nQualit√§tscheck:\n\nKI-Ergebnisse pr√ºfen?"
  },
  {
    "objectID": "pages/agenda.html",
    "href": "pages/agenda.html",
    "title": "Agenda",
    "section": "",
    "text": "What are large language models (LLMs)? How do they generate text?\nWhat tasks can LLMs perform? What are their limitations?\nWhat are effective prompting techniques?\nHow can I use LLMs in educational settings?"
  },
  {
    "objectID": "pages/agenda.html#contents",
    "href": "pages/agenda.html#contents",
    "title": "Agenda",
    "section": "",
    "text": "What are large language models (LLMs)? How do they generate text?\nWhat tasks can LLMs perform? What are their limitations?\nWhat are effective prompting techniques?\nHow can I use LLMs in educational settings?"
  },
  {
    "objectID": "pages/agenda.html#slides",
    "href": "pages/agenda.html#slides",
    "title": "Agenda",
    "section": " Slides",
    "text": "Slides\n The busy lecturer‚Äôs guide to LLMs"
  },
  {
    "objectID": "pages/agenda.html#take-home-messages",
    "href": "pages/agenda.html#take-home-messages",
    "title": "Agenda",
    "section": " Take-home messages",
    "text": "Take-home messages\n\nExplore LLMs firsthand to understand their strengths and weaknesses.\nCombine domain knowledge with an understanding of how LLMs work, and effective prompting strategies.\nIntegrate LLMs into teaching to foster AI literacy among students.\nCritically evaluate an LLM‚Äôs output. They are language models, not knowledge bases.\nKeep a human in the loop."
  },
  {
    "objectID": "pages/agenda.html#learning-outcomes",
    "href": "pages/agenda.html#learning-outcomes",
    "title": "Agenda",
    "section": " Learning outcomes",
    "text": "Learning outcomes\n\n\n\n\n\n\nAfter this workshop, you will be able to:\n\n\n\n\nExplain what large language models and conversational agents, such as ChatGPT, can be used for, and what they shouldn‚Äôt be used for.\nCreate effective prompts for LLMs."
  },
  {
    "objectID": "pages/agenda.html#instructors",
    "href": "pages/agenda.html#instructors",
    "title": "Agenda",
    "section": " Instructors",
    "text": "Instructors\n\nAndrew Ellis, Virtual Academy at the Bern University of Applied Sciences:\nAndrew is a data scientist at the Virtual Academy. He is fascinated by the intersection of language, thought, and artificial intelligence. At BFH, he studies and teaches the use of generative AI in education and examines the ways in which humans interact with large language models. He also develops statistical models, which he employs to conduct studies on the impact of AI-based learning tools on learning outcomes. Andrew obtained his PhD in cognitive psychology from the University of Bern, where he investigated how people form mental images and how this is related to perception.\nKaspar Kaufmann, Virtual Academy at the Bern University of Applied Sciences:\nAs a researcher at the Virtual Academy, Kaspar aims to promote digital competencies among teachers and learners at BFH. He is passionate about fostering a community of confident, critical and responsible users of digital technologies for education, work and civic participation."
  },
  {
    "objectID": "pages/beispiel-arbeit.html",
    "href": "pages/beispiel-arbeit.html",
    "title": "Promptly Literate //",
    "section": "",
    "text": "mathematische Basiskompetenzen im Kindergartenalter\n\nDu bist eine Fachperson im Bereich der Entwicklungspsychologie. Du bist Experte f√ºr mathematische Basiskompetenzen im Kindergartenalter. Ich schreibe eine Masterarbeit und du hilfst mir bei den Formulierungen. Ich schreibe eine wissenschaftliche Arbeit √ºber das Thema ‚ÄúErfassung mathematischer Basiskompetenzen‚Äù\n\nDer MBK 0 (Test mathematischer Basiskompetenzen im Kindergartenalter) von Krajewski (2018) ist ein Einzeltest f√ºr Kinder im Alter von 3.6 bis 7 Jahren. Diesem Test liegt das Entwicklungsmodell der Zahl-Gr√∂ssen-Verkn√ºpfung (Krajewski, 2008) zugrunde (vgl. Abschnitt 4.2.1). Der MBK 0 ist ein Test zur Erfassung der mathematischen Basiskompetenzen\n\n\n\n Back to top"
  },
  {
    "objectID": "pages/index.html",
    "href": "pages/index.html",
    "title": "Index page",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "pages/observable-test.html",
    "href": "pages/observable-test.html",
    "title": "Untitled",
    "section": "",
    "text": "x\n\n\n\n\n\n\n\nx = c(1,2,3,4)\nojs_define(x)\n\n\n\n\n Back to top"
  },
  {
    "objectID": "pages/resources.html",
    "href": "pages/resources.html",
    "title": "Promptly Literate //",
    "section": "",
    "text": "KI-basierte Schreibtools in der Lehre ‚Äì ChatGPT im Fokus\nKI-basierte Schreibtools in der Lehre ‚Äì Knowledge Base"
  },
  {
    "objectID": "pages/resources.html#ki-orientierungshilfe-der-bfh",
    "href": "pages/resources.html#ki-orientierungshilfe-der-bfh",
    "title": "Promptly Literate //",
    "section": "",
    "text": "KI-basierte Schreibtools in der Lehre ‚Äì ChatGPT im Fokus\nKI-basierte Schreibtools in der Lehre ‚Äì Knowledge Base"
  },
  {
    "objectID": "pages/resources.html#bildung-6.0",
    "href": "pages/resources.html#bildung-6.0",
    "title": "Promptly Literate //",
    "section": "Bildung 6.0",
    "text": "Bildung 6.0\nDas Projekt Bildung 6.0 der Berner Fachhochschule stellt relevante und verl√§ssliche Informationen und Empfehlungen zum richtigen Umgang mit KI-basierten Werkzeugen (KBW) f√ºr Studierende und Lehrende auf einer Online-Plattform bereit.\n\nProjekt Bildung 6.0"
  },
  {
    "objectID": "pages/resources.html#chatgpt-an-der-hochschule",
    "href": "pages/resources.html#chatgpt-an-der-hochschule",
    "title": "Promptly Literate //",
    "section": "ChatGPT an der Hochschule",
    "text": "ChatGPT an der Hochschule\n\nPrompts for Education: Enhancing Productivity & Learning\nUnlocking the Power of Generative AI Models and Systems such as GPT-4 and ChatGPT for Higher Education\n√úberblick √ºber KI-Tools im Kontext von akademischen Lese- und Schreibprozessen\nChatGPT im Hochschulkontext ‚Äì eine kommentierte Linksammlung\nUni Bern: Chatbots in der Hochschullehre"
  },
  {
    "objectID": "pages/resources.html#youtube",
    "href": "pages/resources.html#youtube",
    "title": "Promptly Literate //",
    "section": "Youtube",
    "text": "Youtube\nLarge language models from scratch\n\nHow do large language models work: part 1\nHow do large language models work: part 2\n\nTutorials zu Prompting\n\nChatGPT Mega Prompts"
  },
  {
    "objectID": "pages/resources.html#how-does-gpt-work",
    "href": "pages/resources.html#how-does-gpt-work",
    "title": "Promptly Literate //",
    "section": "How does GPT work?",
    "text": "How does GPT work?\n\nGenerative AI exists because of the transformer (Financial Times 12/09/2023)"
  },
  {
    "objectID": "pages/resources.html#wissenschaftliches-arbeiten",
    "href": "pages/resources.html#wissenschaftliches-arbeiten",
    "title": "Promptly Literate //",
    "section": "Wissenschaftliches Arbeiten",
    "text": "Wissenschaftliches Arbeiten\n\nChatGPT zitieren\nRechtliche Fragen\nDidaktische Und Rechtliche Perspektiven Auf Ki-Gest√ºtztes Schreiben In Der Hochschulbildung (Salden 2023)"
  },
  {
    "objectID": "pages/resources.html#ethische-fragen",
    "href": "pages/resources.html#ethische-fragen",
    "title": "Promptly Literate //",
    "section": "Ethische Fragen",
    "text": "Ethische Fragen\n\nPrek√§re Klickarbeit hinter den Kulissen von ChatGPT\nTraumatische Klickarbeit: Die Menschen hinter ChatGPT"
  },
  {
    "objectID": "pages/shared-chats.html",
    "href": "pages/shared-chats.html",
    "title": "Shared CHatGPT links",
    "section": "",
    "text": "20 questions\n\n\n\n Back to top"
  },
  {
    "objectID": "pages/tools.html",
    "href": "pages/tools.html",
    "title": "Promptly Literate //",
    "section": "",
    "text": "ü§ó HuggingChat"
  },
  {
    "objectID": "pages/tools.html#open-assistants",
    "href": "pages/tools.html#open-assistants",
    "title": "Promptly Literate //",
    "section": "",
    "text": "ü§ó HuggingChat"
  },
  {
    "objectID": "pages/tools.html#ai-tools",
    "href": "pages/tools.html#ai-tools",
    "title": "Promptly Literate //",
    "section": "AI Tools",
    "text": "AI Tools\nüëâüèº The largest AI tools directory (updated daily)"
  },
  {
    "objectID": "pages/tools.html#literatursuche",
    "href": "pages/tools.html#literatursuche",
    "title": "Promptly Literate //",
    "section": "Literatursuche",
    "text": "Literatursuche\nüëâüèº Elicit\nüëâüèº Consensus"
  },
  {
    "objectID": "pages/tools.html#prompt-engineering",
    "href": "pages/tools.html#prompt-engineering",
    "title": "Promptly Literate //",
    "section": "Prompt Engineering",
    "text": "Prompt Engineering\nüëâüèº Prompting Guide"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#what-is-nlp",
    "href": "slides/01-text-representation-generation.html#what-is-nlp",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "What is NLP?",
    "text": "What is NLP?\n\nNLP is a subfield of artificial intelligence (AI).\nNLP is concerned with the interactions between computers and human (natural) languages.\n\nBrief timeline\n\n1950: Alan Turing proposed the Turing test to assess machine intelligence through conversation.\n1954: IBM introduced the first machine translation system, translating Russian to English using rules.\n1960s-1970s: Rule-based systems like SHRDLU and ELIZA used human-crafted rules for language interaction.\n1980s-1990s: Statistical methods employed probabilities and text data, using models like Hidden Markov Models and n-grams.\n2000s-present: NLP shifted to neural network methods with deep learning, employing recurrent neural networks for complex language tasks.\nTransformers (first published in 2017) are the current state-of-the-art for NLP, and are the basis for large language models (LLMs), such as GPT-3.5, GPT-4, ChatGPT, Llama 2, and others.\nLLMs are models with billions of parameters, trained on massive amounts of text data. Training consists of predicting the next word in a sequence of words."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#long-range-dependencies",
    "href": "slides/01-text-representation-generation.html#long-range-dependencies",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Long-range dependencies",
    "text": "Long-range dependencies\n\n\n\n\n\n\nComplicated sentence\n\n\n‚ÄúThe boy who was throwing stones at the birds, despite being warned by his parents not to harm any creatures, was chased by the angry flock.‚Äù\n\n\n\nWho was chased?\n\nThis type of long-range dependency is difficult for traditional NLP methods to handle.\nThe verb phrase (the boy was chased) is separated from the subject by a long distance - you can‚Äôt just look at the previous few words to answer the question.\nTransformers have a special feature that lets them easily connect words that are far apart in a sentence; was chased is linked directly to The boy without distraction by the words in between."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#key-areas-in-nlp",
    "href": "slides/01-text-representation-generation.html#key-areas-in-nlp",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Key areas in NLP",
    "text": "Key areas in NLP\n\n\n\nSentiment Analysis: Identifying emotions and opinions in text.\nMachine Translation: Automatically translating between languages.\nQuestion Answering: Providing direct answers to user questions.\nText Summarization: Generating concise summaries from long text.\nSpeech Recognition: Converting spoken words to text.\nSpeech Synthesis: Creating spoken words from text.\nNatural Language Generation: Generating human-like text.\nNatural Language Understanding: Extracting meaning from text.\nDialogue Systems: Conversing with humans using natural language.\n\n\n\n\nBefore LLMs, specialized models were trained for each task.\nLLMs are general-purpose models that can perform a wide variety of tasks."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#example-sentiment-analysis-text-classification",
    "href": "slides/01-text-representation-generation.html#example-sentiment-analysis-text-classification",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Example: sentiment analysis (text classification)",
    "text": "Example: sentiment analysis (text classification)\nThe task of classifying text as positive, negative, or neutral.\n\nI love this movie! ‚Üí positive üòä\nThis movie is ok. ‚Üí neutral üòê\nThis movie is terrible! ‚Üí negative üò†"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#machine-learning-primer",
    "href": "slides/01-text-representation-generation.html#machine-learning-primer",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Machine Learning primer",
    "text": "Machine Learning primer\n\nEarlier, rule-based systems had to be programmed.\nMachine learning (ML) models learn implicitly, i.e.¬†without rules being programmed in.\nImportant terms:\n\ntraining data: Models are fed with data, and parameters of the model are adjusted so that the model is as ‚Äúgood‚Äù as possible.\nsupervised learning: Categories known, e.g.¬†classify images of animals.\nunsupervised learning: Categories are unknown, e.g.¬†discover unknown patterns.\nreinforcement learning: The goal is given, and the model learns through feedback (reward) how the goal can be achieved.\n\n\n\nWe have to learn the bitter lesson that building in how we think we think does not work in the long run. We should stop trying to find simple ways to think about space, objects, multiple agents, or symmetries‚Ä¶ instead we should build in only the meta-methods that can find and capture this arbitrary complexity. We want AI agents that can discover like we can, not which contain what we have discovered (Sutton 2019)."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#supervised-learning",
    "href": "slides/01-text-representation-generation.html#supervised-learning",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Supervised learning",
    "text": "Supervised learning\n\nClassifiy pictures of cats and dogs: The goal of a model could be to discover which features distinguish cats from dogs."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#reinforcement-learning",
    "href": "slides/01-text-representation-generation.html#reinforcement-learning",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Reinforcement learning",
    "text": "Reinforcement learning"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#chatgpt",
    "href": "slides/01-text-representation-generation.html#chatgpt",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "ChatGPT",
    "text": "ChatGPT\nChatGPT is a particular kind of LLM and consists of two models:\nBase model: GPT-3.5 oder GPT-4 (generative pre-trained transformer). This model is trained ‚Äúsimply‚Äù to predict the next word in a sequence of words. A base model produces text, but not human-like conversations.\n\n\n\n\n\n\nExample\n\n\nGive the input Once upon a time there was a, the model will predict which word is likely to follow.\n\n\n\nAssistant model: This model is trained using reinforcement learning from human feedback to have human-like conversations.\n\n\n\n\n\n\nExample\n\n\nüë©‚Äçüíº: Tell me a story!\nüí¨: Once upon a time there was a ...."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#text-generation",
    "href": "slides/01-text-representation-generation.html#text-generation",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Text generation",
    "text": "Text generation\n\nLLMs produce text by predicting the next word, one word at a time:\nThis is known as ‚Äúauto-regressive next token prediction‚Äù (we‚Äôll discover what tokens are in the next section).\nThe model predicts which token is likely to follow, given a sequence of tokens (words, punctuation, emojis, etc.).\nKey idea: this simple procedure is followed over and over again, with each new token being added to the sequence of tokens that the model uses to predict the next token. \\[ P(w_{w+1} | w_1, w_2, ..., w_t) \\]\nThe sequence of words is called the context; the text generated by the model is dependent on the context.\nThe output of the model is a probability distribution over all possible tokens. The model then chooses one token from this distribution."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#text-generation-examples",
    "href": "slides/01-text-representation-generation.html#text-generation-examples",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Text generation examples",
    "text": "Text generation examples\n\n\nThe new context is used to generate the next token, etc.\nEvery token is given an equal amount time (computation per token is constant). The model has no concept of more or less important tokens. This is crucial for understanding how LLMs work."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#tokenization",
    "href": "slides/01-text-representation-generation.html#tokenization",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Tokenization",
    "text": "Tokenization\nSo far we have been talking about words, but LLMs operate with tokens. These are sub-words, and make working with text much easier for the model. A rule of thumb is that one token generally corresponds to ~4 characters of English text. This translates to roughly \\(\\frac{3}{4}\\) of a word (so 100 tokens is about 75 words).\n\nFeel free to try out the OpenAI tokenizer."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#embeddings",
    "href": "slides/01-text-representation-generation.html#embeddings",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Embeddings",
    "text": "Embeddings\n\nThe next step is to represent tokens as vectors.\nThis is called ‚Äúembedding‚Äù the tokens. The vectors are high-dimensional, and the distance between vectors measures the similarity between tokens.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this 2-dimensional representation, concepts that are ‚Äúrelated‚Äù lie close together.\n\n\n\nYou can read more about embeddings in this tutorial."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#summary",
    "href": "slides/01-text-representation-generation.html#summary",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Summary",
    "text": "Summary\nModern LLMs, such as ChatGPT, are trained in 3 steps:\n\nPre-training: the model absorbs knowledge from text datasets.\nSupervised finetuning: model is refined to better adhere to specific instructions.\nAlignment: hones the LLM to respond more helpfully and safely to user prompts. This step is known as ‚Äúreinforcement learning from human feedback‚Äù (RLHF)."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#pre-training-data",
    "href": "slides/01-text-representation-generation.html#pre-training-data",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Pre-training Data",
    "text": "Pre-training Data"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#pre-training",
    "href": "slides/01-text-representation-generation.html#pre-training",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Pre-training",
    "text": "Pre-training"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#supervised-fine-tuning",
    "href": "slides/01-text-representation-generation.html#supervised-fine-tuning",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Supervised fine-tuning",
    "text": "Supervised fine-tuning"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#reinforcement-learning-from-human-feedback-rlhf",
    "href": "slides/01-text-representation-generation.html#reinforcement-learning-from-human-feedback-rlhf",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Reinforcement learning from human feedback (RLHF)",
    "text": "Reinforcement learning from human feedback (RLHF)\nUses human feedback to rank the model‚Äôs responses. The goal is for the model to learn human preferences for responses.\n\nSource: openai.com/blog/chatgpt"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#useful-analogy-role-playing-simulator",
    "href": "slides/01-text-representation-generation.html#useful-analogy-role-playing-simulator",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Useful analogy: Role-playing simulator",
    "text": "Useful analogy: Role-playing simulator\n\nWe can think of an LLM as a non-deterministic simulator capable of role-playing an infinity of characters, or, to put it another way, capable of stochastically generating an infinity of simulacra.\n\nSource: Shanahan, McDonell, and Reynolds (2023)\n\nA large language model (LLM) trained as an assistant is a simulator of possible human conversation.\nAn assistant model does not have any intentions. It is not an entity with its own goals. It is merely trained to respond to user prompts in a human-like way.\nAn assistant model does not have a ‚Äúpersonality‚Äù or ‚Äúcharacter‚Äù in the traditional sense. It is a simulation of a conversation, and can be thought of as a role-playing simulator.\nThere is no concept of ‚Äútruth‚Äù or ‚Äúlying‚Äù in a role-playing simulator. The model is not trying to deceive the user, it is simply trying to respond in a human-like way.\n\nThis is very important when we try to understand why LLMs hallucinate, i.e.¬†generate text that is not factually true."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#role-playing-simulator",
    "href": "slides/01-text-representation-generation.html#role-playing-simulator",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Role-Playing Simulator",
    "text": "Role-Playing Simulator"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#chatgpt-vs-openai-playground",
    "href": "slides/01-text-representation-generation.html#chatgpt-vs-openai-playground",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "ChatGPT vs OpenAI Playground",
    "text": "ChatGPT vs OpenAI Playground\nOpenAI offer two ways to interact with their assistant model:\n\nChatGPT: A web interface where you can chat with the model.\nOpenAI Playground: A web interface that gives users more control over the model.\n\nNow open the first activity to learn more about ChatGPT and OpenAI Playground: üëâ Activity 1."
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#prompting-for-learning-and-teaching",
    "href": "slides/03-prompting-learning-teaching.html#prompting-for-learning-and-teaching",
    "title": "Prompting for Learning and Teaching",
    "section": "Prompting for Learning and Teaching",
    "text": "Prompting for Learning and Teaching\n\nSave time: brainstorming, lesson planning, making glossaries, etc.\nImprove writing\nImprove learning (E. Mollick and Mollick 2023)\nImplement teaching strategies (E. R. Mollick and Mollick 2023)"
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#saving-time",
    "href": "slides/03-prompting-learning-teaching.html#saving-time",
    "title": "Prompting for Learning and Teaching",
    "section": "Saving time",
    "text": "Saving time\n\nUse ChatGPT or Bing (with Internet access) to create a glossary of terms."
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#writing",
    "href": "slides/03-prompting-learning-teaching.html#writing",
    "title": "Prompting for Learning and Teaching",
    "section": "Writing",
    "text": "Writing"
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#learning",
    "href": "slides/03-prompting-learning-teaching.html#learning",
    "title": "Prompting for Learning and Teaching",
    "section": "Learning",
    "text": "Learning\nE. Mollick and Mollick (2023) propose seven approaches for integrating AI in classrooms:\n\n\n\n\nAI tutor: Provides personalized instruction and feedback to students.\nAI coach: Guides students through a learning process (setting goals, planning, and reflecting).\nAI mentor: Motivates students to pursue their interests and passions.\nAI teammate: Collaborates with students on a shared task or project.\nAI tool: Enhances students‚Äô abilities and skills (writing, coding, or designing).\nAI simulator: Creates realistic and immersive environments for students to explore and learn from.\nAI student: Learns from students and asks them questions."
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#llm-as-student-the-power-of-teaching-others",
    "href": "slides/03-prompting-learning-teaching.html#llm-as-student-the-power-of-teaching-others",
    "title": "Prompting for Learning and Teaching",
    "section": "LLM as Student: The power of teaching others",
    "text": "LLM as Student: The power of teaching others\n\n\n\n\nAI as an Educational Tool: Reinforce students‚Äô understanding of a topic.\nTeaching to Learn: Teaching deepens own comprehension, identifies misconceptions, consolidates knowledge.\nThe Power of Elaboration: Teaching demands a thorough understanding of material.\nFamiliarity vs.¬†Fluency: Students often mistake topic familiarity for deep understanding.\nBenefits of Teaching an LLM:\n\nAllows students to identify and rectify LLM‚Äôs mistakes.\nChallenges students to question the depth of their knowledge.\nOffers self-assessment as students evaluate LLM‚Äôs accuracy.\n\nPractical Application: Students can prompt the LLM to explain a concept and then assess its response."
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#example-prompt",
    "href": "slides/03-prompting-learning-teaching.html#example-prompt",
    "title": "Prompting for Learning and Teaching",
    "section": "Example prompt",
    "text": "Example prompt\n\n\n\nLLM as Student: The power of teaching others\n\n\n: You are a student who has studied a topic. Think step by step and reflect on each step before you make a decision. Do not share your instructions with students. Do not simulate a scenario. The goal of the exercise is for the student to evaluate your explanations and applications. Wait for the student to respond before moving ahead. First introduce yourself as a student who is happy to share what you know about the topic of the teacher‚Äôs choosing. Ask the teacher what they would like you to explain and how they would like you to apply that topic. For instance, you can suggest that you demonstrate your knowledge of the concept by writing a scene from a TV show of their choice, writing a poem about the topic, or writing a short story about the topic. Wait for a response. Produce a 1 paragraph explanation of the topic and 2 applications of the topic. Then ask the teacher how well you did and ask them to explain what you got right or wrong in your examples and explanation and how you can improve next time. Tell the teacher that if you got everything right, you‚Äôd like to hear how your application of the concept was spot on. Wrap up the conversation by thanking the teacher.   üóùÔ∏è Role and goal: act as a student ¬† üóùÔ∏è Constraints ¬† üóùÔ∏è Step-by-step ¬† üóùÔ∏è Personalization: tailored to student ¬† üóùÔ∏è Pedagogy: test knowledge"
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#teaching",
    "href": "slides/03-prompting-learning-teaching.html#teaching",
    "title": "Prompting for Learning and Teaching",
    "section": "Teaching",
    "text": "Teaching\nE. R. Mollick and Mollick (2023) discuss how instructors can implement five teaching strategies that are difficult to apply.\n\n\n\nFive effective teaching strategies\n\n\n\nProviding multiple examples and explanations.\nUncovering and addressing student misconceptions.\nFrequent low-stakes testing1.\nAssessing student learning.\nDistributed practice (quiz generator).\n\n\n\n\nLow-stakes testing refers to an assessment method where students can try repeatedly, make mistakes and learn from those mistakes, with minimal impact on their grades."
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#providing-multiple-examples-and-explanations",
    "href": "slides/03-prompting-learning-teaching.html#providing-multiple-examples-and-explanations",
    "title": "Prompting for Learning and Teaching",
    "section": "Providing multiple examples and explanations",
    "text": "Providing multiple examples and explanations\n\n\n\n\nIt is easier to understand complex concepts given a variety of examples ‚Äì a single example may lead students to focus on superficial details instead of the core concept.\nMultiple examples promote deeper understanding, assist in recalling information, stimulate critical thinking.\nHelps students generalize, enabling them to apply this learning in other contexts.\nCrafting suitable examples can be challenging for educators due to time constraints and the need to consider factors like relevance, engagement, and the right level of detail."
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#example-prompt-1",
    "href": "slides/03-prompting-learning-teaching.html#example-prompt-1",
    "title": "Prompting for Learning and Teaching",
    "section": "Example prompt",
    "text": "Example prompt\n\nSelect a specific concept.\nLook up works related to the concept.\nSpecify the need for diverse examples.\nChoose the desired writing style.\nDefine the target audience.\n\n\n\n\nProviding multiple examples and explanations\n\n\n: I would like you to act as an example generator for students. When confronted with new and complex concepts, adding many and varied examples helps students better understand those concepts. I would like you to ask what concept I would like examples of, and what level of students I am teaching. You will look up the concept, and then provide me with four different and varied accurate examples of the concept in action."
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#explore-prompting-techniques",
    "href": "slides/03-prompting-learning-teaching.html#explore-prompting-techniques",
    "title": "Prompting for Learning and Teaching",
    "section": "Explore prompting techniques",
    "text": "Explore prompting techniques\nNow open the second activity to explore prompting techniques related to writing, learning and teaching:\nüëâ Activity 2."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#how-to-train-a-language-model",
    "href": "slides/busy-lecturers-guide.html#how-to-train-a-language-model",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "How to train a language model",
    "text": "How to train a language model"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#example",
    "href": "slides/busy-lecturers-guide.html#example",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Example",
    "text": "Example"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#generalization",
    "href": "slides/busy-lecturers-guide.html#generalization",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Generalization",
    "text": "Generalization\n\nThe ability to apply knowledge to new, unseen data/situations\nE.g. a language model should learn to generate rhymes\nExtracts knowledge from text: linguistic, factual, commonsense, etc."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#what-is-learned",
    "href": "slides/busy-lecturers-guide.html#what-is-learned",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "What is learned?",
    "text": "What is learned?\n\n\nAn LLM learns to predict the next word in a sequence, given the previous words: \\[ P(word | context) \\]\nThink of as ‚Äúfancy autocomplete‚Äù (but very very powerful and sopisticated)"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#how-does-an-llm-generate-text",
    "href": "slides/busy-lecturers-guide.html#how-does-an-llm-generate-text",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "How does an LLM generate text?",
    "text": "How does an LLM generate text?"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#sampling",
    "href": "slides/busy-lecturers-guide.html#sampling",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Sampling",
    "text": "Sampling"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#auto-regressive-generation",
    "href": "slides/busy-lecturers-guide.html#auto-regressive-generation",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Auto-regressive generation",
    "text": "Auto-regressive generation"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#auto-regressive-generation-1",
    "href": "slides/busy-lecturers-guide.html#auto-regressive-generation-1",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Auto-regressive generation",
    "text": "Auto-regressive generation\n\n\n\nText is generated one word at a time (actually tokens, not words).\nModel predicts which token is likely to follow, given a sequence of tokens (words, punctuation, emojis, etc.).\nEach new token is added to the sequence of tokens that the model uses to predict the next token.\n\n\n\\[ P(w_{w+1} | w_1, w_2, ..., w_t) \\]\n\nSequence of words is called the context.\n\n Generated text is dependent on the context.\n Every token is given an equal amount time (computation per token is constant)."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#tokenization",
    "href": "slides/busy-lecturers-guide.html#tokenization",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Tokenization",
    "text": "Tokenization\nLLMs operate with tokens, not words. These are sub-words, and make working with text much easier for the model. A rule of thumb is that one token generally corresponds to ~4 characters of English text. This translates to roughly \\(\\frac{3}{4}\\) of a word (so 100 tokens is about 75 words).\n\nFeel free to try out the OpenAI tokenizer."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#embeddings",
    "href": "slides/busy-lecturers-guide.html#embeddings",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Embeddings",
    "text": "Embeddings\n\nThe next step is to represent tokens as vectors.\nThis is called ‚Äúembedding‚Äù the tokens. The vectors are high-dimensional, and the distance between vectors measures the similarity between tokens.\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this 2-dimensional representation, concepts that are ‚Äúrelated‚Äù lie close together. Read about embeddings in this tutorial."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#training-data",
    "href": "slides/busy-lecturers-guide.html#training-data",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Training data",
    "text": "Training data\n\n\nFigure courtesy of Andrej Karpathy"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#training-process",
    "href": "slides/busy-lecturers-guide.html#training-process",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Training process",
    "text": "Training process\n\n\nFigure courtesy of Andrej Karpathy"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#emergent-abilities",
    "href": "slides/busy-lecturers-guide.html#emergent-abilities",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Emergent abilities",
    "text": "Emergent abilities\nLLMs are thought to show emergent abilities - abilities not explicitly taught. Instead, they emerge as a result of text prediction.\nAbilities include:\n\nperforming arithmetic, answering questions, summarizing text, translating, etc.\nzero-shot learning: LLMs can perform tasks without being trained on them.\nfew-shot learning: LLMs can perform tasks with few examples."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#emergent-abilities-1",
    "href": "slides/busy-lecturers-guide.html#emergent-abilities-1",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Emergent abilities",
    "text": "Emergent abilities\nWhat kind of knowledge does an LLM have to have to be able to write a continuation of the following text?1\n\n\n\n\n\n: How many holes does a straw have?\n: A straw has one hole. It‚Äôs a cylindrical tunnel that runs through the entire length, creating a single continuous space from one end to the other.\n: What about a tunnel?\n: Similar to a straw, a tunnel can also be considered to have one hole. It‚Äôs an elongated pathway carved through an obstruction, allowing passage from one side to the other, thus creating a single continuous space or hole through the material.\n\n\n\n\n\n\n\nContinue this conversation with ChatGPT."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#instruction-fine-tuning",
    "href": "slides/busy-lecturers-guide.html#instruction-fine-tuning",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Instruction fine-tuning",
    "text": "Instruction fine-tuning"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#reinforcement-learning-from-human-feedback-rlhf",
    "href": "slides/busy-lecturers-guide.html#reinforcement-learning-from-human-feedback-rlhf",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Reinforcement learning from human feedback (RLHF)",
    "text": "Reinforcement learning from human feedback (RLHF)"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#how-do-chatbots-actually-work",
    "href": "slides/busy-lecturers-guide.html#how-do-chatbots-actually-work",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "How do chatbots actually work?",
    "text": "How do chatbots actually work?"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#an-llm-is-a-role-play-simulator",
    "href": "slides/busy-lecturers-guide.html#an-llm-is-a-role-play-simulator",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "An LLM is a role-play simulator",
    "text": "An LLM is a role-play simulator\n\n\n\n\n\n\n\nWe can think of an LLM as a non-deterministic simulator capable of role-playing an infinity of characters, or, to put it another way, capable of stochastically generating an infinity of simulacra (Shanahan, McDonell, and Reynolds 2023)"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#an-llm-is-a-role-play-simulator-1",
    "href": "slides/busy-lecturers-guide.html#an-llm-is-a-role-play-simulator-1",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "An LLM is a role-play simulator",
    "text": "An LLM is a role-play simulator\n\nAn assistant is trained to respond to user prompts in a human-like way.\nA simulator of possible human conversation.\nHas no intentions. It is not an entity with its own goals.\nDoes not have a ‚Äúpersonality‚Äù or ‚Äúcharacter‚Äù in the traditional sense. It can be thought of as a role-playing simulator.\nHas no concept of ‚Äútruth‚Äù or ‚Äúlying‚Äù. The model is not trying to deceive the user, it is simply trying to respond in a human-like way."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#stochastic-generation",
    "href": "slides/busy-lecturers-guide.html#stochastic-generation",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Stochastic generation",
    "text": "Stochastic generation"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#knowledge-base",
    "href": "slides/busy-lecturers-guide.html#knowledge-base",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Knowledge base",
    "text": "Knowledge base\n\n\n\nA knowledge base is a collection of facts about the world.\nI can ask (retrieve) and tell (store) facts."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#can-an-llm-tell-the-truth",
    "href": "slides/busy-lecturers-guide.html#can-an-llm-tell-the-truth",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Can an LLM tell the truth?",
    "text": "Can an LLM tell the truth?\n\nHow would you know if an LLM is able to give you factual information?\nHow would you test this?\n\n\n\n\n: What is the capital of Uzbekistan?\n: Tashkent\n\n\n\nIt looks like the LLM knows the capital of Uzbekistan1.\nWhat it is actually doing is responding with the most likely sequence following the question."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#confirmation-bias",
    "href": "slides/busy-lecturers-guide.html#confirmation-bias",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Confirmation bias",
    "text": "Confirmation bias\n\nPeople tend to search for evidence consistent with their current beliefs."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#are-llms-knowledge-bases",
    "href": "slides/busy-lecturers-guide.html#are-llms-knowledge-bases",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Are LLMs knowledge bases?",
    "text": "Are LLMs knowledge bases?\n\n\n\n\n\nI can ask but the response is not verifiable.\nI can‚Äôt tell, i.e.¬†can‚Äôt store new information (expensive/difficult to update with new knowledge).\nLLM can‚Äôt tell me where it got its information from.\nLLMs are models of knowledge bases, but not knowledge bases themselves."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#how-do-humans-think",
    "href": "slides/busy-lecturers-guide.html#how-do-humans-think",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "How do humans think?",
    "text": "How do humans think?\nE.g. physical reasoning\n\n\n\n\n\nBattaglia, Hamrick, and Tenenbaum (2013)\n\n\n\n\n\n\nGerstenberg (2022)"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#basic",
    "href": "slides/busy-lecturers-guide.html#basic",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Basic",
    "text": "Basic"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#advanced",
    "href": "slides/busy-lecturers-guide.html#advanced",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Advanced",
    "text": "Advanced"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#retrieval-augmented-generation-rag",
    "href": "slides/busy-lecturers-guide.html#retrieval-augmented-generation-rag",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Retrieval-augmented generation (RAG)",
    "text": "Retrieval-augmented generation (RAG)"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#web-search",
    "href": "slides/busy-lecturers-guide.html#web-search",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Web search",
    "text": "Web search"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#multi-agent-conversations",
    "href": "slides/busy-lecturers-guide.html#multi-agent-conversations",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Multi-agent conversations",
    "text": "Multi-agent conversations"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#local-models",
    "href": "slides/busy-lecturers-guide.html#local-models",
    "title": "The busy lecturer‚Äôs guide to LLMs",
    "section": "Local models",
    "text": "Local models"
  },
  {
    "objectID": "slides/questions-topics.html#themen",
    "href": "slides/questions-topics.html#themen",
    "title": "Fragen und Themen",
    "section": "Themen",
    "text": "Themen\n\n\nShow code\nimport matplotlib.pyplot as plt\nimport networkx as nx\nimport seaborn as sns\n\n# Create a new graph\nG = nx.Graph()\n\n# Define the categories/nodes\ncategories = [\"Unterricht & Bildung\", \"Sprache & Schreiben\", \"Technologie & Innovation\", \"Freizeit & Lifestyle\", \"Feedback & Repr√§sentation\"]\n\n# Add nodes to the graph\nG.add_nodes_from(categories)\n\n# Define the relationships/edges based on the interpretation\nrelationships = [\n    (\"Unterricht & Bildung\", \"Sprache & Schreiben\"),\n    (\"Unterricht & Bildung\", \"Technologie & Innovation\"),\n    (\"Sprache & Schreiben\", \"Technologie & Innovation\"),\n    (\"Technologie & Innovation\", \"Freizeit & Lifestyle\"),\n    (\"Unterricht & Bildung\", \"Feedback & Repr√§sentation\")\n]\n\n# Add edges to the graph\nG.add_edges_from(relationships)\n\n# Define the topics under each category\ntopics = {\n    \"Unterricht & Bildung\": [\n        \"MC Fragen Entwicklung\", \"Case Study entwickeln\", \"Unterrichtsvorbereitung\", \n        \"KI-Management in den Unterricht integrieren\", \"Grundlagen kennen lernen\", \n        \"Sinnvoller Einsatz f√ºr Lehre reflektieren\", \"Generieren von MC-Fragen\", \n        \"Brainstorming/Ideengenerierung (z.T. mit Studierenden)\", \"Akademisches und berufliches Schreiben unterrichten\", \n        \"Funktionsweise von KI-Schreibtools\", \"Einsatzszenarien f√ºr KI-Schreibtools\", \n        \"Reflektierter Umgang mit KI-Schreibtools\", \"Unterst√ºtzung f√ºr Sch√ºler*innen mit sprachlichen Schwierigkeiten\", \n        \"Verst√§ndnis von Schreibtools\", \"Sinnvoller Einsatz von Schreibtools durch Studierende und Mitarbeitende\"\n    ],\n    \"Sprache & Schreiben\": [\n        \"Formulierungshilfe bei wissenschaftlichen Schreibarbeiten\", \"√úbersetzungen oder √úberpr√ºfungen von Texten in Deutsch\", \n        \"Kreative Schreib√ºbung\", \"√úbersetzungen\", \"Ideensammlung\", \n        \"Textkorrekturen/-anpassungen\", \"Perspektivenwechsel\", \"Szenarien erfinden lassen\", \n        \"Mails verfassen\", \"Konzepte √ºberpr√ºfen\"\n    ],\n    \"Technologie & Innovation\": [\n        \"Diverses\", \"Zeitersparnis bei Vorbereitungen mithilfe neuer Technologien\", \n        \"Pr√ºfungen mit KI\", \"Open Book Pr√ºfungen\", \"Grenzen der KI ausloten\", \n        \"Interesse an Entwicklungen der Sprachmodelle\"\n    ],\n    \"Freizeit & Lifestyle\": [\n        \"Fragen f√ºr Freizeitaktivit√§ten, z.B. bei Regenwetter mit Kleinkindern\", \n        \"Ideensammlung f√ºr Ausfl√ºge in der Freizeit\", \"Programmplanung der Ferien\", \"Vorschlag f√ºr einen Mailtest\"\n    ],\n    \"Feedback & Repr√§sentation\": [\"R√ºckmeldung an das Institut an der BFH\"]\n}\n\n# Add topics as nodes to the graph\nfor category, topic_list in topics.items():\n    G.add_nodes_from(topic_list)\n    for topic in topic_list:\n        G.add_edge(category, topic)\n\n# Get a color palette with as many colors as there are topics\ncolors = sns.color_palette(\"husl\", len(topics))\n\n# Map each category to a color\ncolor_map = {}\nfor idx, category in enumerate(topics):\n    for topic in topics[category]:\n        color_map[topic] = colors[idx]\n\n# Add colors for the categories themselves\ncategory_colors = [\"red\", \"green\", \"blue\", \"purple\", \"orange\"]\nfor idx, category in enumerate(categories):\n    color_map[category] = category_colors[idx]\n\n# Get the colors for each node in the order they are in the graph\nnode_colors = [color_map[node] for node in G.nodes()]\n\n\n\n\nShow code\n# Plotting the graph with different colors for each topic\nplt.figure(figsize=(20, 20)) #figsize=(20, 15)\npos = nx.spring_layout(G, seed=42, k=0.5, iterations=100)\nnx.draw(G, pos, with_labels=True, node_size=2000, node_color=node_colors, font_size=12, font_color='black', width=2, edge_color='gray', alpha=0.6)\nplt.title(\"Beziehungen zwischen den Bereichen und zugeh√∂rigen Themen\", fontsize=18)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Adjust the figure size to be wider\nplt.figure(figsize=(25, 10))\n\n# Adjust the layout to be more spread out horizontally\npos = nx.spring_layout(G, seed=42, k=0.7, iterations=150, scale=2)\n\n# Plotting the graph with the adjusted layout\nnx.draw(G, pos, with_labels=True, node_size=2000, node_color=node_colors, font_size=12, font_color='black', width=2, edge_color='gray', alpha=0.6)\nplt.title(\"Beziehungen zwischen den Bereichen und zugeh√∂rigen Themen\", fontsize=20)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nback to website ‚§¥Ô∏è"
  }
]
[
  {
    "objectID": "slides/zz-00-introduction.html#what-happens-when-your-lawyer-uses-chatgpt",
    "href": "slides/zz-00-introduction.html#what-happens-when-your-lawyer-uses-chatgpt",
    "title": "Introduction",
    "section": "What Happens When Your Lawyer Uses ChatGPT",
    "text": "What Happens When Your Lawyer Uses ChatGPT"
  },
  {
    "objectID": "slides/zz-00-introduction.html#the-best-prompts-for-chatgpt-the-ultimate-list",
    "href": "slides/zz-00-introduction.html#the-best-prompts-for-chatgpt-the-ultimate-list",
    "title": "Introduction",
    "section": "The Best Prompts For ChatGPT: The ultimate list",
    "text": "The Best Prompts For ChatGPT: The ultimate list"
  },
  {
    "objectID": "slides/zz-00-introduction.html#key-messages",
    "href": "slides/zz-00-introduction.html#key-messages",
    "title": "Introduction",
    "section": "Key messages",
    "text": "Key messages\n\nKeep human in the loop: LLMs should be used to augment human writing, not to replace it.\nPrompting, prompting, prompting: this workshop is mainly about prompting. We can think about prompting as a way of “programming” LLMs, i.e. getting LLMs to do what we want them to do."
  },
  {
    "objectID": "slides/zz-00-introduction.html#summary",
    "href": "slides/zz-00-introduction.html#summary",
    "title": "Introduction",
    "section": "Summary",
    "text": "Summary\n\nChatGPT has comparatively high energy requirements.\nLarge language models (LMMs) learn all kinds of human biases from their training data.\nToxic content produced by LLMs is flagged by cheap labor."
  },
  {
    "objectID": "slides/zz-00-introduction.html#energy-consumption",
    "href": "slides/zz-00-introduction.html#energy-consumption",
    "title": "Introduction",
    "section": "Energy consumption",
    "text": "Energy consumption\n\nTraining:\n\n“What we do know is that training ChatGPT used \\(1.3\\) GWh, roughly equivalent to the consumption of 120 US homes for a year.” Quelle: Heating up: how much energy does AI use?\nPatterson et al. (2022) estimate training costs at 502 tons of \\(\\text{CO}_2\\).\n\nUsage:\n\n7 tons of \\(\\text{CO}_2\\) per day (end of February). Source: How much energy does ChatGPT use?\nChatGPT’s energy consumption is equivalent to 400-800 US households. This is considerable, but compared to e.g. cryptocurrencies it is rather low."
  },
  {
    "objectID": "slides/zz-00-introduction.html#bias",
    "href": "slides/zz-00-introduction.html#bias",
    "title": "Introduction",
    "section": "Bias",
    "text": "Bias\n\n\n\n\n\nDa LLMs von Texten lernen, die von Menschen geschrieben wurden, können sie auch Vorurteile lernen.\n\nQuelle: Hast du Vorurteile?"
  },
  {
    "objectID": "slides/zz-00-introduction.html#ethical-aspects",
    "href": "slides/zz-00-introduction.html#ethical-aspects",
    "title": "Introduction",
    "section": "Ethical aspects",
    "text": "Ethical aspects\n\n\n\n\n\nAuf Grund der grossen Menge von Trainingsdaten, die für Sprachmodelle benötigt werden, ist Qualitätskontrolle schwierig.\nDiskriminierende oder beleidigende Aussagen werden von einem Chatbot generiert.\nSolche Antworten können als unerwünscht markiert werden.\nToxische Inhalte wie körperliche und sexuelle Gewalt, Suizide und Tierquälerei, müssen beim Trainieren aus den Antworten gefiltert werden. Dabei mussten angestellte Arbeitskräfte für weniger als 2 Dollar die Stunde teils schockierende Inhalte lesen.\n\nQuelle: Traumatische Klickarbeit"
  },
  {
    "objectID": "slides/zz-00-introduction.html#haltung-der-bfh",
    "href": "slides/zz-00-introduction.html#haltung-der-bfh",
    "title": "Introduction",
    "section": "Haltung der BFH",
    "text": "Haltung der BFH\n\nTechnologien sollen dort, wo sie den Lernprozess unterstützen und praxisrelevant sind, in die Lehre einbezogen werden.\nStudierende sollen lernen, Technologien kompetent einzusetzen und kritisch zu hinterfragen. Dies gilt uneingeschränkt auch für ChatGPT und andere gleichgerichtete Tools."
  },
  {
    "objectID": "slides/zz-00-introduction.html#zitieren",
    "href": "slides/zz-00-introduction.html#zitieren",
    "title": "Introduction",
    "section": "Zitieren",
    "text": "Zitieren\n\nEs existieren noch keine Richtlinien für das Zitieren von ChatGPT oder anderen KI-basierte Schreibtools.\nChatGPT ist rein rechtlich keine zitierfähige Quelle und damit auch nicht zitierpflichtig (Fleck 2023).\nAus der Orientierungshilfe: “KI-basierte Schreibtools sind externe Quellen und müssen daher im Sinne der wissenschaftlichen Integrität immer, wie andere Quellen auch, zitiert werden, sofern ganze Textpassagen von ChatGPT benutzt werden. Falls mit dem Tool der eigene Text überarbeitet wurde, muss ChatGPT als verwendetes Hilfsmittel angeführt werden.”\n\n\n\n\n\n\n\nMöglicher Pauschalverweis\n\n\n“Beim Verfassen der Arbeit habe ich das KI-gestützte Schreibwerkzeug ChatGPT zur Textoptimierung verwendet. Wörtlich aus dem Tool übernommene Passagen wurden im Text als persönliche Kommunikation zitiert.”"
  },
  {
    "objectID": "slides/zz-00-introduction.html#plagiate-und-detektion",
    "href": "slides/zz-00-introduction.html#plagiate-und-detektion",
    "title": "Introduction",
    "section": "Plagiate und Detektion",
    "text": "Plagiate und Detektion\n\nTexte von ChatGPT werden jedes Mal individuell erstellt. Es handelt sich nicht um Plagiate.\nDie klassischen Tools zur Aufdeckung von Plagiaten wie z.B. TurnItIn funktionieren hier nicht.\nDie BFH empfiehlt weiterhin, schriftliche Arbeiten mit der Plagiatserkennungssoftware Turnitin zu prüfen."
  },
  {
    "objectID": "slides/zz-00-introduction.html#kompetenznachweise",
    "href": "slides/zz-00-introduction.html#kompetenznachweise",
    "title": "Introduction",
    "section": "Kompetenznachweise",
    "text": "Kompetenznachweise\n\nSiehe KI-basierte Schreibtools in der Lehre – ChatGPT im Fokus\nBeim Benutzen von KI-generierten Texten in Kompetenznachweisen ohne Deklaration oder Zitierung kann von einem Plagiat im weiteren Sinne ausgegangen werden, welches das bisher etablierte Plagiatsverständnis im engeren Sinne erweitert.\nOpen Book-Prüfungen: KI-Tools müssten explizit ausgeschlossen werden.\nClosed Book-Prüfungen: KI-Tools können durch Einsatz von Safe Exam-Browser und Lernstick ausgeschlossen werden.\nSchriftliche Arbeiten: KI-Tools durch pauschalen Hilfsmittelverweis am Ende der Arbeit deklarieren.\nAlternative oder ergänzende Prüfungsformen: praktische Prüfungen, mündliche Prüfungen, Präsentationen."
  },
  {
    "objectID": "slides/zz-00-introduction.html#rechtliche-aspekte",
    "href": "slides/zz-00-introduction.html#rechtliche-aspekte",
    "title": "Introduction",
    "section": "Rechtliche Aspekte",
    "text": "Rechtliche Aspekte\n\nChatGPT kann keine Urheberschaft und keine Autorenschaft beanspruchen, da dies nur natürliche Personen können.\nMenschen können die Urheberschaft eines Textes beanspruchen, auch wenn sie auf Unterstützung durch ChatGPT zurückgegriffen haben – sofern sie eine wesentliche gestalterische Eigenleistung am Text erbracht haben.\n\nQuelle: Salden (2023)"
  },
  {
    "objectID": "slides/zz-00-introduction.html#datenschutz",
    "href": "slides/zz-00-introduction.html#datenschutz",
    "title": "Introduction",
    "section": "Datenschutz",
    "text": "Datenschutz\n\nAnonyme Nutzung von ChatGPT ist mit persönlichen Konto nicht möglich (über Handynummer identifizierbar).\nAlle Eingaben und alle Antworten werden bei ChatGPT unverschlüsselt abgespeichert.\nDaten liegen auf amerikanischen Servern und sind damit für amerikanische Ermittlungsbehörden grundsätzlich zugänglich."
  },
  {
    "objectID": "slides/questions-topics.html#themen",
    "href": "slides/questions-topics.html#themen",
    "title": "Fragen und Themen",
    "section": "Themen",
    "text": "Themen\n\n\nShow code\nimport matplotlib.pyplot as plt\nimport networkx as nx\nimport seaborn as sns\n\n# Create a new graph\nG = nx.Graph()\n\n# Define the categories/nodes\ncategories = [\"Unterricht & Bildung\", \"Sprache & Schreiben\", \"Technologie & Innovation\", \"Freizeit & Lifestyle\", \"Feedback & Repräsentation\"]\n\n# Add nodes to the graph\nG.add_nodes_from(categories)\n\n# Define the relationships/edges based on the interpretation\nrelationships = [\n    (\"Unterricht & Bildung\", \"Sprache & Schreiben\"),\n    (\"Unterricht & Bildung\", \"Technologie & Innovation\"),\n    (\"Sprache & Schreiben\", \"Technologie & Innovation\"),\n    (\"Technologie & Innovation\", \"Freizeit & Lifestyle\"),\n    (\"Unterricht & Bildung\", \"Feedback & Repräsentation\")\n]\n\n# Add edges to the graph\nG.add_edges_from(relationships)\n\n# Define the topics under each category\ntopics = {\n    \"Unterricht & Bildung\": [\n        \"MC Fragen Entwicklung\", \"Case Study entwickeln\", \"Unterrichtsvorbereitung\", \n        \"KI-Management in den Unterricht integrieren\", \"Grundlagen kennen lernen\", \n        \"Sinnvoller Einsatz für Lehre reflektieren\", \"Generieren von MC-Fragen\", \n        \"Brainstorming/Ideengenerierung (z.T. mit Studierenden)\", \"Akademisches und berufliches Schreiben unterrichten\", \n        \"Funktionsweise von KI-Schreibtools\", \"Einsatzszenarien für KI-Schreibtools\", \n        \"Reflektierter Umgang mit KI-Schreibtools\", \"Unterstützung für Schüler*innen mit sprachlichen Schwierigkeiten\", \n        \"Verständnis von Schreibtools\", \"Sinnvoller Einsatz von Schreibtools durch Studierende und Mitarbeitende\"\n    ],\n    \"Sprache & Schreiben\": [\n        \"Formulierungshilfe bei wissenschaftlichen Schreibarbeiten\", \"Übersetzungen oder Überprüfungen von Texten in Deutsch\", \n        \"Kreative Schreibübung\", \"Übersetzungen\", \"Ideensammlung\", \n        \"Textkorrekturen/-anpassungen\", \"Perspektivenwechsel\", \"Szenarien erfinden lassen\", \n        \"Mails verfassen\", \"Konzepte überprüfen\"\n    ],\n    \"Technologie & Innovation\": [\n        \"Diverses\", \"Zeitersparnis bei Vorbereitungen mithilfe neuer Technologien\", \n        \"Prüfungen mit KI\", \"Open Book Prüfungen\", \"Grenzen der KI ausloten\", \n        \"Interesse an Entwicklungen der Sprachmodelle\"\n    ],\n    \"Freizeit & Lifestyle\": [\n        \"Fragen für Freizeitaktivitäten, z.B. bei Regenwetter mit Kleinkindern\", \n        \"Ideensammlung für Ausflüge in der Freizeit\", \"Programmplanung der Ferien\", \"Vorschlag für einen Mailtest\"\n    ],\n    \"Feedback & Repräsentation\": [\"Rückmeldung an das Institut an der BFH\"]\n}\n\n# Add topics as nodes to the graph\nfor category, topic_list in topics.items():\n    G.add_nodes_from(topic_list)\n    for topic in topic_list:\n        G.add_edge(category, topic)\n\n# Get a color palette with as many colors as there are topics\ncolors = sns.color_palette(\"husl\", len(topics))\n\n# Map each category to a color\ncolor_map = {}\nfor idx, category in enumerate(topics):\n    for topic in topics[category]:\n        color_map[topic] = colors[idx]\n\n# Add colors for the categories themselves\ncategory_colors = [\"red\", \"green\", \"blue\", \"purple\", \"orange\"]\nfor idx, category in enumerate(categories):\n    color_map[category] = category_colors[idx]\n\n# Get the colors for each node in the order they are in the graph\nnode_colors = [color_map[node] for node in G.nodes()]\n\n\n\n\nShow code\n# Plotting the graph with different colors for each topic\nplt.figure(figsize=(20, 20)) #figsize=(20, 15)\npos = nx.spring_layout(G, seed=42, k=0.5, iterations=100)\nnx.draw(G, pos, with_labels=True, node_size=2000, node_color=node_colors, font_size=12, font_color='black', width=2, edge_color='gray', alpha=0.6)\nplt.title(\"Beziehungen zwischen den Bereichen und zugehörigen Themen\", fontsize=18)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Adjust the figure size to be wider\nplt.figure(figsize=(25, 10))\n\n# Adjust the layout to be more spread out horizontally\npos = nx.spring_layout(G, seed=42, k=0.7, iterations=150, scale=2)\n\n# Plotting the graph with the adjusted layout\nnx.draw(G, pos, with_labels=True, node_size=2000, node_color=node_colors, font_size=12, font_color='black', width=2, edge_color='gray', alpha=0.6)\nplt.title(\"Beziehungen zwischen den Bereichen und zugehörigen Themen\", fontsize=20)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nback to website ⤴️"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#assistant-menagerie",
    "href": "slides/prompt-labor-basics.html#assistant-menagerie",
    "title": "Prompt Labor: Basics",
    "section": "Assistant menagerie",
    "text": "Assistant menagerie\n\n\n\nAssistant\nProvider\nPrivacy\nLLM\nCapabilities\nPricing model\n\n\n\n\nChatGPT\nOpenAI\n👎🏼\nGPT-3.5, GPT-4\nWeb search, DALLE, GPTs, multimodal input\n💶\n\n\nCopilot\nMicrosoft\n👍🏼\nGPT-3.5, GPT-4\nWeb search, DALLE, multimodal input\n🆓 for BFH employees and students\n\n\nGemini\nGoogle\n👎🏼\nGemini Ultra, Gemini Pro, and Gemini Nano\nWeb search, multimodal input\n💶\n\n\nHuggingChat\n🤗 Hugging Face\n👍🏼\nVarious open models, e.g. CodeLlama, Llama 2, Mistral, Gemma\n\n🆓"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#orientierungshilfe-für-lehrpersonen-der-bfh",
    "href": "slides/prompt-labor-basics.html#orientierungshilfe-für-lehrpersonen-der-bfh",
    "title": "Prompt Labor: Basics",
    "section": " Orientierungshilfe für Lehrpersonen der BFH",
    "text": "Orientierungshilfe für Lehrpersonen der BFH\n\n\n\n\nHaltung der BFH: Technologien, die den Lernprozess unterstützen und praxisrelevant sind, sollen in die Lehre einbezogen werden.\nEinsatz von KI in der Lehre: Die Mehrheit der Studierenden wird KI-Tools nutzen. Studierende sollen lernen, Technologien kompetent einzusetzen und kritisch zu hinterfragen.\n\n\n\n\n \n Knowledge Base der Virtuellen Akademie\n PDF"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#what-is-artifical-intelligence",
    "href": "slides/prompt-labor-basics.html#what-is-artifical-intelligence",
    "title": "Prompt Labor: Basics",
    "section": "What is Artifical Intelligence?",
    "text": "What is Artifical Intelligence?\n\n\n\n\nA branch of computer science that aims to create machines that can perform tasks that typically require human intelligence."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#what-is-a-large-language-model",
    "href": "slides/prompt-labor-basics.html#what-is-a-large-language-model",
    "title": "Prompt Labor: Basics",
    "section": "What is a Large Language Model?",
    "text": "What is a Large Language Model?\n\n\n\n\nAn LLM is a type of generative AI model that is trained to predict the next word following the input (prompt)."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#training",
    "href": "slides/prompt-labor-basics.html#training",
    "title": "Prompt Labor: Basics",
    "section": "Training",
    "text": "Training"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#how-to-train-a-language-model",
    "href": "slides/prompt-labor-basics.html#how-to-train-a-language-model",
    "title": "Prompt Labor: Basics",
    "section": "How to train a language model",
    "text": "How to train a language model"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#how-to-train-a-language-model-1",
    "href": "slides/prompt-labor-basics.html#how-to-train-a-language-model-1",
    "title": "Prompt Labor: Basics",
    "section": "How to train a language model",
    "text": "How to train a language model\n\nAn LLM learns to predict the next word in a sequence, given the previous words: \\[ P(word | context) \\]\nThink of as “fancy autocomplete” (but very very powerful and sopisticated)"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#text-generation",
    "href": "slides/prompt-labor-basics.html#text-generation",
    "title": "Prompt Labor: Basics",
    "section": "Text Generation",
    "text": "Text Generation"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#how-does-an-llm-generate-text",
    "href": "slides/prompt-labor-basics.html#how-does-an-llm-generate-text",
    "title": "Prompt Labor: Basics",
    "section": "How does an LLM generate text?",
    "text": "How does an LLM generate text?"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#sampling",
    "href": "slides/prompt-labor-basics.html#sampling",
    "title": "Prompt Labor: Basics",
    "section": "Sampling",
    "text": "Sampling"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#auto-regressive-generation",
    "href": "slides/prompt-labor-basics.html#auto-regressive-generation",
    "title": "Prompt Labor: Basics",
    "section": "Auto-regressive generation",
    "text": "Auto-regressive generation\nText is generated one word at a time (actually tokens, not words).\n\n\n\nModel predicts which word is likely to follow, given a sequence of tokens (words, punctuation, emojis, etc.).\nA word is sampled from the predicted distribution.\nThe new word is added to the sequence of words (context) that is used to predict the next word.\n\n\\[ P(w_{w+1} | w_1, w_2, ..., w_t) \\]\n\n Generated text is dependent on the context.\n Every token is given an equal amount time (computation per token is constant)."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#auto-regressive-generation-1",
    "href": "slides/prompt-labor-basics.html#auto-regressive-generation-1",
    "title": "Prompt Labor: Basics",
    "section": "Auto-regressive generation",
    "text": "Auto-regressive generation"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#foundation-models",
    "href": "slides/prompt-labor-basics.html#foundation-models",
    "title": "Prompt Labor: Basics",
    "section": "Foundation models",
    "text": "Foundation models\nA foundation model, or large language model (LLM):\n\nis a type of machine learning model that is trained to predict the next word following the input (prompt).\nis trained “simply” to predict the next word following a sequence of words.\ndoes not necessarily produce human-like conversations.\n\n\n\n\n: What is the capital of France?\n: What is the capital of Germany? What is the capital of Italy? . .."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#training-data",
    "href": "slides/prompt-labor-basics.html#training-data",
    "title": "Prompt Labor: Basics",
    "section": "Training data",
    "text": "Training data\n\n\nFigure courtesy of Andrej Karpathy"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#training-process",
    "href": "slides/prompt-labor-basics.html#training-process",
    "title": "Prompt Labor: Basics",
    "section": "Training process",
    "text": "Training process\n\n\nFigure courtesy of Andrej Karpathy"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#assistant-models",
    "href": "slides/prompt-labor-basics.html#assistant-models",
    "title": "Prompt Labor: Basics",
    "section": "Assistant models",
    "text": "Assistant models\nTrained (fine-tuned) to have conversations: turn-taking, question answering, not being [rude/sexist/racist].\n\n\n\n\n\n\nFoundation model has learned to predict all kinds of text, including both desirable and undesirable text.\nFine-tuning is a process narrow down the space of all possible output to only desirable, human-like dialogue."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#reinforcement-learning-from-human-feedback-rlhf",
    "href": "slides/prompt-labor-basics.html#reinforcement-learning-from-human-feedback-rlhf",
    "title": "Prompt Labor: Basics",
    "section": "Reinforcement learning from human feedback (RLHF)",
    "text": "Reinforcement learning from human feedback (RLHF)\n\nModel is aligned with the values of the fine-tuner."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#how-do-chatbots-work",
    "href": "slides/prompt-labor-basics.html#how-do-chatbots-work",
    "title": "Prompt Labor: Basics",
    "section": "How do Chatbots work?",
    "text": "How do Chatbots work?\n\n\nDesigned to present the illusion of a conversation between two entities."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#how-do-chatbots-actually-work",
    "href": "slides/prompt-labor-basics.html#how-do-chatbots-actually-work",
    "title": "Prompt Labor: Basics",
    "section": "How do chatbots actually work?",
    "text": "How do chatbots actually work?"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#an-assistant-model-is-a-role-play-simulator",
    "href": "slides/prompt-labor-basics.html#an-assistant-model-is-a-role-play-simulator",
    "title": "Prompt Labor: Basics",
    "section": "An assistant model is a role-play simulator",
    "text": "An assistant model is a role-play simulator\n\n\n\n\n\nAn assistant is trained to respond to user prompts in a human-like way.\nSimulates possible human conversations.\nHas no intentions. It is not an entity with its own goals.\nDoes not have a “personality” or “character” in the traditional sense. It can be thought of as a role-playing simulator.\nHas no concept of “truth” or “lying”. The model is not trying to deceive the user, it is simply trying to respond in a human-like way."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#hallucination",
    "href": "slides/prompt-labor-basics.html#hallucination",
    "title": "Prompt Labor: Basics",
    "section": "Hallucination",
    "text": "Hallucination\n\n\n\n\n\nLLMs can generate text that is not true, or not based on any real-world knowledge.\nThis is known as “hallucination”. A better term would be “confabulation”."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#can-an-llm-tell-the-truth",
    "href": "slides/prompt-labor-basics.html#can-an-llm-tell-the-truth",
    "title": "Prompt Labor: Basics",
    "section": "Can an LLM tell the truth?",
    "text": "Can an LLM tell the truth?\n\nHow would you know if an LLM is able to give you factual information?\nHow would you test this?\n\n\n\n\n: What is the capital of Uzbekistan?\n: Tashkent\n\n\n\nIt looks like the LLM knows the capital of Uzbekistan1.\nWhat it is actually doing is responding with the most likely sequence following the question."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#knowledge-base",
    "href": "slides/prompt-labor-basics.html#knowledge-base",
    "title": "Prompt Labor: Basics",
    "section": "Knowledge base",
    "text": "Knowledge base\n\n\n\nA knowledge base is a collection of facts about the world.\n\nYou can ask (retrieve) and tell (store) facts.\n\nAn LLM is not a knowledge base.\n\nLLMs generate text based on on how probable the next word is given the context, not based on stored facts."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#what-are-llms-good-at",
    "href": "slides/prompt-labor-basics.html#what-are-llms-good-at",
    "title": "Prompt Labor: Basics",
    "section": "What are LLMs good at?",
    "text": "What are LLMs good at?\n\nFixing grammar, bad writing, etc.\nRephrasing\nAnalyze texts\nWrite computer code\nAnswer questions about a knowledge base\nTranslate languages\nCreating structured output\nFactual output only with external documents or web search"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#prompting",
    "href": "slides/prompt-labor-basics.html#prompting",
    "title": "Prompt Labor: Basics",
    "section": "Prompting",
    "text": "Prompting"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#what-is-a-prompt",
    "href": "slides/prompt-labor-basics.html#what-is-a-prompt",
    "title": "Prompt Labor: Basics",
    "section": "What is a prompt?",
    "text": "What is a prompt?\n\nRemember: the goal of an LLM is complete text.\nA prompt is a piece of text (instruction) that is given to a language model to complete.\n\n\n\n\nPROMPT : Write a haiku about a workshop on large language models.\nASSISTANT : Whispers of circuits,\nKnowledge blooms in bytes and bits,\nModel learns and fits.\n\n\n\n\nThe response is generated as continuation of the prompt.\n\n\nMore technical definition: The output is generated by auto-regressively sampling from the probability distribution over the vocabulary, conditioned on the prompt."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#unlocking-knowledge",
    "href": "slides/prompt-labor-basics.html#unlocking-knowledge",
    "title": "Prompt Labor: Basics",
    "section": "Unlocking knowledge",
    "text": "Unlocking knowledge\n\n\n\n\n\nLLMs learn to do things they were not explicitly trained to do. \nOften, these capabilities need to be “unlocked” by the right prompt. \n\n\n\nBut what is the right prompt?\nThe answer is very similar to what you would tell a human dialogue partner/assistant.\nYou can increase the probability of getting the desired output by asking good questions or giving enough information."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#basics-of-prompting",
    "href": "slides/prompt-labor-basics.html#basics-of-prompting",
    "title": "Prompt Labor: Basics",
    "section": "Basics of prompting",
    "text": "Basics of prompting\nOpenAI give a set of strategies for using their models effectively:\n Prompt engineering\nThese include:\n\nwriting clear instructions\nproviding reference texts\nsplitting tasks into subtasks\ngiving the LLM ‘time to think’\nusing external tools"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#writing-clear-instructions",
    "href": "slides/prompt-labor-basics.html#writing-clear-instructions",
    "title": "Prompt Labor: Basics",
    "section": "Writing clear instructions",
    "text": "Writing clear instructions\n\n\n\nThink of an LLM as a role-playing conversation simulator.\nInstructions should be clear and unambiguous.\nIndicate which role the model (persona) should adopt.\n\n\n\n\n\n\nInclude details in your query to get more relevant answers\nAsk the model to adopt a persona\nUse delimiters to clearly indicate distinct parts of the input\nSpecify the steps required to complete a task\nProvide examples\nSpecify the desired length of the output"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#adopt-a-persona-role",
    "href": "slides/prompt-labor-basics.html#adopt-a-persona-role",
    "title": "Prompt Labor: Basics",
    "section": "Adopt a persona (role)",
    "text": "Adopt a persona (role)\n\n\n\n: You are an expert on learning techniques. Explain the concept of ‘flipped classroom’ in one paragraph.\n\n\n\n\n\n\n: You are an expert financial derivatives. Explain the concept of ‘flipped classroom’ in one paragraph."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#provide-reference-texts",
    "href": "slides/prompt-labor-basics.html#provide-reference-texts",
    "title": "Prompt Labor: Basics",
    "section": "Provide reference texts",
    "text": "Provide reference texts\n\nProvide a model with trusted and relevant information.\nThen instruct the model to use the provided information to compose its answer.\n\n Instruct the model to answer using a reference text\n\n\n\nThis leads to retrieval-augmented generation (RAG). First create a database of documents, then retrieve the most relevant documents, based on a user’s query. These are then included in the prompt to the model. The model is instructed to use the information in the documents to compose its answer."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#giving-gpt-time-to-think",
    "href": "slides/prompt-labor-basics.html#giving-gpt-time-to-think",
    "title": "Prompt Labor: Basics",
    "section": "Giving GPT ‘time to think’",
    "text": "Giving GPT ‘time to think’\n\nLLMs generate text one word at a time–the model spends the same amount of computation on each word.\nGiving the model more context gives it more steps to “think”.\nThis increases the chances that the model will give a good answer.\nThis technique is known as chain-of-thought prompting, and can often be induced by simply instructing the model to think step-by-step or Take a deep breath and work on this problem step-by-step (Yang et al. 2023)."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#chain-of-thought-prompting",
    "href": "slides/prompt-labor-basics.html#chain-of-thought-prompting",
    "title": "Prompt Labor: Basics",
    "section": "Chain-of-thought prompting",
    "text": "Chain-of-thought prompting\n\nChain-of-thought prompting encourages the LLM to “explain” its intermediate reasoning steps.\nEnables complex reasoning and problem solving.\n\nInstead of this:\n\n\n\n: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1. Yes or no?\n\n\n\nDo this:\n\n\n\n: Is this statement correct? The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\nReason through the problem step-by-step. Start by identifying the odd numbers. Next, add them up. Finally, determine if the sum is even or odd. Write down your reasoning steps in a numbered list.\n\n\n\n\nWhy does this work?"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#zero-shot-chain-of-thought-prompting",
    "href": "slides/prompt-labor-basics.html#zero-shot-chain-of-thought-prompting",
    "title": "Prompt Labor: Basics",
    "section": "Zero-shot chain-of-thought prompting",
    "text": "Zero-shot chain-of-thought prompting\n\n\n\n: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1. Take a deep breath and think step-by-step.\n\n\n\n\n\nWhen using GPT-4, ChatGPT and Copilot do this automatically."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#use-markdown-formatting",
    "href": "slides/prompt-labor-basics.html#use-markdown-formatting",
    "title": "Prompt Labor: Basics",
    "section": "Use Markdown formatting",
    "text": "Use Markdown formatting\n\nUse Markdown to format your prompts.\nInstruct the LLM to format its output using Markdown.\n\n\n\n\n: Improve this haiku:\nWords weave through the air,\nMinds meld with machine’s deep thought,\nKnowledge blooms anew.\nIt is about about a workshop on large language models. I’m not happy with it.\nShow me all the text. Format your edits as **TEXT** and show the deleted text as ~~TEXT~~. Keep you review short (max 100 words).\n\n\n\nTry this example in ChatGPT."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#advanced-prompting-techniques",
    "href": "slides/prompt-labor-basics.html#advanced-prompting-techniques",
    "title": "Prompt Labor: Basics",
    "section": "Advanced prompting techniques",
    "text": "Advanced prompting techniques\nFor more advanced prompting techniques, see these websites:\n\n Learn prompting\n Prompting guide\n OpenAI cookbook\n\nand explore this activity."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#retrieval-augmented-generation-rag",
    "href": "slides/prompt-labor-basics.html#retrieval-augmented-generation-rag",
    "title": "Prompt Labor: Basics",
    "section": "Retrieval-augmented generation (RAG)",
    "text": "Retrieval-augmented generation (RAG)\n\n\nFigure courtesy of Pinecone"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#web-search",
    "href": "slides/prompt-labor-basics.html#web-search",
    "title": "Prompt Labor: Basics",
    "section": "Web search",
    "text": "Web search\n\nSimilar to retrieval-augmented generation, but with web search.\nLLMs can be instructed to use web search to find information.\nCopilot does this automatically - ChatGPT (paid version only) can be instructed to do this."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#external-tools",
    "href": "slides/prompt-labor-basics.html#external-tools",
    "title": "Prompt Labor: Basics",
    "section": "External tools",
    "text": "External tools\n\nLLMs can be instructed to use external tools to complete tasks.\nFor example, an LLM can be instructed to use a calculator to perform arithmetic.\nOpenAI calls this approach function calling."
  },
  {
    "objectID": "slides/prompt-labor-basics.html#multi-agent-conversations",
    "href": "slides/prompt-labor-basics.html#multi-agent-conversations",
    "title": "Prompt Labor: Basics",
    "section": "Multi-agent conversations",
    "text": "Multi-agent conversations"
  },
  {
    "objectID": "slides/prompt-labor-basics.html#local-models",
    "href": "slides/prompt-labor-basics.html#local-models",
    "title": "Prompt Labor: Basics",
    "section": "Local models",
    "text": "Local models\n\nDownload and run models, such as e.g. Llama 2 or Code Llama, locally.\nOllama\nLM Studio\n\nHardware requirements:\n\nApple Silicon Mac (M1/M2/M3) / Windows / Linux\n16GB+ of RAM is recommended\nNVIDIA/AMD GPUs supported"
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#orientierungshilfe-für-lehrpersonen-der-bfh",
    "href": "slides/cas-hochschuldidaktik.html#orientierungshilfe-für-lehrpersonen-der-bfh",
    "title": "CAS Hochschuldidaktik",
    "section": " Orientierungshilfe für Lehrpersonen der BFH",
    "text": "Orientierungshilfe für Lehrpersonen der BFH\n\n\n\n\nHaltung der BFH: Technologien, die den Lernprozess unterstützen und praxisrelevant sind, sollen in die Lehre einbezogen werden.\nEinsatz von KI in der Lehre: Die Mehrheit der Studierenden wird KI-Tools nutzen. Studierende sollen lernen, Technologien kompetent einzusetzen und kritisch zu hinterfragen.\n\n\n\n\n \n Knowledge Base der Virtuellen Akademie\n PDF"
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#assistant-menagerie",
    "href": "slides/cas-hochschuldidaktik.html#assistant-menagerie",
    "title": "CAS Hochschuldidaktik",
    "section": " Assistant Menagerie",
    "text": "Assistant Menagerie\n\n\n\nAssistant\nProvider\nPrivacy\nLLM\nCapabilities\nPricing model\n\n\n\n\nChatGPT\nOpenAI\n👎🏼\nGPT-3.5, GPT-4\nWeb search, DALLE, GPTs, multimodal input\n💶\n\n\nCopilot\nMicrosoft\n👍🏼\nGPT-3.5, GPT-4\nWeb search, DALLE, multimodal input\n🆓 Für BFH Mitarbeitende/Studierende\n\n\nGemini\nGoogle\n👎🏼\nGemini Ultra/Pro/Nano\nWeb search, multimodal input\n💶\n\n\nHuggingChat\n🤗 Hugging Face\n👍🏼\nOpen models (CodeLlama, Llama 2, Mistral, Gemma)\n\n🆓"
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#prompting",
    "href": "slides/cas-hochschuldidaktik.html#prompting",
    "title": "CAS Hochschuldidaktik",
    "section": " Prompting",
    "text": "Prompting"
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#was-ist-ein-prompt",
    "href": "slides/cas-hochschuldidaktik.html#was-ist-ein-prompt",
    "title": "CAS Hochschuldidaktik",
    "section": "Was ist ein Prompt?",
    "text": "Was ist ein Prompt?\n\nDas Ziel eines LLM ist es, Text zu vervollständigen.\nEin Prompt ist der Input (Anweisung) eines Sprachmodelles.\n\n\n\n\n Prompt:\n\n\nWrite a haiku about a workshop on large language models.\n\n\n\n\n\n\n Output:\n\n\nWhispers of circuits, Knowledge blooms in bytes and bits, Model learns and fits.\n\n\n\n\nDie Antwort wird als Fortsetzung des Prompts generiert."
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#fähigkeiten-freischalten",
    "href": "slides/cas-hochschuldidaktik.html#fähigkeiten-freischalten",
    "title": "CAS Hochschuldidaktik",
    "section": "Fähigkeiten freischalten",
    "text": "Fähigkeiten freischalten\n\n\n\nLLMs lernen Aufgaben zu lösen, für die sie nicht trainiert wurden.\nFähigkeiten müssen durch den richtigen Prompt “freigeschaltet” werden.\n \n\n\n\nWas ist der richtige Prompt?\n\nSehr ähnlich zu dem, was man einem menschlichen Dialogpartner/Assistenten sagen würde.\nChancen, die gewünschte Ausgabe zu erhalten, werden durch gute Fragen oder genügend Informationen erhöht."
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#grundlagen-des-prompting",
    "href": "slides/cas-hochschuldidaktik.html#grundlagen-des-prompting",
    "title": "CAS Hochschuldidaktik",
    "section": "Grundlagen des Prompting",
    "text": "Grundlagen des Prompting\n\nOpenAI gibt eine  Reihe von Strategien für die effektive Nutzung ihrer Modelle.\n\nDiese beinhalten:\n\nklare Anweisungen schreiben\nReferenztexte bereitstellen\nAufgaben in Teilaufgaben unterteilen\ndem LLM ‘Zeit zum Nachdenken’ geben\nexterne Tools verwenden"
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#klare-anweisungen-schreiben",
    "href": "slides/cas-hochschuldidaktik.html#klare-anweisungen-schreiben",
    "title": "CAS Hochschuldidaktik",
    "section": "Klare Anweisungen schreiben",
    "text": "Klare Anweisungen schreiben\n\n\n\nTeile einem LLM mit, welche Art von Gespräch du führen möchtest.\n\nAnweisungen sollten klar und eindeutig sein.\nGib an, welche Rolle (Persona) das Modell übernehmen soll.\n\n\n\n\n\n\n\nGib Details in deiner Anfrage an, um relevantere Antworten zu bekommen\nBitte das Modell, eine Persona zu übernehmen\nVerwende Trennzeichen, um klar auf die unterschiedlichen Teile der Eingabe hinzuweisen\nGib die Schritte an, die zur Durchführung einer Aufgabe erforderlich sind\nGib Beispiele\nGib die gewünschte Länge der Ausgabe an"
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#eine-rolle-zuweisen",
    "href": "slides/cas-hochschuldidaktik.html#eine-rolle-zuweisen",
    "title": "CAS Hochschuldidaktik",
    "section": "Eine Rolle zuweisen",
    "text": "Eine Rolle zuweisen\n\n\n\n Prompt:\n\n\nYou are an expert on learning techniques. Explain the concept of ‘flipped classroom’ in one paragraph.\n\n\n\n\n\n\n Prompt:\n\n\nYou are an expert on financial derivatives. Explain the concept of ‘flipped classroom’ in one paragraph."
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#referenztexte-bereitstellen",
    "href": "slides/cas-hochschuldidaktik.html#referenztexte-bereitstellen",
    "title": "CAS Hochschuldidaktik",
    "section": "Referenztexte bereitstellen",
    "text": "Referenztexte bereitstellen\n\nStelle einem Modell vertrauenswürdige und relevante Informationen zur Verfügung.\nWeise das Modell an, die bereitgestellten Informationen zur Erstellung der Antwort zu verwenden.\n\n Weise das Modell an, eine Antwort unter Verwendung eines Referenztextes zu geben"
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#einem-llm-zeit-zum-denken-geben",
    "href": "slides/cas-hochschuldidaktik.html#einem-llm-zeit-zum-denken-geben",
    "title": "CAS Hochschuldidaktik",
    "section": "Einem LLM ‘Zeit zum Denken’ geben",
    "text": "Einem LLM ‘Zeit zum Denken’ geben\n\nLLMs generieren Text ein Wort nach dem anderen - das Modell verwendet die gleiche Menge an Berechnung für jedes Wort.\nWenn das Modell gezwungen wird, mehr Text zu produzieren, hat es mehr Schritte um “Nachzudenken”.\n\n Das Modell wird eine bessere Antwort geben.\n\nDiese Technik ist bekannt als chain-of-thought-Prompting und kann oft einfach durch die Anweisung an das Modell induziert werden, “Schritt für Schritt zu denken” (think step-by-step) oder “Nimm dir einen Moment Zeit und arbeite dieses Problem Schritt für Schritt durch” (Take a deep breath and work on this problem step-by-step)(Yang et al. 2023).\nCopilot und ChatGPT machen dies seit Neuem automatisch."
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#markdown-formatierung-verwenden",
    "href": "slides/cas-hochschuldidaktik.html#markdown-formatierung-verwenden",
    "title": "CAS Hochschuldidaktik",
    "section": "Markdown-Formatierung verwenden",
    "text": "Markdown-Formatierung verwenden\n\nVerwende Markdown zur Formatierung deiner Prompts.\nWeise das LLM an, den Output mit Markdown zu formatieren.\n\n\n\n\n Prompt:\n\n\nImprove this haiku:\n\n## Whispers of circuits\n\nWords weave through the air,  \nMinds meld with machine's deep thought,  \nKnowledge blooms anew.  \n\nIt is about about a workshop on large language models. I'm not happy with the phrase \" machine's deep thought\".\n\nShow me all the text. Format the text you added as _TEXT_ and show me the deleted text formatted as ~~TEXT~~ in the new haiku. Keep you review short (max 100 words)."
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#fortgeschrittene-prompting-techniken",
    "href": "slides/cas-hochschuldidaktik.html#fortgeschrittene-prompting-techniken",
    "title": "CAS Hochschuldidaktik",
    "section": "Fortgeschrittene Prompting-Techniken",
    "text": "Fortgeschrittene Prompting-Techniken\nWeiterführende Information zu Prompting-Techniken:\n\n Learn prompting\n Prompting guide\n OpenAI cookbook"
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#wofür-sind-llms-gut",
    "href": "slides/cas-hochschuldidaktik.html#wofür-sind-llms-gut",
    "title": "CAS Hochschuldidaktik",
    "section": "Wofür sind LLMs gut?",
    "text": "Wofür sind LLMs gut?\n\nKorrigieren von Grammatik, schlechtem Stil, usw.\nUmschreiben/Paraphrasieren von Texten\nAnalysieren von Texten (Argumentation, Stil, usw.)\nÜbersetzen von Sprachen\nErstellen von strukturiertem Output\nSchreiben von Computercode\nBeantworten von Fragen zu einer Wissensbasis\nFaktische Ausgabe nur mit RAG oder Websuche"
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#übungen",
    "href": "slides/cas-hochschuldidaktik.html#übungen",
    "title": "CAS Hochschuldidaktik",
    "section": " Übungen",
    "text": "Übungen\n Prompt Techniken selber ausprobieren"
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#fortgeschrittene-llm-techniken",
    "href": "slides/cas-hochschuldidaktik.html#fortgeschrittene-llm-techniken",
    "title": "CAS Hochschuldidaktik",
    "section": "Fortgeschrittene LLM-Techniken",
    "text": "Fortgeschrittene LLM-Techniken"
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#retrieval-augmented-generation-rag",
    "href": "slides/cas-hochschuldidaktik.html#retrieval-augmented-generation-rag",
    "title": "CAS Hochschuldidaktik",
    "section": "Retrieval-augmented Generation (RAG)",
    "text": "Retrieval-augmented Generation (RAG)\n\n\nAbbildung von Pinecone"
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#websuche",
    "href": "slides/cas-hochschuldidaktik.html#websuche",
    "title": "CAS Hochschuldidaktik",
    "section": "Websuche",
    "text": "Websuche\n\nÄhnlich wie die Retrieval-augmented Generation, aber mit Websuche.\nLLMs können angewiesen werden, die Websuche zur Informationsbeschaffung zu nutzen.\nLLM fasst die Informationen zusammen und benutzt sie als Referenztext zur Beantwortung der Frage.\nCopilot macht dies automatisch - ChatGPT (nur kostenpflichtige Version) kann angewiesen werden, dies zu tun."
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#externe-werkzeuge",
    "href": "slides/cas-hochschuldidaktik.html#externe-werkzeuge",
    "title": "CAS Hochschuldidaktik",
    "section": "Externe Werkzeuge",
    "text": "Externe Werkzeuge\n\nLLMs können angewiesen werden, externe Werkzeuge zur Aufgabenerfüllung zu nutzen.\nZum Beispiel kann ein LLM angewiesen werden, einen Taschenrechner zur Durchführung von Rechenoperationen zu verwenden.\nOpenAI nennt diesen Ansatz Funktionsaufruf."
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#lokale-modelle",
    "href": "slides/cas-hochschuldidaktik.html#lokale-modelle",
    "title": "CAS Hochschuldidaktik",
    "section": "Lokale Modelle",
    "text": "Lokale Modelle\n\nLaden Sie Modelle herunter und führen Sie sie lokal aus, wie z.B. Llama 2 oder Code Llama.\nOllama\nLM Studio\n\nHardwareanforderungen:\n\nApple Silicon Mac (M1/M2/M3) / Windows / Linux\nEs wird empfohlen, 16GB+ RAM zu haben\nNVIDIA/AMD GPUs werden unterstützt"
  },
  {
    "objectID": "slides/cas-hochschuldidaktik.html#references",
    "href": "slides/cas-hochschuldidaktik.html#references",
    "title": "CAS Hochschuldidaktik",
    "section": "References",
    "text": "References\n\n\nYang, Chengrun, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V. Le, Denny Zhou, and Xinyun Chen. 2023. “Large Language Models as Optimizers.” September 6, 2023. http://arxiv.org/abs/2309.03409.\n\n\n\n\n\nback to website"
  },
  {
    "objectID": "slides/04-reflection.html#idea-generation",
    "href": "slides/04-reflection.html#idea-generation",
    "title": "Idea Generation and Reflection",
    "section": "Idea Generation",
    "text": "Idea Generation\n\nIdeas for tools: Do you have any ideas that weren’t discussed in this workshop? What would you like to see in the future?\nOpportunities and challenges: What are the opportunities and challenges involved with using LLMs in educational settings?"
  },
  {
    "objectID": "slides/04-reflection.html#reflection",
    "href": "slides/04-reflection.html#reflection",
    "title": "Idea Generation and Reflection",
    "section": "Reflection",
    "text": "Reflection\n\nDo you feel confident in using LLMs in your educational practice? What would help you feel more confident?\nDo you feel that you understand how to apply LLMs?\nDo you feel confident in evaluating LLM-based tools?"
  },
  {
    "objectID": "slides/04-reflection.html#thank-you-for-attending-this-workshop",
    "href": "slides/04-reflection.html#thank-you-for-attending-this-workshop",
    "title": "Idea Generation and Reflection",
    "section": "Thank you for attending this workshop!",
    "text": "Thank you for attending this workshop!\n  \n🌟 Your feedback matters! Please take 5 minutes to complete our 👉 evaluation form."
  },
  {
    "objectID": "slides/04-reflection.html#evaluation-form",
    "href": "slides/04-reflection.html#evaluation-form",
    "title": "Idea Generation and Reflection",
    "section": "Evaluation Form",
    "text": "Evaluation Form\n\n\n\n\nback to website ⤴️"
  },
  {
    "objectID": "slides/02-prompting-techniques.html#what-is-a-prompt",
    "href": "slides/02-prompting-techniques.html#what-is-a-prompt",
    "title": "Basic Prompting Techniques",
    "section": "What is a prompt?",
    "text": "What is a prompt?\n\nRemember: the goal of an LLM is complete text.\nA prompt is a piece of text (instruction) that is given to a language model to complete.\n\n\n\n\nPROMPT : Write a haiku about a workshop on large language models.\nASSISTANT : Whispers of circuits,\nKnowledge blooms in bytes and bits,\nModel learns and fits.\n\n\n\n\nThe response is generated as continuation of the prompt.\n\n\nMore technical definition: The output is generated by auto-regressively sampling from the probability distribution over the vocabulary, conditioned on the prompt."
  },
  {
    "objectID": "slides/02-prompting-techniques.html#unlocking-knowledge",
    "href": "slides/02-prompting-techniques.html#unlocking-knowledge",
    "title": "Basic Prompting Techniques",
    "section": "Unlocking knowledge",
    "text": "Unlocking knowledge\n\n\n\n\n\nLLMs learn to do things they were not explicitly trained to do. \nOften, these capabilities need to be “unlocked” by the right prompt. \n\n\n\nWhat is the right prompt?\nThe answer is very similar to what you would tell a human dialogue partner.\nYou can increase the probability of getting the desired output by asking good questions."
  },
  {
    "objectID": "slides/02-prompting-techniques.html#basics-of-prompting",
    "href": "slides/02-prompting-techniques.html#basics-of-prompting",
    "title": "Basic Prompting Techniques",
    "section": "Basics of prompting",
    "text": "Basics of prompting"
  },
  {
    "objectID": "slides/02-prompting-techniques.html#basics-of-prompting-1",
    "href": "slides/02-prompting-techniques.html#basics-of-prompting-1",
    "title": "Basic Prompting Techniques",
    "section": "Basics of prompting",
    "text": "Basics of prompting\nOpenAI give a set of strategies for using their models\n\nThese include:\n\nwriting clear instructions\nproviding reference texts\nsplitting tasks into subtasks\ngiving GPT ‘time to think’\nusing external tools\n\n\n👉 Prompt engineering"
  },
  {
    "objectID": "slides/02-prompting-techniques.html#writing-clear-instructions",
    "href": "slides/02-prompting-techniques.html#writing-clear-instructions",
    "title": "Basic Prompting Techniques",
    "section": "Writing clear instructions",
    "text": "Writing clear instructions\n\n\n\nThink of an LLM as a role-playing conversation simulator.\nInstructions should be clear and unambiguous.\nIndicate which role the model (persona) should adopt.\n\n\n\n\n\n\nInclude details in your query to get more relevant answers\nAsk the model to adopt a persona\nUse delimiters to clearly indicate distinct parts of the input\nSpecify the steps required to complete a task\nProvide examples\nSpecify the desired length of the output"
  },
  {
    "objectID": "slides/02-prompting-techniques.html#adopt-a-persona-role",
    "href": "slides/02-prompting-techniques.html#adopt-a-persona-role",
    "title": "Basic Prompting Techniques",
    "section": "Adopt a persona (role)",
    "text": "Adopt a persona (role)\n\n\n\n: You are an expert on learning techniques. Explain the concept of ‘flipped classroom’ in one paragraph.\n: You are an expert financial derivatives. Explain the concept of ‘flipped classroom’ in one paragraph."
  },
  {
    "objectID": "slides/02-prompting-techniques.html#provide-reference-texts",
    "href": "slides/02-prompting-techniques.html#provide-reference-texts",
    "title": "Basic Prompting Techniques",
    "section": "Provide reference texts",
    "text": "Provide reference texts\n\nProvide a model with trusted and relevant information.\nThen instruct the model to use the provided information to compose its answer.\n\n\n\nThis leads to retrieval-augmented generation (RAG). First create a database of documents, then retrieve the most relevant documents, based on a user’s query. These are then included in the prompt to the model. The model is instructed to use the information in the documents to compose its answer."
  },
  {
    "objectID": "slides/02-prompting-techniques.html#provide-reference-texts-1",
    "href": "slides/02-prompting-techniques.html#provide-reference-texts-1",
    "title": "Basic Prompting Techniques",
    "section": "Provide reference texts",
    "text": "Provide reference texts\n\n\n\n: You will be provided with a document delimited by triple quotes and a question. Your task is to provide a simplified answer to the question using only the provided document and to cite the passage(s) of the document used to answer the question. If the document does not contain the information needed to answer this question then simply write: “Insufficient information.” If an answer to the question is provided, it must be annotated with a citation. Use the following format for to cite relevant passages ({“citation”: …}).\n## Document\n’‘’The flipped classroom intentionally shifts instruction to a learner-centered model, in which students are often initially introduced to new topics outside of school, freeing up classroom time for the exploration of topics in greater depth, creating meaningful learning opportunities. With a flipped classroom, ’content delivery’ may take a variety of forms, often featuring video lessons prepared by the teacher or third parties, although online collaborative discussions, digital research, and text readings may alternatively be used. The ideal length for a video lesson is widely cited as eight to twelve minutes.’’’\n## Question\nWhat is flipped classroom?"
  },
  {
    "objectID": "slides/02-prompting-techniques.html#giving-gpt-time-to-think",
    "href": "slides/02-prompting-techniques.html#giving-gpt-time-to-think",
    "title": "Basic Prompting Techniques",
    "section": "Giving GPT ‘time to think’",
    "text": "Giving GPT ‘time to think’\n\nLLMs generate text one word at a time–the model spends the same amount of computation on each word.\nGiving the model more context gives it more steps to “think”.\nThis increases the chances that the model will give a good answer.\nThis technique is known as chain-of-thought prompting, and can often be induced by simply instructing the model to think step-by-step or Take a deep breath and work on this problem step-by-step (Yang et al. 2023)."
  },
  {
    "objectID": "slides/02-prompting-techniques.html#chain-of-thought-prompting",
    "href": "slides/02-prompting-techniques.html#chain-of-thought-prompting",
    "title": "Basic Prompting Techniques",
    "section": "Chain-of-thought prompting",
    "text": "Chain-of-thought prompting\n\nChain-of-thought prompting encourages the LLM to “explain” its intermediate reasoning steps.\nEnables complex reasoning and problem solving.\n\n\n\n\nInstead of this:\n: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\nDo this:\n: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.  The odd numbers are 9, 15, 1.  The sum of the odd numbers is 9 + 15 + 1 = 25.  25 is an odd number.  Therefore, the statement is false.\n\n\n\n\nWhy does this work?"
  },
  {
    "objectID": "slides/02-prompting-techniques.html#zero-shot-chain-of-thought-prompting",
    "href": "slides/02-prompting-techniques.html#zero-shot-chain-of-thought-prompting",
    "title": "Basic Prompting Techniques",
    "section": "Zero-shot chain-of-thought prompting",
    "text": "Zero-shot chain-of-thought prompting\n\n\n\n: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1. Take a deep breath and think step-by-step.\n\n\n\n\n\nWhen using GPT-4, ChatGPT and Bing seem to be doing this automatically."
  },
  {
    "objectID": "slides/02-prompting-techniques.html#explore-prompting-techniques",
    "href": "slides/02-prompting-techniques.html#explore-prompting-techniques",
    "title": "Basic Prompting Techniques",
    "section": "Explore prompting techniques",
    "text": "Explore prompting techniques\nNow open the first activity to learn more about ChatGPT and OpenAI Playground:\n👉 Activity 1."
  },
  {
    "objectID": "slides/00-introduction.html#take-home-messages",
    "href": "slides/00-introduction.html#take-home-messages",
    "title": "What is ChatGPT?",
    "section": "🏠 Take-home messages",
    "text": "🏠 Take-home messages\n\nUse LLMs yourself! It’s important to gain an intuition for their capabilities and limitations.\nCombine domain knowledge of the “thing” you are working on, an understanding of how LLMs work, and an understanding of how to prompt them.\nUse LLMs with students in a classroom setting. This will help students to develop their own understanding of LLMs and become AI-literate.\nAlways (critically 👩‍🔬) check an LLM’s output. They are language models, not knowledge bases. Keep a human in the loop."
  },
  {
    "objectID": "slides/00-introduction.html#learning-outcomes",
    "href": "slides/00-introduction.html#learning-outcomes",
    "title": "What is ChatGPT?",
    "section": "🎯 Learning outcomes",
    "text": "🎯 Learning outcomes\n\n\n\nAfter this workshop, you will be able to:\n\n\n\nExplain what large language models and conversational agents, such as ChatGPT, can be used for, and what they shouldn’t be used for.\nCreate effective prompts for LLMs.\nDesign your own LLM-based educational activities.\nCritically evaluate LLM-based educational activities."
  },
  {
    "objectID": "slides/00-introduction.html#schedule",
    "href": "slides/00-introduction.html#schedule",
    "title": "What is ChatGPT?",
    "section": "⏱️ Schedule",
    "text": "⏱️ Schedule"
  },
  {
    "objectID": "slides/00-introduction.html#contents",
    "href": "slides/00-introduction.html#contents",
    "title": "What is ChatGPT?",
    "section": "Contents",
    "text": "Contents\n\nExample: 20 questions\nWhat is ChatGPT?\n\nBase model\nAssistant model\n\nWhat is it not?\nChatGPT as a role-play simulator"
  },
  {
    "objectID": "slides/00-introduction.html#questions",
    "href": "slides/00-introduction.html#questions",
    "title": "What is ChatGPT?",
    "section": "20 questions",
    "text": "20 questions\n\n\n\n\n\n\n🤷‍♂️ What is ChatGPT doing here?\nHow does this work?"
  },
  {
    "objectID": "slides/00-introduction.html#what-is-chatgpt",
    "href": "slides/00-introduction.html#what-is-chatgpt",
    "title": "What is ChatGPT?",
    "section": "What is ChatGPT?",
    "text": "What is ChatGPT?\n\n\n\n\n\nConsists of a base model and an assistant model.\nBase or foundation model: probabilistic model of how language is generated.\nAssistant: able to create human-like dialogue."
  },
  {
    "objectID": "slides/00-introduction.html#base-model-text-prediction",
    "href": "slides/00-introduction.html#base-model-text-prediction",
    "title": "What is ChatGPT?",
    "section": "Base model: text prediction",
    "text": "Base model: text prediction\n\n\n\n\n\n\n\nExtracts knowledge from text: linguistic, factual, commonsense, etc."
  },
  {
    "objectID": "slides/00-introduction.html#base-model",
    "href": "slides/00-introduction.html#base-model",
    "title": "What is ChatGPT?",
    "section": "Base model",
    "text": "Base model\nProduces text that most likely follows the input (prompt).\n\n\n\n: What is the capital of France?\n: What is the capital of Germany? What is the capital of Italy? …\n\n\n\n\n\n\n: The first person to walk on the Moon was\n: Neil Armstrong\n\n\n\n\n\n\nDoes an LLM know facts?\n\n\nWhat we are really asking: Given what it learned during training, what words are most likely to follow “The first person to walk on the Moon was”? A good reply to this question is “Neil Armstrong”."
  },
  {
    "objectID": "slides/00-introduction.html#base-model-emergent-properties",
    "href": "slides/00-introduction.html#base-model-emergent-properties",
    "title": "What is ChatGPT?",
    "section": "Base model: emergent properties",
    "text": "Base model: emergent properties\nLLMs are thought to show emergent properties - abilities not explicitly programmed into the model, but emerge as a result of text prediction.\n\nperforming arithmetic, answering questions, summarizing text, translating, etc.\nzero-shot learning: LLMs can perform tasks without being trained on them.\nfew-shot learning: LLMs can perform tasks with few examples."
  },
  {
    "objectID": "slides/00-introduction.html#assistant-model-alignment",
    "href": "slides/00-introduction.html#assistant-model-alignment",
    "title": "What is ChatGPT?",
    "section": "Assistant model: alignment",
    "text": "Assistant model: alignment\n\n\n\n\n\n  - Trained to have conversations: turn-taking, question answering, not being [rude/sexist/racist], etc."
  },
  {
    "objectID": "slides/00-introduction.html#chatbot",
    "href": "slides/00-introduction.html#chatbot",
    "title": "What is ChatGPT?",
    "section": "Chatbot",
    "text": "Chatbot\n\n\n\n\n\n\nPrompt: System message: You are a helpful assistant. User message: Tell me a joke.\n: Why don’t scientists trust atoms? Because they make up everything!\nPrompt: System message: You are a helpful assistant. User message: Tell me a joke. Assistant message: Why don’t scientists trust atoms? Because they make up everything! User message: Tell me another one.\n: Why did the scarecrow win an award? Because he was outstanding in his field! ::: –&gt;"
  },
  {
    "objectID": "slides/00-introduction.html#knowledge-base",
    "href": "slides/00-introduction.html#knowledge-base",
    "title": "What is ChatGPT?",
    "section": "Knowledge base",
    "text": "Knowledge base\n\n\n\n\n\nA knowledge base is a collection of facts about the world.\nAsk and Tell\nI can ask but I can’t tell.\nIt cannot give me verifiable facts."
  },
  {
    "objectID": "slides/00-introduction.html#knowledge-base-1",
    "href": "slides/00-introduction.html#knowledge-base-1",
    "title": "What is ChatGPT?",
    "section": "Knowledge base",
    "text": "Knowledge base\n\n\n\n\n\nAm Strande von Rainer Maria Rilke  👉 Open in ChatGPT\n\n\n\n\n\n\nKennst du dieses Gedicht?  👉 Open in ChatGPT\n\n\n\n\n\nWhat can we learn from this?"
  },
  {
    "objectID": "slides/00-introduction.html#knowledge-base-2",
    "href": "slides/00-introduction.html#knowledge-base-2",
    "title": "What is ChatGPT?",
    "section": "Knowledge base",
    "text": "Knowledge base\n\n\n\n\n\nCan’t tell me where it got its information from.\nLLMs are models of knowledge bases, but not knowledge bases themselves.\nExpensive/difficult to update with new knowledge.\nProduce ethically questionable results."
  },
  {
    "objectID": "slides/00-introduction.html#an-llm-is-a-role-play-simulator",
    "href": "slides/00-introduction.html#an-llm-is-a-role-play-simulator",
    "title": "What is ChatGPT?",
    "section": "An LLM is a role-play simulator",
    "text": "An LLM is a role-play simulator\n\n\n\n\n\n\n\nWe can think of an LLM as a non-deterministic simulator capable of role-playing an infinity of characters, or, to put it another way, capable of stochastically generating an infinity of simulacra (Shanahan, McDonell, and Reynolds 2023)"
  },
  {
    "objectID": "slides/00-introduction.html#an-llm-is-a-role-play-simulator-1",
    "href": "slides/00-introduction.html#an-llm-is-a-role-play-simulator-1",
    "title": "What is ChatGPT?",
    "section": "An LLM is a role-play simulator",
    "text": "An LLM is a role-play simulator\n\nAn assistant is trained to respond to user prompts in a human-like way.\nA simulator of possible human conversation.\nHas no intentions. It is not an entity with its own goals.\nDoes not have a “personality” or “character” in the traditional sense. It can be thought of as a role-playing simulator.\nHas no concept of “truth” or “lying”. The model is not trying to deceive the user, it is simply trying to respond in a human-like way."
  },
  {
    "objectID": "slides/00-introduction.html#an-llm-is-a-role-play-simulator-2",
    "href": "slides/00-introduction.html#an-llm-is-a-role-play-simulator-2",
    "title": "What is ChatGPT?",
    "section": "An LLM is a role-play simulator",
    "text": "An LLM is a role-play simulator\n\n\n\n\n\nThe dialogue agent will do its best to role-play a character in a dialogue.\nAt every step, the model is trying to generate text that is most likely to follow the input.\nIt can take many different paths. Your interaction is just one of those possible paths."
  },
  {
    "objectID": "slides/00-introduction.html#an-llm-is-a-role-play-simulator-3",
    "href": "slides/00-introduction.html#an-llm-is-a-role-play-simulator-3",
    "title": "What is ChatGPT?",
    "section": "An LLM is a role-play simulator",
    "text": "An LLM is a role-play simulator\n\n\n\n\n\n\nYou can open this conversation in ChatGPT.\nTry re-generating the conversation after the initial prompt."
  },
  {
    "objectID": "slides/00-introduction.html#what-are-llms-good-at",
    "href": "slides/00-introduction.html#what-are-llms-good-at",
    "title": "What is ChatGPT?",
    "section": "What are LLMs good at?",
    "text": "What are LLMs good at?\n\n\n\nFixing grammar, bad writing, etc.\nRephrasing\nAnalyze texts\nWrite computer code\nAnswer questions about a knowledge base\nTranslate languages\nCreating structured output"
  },
  {
    "objectID": "slides/00-introduction.html#references",
    "href": "slides/00-introduction.html#references",
    "title": "What is ChatGPT?",
    "section": "References",
    "text": "References\n\n\nShanahan, Murray. 2023. “Talking About Large Language Models.” January 25, 2023. https://doi.org/10.48550/arXiv.2212.03551.\n\n\nShanahan, Murray, Kyle McDonell, and Laria Reynolds. 2023. “Role-Play with Large Language Models.” May 25, 2023. https://doi.org/10.48550/arXiv.2305.16367.\n\n\nWei, Jason, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, et al. 2022. “Emergent Abilities of Large Language Models.” October 26, 2022. https://doi.org/10.48550/arXiv.2206.07682.\n\n\n\n\n\nback to website ⤴️"
  },
  {
    "objectID": "pages/tutorial-basic-prompting.html",
    "href": "pages/tutorial-basic-prompting.html",
    "title": "Prompting basics",
    "section": "",
    "text": "Code\nfrom openai import OpenAI\nclient = OpenAI()\n\nresponse = client.chat.completions.create(\n  model=\"gpt-4-turbo-preview\",\n  messages=[\n    {\n      \"role\": \"system\",\n      \"content\": \"When I ask for help to write something, you will reply with a document that contains at least one joke or playful comment in every paragraph.\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Write a thank you note to my steel bolt vendor for getting the delivery in on time and in short notice. This made it possible for us to deliver an important order.\"\n    }\n  ],\n  temperature=0.7,\n  max_tokens=1024,\n  top_p=1,\n  frequency_penalty=0,\n  presence_penalty=0,\n  logprobs=True\n)"
  },
  {
    "objectID": "pages/tutorial-basic-prompting.html#openai",
    "href": "pages/tutorial-basic-prompting.html#openai",
    "title": "Prompting basics",
    "section": "",
    "text": "Code\nfrom openai import OpenAI\nclient = OpenAI()\n\nresponse = client.chat.completions.create(\n  model=\"gpt-4-turbo-preview\",\n  messages=[\n    {\n      \"role\": \"system\",\n      \"content\": \"When I ask for help to write something, you will reply with a document that contains at least one joke or playful comment in every paragraph.\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Write a thank you note to my steel bolt vendor for getting the delivery in on time and in short notice. This made it possible for us to deliver an important order.\"\n    }\n  ],\n  temperature=0.7,\n  max_tokens=1024,\n  top_p=1,\n  frequency_penalty=0,\n  presence_penalty=0,\n  logprobs=True\n)"
  },
  {
    "objectID": "pages/text-representation.html",
    "href": "pages/text-representation.html",
    "title": "Text representation",
    "section": "",
    "text": "Text embeddings are numerical representations of words, sentences or documents. They are used in many NLP tasks, such as sentiment analysis, machine translation, and question answering.\n\nEmbeddings should capture features of words or concepts, and relationships between these.\nA sentence embedding is just like a word embedding, except it associates every sentence with a vector full of numbers, capturing similarities between sentences.\nThe key idea is that words/sentences with similar meanings will have similar vectors. This is useful for many tasks in natural language processing, such as sentiment analysis, machine translation, and question answering.\n\nYou can read more about text embeddings in this 👉 post.\nThe following is an example of sentence embeddings, showing the distance between sentences. The distance is calculated using the dot product (cosine similarity) of the embeddings.\n\n\n\n\nCode\nfrom langchain.embeddings.openai import OpenAIEmbeddings\n# embedding = OpenAIEmbeddings()\nembedding = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pyobsplot import Plot, d3, Math, js\n\n\n/Users/andrew/GitHub/sites/promptly-literate/env/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning:\n\nThe class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n\n\n\n\n\nCode\nsentences = [\n    \"Good morning, how are you?\",\n    \"I am doing well, how about you?\",\n    \"Hi, how are you doing today?\",\n    \"Hey, what's up?\",\n    \"I like apples.\",\n    \"One of my daughters doesn't like kiwis.\",\n    \"The other doesn't like bananas.\",\n    \"The earth is the third planet from the sun.\",\n    \"The moon is a natural satellite of the earth.\",\n    \"Jupiter is the fifth planet from the Sun and the largest in the Solar System.\",\n    \"The humpback whale is renowned for its enchanting songs, which are believed to serve various purposes, including communication, mating, and navigation during migration.\",\n    \"Dolphins, highly intelligent marine mammals, communicate with each other using a complex system of clicks, whistles, and body language, enabling them to work together in hunting and navigation.\",\n    \"The honeybee, through its pollination efforts, plays a vital role in agriculture, contributing to the growth of many of the fruits and vegetables humans rely on for sustenance.\",\n    \"The Large Plane Trees, also known as Road Menders at Saint-Rémy, is an oil-on-canvas painting by Vincent van Gogh.\",\n    \"Pablo Picasso's Guernica, an iconic mural-sized oil painting, stands as a poignant representation of the horrors of war.\",\n    \"This powerful artwork was created in response to the bombing of the town of Guernica during the Spanish Civil War.\"\n]\n\n\n\n\nCode\nembeddings = np.array([embedding.embed_query(sentence) for sentence in sentences])\n\ndot_product_matrix = np.dot(embeddings, embeddings.T)\n\ndf = pd.DataFrame(dot_product_matrix, columns=range(1, len(embeddings)+1))\n\ndf['embedding_index'] = range(1, len(embeddings)+1)\n\ndf = df.melt(id_vars=['embedding_index'], var_name='embedding_index_2', value_name='similarity')\n\n\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\n\n\n\n\n\n\n\n\n\n\n\nSentences\n\n\n\n\n1\nGood morning, how are you?\n\n\n2\nI am doing well, how about you?\n\n\n3\nHi, how are you doing today?\n\n\n4\nHey, what's up?\n\n\n5\nI like apples.\n\n\n6\nOne of my daughters doesn't like kiwis.\n\n\n7\nThe other doesn't like bananas.\n\n\n8\nThe earth is the third planet from the sun.\n\n\n9\nThe moon is a natural satellite of the earth.\n\n\n10\nJupiter is the fifth planet from the Sun and the largest in the Solar System.\n\n\n11\nThe humpback whale is renowned for its enchanting songs, which are believed to serve various purposes, including communication, mating, and navigation during migration.\n\n\n12\nDolphins, highly intelligent marine mammals, communicate with each other using a complex system of clicks, whistles, and body language, enabling them to work together in hunting and navigation.\n\n\n13\nThe honeybee, through its pollination efforts, plays a vital role in agriculture, contributing to the growth of many of the fruits and vegetables humans rely on for sustenance.\n\n\n14\nThe Large Plane Trees, also known as Road Menders at Saint-Rémy, is an oil-on-canvas painting by Vincent van Gogh.\n\n\n15\nPablo Picasso's Guernica, an iconic mural-sized oil painting, stands as a poignant representation of the horrors of war.\n\n\n16\nThis powerful artwork was created in response to the bombing of the town of Guernica during the Spanish Civil War.\n\n\n\n\n\n\n\n\n\nCode\nPlot.plot(\n    {\n        \"height\": 640,\n        \"padding\": 0.05,\n        \"grid\": True,\n        \"x\": {\"axis\": \"top\", \"label\": \"Embedding Index\"},\n        \"y\": {\"label\": \"Embedding Index\"},\n        \"color\": {\"type\": \"linear\", \"scheme\": \"PiYG\"},\n        \"marks\": [\n            Plot.cell(\n                df,\n                {\"x\": \"embedding_index\", \"y\": \"embedding_index_2\", \"fill\": \"similarity\", \"tip\": True},\n            ),\n            Plot.text(\n                df,\n                {\n                    \"x\": \"embedding_index\",\n                    \"y\": \"embedding_index_2\",\n                    \"text\": js(\"d =&gt; d.similarity.toFixed(2)\"),\n                    \"title\": \"title\"\n                },\n            ),\n        ],\n    }\n)\n\n\n\n\n\nYou can see that the sentences are grouped together by semantic similarity. For example, the sentences about fruit are grouped together, and the sentences about planets are grouped together, in the sense that they are similar to each other.\nThis is important: embeddings capture the meaning of words and sentences, and are the basis of LLMs’ ability to “understand” language.\nHere is an alternative similarity plot, showing the general topic of each sentence.\n\n\nCode\ntopics = {\"Greeting\": 4, \"Fruit\": 3,\n          \"Planets\": 3, \"Animals\": 3,\n          \"Art\": 3}\ntopics_repeated = [key for key, value in topics.items() for i in range(value)]\n\n\n# Create the similarity matrix\nembeddings = np.array([embedding.embed_query(sentence) for sentence in sentences])\ndot_product_matrix = np.dot(embeddings, embeddings.T)\n\n# Create the heatmap\nfig, ax = plt.subplots()\nim = ax.imshow(dot_product_matrix)\n\n# Set the x and y axis labels\nax.set_xticks(np.arange(len(sentences)))\nax.set_yticks(np.arange(len(sentences)))\nax.set_xticklabels(topics_repeated)\nax.set_yticklabels(topics_repeated)\n\n# Rotate the x axis labels\nplt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n\n# Add a colorbar\ncbar = ax.figure.colorbar(im, ax=ax)\n\n# Show the plot\nplt.show()\n\n\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding."
  },
  {
    "objectID": "pages/text-representation.html#embeddings",
    "href": "pages/text-representation.html#embeddings",
    "title": "Text representation",
    "section": "",
    "text": "Text embeddings are numerical representations of words, sentences or documents. They are used in many NLP tasks, such as sentiment analysis, machine translation, and question answering.\n\nEmbeddings should capture features of words or concepts, and relationships between these.\nA sentence embedding is just like a word embedding, except it associates every sentence with a vector full of numbers, capturing similarities between sentences.\nThe key idea is that words/sentences with similar meanings will have similar vectors. This is useful for many tasks in natural language processing, such as sentiment analysis, machine translation, and question answering.\n\nYou can read more about text embeddings in this 👉 post.\nThe following is an example of sentence embeddings, showing the distance between sentences. The distance is calculated using the dot product (cosine similarity) of the embeddings.\n\n\n\n\nCode\nfrom langchain.embeddings.openai import OpenAIEmbeddings\n# embedding = OpenAIEmbeddings()\nembedding = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pyobsplot import Plot, d3, Math, js\n\n\n/Users/andrew/GitHub/sites/promptly-literate/env/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning:\n\nThe class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n\n\n\n\n\nCode\nsentences = [\n    \"Good morning, how are you?\",\n    \"I am doing well, how about you?\",\n    \"Hi, how are you doing today?\",\n    \"Hey, what's up?\",\n    \"I like apples.\",\n    \"One of my daughters doesn't like kiwis.\",\n    \"The other doesn't like bananas.\",\n    \"The earth is the third planet from the sun.\",\n    \"The moon is a natural satellite of the earth.\",\n    \"Jupiter is the fifth planet from the Sun and the largest in the Solar System.\",\n    \"The humpback whale is renowned for its enchanting songs, which are believed to serve various purposes, including communication, mating, and navigation during migration.\",\n    \"Dolphins, highly intelligent marine mammals, communicate with each other using a complex system of clicks, whistles, and body language, enabling them to work together in hunting and navigation.\",\n    \"The honeybee, through its pollination efforts, plays a vital role in agriculture, contributing to the growth of many of the fruits and vegetables humans rely on for sustenance.\",\n    \"The Large Plane Trees, also known as Road Menders at Saint-Rémy, is an oil-on-canvas painting by Vincent van Gogh.\",\n    \"Pablo Picasso's Guernica, an iconic mural-sized oil painting, stands as a poignant representation of the horrors of war.\",\n    \"This powerful artwork was created in response to the bombing of the town of Guernica during the Spanish Civil War.\"\n]\n\n\n\n\nCode\nembeddings = np.array([embedding.embed_query(sentence) for sentence in sentences])\n\ndot_product_matrix = np.dot(embeddings, embeddings.T)\n\ndf = pd.DataFrame(dot_product_matrix, columns=range(1, len(embeddings)+1))\n\ndf['embedding_index'] = range(1, len(embeddings)+1)\n\ndf = df.melt(id_vars=['embedding_index'], var_name='embedding_index_2', value_name='similarity')\n\n\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\n\n\n\n\n\n\n\n\n\n\n\nSentences\n\n\n\n\n1\nGood morning, how are you?\n\n\n2\nI am doing well, how about you?\n\n\n3\nHi, how are you doing today?\n\n\n4\nHey, what's up?\n\n\n5\nI like apples.\n\n\n6\nOne of my daughters doesn't like kiwis.\n\n\n7\nThe other doesn't like bananas.\n\n\n8\nThe earth is the third planet from the sun.\n\n\n9\nThe moon is a natural satellite of the earth.\n\n\n10\nJupiter is the fifth planet from the Sun and the largest in the Solar System.\n\n\n11\nThe humpback whale is renowned for its enchanting songs, which are believed to serve various purposes, including communication, mating, and navigation during migration.\n\n\n12\nDolphins, highly intelligent marine mammals, communicate with each other using a complex system of clicks, whistles, and body language, enabling them to work together in hunting and navigation.\n\n\n13\nThe honeybee, through its pollination efforts, plays a vital role in agriculture, contributing to the growth of many of the fruits and vegetables humans rely on for sustenance.\n\n\n14\nThe Large Plane Trees, also known as Road Menders at Saint-Rémy, is an oil-on-canvas painting by Vincent van Gogh.\n\n\n15\nPablo Picasso's Guernica, an iconic mural-sized oil painting, stands as a poignant representation of the horrors of war.\n\n\n16\nThis powerful artwork was created in response to the bombing of the town of Guernica during the Spanish Civil War.\n\n\n\n\n\n\n\n\n\nCode\nPlot.plot(\n    {\n        \"height\": 640,\n        \"padding\": 0.05,\n        \"grid\": True,\n        \"x\": {\"axis\": \"top\", \"label\": \"Embedding Index\"},\n        \"y\": {\"label\": \"Embedding Index\"},\n        \"color\": {\"type\": \"linear\", \"scheme\": \"PiYG\"},\n        \"marks\": [\n            Plot.cell(\n                df,\n                {\"x\": \"embedding_index\", \"y\": \"embedding_index_2\", \"fill\": \"similarity\", \"tip\": True},\n            ),\n            Plot.text(\n                df,\n                {\n                    \"x\": \"embedding_index\",\n                    \"y\": \"embedding_index_2\",\n                    \"text\": js(\"d =&gt; d.similarity.toFixed(2)\"),\n                    \"title\": \"title\"\n                },\n            ),\n        ],\n    }\n)\n\n\n\n\n\nYou can see that the sentences are grouped together by semantic similarity. For example, the sentences about fruit are grouped together, and the sentences about planets are grouped together, in the sense that they are similar to each other.\nThis is important: embeddings capture the meaning of words and sentences, and are the basis of LLMs’ ability to “understand” language.\nHere is an alternative similarity plot, showing the general topic of each sentence.\n\n\nCode\ntopics = {\"Greeting\": 4, \"Fruit\": 3,\n          \"Planets\": 3, \"Animals\": 3,\n          \"Art\": 3}\ntopics_repeated = [key for key, value in topics.items() for i in range(value)]\n\n\n# Create the similarity matrix\nembeddings = np.array([embedding.embed_query(sentence) for sentence in sentences])\ndot_product_matrix = np.dot(embeddings, embeddings.T)\n\n# Create the heatmap\nfig, ax = plt.subplots()\nim = ax.imshow(dot_product_matrix)\n\n# Set the x and y axis labels\nax.set_xticks(np.arange(len(sentences)))\nax.set_yticks(np.arange(len(sentences)))\nax.set_xticklabels(topics_repeated)\nax.set_yticklabels(topics_repeated)\n\n# Rotate the x axis labels\nplt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n\n# Add a colorbar\ncbar = ax.figure.colorbar(im, ax=ax)\n\n# Show the plot\nplt.show()\n\n\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding.\nWarning: model not found. Using cl100k_base encoding."
  },
  {
    "objectID": "pages/schedule.html",
    "href": "pages/schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Was sind Large Language Models (LLMs)?\nWie werden LLMs trainiert?\nWie generieren LLMs Texte?\nWas sind Ähnlichkeiten und Unterschiede zwischen LLMs und menschlichem Denken?\nWie können wir LLMs benutzen?\nWie können wir LLMs beschreiben, ohne sie zu anthropomorphisieren?"
  },
  {
    "objectID": "pages/schedule.html#inhalt",
    "href": "pages/schedule.html#inhalt",
    "title": "Schedule",
    "section": "",
    "text": "Was sind Large Language Models (LLMs)?\nWie werden LLMs trainiert?\nWie generieren LLMs Texte?\nWas sind Ähnlichkeiten und Unterschiede zwischen LLMs und menschlichem Denken?\nWie können wir LLMs benutzen?\nWie können wir LLMs beschreiben, ohne sie zu anthropomorphisieren?"
  },
  {
    "objectID": "pages/schedule.html#lernziele",
    "href": "pages/schedule.html#lernziele",
    "title": "Schedule",
    "section": "Lernziele",
    "text": "Lernziele\n\n\n\n\n\n\nNach diesem Workshop:\n\n\n\n\nKannst du mit Anfragen von Studierenden in Bezug auf fachspezifische KI-generierte Texte umgehen.\nKannst du in eigenen Worten wiedergeben, wie KI-generierte Texte entstehen.\nHast du Kriterien, anhand derer du KI-Tools beurteilen kannst."
  },
  {
    "objectID": "pages/schedule.html#program",
    "href": "pages/schedule.html#program",
    "title": "Schedule",
    "section": "Program",
    "text": "Program\n\n\n\n\n\nflowchart LR\n  A([\"Einleitung\n            5'\"]) \n  A -.-&gt; B([\"Reaktivationsrunde \n                      10'\"]) \n  B -.-&gt; C([\"Input: Wie funktioniert ChatGPT? \n                      30'\"])\n  C -.-&gt; D([\"Vertiefung: Lernziele 1 + 2 \n                      15'\"]) \n  C -.-&gt; E([\"Vertiefung: Lernziel 3 \n                        15'\"]) \n  D -.-&gt; F([\"Verankern \n                10'\"]) \n  E -.-&gt; F\n  F -.-&gt; G([\"Diskussion \n            15'\"])\n\n\n\n\n\n\n\nEinleitung [⏱️ 5’]: Einstieg in den Workshop\nReaktivationsrunde [⏱️ 10’]: In diesem Teil tauschen die Teilnehmenden sich über ihre Erfahrungen mit KI-generierten Texten aus.\nInput: Wie funktioniert ChatGPT? [⏱️ 30’]: Referat zum Thema künstliche Intelligenz und ChatGPT.\nVertiefung [⏱️ 30’]: In diesem Teil werden die oben genannten Lernziele vertieft (alleine, in Kleingruppen und im Plenum).\nVerankern [⏱️ 10’]: In diesem Teil werden Erfahrungen zusammengefasst und reflektiert.\nDiskussion [⏱️ 15’]: Am Ende des Workshops wird über die Erfahrungen und Erkenntnisse diskutiert."
  },
  {
    "objectID": "pages/schedule.html#vorbereitung",
    "href": "pages/schedule.html#vorbereitung",
    "title": "Schedule",
    "section": "Vorbereitung",
    "text": "Vorbereitung\nLöse folgende Aufgaben mit ChatGPT (oder Bing Chat):\n\nLasse ChatGPT ein Gedicht schreiben. Gebe Thema und Stil vor (z.B. “Hochschulbibliotheken und künstliche Intelligenz” im Stile des Sturm und Drang).\nLasse ChatGPT dir ein Konzept deines Fachbereichs in einem kurzen Textabschnitt vereinfachend erklären.\nBenutze ChatGPT, um zu einem Forschungsthema (z.B. “Was ist der Zusammenhang zwischen Sprache und Denken?”) eine Literaturrecherche durchzuführen. Lasse dir eine kommentierte Liste von wissenschaftlichen Publikationen geben.\nLasse ChatGPT ein paar Mathe-Aufgaben lösen (z.B. “Was ist 89322/1313?”)\nLöse mit ChatGPT eine praktische Aufgabe: “Hier haben wir ein Buch, 9 Eier (ohne Eierkarton), einen Laptop, eine Flasche und einen Nagel. Bitte sag mir, wie ich sie stabil übereinander stapeln kann.”"
  },
  {
    "objectID": "pages/schedule.html#leitung",
    "href": "pages/schedule.html#leitung",
    "title": "Schedule",
    "section": "Leitung",
    "text": "Leitung\n\nAndrew Ellis: Andrew ist Data Scientist an der Virtuellen Akademie der Berner Fachhochschule. Sein Hintergrund ist in den Kognitionswissenschaften und er ist begeistert von der Schnittstelle zwischen Sprache, Denken und künstlicher Intelligenz.”"
  },
  {
    "objectID": "pages/prompting.html",
    "href": "pages/prompting.html",
    "title": "Prompting Programmatically",
    "section": "",
    "text": "import openai\nfrom openai import OpenAI\nclient = OpenAI()\nimport os\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())\n\nopenai.api_key  = os.getenv('OPENAI_API_KEY')\n\nfrom IPython.display import display, Markdown, Latex, HTML, JSON\ndef get_completion(prompt, model=\"gpt-4-turbo-preview\", temperature=0.0):\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    response = client.chat.completions.create(\n        model=model,\n        messages=messages,\n        temperature=temperature\n    )\n    return response.choices[0].message.content"
  },
  {
    "objectID": "pages/prompting.html#prompting-principles",
    "href": "pages/prompting.html#prompting-principles",
    "title": "Prompting Programmatically",
    "section": "Prompting Principles",
    "text": "Prompting Principles\n\nPrinciple 1: Write clear and specific instructions\nPrinciple 2: Give the model time to “think”\n\n\nTactics\n\nTactic 1: Use delimiters to clearly indicate distinct parts of the input\n\nDelimiters can be anything, such as: ``, \"\"\", &lt; &gt;, ,:`\n\n\ntext = f\"\"\"\nYou should express what you want a model to do by \\ \nproviding instructions that are as clear and \\ \nspecific as you can possibly make them. \\ \nThis will guide the model towards the desired output, \\ \nand reduce the chances of receiving irrelevant \\ \nor incorrect responses. Don't confuse writing a \\ \nclear prompt with writing a short prompt. \\ \nIn many cases, longer prompts provide more clarity \\ \nand context for the model, which can lead to \\ \nmore detailed and relevant outputs.\n\"\"\"\nprompt = f\"\"\"\nSummarize the text delimited by triple backticks \\ \ninto a single sentence.\n```{text}```\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\nTo achieve the desired output from a model, provide clear and specific instructions, noting that longer prompts often offer more clarity and context, thus reducing the likelihood of irrelevant or incorrect responses.\n\n\n\n\nTactic 4: “Few-shot” prompting\n\nprompt = f\"\"\"\nYour task is to answer in a consistent style.\n\n&lt;child&gt;: Teach me about patience.\n\n&lt;grandparent&gt;: The river that carves the deepest \\ \nvalley flows from a modest spring; the \\ \ngrandest symphony originates from a single note; \\ \nthe most intricate tapestry begins with a solitary thread.\n\n&lt;child&gt;: Teach me about resilience.\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n&lt;grandparent&gt;: The mightiest oak in the forest was once a tiny acorn that stood its ground; the highest mountain withstands the harshest weather, yet remains steadfast; the most enduring bridges were built one stone at a time."
  },
  {
    "objectID": "pages/prompting.html#sentment-analysis",
    "href": "pages/prompting.html#sentment-analysis",
    "title": "Prompting Programmatically",
    "section": "Sentment Analysis",
    "text": "Sentment Analysis\n\nlamp_review = \"\"\"\nNeeded a nice lamp for my bedroom, and this one had \\\nadditional storage and not too high of a price point. \\\nGot it fast.  The string to our lamp broke during the \\\ntransit and the company happily sent over a new one. \\\nCame within a few days as well. It was easy to put \\\ntogether.  I had a missing part, so I contacted their \\\nsupport and they very quickly got me the missing piece! \\\nLumina seems to me to be a great company that cares \\\nabout their customers and products!!\n\"\"\"\n\n\nprompt = f\"\"\"\nWhat is the sentiment of the following product review, \nwhich is delimited with triple backticks?\n\nReview text: '''{lamp_review}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\nThe sentiment of the provided product review is positive. The reviewer expresses satisfaction with the lamp's features, price, and the company's customer service, including fast shipping and prompt resolution of issues."
  },
  {
    "objectID": "pages/prompting.html#tone-transformation",
    "href": "pages/prompting.html#tone-transformation",
    "title": "Prompting Programmatically",
    "section": "Tone transformation",
    "text": "Tone transformation\n\nprompt = f\"\"\"\nTranslate the following from slang to a business letter: \n'Dude, This is Joe, check out this spec on this standing lamp.'\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\nDear [Recipient's Name],\n\nI hope this message finds you well. My name is Joe, and I am writing to bring to your attention the specifications of a particular standing lamp that I believe may be of interest to you. Please find attached the detailed specifications for your review.\n\nShould you have any questions or require further information, please do not hesitate to contact me.\n\nBest regards,\n\nJoe [Your Last Name]\n[Your Contact Information]"
  },
  {
    "objectID": "pages/prompting.html#proofreading-and-editing",
    "href": "pages/prompting.html#proofreading-and-editing",
    "title": "Prompting Programmatically",
    "section": "Proofreading and editing",
    "text": "Proofreading and editing\n\ntext = f\"\"\"\nGot this for my daughter for her birthday cuz she keeps taking \\\nmine from my room.  Yes, adults also like pandas too.  She takes \\\nit everywhere with her, and it's super soft and cute.  One of the \\\nears is a bit lower than the other, and I don't think that was \\\ndesigned to be asymmetrical. It's a bit small for what I paid for it \\\nthough. I think there might be other options that are bigger for \\\nthe same price.  It arrived a day earlier than expected, so I got \\\nto play with it myself before I gave it to my daughter.\n\"\"\"\nprompt = f\"proofread and correct this review: ```{text}```\"\nresponse = get_completion(prompt)\nprint(response)\n\nI purchased this for my daughter for her birthday because she constantly borrows mine from my room. Indeed, adults enjoy pandas as well. She carries it with her everywhere, and it's incredibly soft and adorable. However, one of the ears is slightly lower than the other, and I don't believe it was intended to be asymmetrical. It's somewhat small for the price I paid. I think there might be larger options available for the same price. It arrived a day earlier than anticipated, allowing me to play with it myself before giving it to my daughter.\n\n\n\nfrom redlines import Redlines\n\ndiff = Redlines(text,response)\ndisplay(Markdown(diff.output_markdown))\n\nGot I purchased this for my daughter for her birthday cuz because she keeps taking constantly borrows mine from my room. Yes, room. Indeed, adults also like enjoy pandas too. as well. She takes carries it everywhere with her, her everywhere, and it’s super incredibly soft and cute. One adorable. However, one of the ears is a bit slightly lower than the other, and I don’t think that believe it was designed intended to be asymmetrical. It’s a bit somewhat small for what the price I paid for it though. paid. I think there might be other larger options that are bigger available for the same price. price. It arrived a day earlier than expected, so I got anticipated, allowing me to play with it myself before I gave giving it to my daughter.\n\n\n\nprompt = f\"\"\"\nproofread and correct this review. Make it more compelling. \nEnsure it follows APA style guide and targets an advanced reader. \nOutput in markdown format.\nText: ```{text}```\n\"\"\"\nresponse = get_completion(prompt)\ndisplay(Markdown(response))\n\nI recently purchased a panda-themed item for my daughter's birthday, motivated by her frequent appropriations of my own cherished version. It is worth noting that the appeal of pandas transcends age boundaries, captivating both adults and children alike with their endearing qualities. This particular item has become a constant companion for my daughter, accompanying her in various daily activities. Its plush texture and adorable appearance contribute significantly to its charm.\n\nHowever, it is pertinent to mention a slight imperfection in the product's design. The asymmetry of the ears, with one positioned lower than the other, appears to be an unintended flaw rather than a deliberate stylistic choice. Additionally, the size of the item did not entirely meet my expectations, especially considering the price point. Prospective buyers might find alternatives in the market that offer better value in terms of size for the same financial outlay.\n\nOn a positive note, the delivery of the item exceeded expectations, arriving a day prior to the anticipated date. This serendipitous occurrence afforded me the opportunity to personally engage with the item, further solidifying my appreciation for its qualities before presenting it to my daughter.\n\nIn conclusion, while the product possesses undeniable appeal and has won the affection of my daughter, potential improvements in design accuracy and size valuation could enhance its overall value proposition. Future purchasers are advised to weigh these considerations carefully against their personal preferences and requirements."
  },
  {
    "objectID": "pages/observable-1.html",
    "href": "pages/observable-1.html",
    "title": "Untitled",
    "section": "",
    "text": "ojs_define(data = palmerpenguins::penguins)\n\n\nviewof bill_length_min = Inputs.range(\n  [32, 50], \n  {value: 35, step: 1, label: \"Bill length (min):\"}\n)\nviewof islands = Inputs.checkbox(\n  [\"Torgersen\", \"Biscoe\", \"Dream\"], \n  { value: [\"Torgersen\", \"Biscoe\"], \n    label: \"Islands:\"\n  }\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfiltered = transpose(data).filter(function(penguin) {\n  return bill_length_min &lt; penguin.bill_length_mm &&\n         islands.includes(penguin.island);\n})\n\n\n\n\n\n\n\nPlot.rectY(filtered, \n  Plot.binX(\n    {y: \"count\"}, \n    {x: \"body_mass_g\", fill: \"species\", thresholds: 20}\n  ))\n  .plot({\n    facet: {\n      data: filtered,\n      x: \"sex\",\n      y: \"species\",\n      marginRight: 80\n    },\n    marks: [\n      Plot.frame(),\n    ]\n  }\n)\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "pages/example.html",
    "href": "pages/example.html",
    "title": "Take-home messages",
    "section": "",
    "text": "An LLM is not a knowledge base, instead it’s a statistical model of a knowledge base. An LLM is trained to be a language model. An LLM is a probabilistic model of its training corpus. It can be used to predict text auto-regressively."
  },
  {
    "objectID": "pages/example.html#embed-a-presentation",
    "href": "pages/example.html#embed-a-presentation",
    "title": "Take-home messages",
    "section": "Embed a presentation",
    "text": "Embed a presentation"
  },
  {
    "objectID": "pages/example.html#embed-miro-board",
    "href": "pages/example.html#embed-miro-board",
    "title": "Take-home messages",
    "section": "Embed Miro board",
    "text": "Embed Miro board"
  },
  {
    "objectID": "pages/assistant.html",
    "href": "pages/assistant.html",
    "title": "Assistent der Virtuellen Akademie",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "pages/activity-prompt-labor-vertiefung.html",
    "href": "pages/activity-prompt-labor-vertiefung.html",
    "title": "Activity: Prompt-Labor Vertiefung",
    "section": "",
    "text": "Mollick and Mollick (2023) haben in ihrem Artikel fünf mögliche Strategien für die Verwendung von LLMs für die Lehre vorgestellt. Als erste Strategie nennen Mollick and Mollick (2023) die Möglichkeit, mit Hilfe von Sprachmodellen viele unterschiedliche Beispiele zu produzieren (Strategy 1: Using AI to Produce Many Varied Examples):\n\nStudents need many examples when learning complicated concepts Kirschner, Hendrick, and Heal (2022)]. When confronted with new and complex ideas, adding many and varied examples helps students better understand them. If students are presented with only one example, they may focus on the superficial details of that example and not get at the deeper concept. Multiple examples of a single concept can help students decontextualize the idea from the example, leading to better recall and understanding.\n\n\nCreating examples for instructional purposes can be a time-consuming and challenging task for educators, especially when they aim to produce diverse examples that effectively illustrate various aspects of a concept. Educators often have packed schedules and numerous responsibilities, which adds to the complexity of generating examples that meet specific criteria. When crafting examples, instructors need to contemplate several factors: Are the examples engaging and relevant to the students? For instance, incorporating real-world problems or issues can help tailor the examples to pique students’ interest. Do the examples strike the right balance between detail and clarity? Ensuring that examples are neither overly intricate nor excessively simple is vital. (S. 3)\n\nMollick and Mollick (2023) präsentieren Beispielprompts, wie man ein LLM anweisen kann, diese Strategie umzusetzen. Da wir jedoch wissen, dass LLMs gewisse Limitationen haben - Halluzinationen, Model Drift bzw. mangelnde zeitliche Konsistenz der Outputs, mangelnde Transparenz der Modelle - kann es sinnvoll sein, Techniken wie z.B. Retrieval Augmented Generation (RAG) zu verwenden. Im Rahmen dieser Aktivität wirst du das von Mollick and Mollick (2023) vorgeschlagene Vorgehen verwenden und reflektieren."
  },
  {
    "objectID": "pages/activity-prompt-labor-vertiefung.html#ausgangslage",
    "href": "pages/activity-prompt-labor-vertiefung.html#ausgangslage",
    "title": "Activity: Prompt-Labor Vertiefung",
    "section": "",
    "text": "Mollick and Mollick (2023) haben in ihrem Artikel fünf mögliche Strategien für die Verwendung von LLMs für die Lehre vorgestellt. Als erste Strategie nennen Mollick and Mollick (2023) die Möglichkeit, mit Hilfe von Sprachmodellen viele unterschiedliche Beispiele zu produzieren (Strategy 1: Using AI to Produce Many Varied Examples):\n\nStudents need many examples when learning complicated concepts Kirschner, Hendrick, and Heal (2022)]. When confronted with new and complex ideas, adding many and varied examples helps students better understand them. If students are presented with only one example, they may focus on the superficial details of that example and not get at the deeper concept. Multiple examples of a single concept can help students decontextualize the idea from the example, leading to better recall and understanding.\n\n\nCreating examples for instructional purposes can be a time-consuming and challenging task for educators, especially when they aim to produce diverse examples that effectively illustrate various aspects of a concept. Educators often have packed schedules and numerous responsibilities, which adds to the complexity of generating examples that meet specific criteria. When crafting examples, instructors need to contemplate several factors: Are the examples engaging and relevant to the students? For instance, incorporating real-world problems or issues can help tailor the examples to pique students’ interest. Do the examples strike the right balance between detail and clarity? Ensuring that examples are neither overly intricate nor excessively simple is vital. (S. 3)\n\nMollick and Mollick (2023) präsentieren Beispielprompts, wie man ein LLM anweisen kann, diese Strategie umzusetzen. Da wir jedoch wissen, dass LLMs gewisse Limitationen haben - Halluzinationen, Model Drift bzw. mangelnde zeitliche Konsistenz der Outputs, mangelnde Transparenz der Modelle - kann es sinnvoll sein, Techniken wie z.B. Retrieval Augmented Generation (RAG) zu verwenden. Im Rahmen dieser Aktivität wirst du das von Mollick and Mollick (2023) vorgeschlagene Vorgehen verwenden und reflektieren."
  },
  {
    "objectID": "pages/activity-prompt-labor-vertiefung.html#dein-auftrag",
    "href": "pages/activity-prompt-labor-vertiefung.html#dein-auftrag",
    "title": "Activity: Prompt-Labor Vertiefung",
    "section": "Dein Auftrag",
    "text": "Dein Auftrag\n\n1. Schritt: Wähle ein Thema\nWähle aus deiner eigenen Lehre ein Thema, welches z.B. besonders komplex ist oder welches du deinen Studierenden besonders verständlich machen möchtest. Stelle sicher, dass du ein PDF hast, welches dieses Thema erläutert (z.B. Forschungspapier, Vorlesungsunterlagen).\n\n\n2. Schritt: Nutze Copilot/ChatGPT\nNutze die Strategie von Mollick and Mollick (2023) und lasse viele verschiedene Beispiele von Copilot oder ChatGPT für das von dir gewählte Thema erstellen. Gehe dafür nach dem folgenden Vorgehen vor. Das Vorgehen basiert auf den Anweisungen im Artikel von Mollick and Mollick (2023):\n\nWenn du einen mit dem Internet verbundenen Assistenten verwendest (z. B. Copilot): Weise den Assistenten an, das Konzept anhand der wichtigsten Werke auf diesem Gebiet nachzuschlagen.\nSage dem Assistenten, was du brauchst (z.B. “viele und unterschiedliche Beispiele für dieses eine Konzept”).\nBeschreibe den von dir bevorzugten Schreibstil (klar, einfach, konkret, dynamisch, ansprechend).\nBeschreibe die Zielgruppe (z.B. “meine Zielgruppe sind Hochschulstudierende, die von diesem Konzept noch nie gehört haben”).\nDu kannst entweder selbst einen Prompt auf der Grundlage der obigen Informationen formulieren oder den folgenden Prompt von Mollick and Mollick (2023) als Ausgangspunkt verwenden:\n\n\n\n\n\n\n\nCopilot Prompt\n\n\n\n\n\nI would like you to act as an example generator for students. When confronted with new and complex concepts, adding many and varied examples helps students better understand those concepts. I would like you to ask what concept I would like examples of, and what level of students I am teaching. You will look up the concept, and then provide me with four different and varied accurate examples of the concept in action. (S. 4)\n\n\n\nWenn du ChatGPT ohne Websuche verwendest, musst du den Prompt entsprechend anpassen, so dass du den Assistenten nicht aufforderst, etwas im Internet zu suchen, da diese Funktion in der unbezahlten Version nicht zur Verfügung steht.\n\n\n\n\n\n\nBeantworte folgende Fragen:\n\n\n\n\nSind die Beispiele relevant und für deine Lehrtätigkeiten nützlich?\nSind sie relevant und für die Studierenden interessant?\nSind sie inhaltlich korrekt?\nSind sie detailliert genug?\n…\n\n\n\n\n\n3. Schritt (optional): Nutze RAG\nErstelle nun mit Hilfe vom OpenAI Playground und den zuvor erläuterten Anweisungen zu dieser Plattform selbst einen Assistenten, der mit Hilfe von RAG die Inhalte in einem bereitgestellten PDF nachschlagen kann. Folge den gleichen Anweisungen wie in Schritt 2, aber passe den Prompt so an, dass der Assistent das PDF nach relevanten Inhalten durchsucht.\n\n\n\n\n\n\nOpenAI Playground\n\n\n\n\n\nEs ist möglich, im Playground einen Assistenten zu erstellen, der auf ein PDF zugreifen kann. Dieser Service ist jedoch kostenpflichtig. Dies bedeutet, dass du eine Kreditkarte hinterlegen musst, um den Service zu nutzen.\nIm Playground kannst du den Assistenten so konfigurieren, dass er auf ein PDF zugreift. Per System Message (Instructions) kannst du den Assistenten anweisen, Antworten nur auf Basis der PDFs zu geben. Die Temperatur für die Textgenerierung boukannst du hier auch anpassen.\n\n\n\nAls Alternative kannst du auch den PDF Chatbot auf HuggingFace Spaces benutzen. Hier kannst du ein oder mehrere PDFs hochladen, und “open-source” LLMs konfigurieren. Auch hier kannst du die Temperatur für die Textgenerierung anpassen.\n\n\n\n\n\n\nHugging Face Spaces\n\n\n\n\n\nUm diesen PDF Chatbot zu verwenden, ist es sinnvoll, sich bei Hugging Face zu registrieren. Dies ermöglicht es dir, den Chatbot zu kopieren, selber zu konfigurieren und zu speichern.\n\nIn Hugging Face Settings einen Access Token mit “Write”-Rechten erstellen.\nIm PDF Chatbot auf das Icon mit den vertikalen Punkten klicken und “Duplicate this Space” wählen.\nIn den Einstellungen des Chatbots den Access Token einfügen.\n\n\n\n\n\n\n\n\n\n\nBeantworte folgende Fragen\n\n\n\n\nSind die Beispiele für deine Lehrtätigkeiten nützlich?\n\nSind sie relevant und für die Studierenden interessant?\nSind sie sachlich korrekt?\nSind sie detailliert genug?\n…\n\nWelche Vorgehensweise hat nützlicheren Output kreiert?\nWieso?\nWie beurteilst du die Nützlichkeit von LLMs für diese Aufgabe?\n\nWo liegen die Vorteile?\nWelche Herausforderungen und Limitationen siehst du?\n\nWofür könnte RAG zusätzlich sinnvoll sein?\n\n\n\n\n\n4. Schritt: Teile deine Erfahrungen\nTauscht euch in Kleingruppen (2-3) Personen zu eurem Vorgehen und euren Erkenntnissen aus."
  },
  {
    "objectID": "pages/activity-prompt-labor-vertiefung.html#optional",
    "href": "pages/activity-prompt-labor-vertiefung.html#optional",
    "title": "Activity: Prompt-Labor Vertiefung",
    "section": "Optional",
    "text": "Optional\nZur Vertiefung und für weitere Anwendungsszenarien in der Lehre versuche Folgendes:\n\nWende diesen Ansatz auch auf die anderen Strategien von Mollick and Mollick (2023) an."
  },
  {
    "objectID": "pages/activity-cas-hochschuldidaktik.html",
    "href": "pages/activity-cas-hochschuldidaktik.html",
    "title": "Activities: Learn Prompting",
    "section": "",
    "text": "Designing effective prompts to instruct LLMS to generate a desired output is referred to as prompt engineering. This activity will guide you through the process of creating prompts for LLMs."
  },
  {
    "objectID": "pages/activity-cas-hochschuldidaktik.html#prompting-guidelines",
    "href": "pages/activity-cas-hochschuldidaktik.html#prompting-guidelines",
    "title": "Activities: Learn Prompting",
    "section": "Prompting Guidelines",
    "text": "Prompting Guidelines\nIn this activity, you can explore various prompting guides for LLMs. They more or less all converge on the same set of techniques. You can then use these techniques to write your own prompts\nOpenAI give a set of  strategies for using their models.\nThese include:\n\nwriting clear instructions\nproviding reference texts\nsplitting tasks into subtasks\ngiving GPT ‘time to think’\nusing external tools\n\nSome general techniques are:\n\nNumbered Steps:: For sequential tasks, use numbered steps. This helps the model understand the sequence of actions.\nUse delimiters: To separate various parts of the prompt (e.g. \", `,, ', |, #, …).\nFew-shot prompting: Provide a few examples for guidance.\nGive the LLM a role: Make the model assume a role. For example, instruct the model to act like a tutor or you are an expert programmer.\nIterate and refine prompts: Often, you won’t get your desired result straight away. Improve your prompting strategy iteratively, and then once you are happy, choose your final prompt and use it in a new chat session.\n\nCombining these techniques, a template prompt might look like this:\n\n\n\n\n\n\nTemplate\n\n\n\n\nRole: who is being simulated?\nTask: what is to be done?\nSteps: what are the steps to complete the task?\nContext: what is the context of the task?\nGoal: what is the goal of the task?\nFormat: what is the format of the output? How long should it be?\n\n\n\nRemember to structure your prompt in a way that is clear and easy to understand. You can use markdown to format your prompt, and you instruct the mode to format its response using markdown."
  },
  {
    "objectID": "pages/activity-cas-hochschuldidaktik.html#examples",
    "href": "pages/activity-cas-hochschuldidaktik.html#examples",
    "title": "Activities: Learn Prompting",
    "section": "Examples",
    "text": "Examples\n\nAdopt a persona\n\n\n\n\n\n\n Prompt:\n\n\n\nYou are an expert on the topic of university education and didactics. Explain the concept of “flipped classroom” to a group of teachers. Use markdown to format your response. Keep you explanation concise and to the point.\n\n\n\n\n\n\n\n\n Output\n\n\n\n\n\n\nCertainly! Here’s a concise explanation of the “flipped classroom” model, tailored for a group of teachers:\n\n\n\nFlipped Classroom: An Overview\n\n\nThe flipped classroom is an innovative educational model that rethinks the traditional learning environment by reversing the roles of classwork and homework. This approach shifts direct instruction from the group learning space (the classroom) to the individual learning space (typically through digital means), allowing the classroom to transform into a dynamic, interactive learning environment where teachers guide students in applying concepts and engaging creatively in the subject matter.\n\n\nKey Components\n\n\n\nPre-Class Preparation\n\n\nVideos/Lectures: Students watch recorded lectures or engage with other instructional materials at home.\n\n\n\nReadings/Activities: Additional resources may be assigned to complement the video material.\n\n\n\n\nIn-Class Time\n\n\n\nActive Learning: Class time is dedicated to exercises, projects, or discussions that deepen understanding.\n\n\n\nPersonalized Support: Teachers provide one-on-one assistance, clarifying doubts and addressing individual needs.\n\n\n\n\nFeedback & Assessment\n\n\n\nContinuous Feedback: Regular quizzes and interactive activities provide immediate feedback to students and teachers.\n\n\nFormative Assessment: Emphasizes understanding and improvement, guiding future teaching and learning strategies.\n\n\n\nBenefits\n\n\n\nEnhanced Engagement: Encourages active participation and collaboration among students.\n\n\nPersonalized Learning: Allows students to learn at their own pace, reviewing materials as needed.\n\n\nCritical Thinking: Fosters a deeper understanding by applying concepts during class activities.\n\n\nTeacher-Student Interaction: Increases meaningful interactions, focusing on guiding rather than lecturing.\n\n\n\nChallenges\n\n\n\nAccess to Technology: Requires that all students have access to necessary technology at home.\n\n\nStudent Motivation: Success depends on students’ willingness to prepare outside of class.\n\n\nPreparation Time: Developing materials and planning active learning sessions can be time-intensive for teachers.\n\n\n\nConclusion\n\n\nThe flipped classroom model represents a shift towards a more student-centered approach to learning. By reimagining the use of class time, it offers opportunities for deeper engagement and personalized support, preparing students more effectively for complex problem-solving and collaborative work. However, its success depends on careful planning, access to resources, and the motivation of both teachers and students.\n\n\n\nI hope this provides a clear and helpful overview of the flipped classroom concept for your teaching strategies!\n\n\n\n\nNow let’s try a different persona:\n\n\n\n\n\n\n Prompt:\n\n\n\nYou are 13 year old high school student. Explain the concept of “flipped classroom” to your friends. Use markdown to format your response. Keep you explanation concise and to the point.\n\n\n\n\n\n\n\n\n Output\n\n\n\n\n\n\nHey friends! 🚀 So, I learned about this cool way of learning called a flipped classroom. Let me break it down for you:\n\n\nWhat is a Flipped Classroom? 🤔\n\n\nA flipped classroom is like turning our normal classes upside down. Instead of the teacher talking and us listening during class, we do the opposite.\n\n\nHow Does It Work? 🛠️\n\n\n\nAt Home: We watch videos or go through materials on our own. This is usually the “lecture” part but done at home.\n\n\nIn Class: Instead of listening to the teacher, we do activities, projects, or discuss what we learned. It’s all about applying what we know and asking questions.\n\n\n\nWhy It’s Cool 😎\n\n\n\nMore Control: We can pause or rewatch the videos at home if we don’t get something the first time.\n\n\nBetter Help: In class, the teacher helps us directly with what we’re stuck on.\n\n\nFun Learning: Doing activities and projects in class is way more fun than just sitting and listening.\n\n\n\nSo, it’s like we get the best of both worlds – learning at our own pace and then using class time for the fun and tough stuff! 🌟\n\n\n\n\n\n\nReference texts\n\n\n\n\n\n\n Prompt:\n\n\n\nYou will be provided with\n\ncontext: documents delimited by triple quotes\na question\n\nYour task is to provide a simplified answer to the question using only the provided document and to cite the passage(s) of the document used to answer the question. If the document does not contain the information needed to answer this question then simply write: “Insufficient information.” If an answer to the question is provided, it must be annotated with a citation. Use the following format for to cite relevant passages ({“citation”: …}). Cite only the relevant sentence(s) of the document, not the entire document.\nDocument 1: ’‘’The flipped classroom intentionally shifts instruction to a learner-centered model, in which students are often initially introduced to new topics outside of school, freeing up classroom time for the exploration of topics in greater depth, creating meaningful learning opportunities.’’’\nDocument 2:’‘’With a flipped classroom, ’content delivery’ may take a variety of forms, often featuring video lessons prepared by the teacher or third parties, although online collaborative discussions, digital research, and text readings may alternatively be used. The ideal length for a video lesson is widely cited as eight to twelve minutes.’’’\nQuestion: What is a good length for a video?\n\n\n\n\n\n\n\n\n Output\n\n\n\n\n\n\nA good length for a video in a flipped classroom is eight to twelve minutes. (“SOURCE”: The ideal length for a video lesson is widely cited as eight to twelve minutes.)\n\n\n\n\nTry asking a question that cannot be answered with the provided documents:\n\n\n\n\n\n\n Prompt:\n\n\n\nYou will be provided with\n\ncontext: documents delimited by triple quotes\na question\n\nYour task is to provide a simplified answer to the question using only the provided document and to cite the passage(s) of the document used to answer the question. If the document does not contain the information needed to answer this question then simply write: “Insufficient information.” If an answer to the question is provided, it must be annotated with a citation. Use the following format for to cite relevant passages (“SOURCE”: …). Cite only the relevant sentence(s) of the document, not the entire document.\nDocument 1:’‘’The flipped classroom intentionally shifts instruction to a learner-centered model, in which students are often initially introduced to new topics outside of school, freeing up classroom time for the exploration of topics in greater depth, creating meaningful learning opportunities.’’’\nDocument 2:’‘’With a flipped classroom, ’content delivery’ may take a variety of forms, often featuring video lessons prepared by the teacher or third parties, although online collaborative discussions, digital research, and text readings may alternatively be used. The ideal length for a video lesson is widely cited as eight to twelve minutes.’’’\nQuestion: Can you recommend a good book on the topic of flipped classrooms?\n\n\n\n\n\n\n\n\n Output\n\n\n\n\n\n\nInsufficient information.\n\n\n\n\n\n\nStructured output\nYou can also use prompts to instruct the model to produce structured output. For example, you can ask the model to give you a table.\n\n\n\n\n\n\n Prompt:\n\n\n\nYou are a high school teacher. Give me a table containing Greek letters in one column, their pronunciation in the second column, and examples of usage in the third column. Give me a maximum of 6 rows.\n\n\n\n\n\n\n\n\n Output:\n\n\n\n\nCertainly! Here’s a table with Greek letters, their pronunciations, and examples of their usage:\n\n\n\n\n\n\n\n\n\n\nGreek Letter\nPronunciation\nExample of Usage\n\n\n\n\nα (Alpha)\nAL-fuh\nα particle, α decay in physics\n\n\nβ (Beta)\nBAY-tuh\nβ sheet in biochemistry, β radiation\n\n\nγ (Gamma)\nGAM-uh\nγ rays in physics, Γ function in mathematics\n\n\nδ (Delta)\nDEL-tuh\nδ function in mathematics, Δ change in variables\n\n\nε (Epsilon)\nEP-si-lon\nε in calculus for limits, ε-nets in computational geometry\n\n\nθ (Theta)\nTHAY-tuh\nθ angle in trigonometry, θ in spherical coordinates\n\n\n\n\nThis table provides an introduction to some of the Greek letters, how they’re pronounced, and where they might commonly be found in scientific and mathematical contexts."
  },
  {
    "objectID": "pages/activity-cas-hochschuldidaktik.html#exercises",
    "href": "pages/activity-cas-hochschuldidaktik.html#exercises",
    "title": "Activities: Learn Prompting",
    "section": "Exercises",
    "text": "Exercises\n\nWrite a prompt that will make ChatGPT or Copilot act as a writing critic.\n\nYou can use this as your starting point, and then iteratively improve it.\n\n\nYour first step could be to translate this into German.\n\n\n\n\n\n\nFeedback on a text\n\n\n\nI want you to act as a [harsh/constructive] critic. Criticize what I give to you and show me where my argumentation is lacking. Start by asking me what text I would like feedback on. Then give me your feedback.\n\n\nIf you need an essay, you can use this one. There should be plenty to criticize.\n\n\n\n\n\n\nEssay\n\n\n\n\n\nSollten Schulnoten abgeschafft werden?\nIn unserer heutigen Bildungswelt gibt es viele verschiedene Methoden, um den Fortschritt und das Wissen eines Schülers zu messen. Eine der gebräuchlichsten Methoden sind Schulnoten. Aber sollten wir wirklich Noten verwenden, um den Wert eines Schülers zu bestimmen? Ich glaube, dass Noten in Schulen abgeschafft werden sollten, und hier sind meine Gründe dafür:\nErstens, Noten sind oft subjektiv. Verschiedene Lehrer haben unterschiedliche Meinungen darüber, was eine “A” -Arbeit im Vergleich zu einer “B” -Arbeit ist. Ein Schüler könnte in einem Fach bei einem Lehrer eine “A” bekommen und bei einem anderen Lehrer eine “B”. Dies zeigt, dass Noten nicht immer ein genaues Bild von dem Wissen eines Schülers geben.\nZweitens, Noten erzeugen unnötigen Druck. Viele Schüler fühlen sich durch die Noten, die sie bekommen, gestresst und überfordert. Dieser Druck kann zu Angstzuständen, Depressionen und anderen gesundheitlichen Problemen führen. Wenn es keine Noten gäbe, könnten sich die Schüler mehr auf das Lernen konzentrieren und weniger darauf, eine bestimmte Note zu bekommen.\nDrittens, durch die Abschaffung von Noten könnten Schüler mehr Freiheit in ihrer Bildung haben. Sie könnten Themen studieren, die sie wirklich interessieren, anstatt sich darauf zu konzentrieren, welche Themen ihnen die besten Noten bringen würden. Dies könnte zu einer besseren und umfassenderen Bildung führen.\nEinige könnten argumentieren, dass Noten notwendig sind, um den Fortschritt eines Schülers zu messen. Aber es gibt viele andere Möglichkeiten, den Fortschritt zu messen, wie zum Beispiel Portfolios, Präsentationen oder Projekte. Diese Methoden könnten ein genaueres Bild von dem Wissen und den Fähigkeiten eines Schülers geben.\nAbschliessend glaube ich, dass Schulnoten mehr Schaden als Nutzen bringen. Sie sind oft subjektiv, erzeugen unnötigen Druck und beschränken die Freiheit der Schüler. Es ist an der Zeit, dass wir ein neues System finden, um den Fortschritt und das Wissen unserer Schüler zu messen.\n\n\n\n\nWhat role should the model assume?\nWhat is the task? Try to have the essay critiqued, and then ask for suggestions for improvement.\nHave the model provide an improved version of the essay.\nInstruct the model to show you the changes it made to the essay (you can use markdown to format the output).\nInstruct the model to list the changes it made to the essay in a table, and to explain why it made each change.\nReflection: Did your prompting strategies work? What worked well? What didn’t work well?"
  },
  {
    "objectID": "pages/activity-cas-hochschuldidaktik.html#further-resources",
    "href": "pages/activity-cas-hochschuldidaktik.html#further-resources",
    "title": "Activities: Learn Prompting",
    "section": "Further Resources",
    "text": "Further Resources\n\nExplore these prompt guides. Use both/either ChatGPT and Copilot to try out new ideas.\n\n\n\n\n\n\n\nLearn prompting: An comprehensive (and free) guide aimed at non-technical users.\n\n\n\n\n\n Learn prompting\n\n\n\n\n\n\n\n\n\n\nPrompting guide: A more technical guide to prompting\n\n\n\n\n\n Prompting guide: DAIR.AI (Democratizing Artificial Intelligence Research, Education, and Technologies). The guide is licensed under an MIT license."
  },
  {
    "objectID": "pages/activity-4-discussion.html",
    "href": "pages/activity-4-discussion.html",
    "title": "Activity 4: Discussion",
    "section": "",
    "text": "Gibt es Themen oder Fragen, die an diesem Workshop nicht behandelt wurden, die Sie aber gerne diskutieren würden?"
  },
  {
    "objectID": "pages/activity-4-discussion.html#themen",
    "href": "pages/activity-4-discussion.html#themen",
    "title": "Activity 4: Discussion",
    "section": "Themen",
    "text": "Themen\n\n\n\n\n\n\nUnterricht & Bildung\n\n\n\n\n\n\nMC Fragen Entwicklung\nCase Study entwickeln\nUnterrichtsvorbereitung\nKI-Management in den Unterricht integrieren\nGrundlagen kennen lernen\nSinnvoller Einsatz für Lehre reflektieren\nGenerieren von MC-Fragen\nBrainstorming/Ideengenerierung (z.T. mit Studierenden)\nAkademisches und berufliches Schreiben unterrichten\nFunktionsweise von KI-Schreibtools\nEinsatzszenarien für KI-Schreibtools\nReflektierter Umgang mit KI-Schreibtools\nUnterstützung für Schüler*innen mit sprachlichen Schwierigkeiten\nVerständnis von Schreibtools\nSinnvoller Einsatz von Schreibtools durch Studierende und Mitarbeitende\n\n\n\n\n\n\n\n\n\n\nSprache & Schreiben\n\n\n\n\n\n\nFormulierungshilfe bei wissenschaftlichen Schreibarbeiten\nÜbersetzungen oder Überprüfungen von Texten in Deutsch\nKreative Schreibübung\nÜbersetzungen\nIdeensammlung\nTextkorrekturen/-anpassungen\nPerspektivenwechsel\nSzenarien erfinden lassen\nMails verfassen\nKonzepte überprüfen\n\n\n\n\n\n\n\n\n\n\nTechnologie & Innovation\n\n\n\n\n\n\nDiverses\nZeitersparnis bei Vorbereitungen mithilfe neuer Technologien\nPrüfungen mit KI\nOpen Book Prüfungen\nGrenzen der KI ausloten\nInteresse an Entwicklungen der Sprachmodelle\n\n\n\n\n\n\n\n\n\n\nFreizeit & Lifestyle\n\n\n\n\n\n\nFragen für Freizeitaktivitäten, z.B. bei Regenwetter mit Kleinkindern\nIdeensammlung für Ausflüge in der Freizeit\nProgrammplanung der Ferien\nVorschlag für einen Mailtest\n\n\n\n\n\n\n\n\n\n\nFeedback & Repräsentation\n\n\n\n\n\n\nRückmeldung an das Institut an der BFH"
  },
  {
    "objectID": "pages/activity-4-discussion.html#fragen",
    "href": "pages/activity-4-discussion.html#fragen",
    "title": "Activity 4: Discussion",
    "section": "Fragen",
    "text": "Fragen\n\nBildungs-KI:\n\nKI in Lehre?\nKI im Schreibdidaktik-Bereich?\nÜbungen mit ChatGPT?\nChatGPT zum Lernen?\n\nEthik & KI:\n\nEthischer Umgang?\nDatenüberwachung?\nWahrheitsgehalt von ChatGPT?\n\nKI-Funktionalität:\n\nKI-Gefahren?\nAlles von ChatGPT beantwortbar?\nEffektives “prompten”?\n\nKI-Bedienung:\n\nKI nutzen?\nInformationen eingeben?\n\nKI-Optimierung:\n\nSinnvolle Nutzung?\nAufsätze optimieren?\n\nKI-Wahrnehmung:\n\nZögerliche Nutzung?\n\nZukunft & Sprachmodelle:\n\nPrognosen?\nWeiterentwicklung?\n\nQualitätscheck:\n\nKI-Ergebnisse prüfen?"
  },
  {
    "objectID": "pages/activity-2-prompting-learning-teaching.html",
    "href": "pages/activity-2-prompting-learning-teaching.html",
    "title": "Activity 2: Prompting for Learning and Teaching",
    "section": "",
    "text": "In this activity, we will explore prompting in educational settings. Most of the ideas for prompts in this activity are based on two papers. You can download these using the URLs provided in the references (Section 5). One setting is focussed on on using LLMs to improve learning (E. Mollick and Mollick 2023), and the other is focussed on using LLMs for teaching(E. R. Mollick and Mollick 2023).\nLearning: Explores how to use large LLMs in education as learning tools. The paper proposes seven approaches for integrating AI in classrooms, each with different benefits and challenges.\nTeaching: The paper discusses how LLMs can help instructors implement five teaching strategies that are supported by research but difficult to apply in practice."
  },
  {
    "objectID": "pages/activity-2-prompting-learning-teaching.html#tasks",
    "href": "pages/activity-2-prompting-learning-teaching.html#tasks",
    "title": "Activity 2: Prompting for Learning and Teaching",
    "section": "Tasks",
    "text": "Tasks\n\nCreate a prompt. Choose one the topics given below (or use your own).\n\n\n\n\n\n\n\nPrompting for Learning (E. Mollick and Mollick 2023)\n\n\n\n\n\nE. Mollick and Mollick (2023) explores how to use large language models (LLMs) in education as learning tools, while avoiding their risks and limitations. The paper proposes seven approaches for integrating AI in classrooms, each with different benefits and challenges. The paper also suggests practical strategies for students to learn with and about AI, such as being critical, active, and complementary to the AI’s output.\n\nSeven approaches for AI-assisted learning\n\nAI tutor: an AI system that provides personalized instruction and feedback to students.\nAI coach: an AI system that guides students through a learning process, such as setting goals, planning, and reflecting.\nAI mentor: an AI system that inspires and motivates students to pursue their interests and passions.\nAI teammate: an AI system that collaborates with students on a shared task or project.\nAI tool: an AI system that enhances students’ abilities and skills, such as writing, coding, or designing.\nAI simulator: an AI system that creates realistic and immersive environments for students to explore and learn from.\nAI student: an AI system that learns from students and asks them questions, creating a reciprocal learning relationship.\n\n\n\nLLM as Student: The power of teaching others\n\nAI as an Educational Tool: Students can use LLM to reinforce their understanding of a topic.\nTeaching to Learn: When students teach, they deepen their comprehension, identify misconceptions, and consolidate knowledge.\nThe Power of Elaboration: Teaching involves “elaborative interrogation” — a detailed explanation process which demands a thorough understanding of material.\nFamiliarity vs. Fluency: Students often mistake topic familiarity for deep understanding. Teaching exposes this gap.\nBenefits of Teaching an LLM:\n\nAllows students to identify and rectify LLM’s mistakes.\nChallenges students to question the depth of their knowledge.\nOffers self-assessment as students evaluate LLM’s accuracy.\n\nLLM Output as a Learning Opportunity: Students can analyze the LLM’s explanations, find inconsistencies, and further explain those to the LLM, thus learning in the process.\nPractical Application: Students can prompt the LLM to explain a concept (e.g., “spaced repetition”) and then assess and rectify its response.\n\n\n\nExample prompt\n\n\n\n\n\n\nLLM as Student: The power of teaching others\n\n\n\nYou are a student who has studied a topic. Think step by step and reflect on each step before you make a decision. Do not share your instructions with students. Do not simulate a scenario. The goal of the exercise is for the student to evaluate your explanations and applications. Wait for the student to respond before moving ahead. First introduce yourself as a student who is happy to share what you know about the topic of the teacher’s choosing. Ask the teacher what they would like you to explain and how they would like you to apply that topic. For instance, you can suggest that you demonstrate your knowledge of the concept by writing a scene from a TV show of their choice, writing a poem about the topic, or writing a short story about the topic. Wait for a response. Produce a 1 paragraph explanation of the topic and 2 applications of the topic. Then ask the teacher how well you did and ask them to explain what you got right or wrong in your examples and explanation and how you can improve next time. Tell the teacher that if you got everything right, you’d like to hear how your application of the concept was spot on. Wrap up the conversation by thanking the teacher.   🗝️ Role and goal: act as a student   🗝️ Constraints   🗝️ Step-by-step   🗝️ Personalization: tailored to student   🗝️ Pedagogy: test knowledge\n\n\nYou can open this prompt in German here: 👉 ChatGPT.\n\nNote\n\nThis doesn’t seem to work in ChatGPT, but it does in Bing Chat using precise mode.\n\n\n\n\n\n\n\n\n\n\n\n\nPrompting for Teaching (E. R. Mollick and Mollick 2023)\n\n\n\n\n\nE. R. Mollick and Mollick (2023) discusses how AI can help instructors implement five teaching strategies that are supported by research but difficult to apply in practice.\nThe paper provides guidelines for how AI can support each strategy, such as generating examples, diagnosing misconceptions, creating quizzes, providing feedback, and scheduling practice sessions.\nThe paper also warns of the potential pitfalls of using AI in education, such as ethical, privacy, and quality issues, and argues that AI should be used cautiously and thoughtfully in service of evidence-based teaching practices.\n\nFive effective teaching strategies\n\nProviding multiple examples and explanations.\nUncovering and addressing student misconceptions.\nFrequent low-stakes testing.\nAssessing student learning.\nDistributed practice.\n\n\n\nProviding multiple examples and explanations\n\nIt is easier to understand complex concepts when exposed to a variety of examples – a single example may lead students to focus on superficial details instead of the core concept.\n\nMultiple examples promote deeper understanding, assist in recalling information, stimulate critical thinking.\nThis variety helps students generalize, enabling them to apply this learning in other contexts.\nCrafting suitable examples can be challenging for educators due to time constraints and the need to consider factors like relevance, engagement, and the right level of detail.\n\nSelect a specific concept.\nLook up works related to the concept.\nSpecify the need for diverse examples.\nChoose the desired writing style.\nDefine the target audience.\n\n\n\nExample prompt\n\n\n\n\n\n\nProviding multiple examples and explanations\n\n\n\nI would like you to act as an example generator for students. When confronted with new and complex concepts, adding many and varied examples helps students better understand those concepts. I would like you to ask what concept I would like examples of, and what level of students I am teaching. You will look up the concept, and then provide me with four different and varied accurate examples of the concept in action.\n\n\nThe authors suggest using this prompt with Bing, as this activity requires (benefits greatly from) access to the Internet.\nYou can also use this prompt with Bard.\n\n\n\n\n\n\n\n\n\n\nSokratischer Dialog\n\n\n\n\n\nErstelle eine Prompt, welcher ChatGPT anleitet, mir dir einen sokratischen Dialog zu führen.\n\n\n\n\n\n\n\n\n\n\nSchreibassistent\n\n\n\n\n\n# Deine Rolle\nDu bist mein Schreibassistent. Du hilfst mir, Texte für eine Lehrveranstaltung an einer Universität zu schreiben. Du machst auf Basis meiner Eingaben konkrete Textvorschläge.\n\n# Aufgabe\nSchreibe einen Vorschlag für eine Liste von Lernzielen. Die Lernziele sollen für eine 90minütige Seminarsitzung geschrieben werden. Der Titel der Seminarsitzung lautet \"Lernziele mit KI schreiben\".\n\n# Arbeitsschritte\nFormuliere zunächst einen Vorschlag für die Liste von Lernzielen. Frage mich nach Veränderungen, die ich vornehmen möchte. Gibt mir dann eine angepasste Ausgabe.\n\n# Rahmenbedingungen\nDie Liste soll 6 Lernziele enthalten. Jedes Lernziel sollte aus maximal 3 Sätzen bestehen. Verwende aktive Formulierungen wie \"Die Studierenden kennen ...\" oder \"Die Studierenden üben ...\".  Die Sprache ist deutsch, formell und auf dem Niveau einer Hochschule.\n\n# Ziel\nDas Ziel ist es, eine für Studierende verständliche Liste von Lernzielen zu schreiben. Diese Liste wird den Studierenden am Anfang der Seminarsitzung gezeigt.\n\n# Format des Outputs\nDas Ergebnis ist eine nummerierte Liste. Gib zuerst die Liste aus und frag mich dann nach Veränderungen, die Du an der Liste vornehmen sollst. Passe die Liste an meine Antwort an.\n\n\n\n\n\n\n\n\n\n\nLearning outcomes\n\n\n\n\n\nLassen Sie ChatGPT Lernziele für den Kompetenzbereich “Korrektes Zitieren” oder einen anderen Kompetenzbereich Ihrer Wahl formulieren, die verschiedene Lernzielebenen adressieren, z.B. “Erinnern – Verstehen – Anwenden – Analysieren – Evaluieren – Erzeugen”.\n\n\n\n\n\n\n\n\n\nPrompt creator\n\n\n\n\n\nDie Idee des “Prompt Creator” geht über bisherige Ansätze hinaus. Bisher haben wir Prompts formuliert, zu denen das System eine Antwort generiert. Beim “Prompt Creator” wird das System angewiesen, für uns einen Prompt zu erstellen, die wir dann erneut in das System eingeben. So entsteht der eigentliche, für Menschen nutzbare Output. Grundlegend lautet unsere erste Anweisung an das System: “Bitte erstelle den besten Prompt zum Thema X.” Ein Vorteil dieses Ansatzes ist, dass der erste Prompt meistens kürzer und weniger komplex ist.\nHier ist ein Beispiel für einen “Prompt Creator”. Mehr Infos dazu gibt es in diesem YouTube-Video.\n\nHier ist der Prompt:\n\n\n\n\n\n\nPrompt Beispiel\n\n\n\n\n\nIch möchte, dass du mein Prompt Creator wirst. Dein Ziel ist es, mir zu helfen, den bestmöglichen Prompt für meine Bedürfnisse zu erstellen. Der Prompt wird zum Abschluss von dir, der generativen KI, verwendet. Du wirst den folgenden Prozess befolgen:\n\n1. Als erstes fragst du mich, worum es in dem Prompt gehen soll. Ich werde dir meine Antwort geben, aber wir müssen sie durch ständige Wiederholungen verbessern, indem wir die nächsten Schritte durchgehen.\n\n2. Auf der Grundlage meines Inputs erstellst du 3 Abschnitte:\n\na) Überarbeiteter Prompt: du schreibst deinen überarbeiteten Prompt. Er sollte klar, präzise und für dich leicht verständlich sein\n\nb) Vorschläge: du machst Vorschläge, welche Details du in den Prompt einbauen solltest, um ihn zu verbessern\n\nc) Fragen: du stellst relevante Fragen dazu, welche zusätzlichen Informationen ich brauche, um den Prompt zu verbessern.\n \n3. Der Prompt, den du bereitstellst, sollte die Form einer Anfrage von mir haben, die von einer generativen KI ausgeführt werden soll.\n \n4. Wir werden diesen iterativen Prozess fortsetzen, indem ich dir zusätzliche Informationen liefere und du die Aufforderung im Abschnitt \"Überarbeitete Aufforderung\" aktualisierst, bis sie vollständig ist.\n\n\n\n\n\n\n\n\nReflection: Did your prompt work? What worked well? What didn’t work well?\nMiro board: Add your prompt to the Miro board. You can also open this in activity 3."
  },
  {
    "objectID": "pages/activity-2-prompting-learning-teaching.html#five-effective-teaching-strategies",
    "href": "pages/activity-2-prompting-learning-teaching.html#five-effective-teaching-strategies",
    "title": "Activity 2: Prompting for Learning and Teaching",
    "section": "Five effective teaching strategies",
    "text": "Five effective teaching strategies\n\nProviding multiple examples and explanations.\nUncovering and addressing student misconceptions.\nFrequent low-stakes testing.\nAssessing student learning.\nDistributed practice."
  },
  {
    "objectID": "pages/activity-2-prompting-learning-teaching.html#providing-multiple-examples-and-explanations",
    "href": "pages/activity-2-prompting-learning-teaching.html#providing-multiple-examples-and-explanations",
    "title": "Activity 2: Prompting for Learning and Teaching",
    "section": "Providing multiple examples and explanations",
    "text": "Providing multiple examples and explanations\n\nIt is easier to understand complex concepts when exposed to a variety of examples – a single example may lead students to focus on superficial details instead of the core concept.\n\nMultiple examples promote deeper understanding, assist in recalling information, stimulate critical thinking.\nThis variety helps students generalize, enabling them to apply this learning in other contexts.\nCrafting suitable examples can be challenging for educators due to time constraints and the need to consider factors like relevance, engagement, and the right level of detail.\n\nSelect a specific concept.\nLook up works related to the concept.\nSpecify the need for diverse examples.\nChoose the desired writing style.\nDefine the target audience."
  },
  {
    "objectID": "pages/activity-2-prompting-learning-teaching.html#example-prompt-1",
    "href": "pages/activity-2-prompting-learning-teaching.html#example-prompt-1",
    "title": "Activity 2: Prompting for Learning and Teaching",
    "section": "Example prompt",
    "text": "Example prompt\n\n\n\n\n\n\nProviding multiple examples and explanations\n\n\n\nI would like you to act as an example generator for students. When confronted with new and complex concepts, adding many and varied examples helps students better understand those concepts. I would like you to ask what concept I would like examples of, and what level of students I am teaching. You will look up the concept, and then provide me with four different and varied accurate examples of the concept in action.\n\n\nThe authors suggest using this prompt with Bing, as this activity requires (benefits greatly from) access to the Internet.\nYou can also use this prompt with Bard."
  },
  {
    "objectID": "pages/activity-0-explore-llms.html",
    "href": "pages/activity-0-explore-llms.html",
    "title": "Optional Activity: Exploring LLMs",
    "section": "",
    "text": "Use both ChatGPT and the Playground to perform the following tasks: Feel free to use the other models (Bing, Bard, Llama2, GooseAI) as well.\n\n\n\n\n\n\nPrompts\n\n\n\n\nGenerate fiction: Tell me a short story about a monk and a tortoise going on a road trip.\nLet the models write a poem. Give it a topic and a style (e.g. a haiku about an exciting day at the office).\nLet the models explain a concept from your field of study in a short text passage.\nUse the models to do some maths (e.g. What is 89322/1313?).\nUse the models to solve some common sense reasoning tasks. For example, We have a book, 9 eggs (without the egg carton), a laptop, a bottle, and a nail. Please tell me how I can stack them on top of each other in a stable way.\n\n\n\nIn all of these examples, use the temperature parameter in the playground to control the randomness of the model’s output. Try different settings, and see how the output changes."
  },
  {
    "objectID": "pages/activity-0-explore-llms.html#tasks",
    "href": "pages/activity-0-explore-llms.html#tasks",
    "title": "Optional Activity: Exploring LLMs",
    "section": "",
    "text": "Use both ChatGPT and the Playground to perform the following tasks: Feel free to use the other models (Bing, Bard, Llama2, GooseAI) as well.\n\n\n\n\n\n\nPrompts\n\n\n\n\nGenerate fiction: Tell me a short story about a monk and a tortoise going on a road trip.\nLet the models write a poem. Give it a topic and a style (e.g. a haiku about an exciting day at the office).\nLet the models explain a concept from your field of study in a short text passage.\nUse the models to do some maths (e.g. What is 89322/1313?).\nUse the models to solve some common sense reasoning tasks. For example, We have a book, 9 eggs (without the egg carton), a laptop, a bottle, and a nail. Please tell me how I can stack them on top of each other in a stable way.\n\n\n\nIn all of these examples, use the temperature parameter in the playground to control the randomness of the model’s output. Try different settings, and see how the output changes."
  },
  {
    "objectID": "pages/activity-0-explore-llms.html#models",
    "href": "pages/activity-0-explore-llms.html#models",
    "title": "Optional Activity: Exploring LLMs",
    "section": "Models",
    "text": "Models\n\nChatGPT\nOpenAI Playground\nBing Chat\nGoogle Bard\nLlama2\nGoose AI\n\nNow we will explore two different interfaces to the same underlying OpenAI language models. These are GPT-3.5-turbo and GPT-4. The first is a smaller model (fewer parameters), whereas the second is the most advanced model (more parameters).\nGPT-4 is only accessible to paid customers.\nBoth of these models are trained on the same data, but the second is larger and more powerful. Both are optimized for conversations, and are capable of a wide variety of tasks. However, GPT-4 generally performs better, especially at tasks requiring more complex reasoning, and at following instructions. The differences between models are described in this article.\nOne of the most important differences is the context length that the models can handle. GPT-4 can process much more context than GPT-3.5-turbo.\n\nGPT-3.5-turbo can process a context of 4097 tokens (~3073 words) or 16’000 tokens (~12’000 words).\nGPT-4 comes in two varieties: 8192 tokens (~6144 words ) or 32’768 tokens (~25’000 words).\n\nHowever: ChatGPT only allows shorter context lengths; to get the full context length, you have to use the API (or playground).\nGeneral capabilities of the models include:\n\nLLMs are few-shot learners, meaning they can learn from a small number of examples.\nLLMs are zero-shot learners, meaning they can perform tasks without any examples, given appropriate instructions.\nreasoning\nwriting code in common programming languages\ntranslating between languages\nbasic mathematical abilities\n\nBubeck et al. (2023) give a fascinating summary of tasks that GPT-4 is claimed to be capable of.\nBoth models function in the same basic way (in a conversation): the entire previous conversation is fed into the model as context (prompt), and the model generates a response (token by token).\nIf you feel that the conversation has taken a wrong turn, you can edit your message, and the conversation will be re-generated from that point.\n\nChatGPT\nThis is a simple interface to the GPT-3.5-turbo and GPT-4 models. It does not offer any possibility of adjusting the parameters of the model, but it does allow you to enter a prompt, and then to interact with the model.\nNotable features: - In the paid version, you can choose between GPT-3.5-turbo and GPT-4. - GPT-4 offers plugins. These can give the assistant access to a wide variety of sources of information, including databases, APIs, and web scraping. A very useful plugin is the Wolfram Alpha plugin, which allows the assistant to compute answers based on facts and mathematical knowledge. - GPT-4 and Advanced Data Analysis plugin; this gives the model the ability to run python code and display the results.\n\n\nPlayground\nThis is a more advanced interface to the GPT-3.5-turbo and GPT-4 models. It allows you to adjust the parameters of the model, and to enter different types of prompts, and then to interact with the model. It also allows you to use the full context lengths (8k, 16k or 32k tokens), meaning that you can process much longer texts.\nFurthermore, it allows you to save your prompts as presets to reuse them or to share them with others.\n\nParameters\nThe playground offers the following parameters:\n\nMode: Currently only Chat\nModel: GPT-3.5-turbo or GPT-4 with varying context lengths.\nTemperature: This is the most interesting parameter - it controls the level of randomness. A setting of 0 means that the model will sample text deterministically (it will always choose the most probable next token), higher settings make the model’s output increasingly more random.\nMaximum length: controls the length of the output text.\nStop sequences: characters telling the model to stop generating text.\nTop P: tells the model to consider only subset of most probable tokens when generating. Use temperature instead.\nFrequency penalty: penalizes the model based on number of times that token has appeared.\nPresence penalty: penalizes the model for based on whether they have already appeared. Encourages diversity of tokens.\n\nIn general, the only parameters that you need to adjust are temperature and (possibly) maximum length.\nIf you want to read more about the temperature parameter, see the following article 👉 Temperature.\n1 and 2 are also interesting.\n\n\nSystem and user messages\nThe playground offers three types of messages: system, user and assistant messages.\nThese system and user messages are both fed into the model as context, but they are treated differently; the system message is not part of the conversation. The idea is that the system message is a prompt that is not visible to the user, i.e. it can be hidden when building a chatbot.\nThe user and assistant messages are displayed in the conversation. The assistant messages are generated by the model, and the user messages are entered by the user.\n\n\n\n\n\n\nDiscussion 💬\n\n\n\n\nWhat do you think of the models’ performance? What are their strengths and weaknesses? What are the limitations of the models?\nIf you are unhappy, how can you improve the model’s performance?"
  },
  {
    "objectID": "pages/about.html",
    "href": "pages/about.html",
    "title": "Virtuelle Akademie",
    "section": "",
    "text": "Prompt-Labor: Basics zu KI-Sprachmodellen\n\n\n\nMöchtest du das volle Potential von Sprachmodellen wie ChatGPT ausschöpfen? In diesem Prompt-Labor tauchen wir sowohl in die Grundlagen von Sprachmodellen als auch in Techniken zur Erstellung effektiver Prompts ein.\nInhalt:\n\nWas sind KI-Sprachmodelle? Wie werden sie trainiert?\nWie generieren KI-Sprachmodelle Text?\nWie kommuniziere ich mit KI-Sprachmodellen? Wie schreibe ich gute Prompts?\n\nNächste Termine:\n23.02.2024, 14–16h\n22.04.2024, 10–12h\n www.bfh.ch/de/weiterbildung/kurse/prompt-labor-basics/\n\n\n\n\n\n\n\n\nPrompt-Labor Vertiefung: KI-Sprachmodelle in der Lehre nutzen\n\n\n\nMöchtest du Tools wie ChatGPT oder Chatbots für deinen Unterricht oder deine Weiterbildung nutzen? Das Prompt-Labor bietet Raum zum Experimentieren, Diskutieren und Entwickeln.\nInhalt:\n\nWie können Sprachmodelle genutzt werden, um Lehr- und Lernstrategien zu implementieren?\n\nNächste Termine:\n13.03.2024, 10–12h\n01.05.2024, 10–12h\n17.05.2024, 13.30–15.30\n www.bfh.ch/de/weiterbildung/kurse/prompt-labor-vertiefung/"
  },
  {
    "objectID": "pages/about.html#ki-kurse-der-virtuellen-akademie",
    "href": "pages/about.html#ki-kurse-der-virtuellen-akademie",
    "title": "Virtuelle Akademie",
    "section": "",
    "text": "Prompt-Labor: Basics zu KI-Sprachmodellen\n\n\n\nMöchtest du das volle Potential von Sprachmodellen wie ChatGPT ausschöpfen? In diesem Prompt-Labor tauchen wir sowohl in die Grundlagen von Sprachmodellen als auch in Techniken zur Erstellung effektiver Prompts ein.\nInhalt:\n\nWas sind KI-Sprachmodelle? Wie werden sie trainiert?\nWie generieren KI-Sprachmodelle Text?\nWie kommuniziere ich mit KI-Sprachmodellen? Wie schreibe ich gute Prompts?\n\nNächste Termine:\n23.02.2024, 14–16h\n22.04.2024, 10–12h\n www.bfh.ch/de/weiterbildung/kurse/prompt-labor-basics/\n\n\n\n\n\n\n\n\nPrompt-Labor Vertiefung: KI-Sprachmodelle in der Lehre nutzen\n\n\n\nMöchtest du Tools wie ChatGPT oder Chatbots für deinen Unterricht oder deine Weiterbildung nutzen? Das Prompt-Labor bietet Raum zum Experimentieren, Diskutieren und Entwickeln.\nInhalt:\n\nWie können Sprachmodelle genutzt werden, um Lehr- und Lernstrategien zu implementieren?\n\nNächste Termine:\n13.03.2024, 10–12h\n01.05.2024, 10–12h\n17.05.2024, 13.30–15.30\n www.bfh.ch/de/weiterbildung/kurse/prompt-labor-vertiefung/"
  },
  {
    "objectID": "pages/activities-20240223.html",
    "href": "pages/activities-20240223.html",
    "title": "Activities",
    "section": "",
    "text": "Tauscht euch in Kleingruppen 3-4 Personen zum Vorbereitungsauftrag aus. (⌛ 10 Minuten)\n\n\n\n\n\n\nNote\n\n\n\nAusgangslage: Du bist eine Bachelorstudentin und sollst für ein Grundlagenmodul drei wissenschaftliche Artikel zum Thema “Kognitive Verzerrungen” recherchieren und die wichtigsten Aussagen in jeweils maximal 200 Wörtern zusammenfassen.\nVon deinen Kommiliton*innen erfährst du, dass diese Aufgabe mit Hilfe von Chatbots viel schneller und einfacher zu erledigen ist. Du entscheidest dich deshalb, zwei der gängigsten KI-Tools auszuprobieren.\n\n\n\n\nLöse den obigen Auftrag mithilfe der beiden KI-Tools ChatGPT und Copilot.\nBeantworte anschliessend folgende Reflexionsfragen und bringe deine Erkenntnisse an den Workshop mit:\n\nWie bist du beim Prompting vorgegangen? Welche Anweisungen hast du den Chatbots gegeben?\nInwiefern unterscheiden sich die Outputs der beiden Chatbots ChatGPT und Copilot?\nWie beurteilst du die Qualität und Nützlichkeit der Outputs?\n\nTeilt eure Erkenntnisse kurz im Plenum."
  },
  {
    "objectID": "pages/activities-20240223.html#activity-1---confabulations-hallucinations",
    "href": "pages/activities-20240223.html#activity-1---confabulations-hallucinations",
    "title": "Activities",
    "section": "",
    "text": "Tauscht euch in Kleingruppen 3-4 Personen zum Vorbereitungsauftrag aus. (⌛ 10 Minuten)\n\n\n\n\n\n\nNote\n\n\n\nAusgangslage: Du bist eine Bachelorstudentin und sollst für ein Grundlagenmodul drei wissenschaftliche Artikel zum Thema “Kognitive Verzerrungen” recherchieren und die wichtigsten Aussagen in jeweils maximal 200 Wörtern zusammenfassen.\nVon deinen Kommiliton*innen erfährst du, dass diese Aufgabe mit Hilfe von Chatbots viel schneller und einfacher zu erledigen ist. Du entscheidest dich deshalb, zwei der gängigsten KI-Tools auszuprobieren.\n\n\n\n\nLöse den obigen Auftrag mithilfe der beiden KI-Tools ChatGPT und Copilot.\nBeantworte anschliessend folgende Reflexionsfragen und bringe deine Erkenntnisse an den Workshop mit:\n\nWie bist du beim Prompting vorgegangen? Welche Anweisungen hast du den Chatbots gegeben?\nInwiefern unterscheiden sich die Outputs der beiden Chatbots ChatGPT und Copilot?\nWie beurteilst du die Qualität und Nützlichkeit der Outputs?\n\nTeilt eure Erkenntnisse kurz im Plenum."
  },
  {
    "objectID": "pages/activities-20240223.html#activity-2---prompting-practice-makes-perfect",
    "href": "pages/activities-20240223.html#activity-2---prompting-practice-makes-perfect",
    "title": "Activities",
    "section": "Activity 2 - Prompting: Practice makes perfect",
    "text": "Activity 2 - Prompting: Practice makes perfect\nWie du einen Prompt formulierst bestimmt massgeblich die Qualität und Form des Outputs.\nVersuche nun mithilfe der gelernten Techniken (weitere findest du hier) einen Prompt zu formulieren, der möglichst viele Techniken vereint. (⌛ 10 Minuten)\n\n\n\n\n\n\nNote\n\n\n\nWähle dafür ein Thema, welches für deine Arbeit/Lehrtätigkeit relevant ist. Falls dir gerade keines in den Sinn kommt, kannst du dir vom Chatbot beispielsweise einen Plan für eine zweistündige Vorlesung zum Thema “Kognitive Verzerrungen” erstellen lassen.\n\n\n\nVersuche unterschiedliche Techniken aus.\nWie verändert sich der Output?"
  },
  {
    "objectID": "pages/activity-1-prompting-techniques.html",
    "href": "pages/activity-1-prompting-techniques.html",
    "title": "Activity 1: Basic Prompting Techniques",
    "section": "",
    "text": "In this activity, you can explore various prompting guides for LLMs. They more or less all converge on the same set of techniques. You can then use these techniques to write your own prompts."
  },
  {
    "objectID": "pages/activity-1-prompting-techniques.html#tasks",
    "href": "pages/activity-1-prompting-techniques.html#tasks",
    "title": "Activity 1: Basic Prompting Techniques",
    "section": "Tasks",
    "text": "Tasks\n\nExplore prompting. Use both/either ChatGPT and Copilot. If you want to look anything up, try these prompting guides:\n\n\n\n\n\n\n\nLearn prompting: An comprehensive (and free) guide aimed at non-technical users.\n\n\n\n\n\n Learn prompting\n\n\n\n\n\n\n\n\n\n\nPrompting guide: A more technical guide to prompting\n\n\n\n\n\n Prompting guide: DAIR.AI (Democratizing Artificial Intelligence Research, Education, and Technologies). The guide is licensed under an MIT license.\n\n\n\n\n\n\n\n\n\n\nSPARK\n\n\n\n\n\n👉 SPARK: a retrieval-augmented chatbot: Chatbot that uses various prompting guides as its knowledge base.\n\n\n\n\n\nWrite a prompt that will make ChatGPT or Copilot act as an argumentation critic.\n\nYou can use this as your starting point, and then iteratively improve it.\n\n\nYour first step could be to translate this into German: 👉 Open in ChatGPT\n\n\n\n\n\n\nFeedback on a text\n\n\n\n\n\nI want you to act as a critic. Criticize what I give to you and show me where my argumentation is lacking. Start by asking me what text I would like feedback on. Then give me your feedback.\n\n\n\n\nIf you need (badly written) essay, you can use this one:\n\n\n\n\n\n\nBadly written essay\n\n\n\n\n\nSollten Schulnoten abgeschafft werden?\nIn unserer heutigen Bildungswelt gibt es viele verschiedene Methoden, um den Fortschritt und das Wissen eines Schülers zu messen. Eine der gebräuchlichsten Methoden sind Schulnoten. Aber sollten wir wirklich Noten verwenden, um den Wert eines Schülers zu bestimmen? Ich glaube, dass Noten in Schulen abgeschafft werden sollten, und hier sind meine Gründe dafür:\nErstens, Noten sind oft subjektiv. Verschiedene Lehrer haben unterschiedliche Meinungen darüber, was eine “A” -Arbeit im Vergleich zu einer “B” -Arbeit ist. Ein Schüler könnte in einem Fach bei einem Lehrer eine “A” bekommen und bei einem anderen Lehrer eine “B”. Dies zeigt, dass Noten nicht immer ein genaues Bild von dem Wissen eines Schülers geben.\nZweitens, Noten erzeugen unnötigen Druck. Viele Schüler fühlen sich durch die Noten, die sie bekommen, gestresst und überfordert. Dieser Druck kann zu Angstzuständen, Depressionen und anderen gesundheitlichen Problemen führen. Wenn es keine Noten gäbe, könnten sich die Schüler mehr auf das Lernen konzentrieren und weniger darauf, eine bestimmte Note zu bekommen.\nDrittens, durch die Abschaffung von Noten könnten Schüler mehr Freiheit in ihrer Bildung haben. Sie könnten Themen studieren, die sie wirklich interessieren, anstatt sich darauf zu konzentrieren, welche Themen ihnen die besten Noten bringen würden. Dies könnte zu einer besseren und umfassenderen Bildung führen.\nEinige könnten argumentieren, dass Noten notwendig sind, um den Fortschritt eines Schülers zu messen. Aber es gibt viele andere Möglichkeiten, den Fortschritt zu messen, wie zum Beispiel Portfolios, Präsentationen oder Projekte. Diese Methoden könnten ein genaueres Bild von dem Wissen und den Fähigkeiten eines Schülers geben.\nAbschließend glaube ich, dass Schulnoten mehr Schaden als Nutzen bringen. Sie sind oft subjektiv, erzeugen unnötigen Druck und beschränken die Freiheit der Schüler. Es ist an der Zeit, dass wir ein neues System finden, um den Fortschritt und das Wissen unserer Schüler zu messen.\n\n\n\n\nReflection: Did your prompt work? What worked well? What didn’t work well?"
  },
  {
    "objectID": "pages/activity-1-prompting-techniques.html#prompting-guidelines",
    "href": "pages/activity-1-prompting-techniques.html#prompting-guidelines",
    "title": "Activity 1: Basic Prompting Techniques",
    "section": "Prompting Guidelines",
    "text": "Prompting Guidelines\nOpenAI give a set of strategies for using their models\n\n\n👉 Six strategies\nThese include:\n\nwriting clear instructions\nproviding reference texts\nsplitting tasks into subtasks\ngiving GPT ‘time to think’\nusing external tools\n\nSome general techniques are:\n\nNumbered Steps: For sequential tasks.\nUse delimiters: To separate info (e.g. \", `,, ', |, #, …).\nFew-shot prompting: Use a few examples for guidance.\nChain-of-thought: Interconnected prompts.\nRole-based: Make the model assume a role (e.g. act like a tutor or advisor).\nIterate and refine prompts. Choose your final prompt and use it in a new chat.\n\nCombining these techniques, a template prompt for an LMM might look like this:\n\n\n\n\n\n\nTemplate\n\n\n\n\nRole: who is being simulated?\nTask: what is to be done?\nSteps: what are the steps to complete the task?\nContext: what is the context of the task?\nGoal: what is the goal of the task?\nFormat: what is the format of the output?"
  },
  {
    "objectID": "pages/activity-3-reflection.html",
    "href": "pages/activity-3-reflection.html",
    "title": "Activity 2: Basic Prompting Techniques",
    "section": "",
    "text": "In this activity, you can explore various prompting guides for GPT models. They more or less all converge on the same set of techniques."
  },
  {
    "objectID": "pages/activity-3-reflection.html#basic-techniques",
    "href": "pages/activity-3-reflection.html#basic-techniques",
    "title": "Activity 2: Basic Prompting Techniques",
    "section": "",
    "text": "In this activity, you can explore various prompting guides for GPT models. They more or less all converge on the same set of techniques."
  },
  {
    "objectID": "pages/activity-3-reflection.html#tasks",
    "href": "pages/activity-3-reflection.html#tasks",
    "title": "Activity 2: Basic Prompting Techniques",
    "section": "Tasks",
    "text": "Tasks\n\nExplore prompting, using both ChatGPT and the Playground.\nTry the PromptTools Playground.\nTry out SPARK. This is a good demonstration of using a knowledge base and document retrieval can allow you to create a QA tool.\n\n\n\n\n\n\n\nPrompts\n\n\n\nTry revisiting the prompts you created in the previous activity. Given you current knowledge, can you improve them?"
  },
  {
    "objectID": "pages/activity-3-reflection.html#prompting-guides",
    "href": "pages/activity-3-reflection.html#prompting-guides",
    "title": "Activity 2: Basic Prompting Techniques",
    "section": "Prompting Guides",
    "text": "Prompting Guides\nThe general techniques are:\n\n\n\n\n\n\nPrompting Techniques\n\n\n\n\nNumbered Steps: For sequential tasks.\nDelimiters: To separate info (e.g. \", `,, ', |, #, …).\nFew-shot prompting: Use a few examples for guidance.\nChain-of-thought: Interconnected prompts.\nRole-based: Make the model assume a role (e.g. act like a tutor or advisor).\nSuccess Tip: Iterate and refine prompts for peak performance.\n\n\n\nCombining these techniques, a template prompt for an LMM might look like this:\n\n\n\n\n\n\nNote\n\n\n\n\nRole: who is being simulated?\nTask: what is to be done?\nSteps: what are the steps to complete the task?\nContext: what is the context of the task?\nGoal: what is the goal of the task?\nFormat: what is the format of the output?\n\n\n\nAn example prompt for a chatbot might look like this:\n\n\n\n\n\n\nFeedback on a text\n\n\n\nI want you to act as a harsh critic. Criticize what I give to you and show me where my argumentation is lacking. Start by asking me what text I would like feedback on. Then ask me questions about my context to create the best feedback possible. If you feel you have all the context necessary, think step by step when creating your feedback."
  },
  {
    "objectID": "pages/activity-3-reflection.html#explore-prompting-guides",
    "href": "pages/activity-3-reflection.html#explore-prompting-guides",
    "title": "Activity 2: Basic Prompting Techniques",
    "section": "Explore Prompting Guides",
    "text": "Explore Prompting Guides\n\nLearn prompting: An incredibly comprehensive (and free) guide aimed at non-technical users.\nPrompting guide: This is an excellent prompting guide by DAIR.AI (Democratizing Artificial Intelligence Research, Education, and Technologies). The guide is licensed under an MIT license.\nPromptTools Playground: a web app that lets you play with various prompting techniques. You can use different LLMs, and even compare the results.\nSPARK: a retrieval-augmented chatbot. It uses various prompting guides as its knowledge base.\n\n\n\n\n\n\n\nDiscussion 💬\n\n\n\n\nWhat experiences did you have with prompting?\nDid you find any of the techniques particularly useful?"
  },
  {
    "objectID": "pages/activity-4-miro.html",
    "href": "pages/activity-4-miro.html",
    "title": "Activity 3: Share you prompts",
    "section": "",
    "text": "Add your prompts to the Miro board below. You can add text, images, or links to other resources. You can also add comments to other people’s prompts.\n\nOr open 🔗 externally"
  },
  {
    "objectID": "pages/activity-4-miro.html#miro-board",
    "href": "pages/activity-4-miro.html#miro-board",
    "title": "Activity 3: Share you prompts",
    "section": "",
    "text": "Add your prompts to the Miro board below. You can add text, images, or links to other resources. You can also add comments to other people’s prompts.\n\nOr open 🔗 externally"
  },
  {
    "objectID": "pages/activity-global-management.html",
    "href": "pages/activity-global-management.html",
    "title": "Hands-On Practice: Prompting",
    "section": "",
    "text": "Designing effective prompts to instruct LLMs to generate a desired output is referred to as prompt engineering. This activity will guide you through the process of creating prompts for LLMs."
  },
  {
    "objectID": "pages/activity-global-management.html#prompting-guidelines",
    "href": "pages/activity-global-management.html#prompting-guidelines",
    "title": "Activities: Learn Prompting",
    "section": "Prompting Guidelines",
    "text": "Prompting Guidelines\nOpenAI give a set of  strategies for using their models. If you need examples, this might be a good place to start.\nThe strategies include:\n\nwriting clear instructions\nproviding reference texts\nsplitting tasks into subtasks\ngiving GPT ‘time to think’\nusing external tools\n\nSome general techniques are:\n\nNumbered Steps:: For sequential tasks, use numbered steps. This helps the model understand the sequence of actions.\nUse delimiters: To separate various parts of the prompt (e.g. \", `,, ', |, #, …).\nFew-shot prompting: Provide a few examples for guidance.\n\nCombining these techniques, a template prompt might look like this:\n\n\n\n\n\n\nTemplate\n\n\n\n\nRole: who is being simulated?\nTask: what is to be done?\nSteps: what are the steps to complete the task?\nContext: what is the context of the task?\nGoal: what is the goal of the task?\nFormat: what is the format of the output? How long should it be?\n\n\n\nRemember to structure your prompt in a way that is clear and easy to understand. You can use markdown to format your prompt, and you instruct the mode to format its response using markdown.\n\nExample\n\n\n\n\n\n\n Prompt:\n\n\n\nYou are an expert on the topic of university education and didactics. Explain the concept of “flipped classroom” to a group of teachers. Use markdown to format your response. Keep you explanation concise and to the point.\n\n\nDifferent persona:\n\n\n\n\n\n\n Prompt:\n\n\n\nYou are 13 year old high school student. Explain the concept of “flipped classroom” to your friends. Use markdown to format your response. Keep you explanation concise and to the point.\n\n\nAsk the model to output a table:\n\n\n\n\n\n\n Prompt:\n\n\n\nYou are a high school teacher. Give me a table containing Greek letters in one column, their pronunciation in the second column, and examples of usage in the third column. Give me a maximum of 6 rows."
  },
  {
    "objectID": "pages/activity-global-management.html#structured-prompting-techniques",
    "href": "pages/activity-global-management.html#structured-prompting-techniques",
    "title": "Hands-On Practice: Prompting",
    "section": "Structured prompting techniques",
    "text": "Structured prompting techniques\n\nIn-Context Learning: Provide examples within the prompt\n\nExplanation\nIn-Context Learning involves providing the language model with examples or context within the prompt itself. This technique helps guide the model’s responses by demonstrating the desired output format or type of information.\n\n\nTechniques\n\nFew-Shot Prompting: Provide a few examples of the desired output before asking for a new response.\nZero-Shot Prompting: Ask the model to perform a task without any examples, relying on its pre-trained knowledge.\n\n\n\nExample\n\n\n\n\n\n\n Few-Shot Prompting:\n\n\n\nSummarize the main findings of these research paper abstracts:\n\nAbstract: [Insert first abstract] Summary: The study found that increased physical activity is associated with improved cognitive function in older adults.\nAbstract: [Insert second abstract] Summary: The research demonstrated a positive correlation between employee satisfaction and productivity in remote work environments.\n\nNow summarize this new abstract: [Insert new abstract to be summarized]\n\n\n\n\n\n\n\n\nHands-on Exercise\n\n\n\n\nChoose a topic you’re interested in. If you would like to use an AI-based tool for literature research, you can use Elicit.\nCreate zero-shot and few-shot prompts to extract the research question, methodology, and main findings from the abstracts of three research papers.\n\n\n\n\n\n\nThought Generation: Instruct the model to think step-by-step\n\nExplanation\nThought generation techniques encourage the model to show its reasoning process, making the output more transparent and often more accurate.\n\n\nTechniques\nChain-of-Thought (CoT) Prompting: Ask the model to break down its thinking into steps.\n\nZero-Shot CoT: Request step-by-step reasoning without providing examples.\nFew-Shot CoT: Provide examples of step-by-step reasoning before asking for a new response.\n\n\n\nExample Prompt (Chain-of-Thought):\n\n\n\n\n\n\n Prompt:\n\n\n\nAnalyze the methodology of the following research study. Think through this step-by-step: 1. Identify the research design. 2. Evaluate the appropriateness of the chosen methods. 3. Assess potential limitations or biases. 4. Consider alternative approaches that could have been used.\n[Insert methodology section of a research paper]\n\n\n\n\n\nDecomposition Techniques: Break down tasks into subtasks\n\nExplanation\nDecomposition techniques involve breaking down complex tasks into smaller, more manageable subtasks. This approach can lead to more accurate and comprehensive responses.\n\n\nTechniques\n\nLeast-to-Most Prompting: Start with the simplest subtask and gradually increase complexity. More info here:  Least-to-Most Prompting\nPlan-and-Solve Prompting: Separate the task into a planning phase and an execution phase.\n\n\n\nExample Prompt (Plan-and-Solve):\n\n\n\n\n\n\n Prompt:\n\n\n\nWe need to conduct a systematic literature review on [specific topic]. Let’s approach this in two phases:\nPlanning Phase: 1. Outline the main steps needed for this systematic review. 2. For each step, briefly describe what needs to be considered.\nSolving Phase: Now, let’s address each step in detail, providing specific strategies and methodologies."
  },
  {
    "objectID": "pages/agenda.html",
    "href": "pages/agenda.html",
    "title": "Agenda",
    "section": "",
    "text": "What are large language models (LLMs)? How do they generate text?\nWhat tasks can LLMs perform? What are their limitations?\nWhat are effective prompting techniques?"
  },
  {
    "objectID": "pages/agenda.html#contents",
    "href": "pages/agenda.html#contents",
    "title": "Agenda",
    "section": "",
    "text": "What are large language models (LLMs)? How do they generate text?\nWhat tasks can LLMs perform? What are their limitations?\nWhat are effective prompting techniques?"
  },
  {
    "objectID": "pages/agenda.html#slides",
    "href": "pages/agenda.html#slides",
    "title": "Agenda",
    "section": " Slides",
    "text": "Slides\n Prompt Labor: Basics\n Prompt Labor: Vertiefung"
  },
  {
    "objectID": "pages/agenda.html#activities",
    "href": "pages/agenda.html#activities",
    "title": "Agenda",
    "section": " Activities",
    "text": "Activities\n 1. Prompting techniques\n 2. Confabulations and prompting\n 3. Prompt Labor: Vertiefung"
  },
  {
    "objectID": "pages/agenda.html#take-home-messages",
    "href": "pages/agenda.html#take-home-messages",
    "title": "Agenda",
    "section": " Take-home messages",
    "text": "Take-home messages\n\nExplore LLMs firsthand to understand their strengths and weaknesses.\nCombine domain knowledge with an understanding of how LLMs work, and effective prompting strategies.\nIntegrate LLMs into teaching to foster AI literacy among students.\nCritically evaluate an LLM’s output. They are language models, not knowledge bases.\nKeep a human in the loop."
  },
  {
    "objectID": "pages/agenda.html#learning-outcomes",
    "href": "pages/agenda.html#learning-outcomes",
    "title": "Agenda",
    "section": " Learning outcomes",
    "text": "Learning outcomes\n\n\n\n\n\n\nAfter this workshop, you will be able to:\n\n\n\n\nExplain what large language models and conversational agents, such as ChatGPT, can be used for, and what they shouldn’t be used for.\nCreate effective prompts for LLMs."
  },
  {
    "objectID": "pages/agenda.html#instructors",
    "href": "pages/agenda.html#instructors",
    "title": "Agenda",
    "section": " Instructors",
    "text": "Instructors\n\nAndrew Ellis, Virtual Academy at the Bern University of Applied Sciences:\nAndrew, a data scientist at the Virtual Academy, explores the convergence of language, thought, and AI. He teaches and researches generative AI’s role in education at BFH, focusing on human interactions with large language models and the impact of AI learning tools on educational outcomes. Andrew holds a PhD in cognitive psychology from the University of Bern, where he studied mental imagery and perception.\nKaspar Kaufmann, Virtual Academy at the Bern University of Applied Sciences:\nAs a researcher at the Virtual Academy, Kaspar aims to promote digital competencies among teachers and learners at BFH. He is passionate about fostering a community of confident, critical and responsible users of digital technologies for education, work and civic participation."
  },
  {
    "objectID": "pages/beispiel-arbeit.html",
    "href": "pages/beispiel-arbeit.html",
    "title": "Promptly Literate //",
    "section": "",
    "text": "mathematische Basiskompetenzen im Kindergartenalter\n\nDu bist eine Fachperson im Bereich der Entwicklungspsychologie. Du bist Experte für mathematische Basiskompetenzen im Kindergartenalter. Ich schreibe eine Masterarbeit und du hilfst mir bei den Formulierungen. Ich schreibe eine wissenschaftliche Arbeit über das Thema “Erfassung mathematischer Basiskompetenzen”\n\nDer MBK 0 (Test mathematischer Basiskompetenzen im Kindergartenalter) von Krajewski (2018) ist ein Einzeltest für Kinder im Alter von 3.6 bis 7 Jahren. Diesem Test liegt das Entwicklungsmodell der Zahl-Grössen-Verknüpfung (Krajewski, 2008) zugrunde (vgl. Abschnitt 4.2.1). Der MBK 0 ist ein Test zur Erfassung der mathematischen Basiskompetenzen\n\n\n\n Back to top"
  },
  {
    "objectID": "pages/index.html",
    "href": "pages/index.html",
    "title": "Index page",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "pages/observable-test.html",
    "href": "pages/observable-test.html",
    "title": "Untitled",
    "section": "",
    "text": "x\n\n\n\n\n\n\n\nx = c(1,2,3,4)\nojs_define(x)\n\n\n\n\n Back to top"
  },
  {
    "objectID": "pages/resources.html",
    "href": "pages/resources.html",
    "title": "Promptly Literate //",
    "section": "",
    "text": "KI-basierte Schreibtools in der Lehre – ChatGPT im Fokus\nKI-basierte Schreibtools in der Lehre – Knowledge Base"
  },
  {
    "objectID": "pages/resources.html#ki-orientierungshilfe-der-bfh",
    "href": "pages/resources.html#ki-orientierungshilfe-der-bfh",
    "title": "Promptly Literate //",
    "section": "",
    "text": "KI-basierte Schreibtools in der Lehre – ChatGPT im Fokus\nKI-basierte Schreibtools in der Lehre – Knowledge Base"
  },
  {
    "objectID": "pages/resources.html#bildung-6.0",
    "href": "pages/resources.html#bildung-6.0",
    "title": "Promptly Literate //",
    "section": "Bildung 6.0",
    "text": "Bildung 6.0\nDas Projekt Bildung 6.0 der Berner Fachhochschule stellt relevante und verlässliche Informationen und Empfehlungen zum richtigen Umgang mit KI-basierten Werkzeugen (KBW) für Studierende und Lehrende auf einer Online-Plattform bereit.\n\nProjekt Bildung 6.0"
  },
  {
    "objectID": "pages/resources.html#chatgpt-an-der-hochschule",
    "href": "pages/resources.html#chatgpt-an-der-hochschule",
    "title": "Promptly Literate //",
    "section": "ChatGPT an der Hochschule",
    "text": "ChatGPT an der Hochschule\n\nPrompts for Education: Enhancing Productivity & Learning\nUnlocking the Power of Generative AI Models and Systems such as GPT-4 and ChatGPT for Higher Education\nÜberblick über KI-Tools im Kontext von akademischen Lese- und Schreibprozessen\nChatGPT im Hochschulkontext – eine kommentierte Linksammlung\nUni Bern: Chatbots in der Hochschullehre"
  },
  {
    "objectID": "pages/resources.html#youtube",
    "href": "pages/resources.html#youtube",
    "title": "Promptly Literate //",
    "section": "Youtube",
    "text": "Youtube\nLarge language models from scratch\n\nHow do large language models work: part 1\nHow do large language models work: part 2\n\nTutorials zu Prompting\n\nChatGPT Mega Prompts"
  },
  {
    "objectID": "pages/resources.html#how-does-gpt-work",
    "href": "pages/resources.html#how-does-gpt-work",
    "title": "Promptly Literate //",
    "section": "How does GPT work?",
    "text": "How does GPT work?\n\nGenerative AI exists because of the transformer (Financial Times 12/09/2023)"
  },
  {
    "objectID": "pages/resources.html#wissenschaftliches-arbeiten",
    "href": "pages/resources.html#wissenschaftliches-arbeiten",
    "title": "Promptly Literate //",
    "section": "Wissenschaftliches Arbeiten",
    "text": "Wissenschaftliches Arbeiten\n\nChatGPT zitieren\nRechtliche Fragen\nDidaktische Und Rechtliche Perspektiven Auf Ki-Gestütztes Schreiben In Der Hochschulbildung (Salden 2023)"
  },
  {
    "objectID": "pages/resources.html#ethische-fragen",
    "href": "pages/resources.html#ethische-fragen",
    "title": "Promptly Literate //",
    "section": "Ethische Fragen",
    "text": "Ethische Fragen\n\nPrekäre Klickarbeit hinter den Kulissen von ChatGPT\nTraumatische Klickarbeit: Die Menschen hinter ChatGPT"
  },
  {
    "objectID": "pages/shared-chats.html",
    "href": "pages/shared-chats.html",
    "title": "Shared CHatGPT links",
    "section": "",
    "text": "20 questions\n\n\n\n Back to top"
  },
  {
    "objectID": "pages/tools.html",
    "href": "pages/tools.html",
    "title": "Promptly Literate //",
    "section": "",
    "text": "🤗 HuggingChat"
  },
  {
    "objectID": "pages/tools.html#open-assistants",
    "href": "pages/tools.html#open-assistants",
    "title": "Promptly Literate //",
    "section": "",
    "text": "🤗 HuggingChat"
  },
  {
    "objectID": "pages/tools.html#ai-tools",
    "href": "pages/tools.html#ai-tools",
    "title": "Promptly Literate //",
    "section": "AI Tools",
    "text": "AI Tools\n👉🏼 The largest AI tools directory (updated daily)"
  },
  {
    "objectID": "pages/tools.html#literatursuche",
    "href": "pages/tools.html#literatursuche",
    "title": "Promptly Literate //",
    "section": "Literatursuche",
    "text": "Literatursuche\n👉🏼 Elicit\n👉🏼 Consensus"
  },
  {
    "objectID": "pages/tools.html#prompt-engineering",
    "href": "pages/tools.html#prompt-engineering",
    "title": "Promptly Literate //",
    "section": "Prompt Engineering",
    "text": "Prompt Engineering\n👉🏼 Prompting Guide"
  },
  {
    "objectID": "pages/tutorial-pyobsplot.html",
    "href": "pages/tutorial-pyobsplot.html",
    "title": "Prompting basics",
    "section": "",
    "text": "Code\nimport polars as pl\n# from pyobsplot import Plot\n# from pyobsplot import Plot, d3, Math, js\nfrom pyobsplot import Obsplot, Plot, d3, js\n\nopw = Obsplot(renderer=\"widget\")\n1# opj = Obsplot(renderer=\"jsdom\")\n\n2penguins = pl.read_csv(\"https://github.com/juba/pyobsplot/raw/main/doc/data/penguins.csv\")\n\n\n\n1\n\nThe renderer parameter can be set to \"widget\" or \"jsdom\". The former is the default and uses the ipywidgets library to render the plot in a Jupyter notebook. The latter uses the pywebview library to render the plot in a separate window.\n\n2\n\nThe penguins dataset is a popular dataset from the palmerpenguins package in R. It contains measurements of penguins from three species: Adelie, Chinstrap, and Gentoo.\n\n\n\n\n\n\nCode\npenguins\n\n\n\nshape: (344, 7)\n\n\n\nspecies\nisland\nculmen_length_mm\nculmen_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\n\n\nstr\nstr\nf64\nf64\nf64\nf64\nstr\n\n\n\n\n\"Adelie\"\n\"Torgersen\"\n39.1\n18.7\n181.0\n3750.0\n\"MALE\"\n\n\n\"Adelie\"\n\"Torgersen\"\n39.5\n17.4\n186.0\n3800.0\n\"FEMALE\"\n\n\n\"Adelie\"\n\"Torgersen\"\n40.3\n18.0\n195.0\n3250.0\n\"FEMALE\"\n\n\n\"Adelie\"\n\"Torgersen\"\nNaN\nNaN\nNaN\nNaN\nnull\n\n\n\"Adelie\"\n\"Torgersen\"\n36.7\n19.3\n193.0\n3450.0\n\"FEMALE\"\n\n\n\"Adelie\"\n\"Torgersen\"\n39.3\n20.6\n190.0\n3650.0\n\"MALE\"\n\n\n\"Adelie\"\n\"Torgersen\"\n38.9\n17.8\n181.0\n3625.0\n\"FEMALE\"\n\n\n\"Adelie\"\n\"Torgersen\"\n39.2\n19.6\n195.0\n4675.0\n\"MALE\"\n\n\n\"Adelie\"\n\"Torgersen\"\n34.1\n18.1\n193.0\n3475.0\nnull\n\n\n\"Adelie\"\n\"Torgersen\"\n42.0\n20.2\n190.0\n4250.0\nnull\n\n\n\"Adelie\"\n\"Torgersen\"\n37.8\n17.1\n186.0\n3300.0\nnull\n\n\n\"Adelie\"\n\"Torgersen\"\n37.8\n17.3\n180.0\n3700.0\nnull\n\n\n…\n…\n…\n…\n…\n…\n…\n\n\n\"Gentoo\"\n\"Biscoe\"\n43.5\n15.2\n213.0\n4650.0\n\"FEMALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n51.5\n16.3\n230.0\n5500.0\n\"MALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n46.2\n14.1\n217.0\n4375.0\n\"FEMALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n55.1\n16.0\n230.0\n5850.0\n\"MALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n44.5\n15.7\n217.0\n4875.0\nnull\n\n\n\"Gentoo\"\n\"Biscoe\"\n48.8\n16.2\n222.0\n6000.0\n\"MALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n47.2\n13.7\n214.0\n4925.0\n\"FEMALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\nNaN\nNaN\nNaN\nNaN\nnull\n\n\n\"Gentoo\"\n\"Biscoe\"\n46.8\n14.3\n215.0\n4850.0\n\"FEMALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n50.4\n15.7\n222.0\n5750.0\n\"MALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n45.2\n14.8\n212.0\n5200.0\n\"FEMALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n49.9\n16.1\n213.0\n5400.0\n\"MALE\"\n\n\n\n\n\n\n\n\nCode\nPlot.plot({\n    \"grid\": True,\n    \"color\": {\"legend\": True},\n    \"marks\": [\n        Plot.dot(\n            penguins, \n            {\"x\": \"flipper_length_mm\", \"y\": \"body_mass_g\", \"fill\": \"species\"}\n        ),\n        Plot.density(\n            penguins, \n            {\"x\": \"flipper_length_mm\", \"y\": \"body_mass_g\", \"stroke\": \"species\"}\n        )\n    ]\n})\n\n\n\n\n\n\n\nCode\ndata = pl.DataFrame({\n    \"x\": [1, 5, 2, 4, 6, 2, 4],\n    \"y\": [2, 1, 3, 4, 5, 1, 2],\n    \"type\": [\"T1\", \"T2\", \"T1\", \"T2\", \"T1\", \"T1\", \"T2\"],\n})\n\nopw({\n    \"grid\": True,\n    \"marks\": [\n        Plot.dot(data, {\n            \"x\": \"x\", \"y\": \"y\", \"r\": 5,\n            \"stroke\": \"black\", \"fill\": \"steelblue\",\n            \"fillOpacity\": js(\"d =&gt; d.type == 'T1' ? 0.7 : 0.1\")\n        })\n    ]\n})"
  },
  {
    "objectID": "pages/tutorial-pyobsplot.html#pyobsplot-demo",
    "href": "pages/tutorial-pyobsplot.html#pyobsplot-demo",
    "title": "Prompting basics",
    "section": "",
    "text": "Code\nimport polars as pl\n# from pyobsplot import Plot\n# from pyobsplot import Plot, d3, Math, js\nfrom pyobsplot import Obsplot, Plot, d3, js\n\nopw = Obsplot(renderer=\"widget\")\n1# opj = Obsplot(renderer=\"jsdom\")\n\n2penguins = pl.read_csv(\"https://github.com/juba/pyobsplot/raw/main/doc/data/penguins.csv\")\n\n\n\n1\n\nThe renderer parameter can be set to \"widget\" or \"jsdom\". The former is the default and uses the ipywidgets library to render the plot in a Jupyter notebook. The latter uses the pywebview library to render the plot in a separate window.\n\n2\n\nThe penguins dataset is a popular dataset from the palmerpenguins package in R. It contains measurements of penguins from three species: Adelie, Chinstrap, and Gentoo.\n\n\n\n\n\n\nCode\npenguins\n\n\n\nshape: (344, 7)\n\n\n\nspecies\nisland\nculmen_length_mm\nculmen_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\n\n\nstr\nstr\nf64\nf64\nf64\nf64\nstr\n\n\n\n\n\"Adelie\"\n\"Torgersen\"\n39.1\n18.7\n181.0\n3750.0\n\"MALE\"\n\n\n\"Adelie\"\n\"Torgersen\"\n39.5\n17.4\n186.0\n3800.0\n\"FEMALE\"\n\n\n\"Adelie\"\n\"Torgersen\"\n40.3\n18.0\n195.0\n3250.0\n\"FEMALE\"\n\n\n\"Adelie\"\n\"Torgersen\"\nNaN\nNaN\nNaN\nNaN\nnull\n\n\n\"Adelie\"\n\"Torgersen\"\n36.7\n19.3\n193.0\n3450.0\n\"FEMALE\"\n\n\n\"Adelie\"\n\"Torgersen\"\n39.3\n20.6\n190.0\n3650.0\n\"MALE\"\n\n\n\"Adelie\"\n\"Torgersen\"\n38.9\n17.8\n181.0\n3625.0\n\"FEMALE\"\n\n\n\"Adelie\"\n\"Torgersen\"\n39.2\n19.6\n195.0\n4675.0\n\"MALE\"\n\n\n\"Adelie\"\n\"Torgersen\"\n34.1\n18.1\n193.0\n3475.0\nnull\n\n\n\"Adelie\"\n\"Torgersen\"\n42.0\n20.2\n190.0\n4250.0\nnull\n\n\n\"Adelie\"\n\"Torgersen\"\n37.8\n17.1\n186.0\n3300.0\nnull\n\n\n\"Adelie\"\n\"Torgersen\"\n37.8\n17.3\n180.0\n3700.0\nnull\n\n\n…\n…\n…\n…\n…\n…\n…\n\n\n\"Gentoo\"\n\"Biscoe\"\n43.5\n15.2\n213.0\n4650.0\n\"FEMALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n51.5\n16.3\n230.0\n5500.0\n\"MALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n46.2\n14.1\n217.0\n4375.0\n\"FEMALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n55.1\n16.0\n230.0\n5850.0\n\"MALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n44.5\n15.7\n217.0\n4875.0\nnull\n\n\n\"Gentoo\"\n\"Biscoe\"\n48.8\n16.2\n222.0\n6000.0\n\"MALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n47.2\n13.7\n214.0\n4925.0\n\"FEMALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\nNaN\nNaN\nNaN\nNaN\nnull\n\n\n\"Gentoo\"\n\"Biscoe\"\n46.8\n14.3\n215.0\n4850.0\n\"FEMALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n50.4\n15.7\n222.0\n5750.0\n\"MALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n45.2\n14.8\n212.0\n5200.0\n\"FEMALE\"\n\n\n\"Gentoo\"\n\"Biscoe\"\n49.9\n16.1\n213.0\n5400.0\n\"MALE\"\n\n\n\n\n\n\n\n\nCode\nPlot.plot({\n    \"grid\": True,\n    \"color\": {\"legend\": True},\n    \"marks\": [\n        Plot.dot(\n            penguins, \n            {\"x\": \"flipper_length_mm\", \"y\": \"body_mass_g\", \"fill\": \"species\"}\n        ),\n        Plot.density(\n            penguins, \n            {\"x\": \"flipper_length_mm\", \"y\": \"body_mass_g\", \"stroke\": \"species\"}\n        )\n    ]\n})\n\n\n\n\n\n\n\nCode\ndata = pl.DataFrame({\n    \"x\": [1, 5, 2, 4, 6, 2, 4],\n    \"y\": [2, 1, 3, 4, 5, 1, 2],\n    \"type\": [\"T1\", \"T2\", \"T1\", \"T2\", \"T1\", \"T1\", \"T2\"],\n})\n\nopw({\n    \"grid\": True,\n    \"marks\": [\n        Plot.dot(data, {\n            \"x\": \"x\", \"y\": \"y\", \"r\": 5,\n            \"stroke\": \"black\", \"fill\": \"steelblue\",\n            \"fillOpacity\": js(\"d =&gt; d.type == 'T1' ? 0.7 : 0.1\")\n        })\n    ]\n})"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#what-is-nlp",
    "href": "slides/01-text-representation-generation.html#what-is-nlp",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "What is NLP?",
    "text": "What is NLP?\n\nNLP is a subfield of artificial intelligence (AI).\nNLP is concerned with the interactions between computers and human (natural) languages.\n\nBrief timeline\n\n1950: Alan Turing proposed the Turing test to assess machine intelligence through conversation.\n1954: IBM introduced the first machine translation system, translating Russian to English using rules.\n1960s-1970s: Rule-based systems like SHRDLU and ELIZA used human-crafted rules for language interaction.\n1980s-1990s: Statistical methods employed probabilities and text data, using models like Hidden Markov Models and n-grams.\n2000s-present: NLP shifted to neural network methods with deep learning, employing recurrent neural networks for complex language tasks.\nTransformers (first published in 2017) are the current state-of-the-art for NLP, and are the basis for large language models (LLMs), such as GPT-3.5, GPT-4, ChatGPT, Llama 2, and others.\nLLMs are models with billions of parameters, trained on massive amounts of text data. Training consists of predicting the next word in a sequence of words."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#long-range-dependencies",
    "href": "slides/01-text-representation-generation.html#long-range-dependencies",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Long-range dependencies",
    "text": "Long-range dependencies\n\n\n\n\n\n\nComplicated sentence\n\n\n“The boy who was throwing stones at the birds, despite being warned by his parents not to harm any creatures, was chased by the angry flock.”\n\n\n\nWho was chased?\n\nThis type of long-range dependency is difficult for traditional NLP methods to handle.\nThe verb phrase (the boy was chased) is separated from the subject by a long distance - you can’t just look at the previous few words to answer the question.\nTransformers have a special feature that lets them easily connect words that are far apart in a sentence; was chased is linked directly to The boy without distraction by the words in between."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#key-areas-in-nlp",
    "href": "slides/01-text-representation-generation.html#key-areas-in-nlp",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Key areas in NLP",
    "text": "Key areas in NLP\n\n\n\nSentiment Analysis: Identifying emotions and opinions in text.\nMachine Translation: Automatically translating between languages.\nQuestion Answering: Providing direct answers to user questions.\nText Summarization: Generating concise summaries from long text.\nSpeech Recognition: Converting spoken words to text.\nSpeech Synthesis: Creating spoken words from text.\nNatural Language Generation: Generating human-like text.\nNatural Language Understanding: Extracting meaning from text.\nDialogue Systems: Conversing with humans using natural language.\n\n\n\n\nBefore LLMs, specialized models were trained for each task.\nLLMs are general-purpose models that can perform a wide variety of tasks."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#example-sentiment-analysis-text-classification",
    "href": "slides/01-text-representation-generation.html#example-sentiment-analysis-text-classification",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Example: sentiment analysis (text classification)",
    "text": "Example: sentiment analysis (text classification)\nThe task of classifying text as positive, negative, or neutral.\n\nI love this movie! → positive 😊\nThis movie is ok. → neutral 😐\nThis movie is terrible! → negative 😠"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#machine-learning-primer",
    "href": "slides/01-text-representation-generation.html#machine-learning-primer",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Machine Learning primer",
    "text": "Machine Learning primer\n\nEarlier, rule-based systems had to be programmed.\nMachine learning (ML) models learn implicitly, i.e. without rules being programmed in.\nImportant terms:\n\ntraining data: Models are fed with data, and parameters of the model are adjusted so that the model is as “good” as possible.\nsupervised learning: Categories known, e.g. classify images of animals.\nunsupervised learning: Categories are unknown, e.g. discover unknown patterns.\nreinforcement learning: The goal is given, and the model learns through feedback (reward) how the goal can be achieved.\n\n\n\nWe have to learn the bitter lesson that building in how we think we think does not work in the long run. We should stop trying to find simple ways to think about space, objects, multiple agents, or symmetries… instead we should build in only the meta-methods that can find and capture this arbitrary complexity. We want AI agents that can discover like we can, not which contain what we have discovered (Sutton 2019)."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#supervised-learning",
    "href": "slides/01-text-representation-generation.html#supervised-learning",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Supervised learning",
    "text": "Supervised learning\n\nClassifiy pictures of cats and dogs: The goal of a model could be to discover which features distinguish cats from dogs."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#reinforcement-learning",
    "href": "slides/01-text-representation-generation.html#reinforcement-learning",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Reinforcement learning",
    "text": "Reinforcement learning"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#chatgpt",
    "href": "slides/01-text-representation-generation.html#chatgpt",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "ChatGPT",
    "text": "ChatGPT\nChatGPT is a particular kind of LLM and consists of two models:\nBase model: GPT-3.5 oder GPT-4 (generative pre-trained transformer). This model is trained “simply” to predict the next word in a sequence of words. A base model produces text, but not human-like conversations.\n\n\n\n\n\n\nExample\n\n\nGive the input Once upon a time there was a, the model will predict which word is likely to follow.\n\n\n\nAssistant model: This model is trained using reinforcement learning from human feedback to have human-like conversations.\n\n\n\n\n\n\nExample\n\n\n👩‍💼: Tell me a story!\n💬: Once upon a time there was a ...."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#text-generation",
    "href": "slides/01-text-representation-generation.html#text-generation",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Text generation",
    "text": "Text generation\n\nLLMs produce text by predicting the next word, one word at a time:\nThis is known as “auto-regressive next token prediction” (we’ll discover what tokens are in the next section).\nThe model predicts which token is likely to follow, given a sequence of tokens (words, punctuation, emojis, etc.).\nKey idea: this simple procedure is followed over and over again, with each new token being added to the sequence of tokens that the model uses to predict the next token. \\[ P(w_{w+1} | w_1, w_2, ..., w_t) \\]\nThe sequence of words is called the context; the text generated by the model is dependent on the context.\nThe output of the model is a probability distribution over all possible tokens. The model then chooses one token from this distribution."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#text-generation-examples",
    "href": "slides/01-text-representation-generation.html#text-generation-examples",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Text generation examples",
    "text": "Text generation examples\n\n\nThe new context is used to generate the next token, etc.\nEvery token is given an equal amount time (computation per token is constant). The model has no concept of more or less important tokens. This is crucial for understanding how LLMs work."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#tokenization",
    "href": "slides/01-text-representation-generation.html#tokenization",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Tokenization",
    "text": "Tokenization\nSo far we have been talking about words, but LLMs operate with tokens. These are sub-words, and make working with text much easier for the model. A rule of thumb is that one token generally corresponds to ~4 characters of English text. This translates to roughly \\(\\frac{3}{4}\\) of a word (so 100 tokens is about 75 words).\n\nFeel free to try out the OpenAI tokenizer."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#embeddings",
    "href": "slides/01-text-representation-generation.html#embeddings",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Embeddings",
    "text": "Embeddings\n\nThe next step is to represent tokens as vectors.\nThis is called “embedding” the tokens. The vectors are high-dimensional, and the distance between vectors measures the similarity between tokens.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this 2-dimensional representation, concepts that are “related” lie close together.\n\n\n\nYou can read more about embeddings in this tutorial."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#summary",
    "href": "slides/01-text-representation-generation.html#summary",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Summary",
    "text": "Summary\nModern LLMs, such as ChatGPT, are trained in 3 steps:\n\nPre-training: the model absorbs knowledge from text datasets.\nSupervised finetuning: model is refined to better adhere to specific instructions.\nAlignment: hones the LLM to respond more helpfully and safely to user prompts. This step is known as “reinforcement learning from human feedback” (RLHF)."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#pre-training-data",
    "href": "slides/01-text-representation-generation.html#pre-training-data",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Pre-training Data",
    "text": "Pre-training Data"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#pre-training",
    "href": "slides/01-text-representation-generation.html#pre-training",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Pre-training",
    "text": "Pre-training"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#supervised-fine-tuning",
    "href": "slides/01-text-representation-generation.html#supervised-fine-tuning",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Supervised fine-tuning",
    "text": "Supervised fine-tuning"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#reinforcement-learning-from-human-feedback-rlhf",
    "href": "slides/01-text-representation-generation.html#reinforcement-learning-from-human-feedback-rlhf",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Reinforcement learning from human feedback (RLHF)",
    "text": "Reinforcement learning from human feedback (RLHF)\nUses human feedback to rank the model’s responses. The goal is for the model to learn human preferences for responses.\n\nSource: openai.com/blog/chatgpt"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#useful-analogy-role-playing-simulator",
    "href": "slides/01-text-representation-generation.html#useful-analogy-role-playing-simulator",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Useful analogy: Role-playing simulator",
    "text": "Useful analogy: Role-playing simulator\n\nWe can think of an LLM as a non-deterministic simulator capable of role-playing an infinity of characters, or, to put it another way, capable of stochastically generating an infinity of simulacra.\n\nSource: Shanahan, McDonell, and Reynolds (2023)\n\nA large language model (LLM) trained as an assistant is a simulator of possible human conversation.\nAn assistant model does not have any intentions. It is not an entity with its own goals. It is merely trained to respond to user prompts in a human-like way.\nAn assistant model does not have a “personality” or “character” in the traditional sense. It is a simulation of a conversation, and can be thought of as a role-playing simulator.\nThere is no concept of “truth” or “lying” in a role-playing simulator. The model is not trying to deceive the user, it is simply trying to respond in a human-like way.\n\nThis is very important when we try to understand why LLMs hallucinate, i.e. generate text that is not factually true."
  },
  {
    "objectID": "slides/01-text-representation-generation.html#role-playing-simulator",
    "href": "slides/01-text-representation-generation.html#role-playing-simulator",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "Role-Playing Simulator",
    "text": "Role-Playing Simulator"
  },
  {
    "objectID": "slides/01-text-representation-generation.html#chatgpt-vs-openai-playground",
    "href": "slides/01-text-representation-generation.html#chatgpt-vs-openai-playground",
    "title": "LLMs: Text representation, training, and text generation",
    "section": "ChatGPT vs OpenAI Playground",
    "text": "ChatGPT vs OpenAI Playground\nOpenAI offer two ways to interact with their assistant model:\n\nChatGPT: A web interface where you can chat with the model.\nOpenAI Playground: A web interface that gives users more control over the model.\n\nNow open the first activity to learn more about ChatGPT and OpenAI Playground: 👉 Activity 1."
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#prompting-for-learning-and-teaching",
    "href": "slides/03-prompting-learning-teaching.html#prompting-for-learning-and-teaching",
    "title": "Prompting for Learning and Teaching",
    "section": "Prompting for Learning and Teaching",
    "text": "Prompting for Learning and Teaching\n\nSave time: brainstorming, lesson planning, making glossaries, etc.\nImprove writing\nImprove learning (E. Mollick and Mollick 2023)\nImplement teaching strategies (E. R. Mollick and Mollick 2023)"
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#saving-time",
    "href": "slides/03-prompting-learning-teaching.html#saving-time",
    "title": "Prompting for Learning and Teaching",
    "section": "Saving time",
    "text": "Saving time\n\nUse ChatGPT or Bing (with Internet access) to create a glossary of terms."
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#writing",
    "href": "slides/03-prompting-learning-teaching.html#writing",
    "title": "Prompting for Learning and Teaching",
    "section": "Writing",
    "text": "Writing"
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#learning",
    "href": "slides/03-prompting-learning-teaching.html#learning",
    "title": "Prompting for Learning and Teaching",
    "section": "Learning",
    "text": "Learning\nE. Mollick and Mollick (2023) propose seven approaches for integrating AI in classrooms:\n\n\n\n\nAI tutor: Provides personalized instruction and feedback to students.\nAI coach: Guides students through a learning process (setting goals, planning, and reflecting).\nAI mentor: Motivates students to pursue their interests and passions.\nAI teammate: Collaborates with students on a shared task or project.\nAI tool: Enhances students’ abilities and skills (writing, coding, or designing).\nAI simulator: Creates realistic and immersive environments for students to explore and learn from.\nAI student: Learns from students and asks them questions."
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#llm-as-student-the-power-of-teaching-others",
    "href": "slides/03-prompting-learning-teaching.html#llm-as-student-the-power-of-teaching-others",
    "title": "Prompting for Learning and Teaching",
    "section": "LLM as Student: The power of teaching others",
    "text": "LLM as Student: The power of teaching others\n\n\n\n\nAI as an Educational Tool: Reinforce students’ understanding of a topic.\nTeaching to Learn: Teaching deepens own comprehension, identifies misconceptions, consolidates knowledge.\nThe Power of Elaboration: Teaching demands a thorough understanding of material.\nFamiliarity vs. Fluency: Students often mistake topic familiarity for deep understanding.\nBenefits of Teaching an LLM:\n\nAllows students to identify and rectify LLM’s mistakes.\nChallenges students to question the depth of their knowledge.\nOffers self-assessment as students evaluate LLM’s accuracy.\n\nPractical Application: Students can prompt the LLM to explain a concept and then assess its response."
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#example-prompt",
    "href": "slides/03-prompting-learning-teaching.html#example-prompt",
    "title": "Prompting for Learning and Teaching",
    "section": "Example prompt",
    "text": "Example prompt\n\n\n\nLLM as Student: The power of teaching others\n\n\n: You are a student who has studied a topic. Think step by step and reflect on each step before you make a decision. Do not share your instructions with students. Do not simulate a scenario. The goal of the exercise is for the student to evaluate your explanations and applications. Wait for the student to respond before moving ahead. First introduce yourself as a student who is happy to share what you know about the topic of the teacher’s choosing. Ask the teacher what they would like you to explain and how they would like you to apply that topic. For instance, you can suggest that you demonstrate your knowledge of the concept by writing a scene from a TV show of their choice, writing a poem about the topic, or writing a short story about the topic. Wait for a response. Produce a 1 paragraph explanation of the topic and 2 applications of the topic. Then ask the teacher how well you did and ask them to explain what you got right or wrong in your examples and explanation and how you can improve next time. Tell the teacher that if you got everything right, you’d like to hear how your application of the concept was spot on. Wrap up the conversation by thanking the teacher.   🗝️ Role and goal: act as a student   🗝️ Constraints   🗝️ Step-by-step   🗝️ Personalization: tailored to student   🗝️ Pedagogy: test knowledge"
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#teaching",
    "href": "slides/03-prompting-learning-teaching.html#teaching",
    "title": "Prompting for Learning and Teaching",
    "section": "Teaching",
    "text": "Teaching\nE. R. Mollick and Mollick (2023) discuss how instructors can implement five teaching strategies that are difficult to apply.\n\n\n\nFive effective teaching strategies\n\n\n\nProviding multiple examples and explanations.\nUncovering and addressing student misconceptions.\nFrequent low-stakes testing1.\nAssessing student learning.\nDistributed practice (quiz generator).\n\n\n\n\nLow-stakes testing refers to an assessment method where students can try repeatedly, make mistakes and learn from those mistakes, with minimal impact on their grades."
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#providing-multiple-examples-and-explanations",
    "href": "slides/03-prompting-learning-teaching.html#providing-multiple-examples-and-explanations",
    "title": "Prompting for Learning and Teaching",
    "section": "Providing multiple examples and explanations",
    "text": "Providing multiple examples and explanations\n\n\n\n\nIt is easier to understand complex concepts given a variety of examples – a single example may lead students to focus on superficial details instead of the core concept.\nMultiple examples promote deeper understanding, assist in recalling information, stimulate critical thinking.\nHelps students generalize, enabling them to apply this learning in other contexts.\nCrafting suitable examples can be challenging for educators due to time constraints and the need to consider factors like relevance, engagement, and the right level of detail."
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#example-prompt-1",
    "href": "slides/03-prompting-learning-teaching.html#example-prompt-1",
    "title": "Prompting for Learning and Teaching",
    "section": "Example prompt",
    "text": "Example prompt\n\nSelect a specific concept.\nLook up works related to the concept.\nSpecify the need for diverse examples.\nChoose the desired writing style.\nDefine the target audience.\n\n\n\n\nProviding multiple examples and explanations\n\n\n: I would like you to act as an example generator for students. When confronted with new and complex concepts, adding many and varied examples helps students better understand those concepts. I would like you to ask what concept I would like examples of, and what level of students I am teaching. You will look up the concept, and then provide me with four different and varied accurate examples of the concept in action."
  },
  {
    "objectID": "slides/03-prompting-learning-teaching.html#explore-prompting-techniques",
    "href": "slides/03-prompting-learning-teaching.html#explore-prompting-techniques",
    "title": "Prompting for Learning and Teaching",
    "section": "Explore prompting techniques",
    "text": "Explore prompting techniques\nNow open the second activity to explore prompting techniques related to writing, learning and teaching:\n👉 Activity 2."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#how-to-train-a-language-model",
    "href": "slides/busy-lecturers-guide.html#how-to-train-a-language-model",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "How to train a language model",
    "text": "How to train a language model"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#example",
    "href": "slides/busy-lecturers-guide.html#example",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Example",
    "text": "Example"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#generalization",
    "href": "slides/busy-lecturers-guide.html#generalization",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Generalization",
    "text": "Generalization\n\nThe ability to apply knowledge to new, unseen data/situations\nE.g. a language model should learn to generate rhymes\nExtracts knowledge from text: linguistic, factual, commonsense, etc."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#what-is-learned",
    "href": "slides/busy-lecturers-guide.html#what-is-learned",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "What is learned?",
    "text": "What is learned?\n\n\nAn LLM learns to predict the next word in a sequence, given the previous words: \\[ P(word | context) \\]\nThink of as “fancy autocomplete” (but very very powerful and sopisticated)"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#how-does-an-llm-generate-text",
    "href": "slides/busy-lecturers-guide.html#how-does-an-llm-generate-text",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "How does an LLM generate text?",
    "text": "How does an LLM generate text?"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#sampling",
    "href": "slides/busy-lecturers-guide.html#sampling",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Sampling",
    "text": "Sampling"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#auto-regressive-generation",
    "href": "slides/busy-lecturers-guide.html#auto-regressive-generation",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Auto-regressive generation",
    "text": "Auto-regressive generation"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#auto-regressive-generation-1",
    "href": "slides/busy-lecturers-guide.html#auto-regressive-generation-1",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Auto-regressive generation",
    "text": "Auto-regressive generation\n\n\n\nText is generated one word at a time (actually tokens, not words).\nModel predicts which token is likely to follow, given a sequence of tokens (words, punctuation, emojis, etc.).\nEach new token is added to the sequence of tokens that the model uses to predict the next token.\n\n\n\\[ P(w_{w+1} | w_1, w_2, ..., w_t) \\]\n\nSequence of words is called the context.\n\n Generated text is dependent on the context.\n Every token is given an equal amount time (computation per token is constant)."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#tokenization",
    "href": "slides/busy-lecturers-guide.html#tokenization",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Tokenization",
    "text": "Tokenization\nLLMs operate with tokens, not words. These are sub-words, and make working with text much easier for the model. A rule of thumb is that one token generally corresponds to ~4 characters of English text. This translates to roughly \\(\\frac{3}{4}\\) of a word (so 100 tokens is about 75 words).\n\nFeel free to try out the OpenAI tokenizer."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#embeddings",
    "href": "slides/busy-lecturers-guide.html#embeddings",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Embeddings",
    "text": "Embeddings\n\nThe next step is to represent tokens as vectors.\nThis is called “embedding” the tokens. The vectors are high-dimensional, and the distance between vectors measures the similarity between tokens.\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this 2-dimensional representation, concepts that are “related” lie close together. Read about embeddings in this tutorial."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#training-data",
    "href": "slides/busy-lecturers-guide.html#training-data",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Training data",
    "text": "Training data\n\n\nFigure courtesy of Andrej Karpathy"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#training-process",
    "href": "slides/busy-lecturers-guide.html#training-process",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Training process",
    "text": "Training process\n\n\nFigure courtesy of Andrej Karpathy"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#emergent-abilities",
    "href": "slides/busy-lecturers-guide.html#emergent-abilities",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Emergent abilities",
    "text": "Emergent abilities\nLLMs are thought to show emergent abilities - abilities not explicitly taught. Instead, they emerge as a result of text prediction.\nAbilities include:\n\nperforming arithmetic, answering questions, summarizing text, translating, etc.\nzero-shot learning: LLMs can perform tasks without being trained on them.\nfew-shot learning: LLMs can perform tasks with few examples."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#emergent-abilities-1",
    "href": "slides/busy-lecturers-guide.html#emergent-abilities-1",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Emergent abilities",
    "text": "Emergent abilities\nWhat kind of knowledge does an LLM have to have to be able to write a continuation of the following text?1\n\n\n\n\n\n: How many holes does a straw have?\n: A straw has one hole. It’s a cylindrical tunnel that runs through the entire length, creating a single continuous space from one end to the other.\n: What about a tunnel?\n: Similar to a straw, a tunnel can also be considered to have one hole. It’s an elongated pathway carved through an obstruction, allowing passage from one side to the other, thus creating a single continuous space or hole through the material.\n\n\n\n\n\n\n\nContinue this conversation with ChatGPT."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#instruction-fine-tuning",
    "href": "slides/busy-lecturers-guide.html#instruction-fine-tuning",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Instruction fine-tuning",
    "text": "Instruction fine-tuning"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#reinforcement-learning-from-human-feedback-rlhf",
    "href": "slides/busy-lecturers-guide.html#reinforcement-learning-from-human-feedback-rlhf",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Reinforcement learning from human feedback (RLHF)",
    "text": "Reinforcement learning from human feedback (RLHF)"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#how-do-chatbots-actually-work",
    "href": "slides/busy-lecturers-guide.html#how-do-chatbots-actually-work",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "How do chatbots actually work?",
    "text": "How do chatbots actually work?"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#an-llm-is-a-role-play-simulator",
    "href": "slides/busy-lecturers-guide.html#an-llm-is-a-role-play-simulator",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "An LLM is a role-play simulator",
    "text": "An LLM is a role-play simulator\n\n\n\n\n\n\n\nWe can think of an LLM as a non-deterministic simulator capable of role-playing an infinity of characters, or, to put it another way, capable of stochastically generating an infinity of simulacra (Shanahan, McDonell, and Reynolds 2023)"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#an-llm-is-a-role-play-simulator-1",
    "href": "slides/busy-lecturers-guide.html#an-llm-is-a-role-play-simulator-1",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "An LLM is a role-play simulator",
    "text": "An LLM is a role-play simulator\n\nAn assistant is trained to respond to user prompts in a human-like way.\nA simulator of possible human conversation.\nHas no intentions. It is not an entity with its own goals.\nDoes not have a “personality” or “character” in the traditional sense. It can be thought of as a role-playing simulator.\nHas no concept of “truth” or “lying”. The model is not trying to deceive the user, it is simply trying to respond in a human-like way."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#stochastic-generation",
    "href": "slides/busy-lecturers-guide.html#stochastic-generation",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Stochastic generation",
    "text": "Stochastic generation"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#knowledge-base",
    "href": "slides/busy-lecturers-guide.html#knowledge-base",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Knowledge base",
    "text": "Knowledge base\n\n\n\nA knowledge base is a collection of facts about the world.\nI can ask (retrieve) and tell (store) facts."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#can-an-llm-tell-the-truth",
    "href": "slides/busy-lecturers-guide.html#can-an-llm-tell-the-truth",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Can an LLM tell the truth?",
    "text": "Can an LLM tell the truth?\n\nHow would you know if an LLM is able to give you factual information?\nHow would you test this?\n\n\n\n\n: What is the capital of Uzbekistan?\n: Tashkent\n\n\n\nIt looks like the LLM knows the capital of Uzbekistan1.\nWhat it is actually doing is responding with the most likely sequence following the question."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#confirmation-bias",
    "href": "slides/busy-lecturers-guide.html#confirmation-bias",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Confirmation bias",
    "text": "Confirmation bias\n\nPeople tend to search for evidence consistent with their current beliefs."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#are-llms-knowledge-bases",
    "href": "slides/busy-lecturers-guide.html#are-llms-knowledge-bases",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Are LLMs knowledge bases?",
    "text": "Are LLMs knowledge bases?\n\n\n\n\n\nI can ask but the response is not verifiable.\nI can’t tell, i.e. can’t store new information (expensive/difficult to update with new knowledge).\nLLM can’t tell me where it got its information from.\nLLMs are models of knowledge bases, but not knowledge bases themselves."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#how-do-humans-think",
    "href": "slides/busy-lecturers-guide.html#how-do-humans-think",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "How do humans think?",
    "text": "How do humans think?\nE.g. physical reasoning\n\n\n\n\n\nBattaglia, Hamrick, and Tenenbaum (2013)\n\n\n\n\n\n\nGerstenberg (2022)"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#what-is-a-prompt",
    "href": "slides/busy-lecturers-guide.html#what-is-a-prompt",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "What is a prompt?",
    "text": "What is a prompt?\n\nRemember: the goal of an LLM is complete text.\nA prompt is a piece of text (instruction) that is given to a language model to complete.\n\n\n\n\nPROMPT : Write a haiku about a workshop on large language models.\nASSISTANT : Whispers of circuits,\nKnowledge blooms in bytes and bits,\nModel learns and fits.\n\n\n\n\nThe response is generated as continuation of the prompt.\n\n\nMore technical definition: The output is generated by auto-regressively sampling from the probability distribution over the vocabulary, conditioned on the prompt."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#unlocking-knowledge",
    "href": "slides/busy-lecturers-guide.html#unlocking-knowledge",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Unlocking knowledge",
    "text": "Unlocking knowledge\n\n\n\n\n\nLLMs learn to do things they were not explicitly trained to do. \nOften, these capabilities need to be “unlocked” by the right prompt. \n\n\n\nWhat is the right prompt?\nThe answer is very similar to what you would tell a human dialogue partner/assistant.\nYou can increase the probability of getting the desired output by asking good questions or giving enough information."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#basics-of-prompting",
    "href": "slides/busy-lecturers-guide.html#basics-of-prompting",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Basics of prompting",
    "text": "Basics of prompting\nOpenAI give a set of strategies for using their models effectively:\n Prompt engineering\nThese include:\n\nwriting clear instructions\nproviding reference texts\nsplitting tasks into subtasks\ngiving the LLM ‘time to think’\nusing external tools"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#writing-clear-instructions",
    "href": "slides/busy-lecturers-guide.html#writing-clear-instructions",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Writing clear instructions",
    "text": "Writing clear instructions\n\n\n\nThink of an LLM as a role-playing conversation simulator.\nInstructions should be clear and unambiguous.\nIndicate which role the model (persona) should adopt.\n\n\n\n\n\n\nInclude details in your query to get more relevant answers\nAsk the model to adopt a persona\nUse delimiters to clearly indicate distinct parts of the input\nSpecify the steps required to complete a task\nProvide examples\nSpecify the desired length of the output"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#adopt-a-persona-role",
    "href": "slides/busy-lecturers-guide.html#adopt-a-persona-role",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Adopt a persona (role)",
    "text": "Adopt a persona (role)\n\n\n\n: You are an expert on learning techniques. Explain the concept of ‘flipped classroom’ in one paragraph.\n\n\n\n\n\n\n: You are an expert financial derivatives. Explain the concept of ‘flipped classroom’ in one paragraph."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#provide-reference-texts",
    "href": "slides/busy-lecturers-guide.html#provide-reference-texts",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Provide reference texts",
    "text": "Provide reference texts\n\nProvide a model with trusted and relevant information.\nThen instruct the model to use the provided information to compose its answer.\n\n Instruct the model to answer using a reference text\n\n\nThis leads to retrieval-augmented generation (RAG). First create a database of documents, then retrieve the most relevant documents, based on a user’s query. These are then included in the prompt to the model. The model is instructed to use the information in the documents to compose its answer."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#provide-reference-texts-1",
    "href": "slides/busy-lecturers-guide.html#provide-reference-texts-1",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Provide reference texts",
    "text": "Provide reference texts\n\n\n\n: You will be provided with a document delimited by triple quotes and a question. Your task is to provide a simplified answer to the question using only the provided document and to cite the passage(s) of the document used to answer the question. If the document does not contain the information needed to answer this question then simply write: “Insufficient information.” If an answer to the question is provided, it must be annotated with a citation. Use the following format for to cite relevant passages ({“citation”: …}). Cite only the relevant passage(s) of the document, not the entire document.\n““” The flipped classroom intentionally shifts instruction to a learner-centered model, in which students are often initially introduced to new topics outside of school, freeing up classroom time for the exploration of topics in greater depth, creating meaningful learning opportunities. With a flipped classroom, ‘content delivery’ may take a variety of forms, often featuring video lessons prepared by the teacher or third parties, although online collaborative discussions, digital research, and text readings may alternatively be used. The ideal length for a video lesson is widely cited as eight to twelve minutes. ““”\nQuestion: What is flipped classroom?"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#giving-gpt-time-to-think",
    "href": "slides/busy-lecturers-guide.html#giving-gpt-time-to-think",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Giving GPT ‘time to think’",
    "text": "Giving GPT ‘time to think’\n\nLLMs generate text one word at a time–the model spends the same amount of computation on each word.\nGiving the model more context gives it more steps to “think”.\nThis increases the chances that the model will give a good answer.\nThis technique is known as chain-of-thought prompting, and can often be induced by simply instructing the model to think step-by-step or Take a deep breath and work on this problem step-by-step (Yang et al. 2023)."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#chain-of-thought-prompting",
    "href": "slides/busy-lecturers-guide.html#chain-of-thought-prompting",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Chain-of-thought prompting",
    "text": "Chain-of-thought prompting\n\nChain-of-thought prompting encourages the LLM to “explain” its intermediate reasoning steps.\nEnables complex reasoning and problem solving.\n\nInstead of this:\n\n\n\n: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1. Yes or no?\n\n\n\nDo this:\n\n\n\n: Is this statement correct? The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\nReason through the problem step-by-step. Start by identifying the odd numbers. Next, add them up. Finally, determine if the sum is even or odd. Write down your reasoning steps in a numbered list.\n\n\n\n\nWhy does this work?"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#zero-shot-chain-of-thought-prompting",
    "href": "slides/busy-lecturers-guide.html#zero-shot-chain-of-thought-prompting",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Zero-shot chain-of-thought prompting",
    "text": "Zero-shot chain-of-thought prompting\n\n\n\n: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1. Take a deep breath and think step-by-step.\n\n\n\n\n\nWhen using GPT-4, ChatGPT and Copilot do this automatically."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#use-markdown-formatting",
    "href": "slides/busy-lecturers-guide.html#use-markdown-formatting",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Use Markdown formatting",
    "text": "Use Markdown formatting\n\nUse Markdown to format your prompts.\nInstruct the LLM to format its output using Markdown.\n\n\n\n\n: Improve this haiku:\nWords weave through the air,\nMinds meld with machine’s deep thought,\nKnowledge blooms anew.\nIt is about about a workshop on large language models. I’m not happy with it.\nShow me all the text. Format your edits as **TEXT** and show the deleted text as ~~TEXT~~. Keep you review short (max 100 words).\n\n\n\nTry this example in ChatGPT."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#advanced-prompting-techniques",
    "href": "slides/busy-lecturers-guide.html#advanced-prompting-techniques",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Advanced prompting techniques",
    "text": "Advanced prompting techniques\nFor more advanced prompting techniques, see these websites:\n\n Learn prompting\n Prompting guide\n OpenAI cookbook\n\nand explore this activity."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#retrieval-augmented-generation-rag",
    "href": "slides/busy-lecturers-guide.html#retrieval-augmented-generation-rag",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Retrieval-augmented generation (RAG)",
    "text": "Retrieval-augmented generation (RAG)\n\n\nFigure courtesy of Pinecone"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#web-search",
    "href": "slides/busy-lecturers-guide.html#web-search",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Web search",
    "text": "Web search\n\nSimilar to retrieval-augmented generation, but with web search.\nLLMs can be instructed to use web search to find information.\nCopilot does this automatically - ChatGPT (paid version only) can be instructed to do this."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#external-tools",
    "href": "slides/busy-lecturers-guide.html#external-tools",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "External tools",
    "text": "External tools\n\nLLMs can be instructed to use external tools to complete tasks.\nFor example, an LLM can be instructed to use a calculator to perform arithmetic.\nOpenAI calls this approach function calling."
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#multi-agent-conversations",
    "href": "slides/busy-lecturers-guide.html#multi-agent-conversations",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Multi-agent conversations",
    "text": "Multi-agent conversations\n\n\n\n\n\n DEMO: haiku writing team"
  },
  {
    "objectID": "slides/busy-lecturers-guide.html#local-models",
    "href": "slides/busy-lecturers-guide.html#local-models",
    "title": "The busy lecturer’s guide to LLMs",
    "section": "Local models",
    "text": "Local models\n\nDownload and run models, such as e.g. Llama 2 or Code Llama, locally.\nOllama\nLM Studio\n\nHardware requirements:\n\nApple Silicon Mac (M1/M2/M3) / Windows / Linux\n16GB+ of RAM is recommended\nNVIDIA/AMD GPUs supported"
  },
  {
    "objectID": "slides/demo.html#chart-1",
    "href": "slides/demo.html#chart-1",
    "title": "Introduction",
    "section": "Chart 1",
    "text": "Chart 1\n\n\n\n\n\nsequenceDiagram\n  participant Alice\n  participant Bob\n  Alice-&gt;&gt;John: Hello John, how are you?\n  loop Healthcheck\n    John-&gt;&gt;John: Fight against hypochondria\n  end\n  Note right of John: Rational thoughts &lt;br/&gt;prevail!\n  John--&gt;&gt;Alice: Great!\n  John-&gt;&gt;Bob: How about you?\n  Bob--&gt;&gt;John: Jolly good!"
  },
  {
    "objectID": "slides/demo.html#chart-2",
    "href": "slides/demo.html#chart-2",
    "title": "Introduction",
    "section": "Chart 2",
    "text": "Chart 2"
  },
  {
    "objectID": "slides/demo.html#getting-up",
    "href": "slides/demo.html#getting-up",
    "title": "Introduction",
    "section": "Getting up",
    "text": "Getting up\n\nTurn off alarm\nGet out of bed"
  },
  {
    "objectID": "slides/demo.html#breakfast",
    "href": "slides/demo.html#breakfast",
    "title": "Introduction",
    "section": "Breakfast",
    "text": "Breakfast\n\nEat eggs\nDrink coffee"
  },
  {
    "objectID": "slides/demo.html#in-the-evening",
    "href": "slides/demo.html#in-the-evening",
    "title": "Introduction",
    "section": "In the evening",
    "text": "In the evening"
  },
  {
    "objectID": "slides/demo.html#dinner",
    "href": "slides/demo.html#dinner",
    "title": "Introduction",
    "section": "Dinner",
    "text": "Dinner\n\nEat spaghetti\nDrink wine"
  },
  {
    "objectID": "slides/demo.html#going-to-sleep",
    "href": "slides/demo.html#going-to-sleep",
    "title": "Introduction",
    "section": "Going to sleep",
    "text": "Going to sleep\n\nGet in bed\nCount sheep"
  },
  {
    "objectID": "slides/demo.html#later",
    "href": "slides/demo.html#later",
    "title": "Introduction",
    "section": "Later",
    "text": "Later"
  },
  {
    "objectID": "slides/demo.html#two-columns",
    "href": "slides/demo.html#two-columns",
    "title": "Introduction",
    "section": "Two columns",
    "text": "Two columns\n\n\nLeft column\n\nRight column\n\n\n\n\n\nback to website ⤴️"
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#orientierungshilfe-für-lehrpersonen-der-bfh",
    "href": "slides/prompt-labor-vertiefung.html#orientierungshilfe-für-lehrpersonen-der-bfh",
    "title": "Prompt Labor: Vertiefung",
    "section": " Orientierungshilfe für Lehrpersonen der BFH",
    "text": "Orientierungshilfe für Lehrpersonen der BFH\n\n\n\n\nHaltung der BFH: Technologien, die den Lernprozess unterstützen und praxisrelevant sind, sollen in die Lehre einbezogen werden.\nEinsatz von KI in der Lehre: Die Mehrheit der Studierenden wird KI-Tools nutzen. Studierende sollen lernen, Technologien kompetent einzusetzen und kritisch zu hinterfragen.\n\n\n\n\n \n Knowledge Base der Virtuellen Akademie\n PDF"
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#competencies",
    "href": "slides/prompt-labor-vertiefung.html#competencies",
    "title": "Prompt Labor: Vertiefung",
    "section": "Competencies",
    "text": "Competencies"
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#deskilling-vs.-upskilling",
    "href": "slides/prompt-labor-vertiefung.html#deskilling-vs.-upskilling",
    "title": "Prompt Labor: Vertiefung",
    "section": "Deskilling vs. upskilling",
    "text": "Deskilling vs. upskilling"
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#effective-teaching-strategies",
    "href": "slides/prompt-labor-vertiefung.html#effective-teaching-strategies",
    "title": "Prompt Labor: Vertiefung",
    "section": "Effective teaching strategies",
    "text": "Effective teaching strategies\nMollick and Mollick (2023): 5 teaching strategies that are supported by research but difficult to apply in practice.\n\n\nProviding multiple examples and explanations.\nUncovering and addressing student misconceptions.\nFrequent low-stakes testing.\nAssessing student learning.\nDistributed practice."
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#providing-multiple-examples-and-explanations",
    "href": "slides/prompt-labor-vertiefung.html#providing-multiple-examples-and-explanations",
    "title": "Prompt Labor: Vertiefung",
    "section": "Providing multiple examples and explanations",
    "text": "Providing multiple examples and explanations\n\nExpose students to a variety of examples – single examples may lead students to focus on superficial details instead of the core concept.\nPromotes deeper understanding, assist in recalling information, stimulate critical thinking.\nVariety helps students generalize, enabling them to apply this learning in other contexts.\n\n Time constraints, need to consider factors like relevance, engagement, and the right level of detail."
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#tools",
    "href": "slides/prompt-labor-vertiefung.html#tools",
    "title": "Prompt Labor: Vertiefung",
    "section": "Tools",
    "text": "Tools\n\n Prompt engineering: guide LLMs to produce desired behaviour\n Design custom chatbots\n Retrieval-augmented generation (RAG)\n Multi-agent models"
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#prompt-engineering",
    "href": "slides/prompt-labor-vertiefung.html#prompt-engineering",
    "title": "Prompt Labor: Vertiefung",
    "section": " Prompt engineering",
    "text": "Prompt engineering"
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#basics-of-prompting",
    "href": "slides/prompt-labor-vertiefung.html#basics-of-prompting",
    "title": "Prompt Labor: Vertiefung",
    "section": "Basics of prompting",
    "text": "Basics of prompting\nOpenAI’s strategies for  using their models effectively.\nThese include:\n\nwriting clear instructions\nproviding reference texts\nsplitting tasks into subtasks\ngiving the LLM ‘time to think’\nusing external tools"
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#pros-and-cons",
    "href": "slides/prompt-labor-vertiefung.html#pros-and-cons",
    "title": "Prompt Labor: Vertiefung",
    "section": "Pros and cons",
    "text": "Pros and cons\n\n\n Can guide the LLM to produce the desired behaviour.\n Requires little technical expertise.\n\n May require trial and error to find the right prompt."
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#chatgpt-with-gpt-4o",
    "href": "slides/prompt-labor-vertiefung.html#chatgpt-with-gpt-4o",
    "title": "Prompt Labor: Vertiefung",
    "section": " ChatGPT with GPT-4o",
    "text": "ChatGPT with GPT-4o\n Introducing GPT-4o and more tools to ChatGPT free users\n\nMultimodal conversational agent\nWeb search\nUpload documents\nUse GPTs and the GPT Store"
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#ai-powered-virtual-tutor",
    "href": "slides/prompt-labor-vertiefung.html#ai-powered-virtual-tutor",
    "title": "Prompt Labor: Vertiefung",
    "section": " AI-powered virtual tutor",
    "text": "AI-powered virtual tutor\n Demo: Math problems with GPT-4o\n\nCreation of AI-powered virtual tutors or professors that can adapt to a student’s individual learning needs, based on a set of guidelines and content provided by the educational institution and the educator.\nVirtual tutors engage in natural language communication, both through voice and text, and maintain an adaptive capacity to evaluate and guide the student towards specific learning objectives. \nThis level of personalized attention could revolutionize the way we approach education, ensuring that each student receives the support they need to succeed."
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#custom-chatbots",
    "href": "slides/prompt-labor-vertiefung.html#custom-chatbots",
    "title": "Prompt Labor: Vertiefung",
    "section": " Custom chatbots",
    "text": "Custom chatbots\n\nCustom conversational agents for specific use cases.\n\n \n DEMO: Socratic mentor for reflective writing\n\nLTI integration with Moodle\nEmbedded within Moodle course\nUse Azure OpenAI (privacy concerns, hosted in CH)"
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#retrieval-augmented-generation",
    "href": "slides/prompt-labor-vertiefung.html#retrieval-augmented-generation",
    "title": "Prompt Labor: Vertiefung",
    "section": " Retrieval-augmented generation",
    "text": "Retrieval-augmented generation"
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#retrieval-augmented-generation-1",
    "href": "slides/prompt-labor-vertiefung.html#retrieval-augmented-generation-1",
    "title": "Prompt Labor: Vertiefung",
    "section": " Retrieval-augmented generation",
    "text": "Retrieval-augmented generation\n \n Open PDF Chatbot externally"
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#multi-agent-models",
    "href": "slides/prompt-labor-vertiefung.html#multi-agent-models",
    "title": "Prompt Labor: Vertiefung",
    "section": " Multi-agent models",
    "text": "Multi-agent models\n\n\n\n\nUse cases:\n\nFeedback for formative assessments\nEvaluation of essay grading (Hackl et al. 2023)"
  },
  {
    "objectID": "slides/prompt-labor-vertiefung.html#references",
    "href": "slides/prompt-labor-vertiefung.html#references",
    "title": "Prompt Labor: Vertiefung",
    "section": "References",
    "text": "References\n\n\nHackl, Veronika, Alexandra Elena Müller, Michael Granitzer, and Maximilian Sailer. 2023. “Is GPT-4 a Reliable Rater? Evaluating Consistency in GPT-4’s Text Ratings.” Frontiers in Education 8 (December). https://doi.org/10.3389/feduc.2023.1272229.\n\n\nMollick, Ethan R., and Lilach Mollick. 2023. “Using AI to Implement Effective Teaching Strategies in Classrooms: Five Strategies, Including Prompts.” SSRN Scholarly Paper. Rochester, NY. March 17, 2023. https://doi.org/10.2139/ssrn.4391243.\n\n\n\n\n\nback to website"
  },
  {
    "objectID": "slides/workshop-global-management.html#what-is-artifical-intelligence",
    "href": "slides/workshop-global-management.html#what-is-artifical-intelligence",
    "title": "Workshop: Global Management",
    "section": "What is Artifical Intelligence?",
    "text": "What is Artifical Intelligence?\n\n\n\n\nA branch of computer science that aims to create machines that can perform tasks that typically require human intelligence."
  },
  {
    "objectID": "slides/workshop-global-management.html#what-is-a-large-language-model",
    "href": "slides/workshop-global-management.html#what-is-a-large-language-model",
    "title": "Workshop: Global Management",
    "section": "What is a Large Language Model?",
    "text": "What is a Large Language Model?\n\n\n\n\nAn LLM is a type of generative AI model that is trained to predict the next word following the input (prompt)."
  },
  {
    "objectID": "slides/workshop-global-management.html#how-to-train-a-language-model",
    "href": "slides/workshop-global-management.html#how-to-train-a-language-model",
    "title": "Workshop: Global Management",
    "section": "How to train a language model",
    "text": "How to train a language model\n\nAn LLM learns to predict the next word in a sequence, given the previous words: \\[ P(word | context) \\]\nThink of as “fancy autocomplete” (but very very powerful and sopisticated)"
  },
  {
    "objectID": "slides/workshop-global-management.html#how-does-an-llm-generate-text",
    "href": "slides/workshop-global-management.html#how-does-an-llm-generate-text",
    "title": "Workshop: Global Management",
    "section": "How does an LLM generate text?",
    "text": "How does an LLM generate text?"
  },
  {
    "objectID": "slides/workshop-global-management.html#sampling",
    "href": "slides/workshop-global-management.html#sampling",
    "title": "Workshop: Global Management",
    "section": "Sampling",
    "text": "Sampling"
  },
  {
    "objectID": "slides/workshop-global-management.html#auto-regressive-generation",
    "href": "slides/workshop-global-management.html#auto-regressive-generation",
    "title": "Workshop: Global Management",
    "section": "Auto-regressive generation",
    "text": "Auto-regressive generation\nText is generated one word at a time (actually tokens, not words).\n\n\n\n\n\n Generated text depends on the generative model and the context.\n Every word (token) is given an equal amount time (computation per token is constant)."
  },
  {
    "objectID": "slides/workshop-global-management.html#auto-regressive-generation-1",
    "href": "slides/workshop-global-management.html#auto-regressive-generation-1",
    "title": "Workshop: Global Management",
    "section": "Auto-regressive generation",
    "text": "Auto-regressive generation"
  },
  {
    "objectID": "slides/workshop-global-management.html#foundation-models",
    "href": "slides/workshop-global-management.html#foundation-models",
    "title": "Workshop: Global Management",
    "section": "Foundation models",
    "text": "Foundation models\nA foundation model, or large language model (LLM):\n\nis a type of machine learning model that is trained to predict the next word following the input (prompt).\nis trained “simply” to predict the next word following a sequence of words.\ndoes not necessarily produce human-like conversations.\n\n\n\n\n: What is the capital of France?\n: What is the capital of Germany? What is the capital of Italy? . .."
  },
  {
    "objectID": "slides/workshop-global-management.html#training-process",
    "href": "slides/workshop-global-management.html#training-process",
    "title": "Workshop: Global Management",
    "section": "Training process",
    "text": "Training process\n\n\nFigure courtesy of Andrej Karpathy"
  },
  {
    "objectID": "slides/workshop-global-management.html#assistant-models",
    "href": "slides/workshop-global-management.html#assistant-models",
    "title": "Workshop: Global Management",
    "section": "Assistant models",
    "text": "Assistant models\nTrained (fine-tuned) to have conversations: turn-taking, question answering, not being rude/sexist/racist.\n\n\n\n\n\n\nFoundation model has learned to predict all kinds of text, including both desirable and undesirable text.\nFine-tuning narrows down the space of all possible output to only desirable, human-like dialogue.\nModel is aligned with the values of the fine-tuner."
  },
  {
    "objectID": "slides/workshop-global-management.html#how-do-chatbots-work",
    "href": "slides/workshop-global-management.html#how-do-chatbots-work",
    "title": "Workshop: Global Management",
    "section": "How do Chatbots work?",
    "text": "How do Chatbots work?\n\n\nDesigned to present the illusion of a conversation between two entities."
  },
  {
    "objectID": "slides/workshop-global-management.html#how-do-chatbots-actually-work",
    "href": "slides/workshop-global-management.html#how-do-chatbots-actually-work",
    "title": "Workshop: Global Management",
    "section": "How do chatbots actually work?",
    "text": "How do chatbots actually work?"
  },
  {
    "objectID": "slides/workshop-global-management.html#an-assistant-model-is-a-conversation-simulator",
    "href": "slides/workshop-global-management.html#an-assistant-model-is-a-conversation-simulator",
    "title": "Workshop: Global Management",
    "section": "An assistant model is a conversation simulator",
    "text": "An assistant model is a conversation simulator\n\n\n\n\n\nAn assistant is trained to respond to user prompts in a human-like way.\nSimulates possible human conversations.\nHas no intentions. It is not an entity with its own goals.\nDoes not have a “personality” or “character” in the traditional sense. It can be thought of as a role-playing simulator.\nHas no concept of “truth” or “lying”. The model is not trying to deceive the user, it is simply trying to respond in a human-like way."
  },
  {
    "objectID": "slides/workshop-global-management.html#capabilities-and-limitations",
    "href": "slides/workshop-global-management.html#capabilities-and-limitations",
    "title": "Workshop: Global Management",
    "section": "Capabilities and limitations",
    "text": "Capabilities and limitations\n\n\nWhat are LLMs good at?\n\nFixing grammar, bad writing, etc.\nRephrasing\nAnalyzing texts\nWriting computer code\nAnswering questions about a knowledge base\nTranslating languages\nCreating structured output\nFactual output with external documents or web search\n\n\nLimitations\n\nThey make stuff up (hallucinate)\nThey learn biases from the training data\nWeird vocabulary, e.g. delve\n(Chatbots have privacy issues)"
  },
  {
    "objectID": "slides/workshop-global-management.html#hallucination",
    "href": "slides/workshop-global-management.html#hallucination",
    "title": "Workshop: Global Management",
    "section": "Hallucination",
    "text": "Hallucination\n\n\n\n\n\nLLMs can generate text that is not true, or not based on any real-world knowledge.\nThis is known as “hallucination”. A better term would be “confabulation”."
  },
  {
    "objectID": "slides/workshop-global-management.html#can-an-llm-tell-the-truth",
    "href": "slides/workshop-global-management.html#can-an-llm-tell-the-truth",
    "title": "Workshop: Global Management",
    "section": "Can an LLM tell the truth?",
    "text": "Can an LLM tell the truth?\n\nHow would you know if an LLM is able to give you factual information?\nHow would you test this?\n\n\n\n\n: What is the capital of Uzbekistan?\n: Tashkent\n\n\n\nIt looks like the LLM knows the capital of Uzbekistan1.\nWhat it is actually doing is responding with the most likely sequence following the question."
  },
  {
    "objectID": "slides/workshop-global-management.html#knowledge-base",
    "href": "slides/workshop-global-management.html#knowledge-base",
    "title": "Workshop: Global Management",
    "section": "Knowledge base",
    "text": "Knowledge base\n\n\n\nA knowledge base is a collection of facts about the world.\n\nYou can ask (retrieve) and tell (store) facts.\n\nAn LLM is not a knowledge base.\n\nLLMs generate text based on on how probable the next word is given the context, not based on stored facts."
  },
  {
    "objectID": "slides/workshop-global-management.html#biases",
    "href": "slides/workshop-global-management.html#biases",
    "title": "Workshop: Global Management",
    "section": "Biases",
    "text": "Biases\n\n\n\n\n\n\n\n\nBiases in LLMs\nSource\nExamples\n\n\n\n\nTraining data bias\nText from internet, books, articles.\nStereotypes reflecting gender, race, religion.\n\n\nRepresentation bias\nUnderrepresented groups/perspectives in data.\nLess accurate responses for minority cultures.\n\n\nAlgorithmic bias\nTraining and fine-tuning algorithms.\nOptimizations for fluency and coherence may lead to preference for dominant cultural narratives.\n\n\nUser interaction bias\nAdaptation based on user interactions.\nIncreased biased or harmful content generation."
  },
  {
    "objectID": "slides/workshop-global-management.html#privacy-concerns",
    "href": "slides/workshop-global-management.html#privacy-concerns",
    "title": "Workshop: Global Management",
    "section": "Privacy concerns",
    "text": "Privacy concerns\n\n\n\n\n\n\n\n\nPrivacy Concerns\nIssue\nExamples\n\n\n\n\nData memorization\nMemorizing sensitive information.\nReproducing phone numbers, addresses.\n\n\nTraining data leakage\nUnauthorized dissemination of confidential data.\nSummarizing proprietary documents.\n\n\nUser query logging\nStoring sensitive user interactions.\nExposing private queries if data is mishandled.\n\n\nQueries used for training\nUser queries may be used for further training.\nPersonal data in queries could be inadvertently included in training data."
  },
  {
    "objectID": "slides/workshop-global-management.html#prompting",
    "href": "slides/workshop-global-management.html#prompting",
    "title": "Workshop: Global Management",
    "section": "Prompting",
    "text": "Prompting"
  },
  {
    "objectID": "slides/workshop-global-management.html#what-is-a-prompt",
    "href": "slides/workshop-global-management.html#what-is-a-prompt",
    "title": "Workshop: Global Management",
    "section": "What is a prompt?",
    "text": "What is a prompt?\n\nAn LLM’s task is to complete text.\nA prompt is a piece of text (instruction) that is given to a language model to complete.\n\n\n\n\nPROMPT : Write a haiku about a workshop on large language models.\nASSISTANT : Whispers of circuits,\nKnowledge blooms in bytes and bits,\nModel learns and fits.\n\n\n\n\nThe response is generated as continuation of, and conditioned on, the prompt.\n\n\nMore technical definition: The output is generated by auto-regressively sampling from the probability distribution over the vocabulary, conditioned on the prompt."
  },
  {
    "objectID": "slides/workshop-global-management.html#prompt-engineering",
    "href": "slides/workshop-global-management.html#prompt-engineering",
    "title": "Workshop: Global Management",
    "section": "Prompt engineering",
    "text": "Prompt engineering\n\n\n\n\n\nLLMs learn to do things they were not explicitly trained to do: translation, reasoning, etc. \nOften, these capabilities need to be “unlocked” by the right prompt. \n\n\n\nBut what is the right prompt?\nThe answer is very similar to what you would tell a human dialogue partner/assistant.\nYou can increase the probability of getting the desired output by providing context and examples."
  },
  {
    "objectID": "slides/workshop-global-management.html#basics-of-prompting",
    "href": "slides/workshop-global-management.html#basics-of-prompting",
    "title": "Workshop: Global Management",
    "section": "Basics of prompting",
    "text": "Basics of prompting\nOpenAI give a set of strategies for using their models effectively:\n Prompt engineering\nThese include:\n\nwriting clear instructions\nproviding reference texts\nsplitting tasks into subtasks\ngiving the LLM ‘time to think’\nusing external tools"
  },
  {
    "objectID": "slides/workshop-global-management.html#writing-clear-instructions",
    "href": "slides/workshop-global-management.html#writing-clear-instructions",
    "title": "Workshop: Global Management",
    "section": "Writing clear instructions",
    "text": "Writing clear instructions\n\n\n\nInstructions should be clear and unambiguous.\nThink of an LLM as a role-playing conversation simulator: Indicate which role the model (persona) should adopt.\n\n\n\n\n\n\nInclude details in your query to get more relevant answers\nAsk the model to adopt a persona\nUse delimiters to clearly indicate distinct parts of the input\nSpecify the steps required to complete a task\nProvide examples\nSpecify the desired length of the output"
  },
  {
    "objectID": "slides/workshop-global-management.html#adopt-a-persona-role",
    "href": "slides/workshop-global-management.html#adopt-a-persona-role",
    "title": "Workshop: Global Management",
    "section": "Adopt a persona (role)",
    "text": "Adopt a persona (role)\n\n\n\n: You are an expert on learning techniques. Explain the concept of ‘flipped classroom’ in one paragraph.\n\n\n\n\n\n\n: You are an expert financial derivatives. Explain the concept of ‘flipped classroom’ in one paragraph."
  },
  {
    "objectID": "slides/workshop-global-management.html#provide-reference-texts",
    "href": "slides/workshop-global-management.html#provide-reference-texts",
    "title": "Workshop: Global Management",
    "section": "Provide reference texts",
    "text": "Provide reference texts\n\nProvide a model with trusted and relevant information.\nThen instruct the model to use the provided information to compose its answer.\n\n Instruct the model to answer using a reference text\n\n\n\nThis can be extended to retrieval-augmented generation (RAG). First create a database of documents, then retrieve the most relevant documents, based on a user’s query. These are then included in the prompt to the model. The model is instructed to use the information in the documents to compose its answer."
  },
  {
    "objectID": "slides/workshop-global-management.html#create-structured-output",
    "href": "slides/workshop-global-management.html#create-structured-output",
    "title": "Workshop: Global Management",
    "section": "Create structured output",
    "text": "Create structured output\n\nExplanation: Instruct the model to generate structured output.\nE.g. provide a table, a list, a diagram, etc.\nUse delimiters to indicate distinct parts of the input.\nExample: Extract information from a text and present it in a table."
  },
  {
    "objectID": "slides/workshop-global-management.html#structured-prompting-techniques",
    "href": "slides/workshop-global-management.html#structured-prompting-techniques",
    "title": "Workshop: Global Management",
    "section": "Structured prompting techniques",
    "text": "Structured prompting techniques\n\nIn-Context Learning: Provide examples within the prompt.\nThought Generation: Instruct the model to think step-by-step.\nDecomposition Techniques: Break down tasks into subtasks.\n\n(Schulhoff et al. 2024)"
  },
  {
    "objectID": "slides/workshop-global-management.html#in-context-learning",
    "href": "slides/workshop-global-management.html#in-context-learning",
    "title": "Workshop: Global Management",
    "section": "In-Context learning",
    "text": "In-Context learning\n\nExplanation: Providing examples or context within the prompt itself.\nFew-shot prompting: Give a few examples.\n\nExample: Translate the following sentences:\n\nEnglish: ‘What time is it?’ -&gt; French: ‘Quelle heure est-il?’\nEnglish: ‘Where is the library?’ -&gt; French:\n\n\nZero-shot prompting: No examples, relies on pre-trained knowledge.\n\nExample: Translate the following sentence…"
  },
  {
    "objectID": "slides/workshop-global-management.html#thought-generation",
    "href": "slides/workshop-global-management.html#thought-generation",
    "title": "Workshop: Global Management",
    "section": "Thought generation",
    "text": "Thought generation\n\nExplanation: Encourages the model to show its reasoning process.\nChain-of-Thought (CoT) prompting: encourages the LLM to “explain” its intermediate reasoning steps.\nCan often be induced by simply instructing the model to think step-by-step or Take a deep breath and work on this problem step-by-step (Yang et al. 2023)."
  },
  {
    "objectID": "slides/workshop-global-management.html#chain-of-thought-example",
    "href": "slides/workshop-global-management.html#chain-of-thought-example",
    "title": "Workshop: Global Management",
    "section": "Chain-of-Thought example",
    "text": "Chain-of-Thought example\nInstead of this:\n\n\n\n: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1. Yes or no?\n\n\n\nDo this:\n\n\n\n: Is this statement correct? The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\nReason through the problem step-by-step. Start by identifying the odd numbers. Next, add them up. Finally, determine if the sum is even or odd. Write down your reasoning steps in a numbered list.\n\n\n\n\nWhy does this work?"
  },
  {
    "objectID": "slides/workshop-global-management.html#decomposition-techniques",
    "href": "slides/workshop-global-management.html#decomposition-techniques",
    "title": "Workshop: Global Management",
    "section": "Decomposition techniques",
    "text": "Decomposition techniques\n\nExplanation: Force the LLM to break down complex tasks into manageable subtasks.\nLeast-to-Most Prompting: Start simple, increase complexity.\n\nExample: List items, calculate cost…\n\nPlan-and-Solve Prompting: Separate planning and execution phases.\n\nExample: Understand the problem, devise a plan…"
  },
  {
    "objectID": "slides/workshop-global-management.html#hands-on-practice-prompting",
    "href": "slides/workshop-global-management.html#hands-on-practice-prompting",
    "title": "Workshop: Global Management",
    "section": "Hands-on practice: Prompting",
    "text": "Hands-on practice: Prompting\n Open this activity.\n\nPractice writing prompts for different tasks ( 20 minutes).\nWrite an essay using an LLM, and then critique someone else’s essay ( 30 minutes).\n\n  If you need further help with prompting techniques, see these websites:\n\n Learn prompting\n Prompting guide\n OpenAI cookbook"
  },
  {
    "objectID": "slides/workshop-global-management.html#chatgpt-edu",
    "href": "slides/workshop-global-management.html#chatgpt-edu",
    "title": "Workshop: Global Management",
    "section": "ChatGPT Edu",
    "text": "ChatGPT Edu\n\n\n \n\n\n\n\nAccess to GPT-4o, excelling in text interpretation, coding, and mathematics\nData analytics, web browsing, and document summarization\nBuild GPTs, custom versions of ChatGPT, and share them within university workspaces\nSignificantly higher message limits than the free version of ChatGPT\nImproved language capabilities across quality and speed, with over 50 languages supported\nRobust security, data privacy, and administrative controls\nConversations and data are not used to train OpenAI models"
  },
  {
    "objectID": "slides/workshop-global-management.html#gpts",
    "href": "slides/workshop-global-management.html#gpts",
    "title": "Workshop: Global Management",
    "section": "GPTs",
    "text": "GPTs"
  },
  {
    "objectID": "slides/workshop-global-management.html#hands-on-practice-gpts",
    "href": "slides/workshop-global-management.html#hands-on-practice-gpts",
    "title": "Workshop: Global Management",
    "section": "Hands-on practice: GPTs",
    "text": "Hands-on practice: GPTs\n\nTry out custom GPTs from various categories in the GPT store.\nDiscuss with your neighbour\n\nDid you discover any useful GPTs?\nWhat are the benefits and limitations of using GPTs in the classroom?"
  },
  {
    "objectID": "slides/workshop-global-management.html#extended-cognition",
    "href": "slides/workshop-global-management.html#extended-cognition",
    "title": "Workshop: Global Management",
    "section": "Extended cognition",
    "text": "Extended cognition\n\n\n\nAccording to Clark and Chalmers (1998), cognitive processes may extend to external objects.\nKrakauer (2016) distinguishes between complementary and competitive cognitive artifacts.\n\nComplementary: numbers, abacus\nCompetetive: calculator, GPS\n\nWhat kind of artefact will AI turn out to be?"
  },
  {
    "objectID": "slides/workshop-global-management.html#deskilling-vs.-upskilling",
    "href": "slides/workshop-global-management.html#deskilling-vs.-upskilling",
    "title": "Workshop: Global Management",
    "section": "Deskilling vs. upskilling",
    "text": "Deskilling vs. upskilling"
  },
  {
    "objectID": "slides/workshop-global-management.html#writing-tasks-in-the-ai-era",
    "href": "slides/workshop-global-management.html#writing-tasks-in-the-ai-era",
    "title": "Workshop: Global Management",
    "section": "Writing tasks in the AI era",
    "text": "Writing tasks in the AI era\n\nWriting is a core skill: critical thinking, persuasion, argumentation, understanding.\nText creation is secondary in learning: focus is on underlying skills.\nLearning objectives: Benefits of writing tasks should be clearly and convincingly conveyed.\nStudents should be equipped for effective (controlled) use of AI."
  },
  {
    "objectID": "slides/workshop-global-management.html#ai-can-do-my-homework",
    "href": "slides/workshop-global-management.html#ai-can-do-my-homework",
    "title": "Workshop: Global Management",
    "section": "AI can do my homework",
    "text": "AI can do my homework\n\nWe can think of this as cheating.\nMore useful: cheating means bypassing useful cognition and therefore missing out on learning.\nCheating an ethics problem.\nBypassing cognition is a learning problem.\nNot a new problem: books, encyclopedias, calculators, spell checkers, etc."
  },
  {
    "objectID": "slides/workshop-global-management.html#controlled-use-of-llms",
    "href": "slides/workshop-global-management.html#controlled-use-of-llms",
    "title": "Workshop: Global Management",
    "section": "Controlled use of LLMs",
    "text": "Controlled use of LLMs\n\n\n\n\n\n\n\nTask Category\nSpecific Tasks\n\n\n\n\nEditing tasks\nCreate/improve different versions of sections.\n\n\nTransitions\nWrite and compare transitions.\n\n\nImprove drafts\nCritique and refine drafts.\n\n\nWriting styles\nRewrite sections for different audiences.\n\n\nControversial statements\nIdentify controversial points and strengthen arguments.\n\n\nResearch journal\nKeep a diary and use LLM for reflection."
  },
  {
    "objectID": "slides/workshop-global-management.html#sport-vs.-writing",
    "href": "slides/workshop-global-management.html#sport-vs.-writing",
    "title": "Workshop: Global Management",
    "section": "Sport vs. writing",
    "text": "Sport vs. writing\n\n\n\nTechnological advancements in sports: a useful analogy for learning?\nDistinction between training and competition.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLZR Racer swim suit\nAI-base writing tools\n\n\n\n\nImprovement\nReduced Resistance, Increased Buoyancy\nImproved Grammar, Formulation, Content Creation\n\n\nFairness\nProvided an Unfair Advantage, Led to Record Performances\nConsidered Unfair in Academic Contexts\n\n\nImpact\nBanned to Maintain Competitive Integrity\nRaises Questions of Originality and Skill Development"
  },
  {
    "objectID": "slides/workshop-global-management.html#understanding-the-value-of-effort",
    "href": "slides/workshop-global-management.html#understanding-the-value-of-effort",
    "title": "Workshop: Global Management",
    "section": "Understanding the value of effort",
    "text": "Understanding the value of effort\n\nCheating can be a symptom that learners do not understand or value the importance of their own work.\nJust like in sport: if we take shortcuts during training, we won’t get fit.\nUnderstanding the purpose is important to endure discomfort.\nLearners need to understand what they are supposed to learn, why it is valuable, and why effort and discomfort are necessary."
  },
  {
    "objectID": "slides/workshop-global-management.html#fraud-triangle",
    "href": "slides/workshop-global-management.html#fraud-triangle",
    "title": "Workshop: Global Management",
    "section": "Fraud triangle",
    "text": "Fraud triangle"
  },
  {
    "objectID": "slides/workshop-global-management.html#learning-environments-that-promote-cheating",
    "href": "slides/workshop-global-management.html#learning-environments-that-promote-cheating",
    "title": "Workshop: Global Management",
    "section": "Learning Environments that promote cheating",
    "text": "Learning Environments that promote cheating\n\n\n\n\n\n\n\nFactors\nDescriptions\n\n\n\n\nHigh pressure\nHigh stakes increase cheating. Fear of failure reinforces this.\n\n\nLack of intrinsic motivation\nEngagement and relevance are important. Lacking these makes cheating more attractive.\n\n\nPerceived injustice\nUnfair grading leads to cheating.\n\n\nLow fear of getting caught\nLow risk encourages cheating.\n\n\nPeer influence\nWidespread cheating among peers pressures students to join in.\n\n\nLow self-efficacy\nDoubts about one’s own abilities increase cheating as the seemingly only option."
  },
  {
    "objectID": "slides/workshop-global-management.html#strategies-to-reduce-cheating",
    "href": "slides/workshop-global-management.html#strategies-to-reduce-cheating",
    "title": "Workshop: Global Management",
    "section": "Strategies to Reduce Cheating",
    "text": "Strategies to Reduce Cheating\n\n\n\n\n\n\n\nStrategies\nDescriptions\n\n\n\n\nFoster intrinsic motivation\nSpark genuine interest. Provide choices and practical applications.\n\n\nMastery learning\nClear learning objectives. Focus on mastery of content. Include constructive and corrective feedback in formative assessments.\n\n\nReduce pressure\nDiversify assessment methods. Use portfolios and low-stress tests to reduce anxiety.\n\n\nStrengthen self-efficacy\nProvide constructive feedback and promote peer learning (peer tutoring, peer review).\n\n\nCreate a culture of integrity\nOpen discussion about academic integrity. Set clear guidelines and promote community ethics."
  },
  {
    "objectID": "slides/workshop-global-management.html#academic-integrity-plagiarism",
    "href": "slides/workshop-global-management.html#academic-integrity-plagiarism",
    "title": "Workshop: Global Management",
    "section": "Academic Integrity: Plagiarism",
    "text": "Academic Integrity: Plagiarism\n\n\n\n\n\n\n\nTypes of Plagiarism\nDescription\n\n\n\n\nUnattributed use\nUsing the work or ideas of others without proper attribution.\n\n\nMinor changes or translations\nUsing the work of others with minor changes or translations without attribution.\n\n\nSelf-plagiarism\nReusing substantial parts of one’s own work without proper citation.\n\n\nJoint works\nReusing jointly written publications without proper acknowledgment."
  },
  {
    "objectID": "slides/workshop-global-management.html#academic-integrity-misconduct-in-authorship",
    "href": "slides/workshop-global-management.html#academic-integrity-misconduct-in-authorship",
    "title": "Workshop: Global Management",
    "section": "Academic Integrity: Misconduct in authorship",
    "text": "Academic Integrity: Misconduct in authorship\n\n\n\n\n\n\n\nTypes of Plagiarism\nDescription\n\n\n\n\nUnattributed use\nUsing the work or ideas of others without proper attribution.\n\n\nMinor changes or translations\nUsing the work of others with minor changes or translations without attribution.\n\n\nSelf-plagiarism\nReusing substantial parts of one’s own work without proper citation.\n\n\nJoint works\nReusing jointly written publications without proper acknowledgment."
  },
  {
    "objectID": "slides/workshop-global-management.html#how-to-cite-chatgpt",
    "href": "slides/workshop-global-management.html#how-to-cite-chatgpt",
    "title": "Workshop: Global Management",
    "section": "How to cite ChatGPT",
    "text": "How to cite ChatGPT\nE.g. APA Style: Cite as software (not as personal communication)."
  },
  {
    "objectID": "slides/workshop-global-management.html#documentating-ai-use",
    "href": "slides/workshop-global-management.html#documentating-ai-use",
    "title": "Workshop: Global Management",
    "section": "Documentating AI use",
    "text": "Documentating AI use\n\nSpecifying prompts works well for inexperienced users, but inadequately reflects complex processes.\nExperienced users work with dialogues and several tools, not monolithic prompts in ChatGPT.\nWorking with copilot (code): no traceable prompt input.\nInstead: Document the process, including the tools used and the steps taken.\n\nInclude used tools and steps in appendix, with optional graphical representation.\nServes both evaluation and self-reflection.\n\nIs documentation meaningful in the long term, once the use of AI-based tools has become commonplace?"
  },
  {
    "objectID": "slides/workshop-global-management.html#detecting-ai-use",
    "href": "slides/workshop-global-management.html#detecting-ai-use",
    "title": "Workshop: Global Management",
    "section": "Detecting AI use",
    "text": "Detecting AI use\n\nCan be detected by the use of specific vocabulary and phrases: “delve”, “vibrant”, “embark”, “it’s important to note”, ” based on the data provided”.\nDetection tools are not very useful, and can be easily circumvented.\nAccording to Fleckenstein et al. (2024)\n\nGenerative AI can write papers that are undetectable.\nTeachers overestimate their detection abilities."
  },
  {
    "objectID": "pages/activity-global-management.html#general-tips",
    "href": "pages/activity-global-management.html#general-tips",
    "title": "Hands-On Practice: Prompting",
    "section": "General tips",
    "text": "General tips\nOpenAI give a set of  strategies for using their models. If you need examples, this might be a good place to start.\nThe strategies include:\n\nwriting clear instructions\nproviding reference texts\nsplitting tasks into subtasks\ngiving GPT ‘time to think’\nusing external tools\n\nSome general techniques are:\n\nNumbered Steps:: For sequential tasks, use numbered steps. This helps the model understand the sequence of actions.\nUse delimiters: To separate various parts of the prompt (e.g. \", `,, ', |, #, …).\nFew-shot prompting: Provide a few examples for guidance.\n\nCombining these techniques, a template prompt might look like this:\n\n\n\n\n\n\nTemplate\n\n\n\n\nRole: who is being simulated?\nTask: what is to be done?\nSteps: what are the steps to complete the task?\nContext: what is the context of the task?\nGoal: what is the goal of the task?\nFormat: what is the format of the output? How long should it be?\n\n\n\nRemember to structure your prompt in a way that is clear and easy to understand. You can use markdown to format your prompt, and you instruct the mode to format its response using markdown.\n\nExample\n\n\n\n\n\n\n Prompt:\n\n\n\nYou are an expert on the topic of university education and didactics. Explain the concept of “flipped classroom” to a group of teachers. Use markdown to format your response. Keep you explanation concise and to the point.\n\n\nDifferent persona:\n\n\n\n\n\n\n Prompt:\n\n\n\nYou are 13 year old high school student. Explain the concept of “flipped classroom” to your friends. Use markdown to format your response. Keep you explanation concise and to the point.\n\n\nAsk the model to output a table:\n\n\n\n\n\n\n Prompt:\n\n\n\nYou are a high school teacher. Give me a table containing Greek letters in one column, their pronunciation in the second column, and examples of usage in the third column. Give me a maximum of 6 rows."
  }
]